<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]
- [cs.CV](#cs.CV) [Total: 39]
- [cs.CR](#cs.CR) [Total: 11]
- [stat.ML](#stat.ML) [Total: 4]
- [math.ST](#math.ST) [Total: 5]
- [cs.LG](#cs.LG) [Total: 46]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems](https://arxiv.org/abs/2601.10738)
*Percy Jardine*

Main category: cs.AI

TL;DR: CTHA是一个约束性时间分层架构，通过结构化流形投影和仲裁机制解决多时间尺度智能体架构中的协调稳定性问题，显著减少故障级联并提升样本效率。


<details>
  <summary>Details</summary>
Motivation: 多时间尺度智能体架构虽然通过时间分层提升了性能，但破坏了统一智能体系统的协调稳定性，导致层间冲突、无界错误传播和可扩展性受限等问题。

Method: 提出约束性时间分层架构(CTHA)，通过三个关键约束：1)消息契约约束，通过类型化摘要、计划和策略包形式化层间信息流；2)权威流形约束，根据时间范围限制每层的决策空间；3)仲裁器解决约束，保证多层决策的无冲突组合。

Result: 实验表明CTHA在复杂任务执行中有效，相比无约束分层基线减少了47%的故障级联，提升了2.3倍的样本效率，并展现出优越的可扩展性。

Conclusion: CTHA作为时间分层架构的原则性扩展，有助于深入理解多智能体协调，并为鲁棒自主系统的演进提供了有前景的方向。

Abstract: Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.

</details>


### [2] [Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration](https://arxiv.org/abs/2601.10744)
*Sen Wang,Bangwei Liu,Zhenkun Gao,Lizhuang Ma,Xuhong Wang,Yuan Xie,Xin Tan*

Main category: cs.AI

TL;DR: 该论文提出LMEE框架和MemoryExplorer方法，通过强化学习微调多模态大语言模型，实现主动记忆查询和探索，以解决现有单次体现任务忽视探索过程和记忆利用的问题。


<details>
  <summary>Details</summary>
Motivation: 理想的体现智能体应具备终身学习能力来处理长视野复杂任务，但现有主流单次体现任务主要关注任务完成结果，忽视了探索过程和记忆利用的关键环节。

Method: 提出LMEE框架统一智能体的探索认知和决策行为，构建LMEE-Bench数据集和基准。提出MemoryExplorer方法，通过强化学习微调多模态大语言模型，采用包含动作预测、边界选择和问答的多任务奖励函数来鼓励主动记忆查询。

Result: 与最先进的体现探索模型相比，该方法在长视野体现任务中取得了显著优势，证明了主动记忆查询和探索的有效性。

Conclusion: 通过统一探索认知和决策行为，并采用强化学习驱动的主动记忆查询机制，能够显著提升体现智能体在长视野任务中的表现，为终身学习型体现智能体的发展提供了新思路。

Abstract: An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.

</details>


### [3] [Optimisation of complex product innovation processes based on trend models with three-valued logic](https://arxiv.org/abs/2601.10768)
*Nina Bočková,Barbora Volná,Mirko Dohnal*

Main category: cs.AI

TL;DR: 使用基于启发式规则的趋势模型分析复杂产品创新过程，通过简单趋势（增、减、恒）作为最小信息强度量化器，避免依赖数值或粗糙集


<details>
  <summary>Details</summary>
Motivation: 研究复杂产品创新过程需要简化的分析框架，避免传统数值方法的信息密集需求，寻求用最小信息强度量化器来理解和预测创新动态

Method: 基于启发式规则建立趋势模型，每个启发式用简单趋势（增加、减少、恒定）表达，定义解决方案为包含可能场景及其转换的集合，用转换图表示系统行为

Result: 提出了一种用转换图表示系统可能行为的框架，任何系统未来或过去行为都可以通过图中的路径描绘，为复杂产品创新过程提供了可视化分析工具

Conclusion: 趋势模型为分析复杂产品创新过程提供了有效的简化框架，使用最小信息强度量化器避免了传统数值方法的复杂性，转换图表示法使系统行为可视化分析成为可能

Abstract: This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.

</details>


### [4] [ARC Prize 2025: Technical Report](https://arxiv.org/abs/2601.10904)
*François Chollet,Mike Knoop,Gregory Kamradt,Bryan Landers*

Main category: cs.AI

TL;DR: ARC Prize 2025竞赛分析：ARC-AGI-2基准测试显示当前AI推理性能仍受知识覆盖限制，精炼循环成为关键方法，前沿AI实验室开始采用该基准，但存在基准污染问题。


<details>
  <summary>Details</summary>
Motivation: 分析ARC-AGI-2基准测试在2025年的发展状况，评估当前AI系统在少样本泛化和抽象推理方面的能力，探讨精炼循环方法的作用，并揭示知识依赖过拟合问题。

Method: 通过Kaggle竞赛数据分析（1455个团队，15154个提交）、90篇论文综述、前沿AI实验室模型卡评估，以及精炼循环方法的分类研究（进化程序合成和商业AI系统应用层优化）。

Result: ARC-AGI-2最高得分24%；精炼循环成为主导方法；前沿AI实验室开始将ARC-AGI作为行业标准基准；发现当前AI推理性能受知识覆盖限制，存在基准污染问题。

Conclusion: ARC-AGI已成为AI推理的行业标准基准，精炼循环是提升性能的关键方法，但当前AI系统仍存在知识依赖过拟合问题，ARC-AGI-3将引入交互式推理挑战以测试更全面的智能能力。

Abstract: The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.

</details>


### [5] [What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge](https://arxiv.org/abs/2601.10922)
*Yosub Shin,Michael Buriek,Boris Sobolev,Pavel Bushuyeu,Vikas Kumar,Haoyang Xu,Samuel Watson,Igor Molybog*

Main category: cs.AI

TL;DR: 该研究通过NeurIPS 2025 DCVLR挑战赛探讨多模态推理的数据策展，发现基于难度的样本选择是性能提升的主要驱动力，而数据集大小增加主要减少方差而非提升平均准确率


<details>
  <summary>Details</summary>
Motivation: 研究多模态推理中的数据策展问题，通过固定模型和训练协议的挑战赛设置来隔离数据集选择的影响，探索数据策展对多模态推理性能的关键因素

Method: 使用基于Walton多模态冷启动数据集的紧凑策展数据集，在DCVLR挑战赛框架下进行实验；赛后通过消融研究分析难度选择、数据集大小、多样性和合成增强等策略的效果

Result: 该提交在挑战赛中排名第一；消融研究表明：基于难度的样本选择是性能提升的主要驱动力；增加数据集大小主要减少运行间方差而非提升平均准确率；常用的多样性和合成增强启发式方法无额外益处且常降低性能

Conclusion: DCVLR是一个饱和状态评估，突出了对齐性和难度在数据高效多模态推理中的核心作用；数据策展应优先考虑样本难度而非单纯扩大规模或追求多样性

Abstract: We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.

</details>


### [6] [ReCreate: Reasoning and Creating Domain Agents Driven by Experience](https://arxiv.org/abs/2601.11100)
*Zhezheng Hao,Hong Wang,Jian Luo,Jianqing Zhang,Yuyan Zhou,Qiang Lin,Can Wang,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: ReCreate：一个基于经验的框架，用于自动创建领域智能体，通过分析交互历史来改进智能体设计，超越人工设计和现有自动生成方法


<details>
  <summary>Details</summary>
Motivation: 当前大多数实用智能体仍由人工设计，因为任务差异大且构建成本高。现有自动生成方法将智能体生成视为黑盒过程，仅依赖最终性能指标，忽略了成功/失败的关键证据且计算成本高。

Method: 提出ReCreate框架，采用智能体即优化器范式，包含三个核心组件：1) 经验存储与检索机制，用于按需检查；2) 推理-创建协同管道，将执行经验映射为脚手架编辑；3) 分层更新，将实例级细节抽象为可重用的领域模式。

Result: 在多个领域的实验中，ReCreate始终优于人工设计的智能体和现有自动智能体生成方法，即使从最小种子脚手架开始也能取得良好效果。

Conclusion: ReCreate通过系统利用智能体交互历史中的具体信号，成功解决了自动创建和适应领域智能体的挑战，为智能体生成提供了更高效、更智能的解决方案。

Abstract: Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.

</details>


### [7] [Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems](https://arxiv.org/abs/2601.11147)
*Zixu Wang,Bingbing Xu,Yige Yuan,Huawei Shen,Xueqi Cheng*

Main category: cs.AI

TL;DR: SCALE框架通过任务级工作流生成和自预测评估，在保持性能的同时大幅降低多智能体系统的令牌消耗


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的多智能体系统在任务级或查询级生成工作流，但两者的相对成本和效益不明确，且基于执行的评估方法令牌成本高且不可靠

Method: 提出SCALE框架：通过少量样本校准的自预测优化器进行任务级工作流生成，替代昂贵的完整验证执行

Result: SCALE在多个数据集上仅比现有方法平均性能下降0.61%，同时将总体令牌使用量减少高达83%

Conclusion: 查询级工作流生成并非总是必要，任务级工作流结合低成本评估方法可在保持性能的同时显著降低计算成本

Abstract: Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \textbf{SCALE}, which means \underline{\textbf{S}}elf prediction of the optimizer with few shot \underline{\textbf{CAL}}ibration for \underline{\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\%.

</details>


### [8] [TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech](https://arxiv.org/abs/2601.11178)
*Girish A. Koushik,Helen Treharne,Diptesh Kanojia*

Main category: cs.AI

TL;DR: TANDEM是一个统一框架，将视听仇恨检测从二元分类任务转化为结构化推理问题，通过串联强化学习实现跨模态上下文优化，显著提升目标识别和时间定位性能。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体长格式多模态内容中，有害叙事通过音频、视觉和文本线索的复杂交互构建。现有自动化系统虽然能高精度标记仇恨言论，但作为"黑箱"无法提供细粒度、可解释的证据（如精确时间戳和目标身份），难以支持有效的人机协同审核。

Method: 提出TANDEM框架，采用新颖的串联强化学习策略，让视觉-语言和音频-语言模型通过自约束的跨模态上下文相互优化，在无需密集帧级监督的情况下稳定处理长时间序列的推理。

Result: 在三个基准数据集上的实验表明，TANDEM显著优于零样本和上下文增强基线，在HateMM数据集上目标识别F1达到0.73（比最先进方法提升30%），同时保持精确的时间定位。二元检测稳健，但在多类别设置中区分冒犯性和仇恨内容仍具挑战性。

Conclusion: 即使在复杂多模态环境中，结构化、可解释的对齐也是可实现的，为下一代透明且可操作的在线安全审核工具提供了蓝图。该方法将检测从二元分类转化为结构化推理问题，增强了可解释性和实用性。

Abstract: Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as "black boxes" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.

</details>


### [9] [XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making](https://arxiv.org/abs/2601.11286)
*Weihong Qi,Fan Huang,Rasika Muralidharan,Jisun An,Haewoon Kwak*

Main category: cs.AI

TL;DR: XChoice是一个可解释的框架，用于评估约束决策中AI与人类的对齐性，通过机制建模而非表面结果匹配来诊断错位。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要关注结果一致性（如准确率、F1分数），但缺乏对决策机制的理解。需要一种能够揭示AI与人类在决策因素重要性、约束敏感性和权衡取舍方面差异的可解释框架。

Method: XChoice框架将基于机制的决策模型拟合到人类数据和LLM生成的决策中，恢复可解释参数（决策因素相对重要性、约束敏感性、隐含权衡）。通过比较这些参数向量来评估对齐性，并在美国时间使用调查数据上进行验证，进行不变性分析和RAG干预评估。

Result: 在美国人日常时间分配研究中，XChoice揭示了模型与活动之间的异质性对齐，以及黑人和已婚群体中显著的错位集中现象。框架通过不变性分析验证了鲁棒性，并通过RAG干预展示了针对性缓解效果。

Conclusion: XChoice提供了基于机制的度量标准，能够诊断AI与人类的错位，并支持超越表面结果匹配的知情改进，为约束决策中的对齐评估提供了可解释框架。

Abstract: We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.

</details>


### [10] [AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems](https://arxiv.org/abs/2601.11354)
*Weiyi Wang,Xinchi Chen,Jingjing Gong,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: AstroReason-Bench是一个用于评估智能体在空间规划问题中规划能力的基准测试，该基准整合了多种调度机制，发现当前智能体在现实约束下表现显著低于专用求解器。


<details>
  <summary>Details</summary>
Motivation: 现有智能体基准主要关注符号化或弱接地环境，缺乏对物理约束现实世界领域性能的充分探索，特别是在具有异构目标、严格物理约束和长时程决策的高风险空间规划问题中。

Method: 引入AstroReason-Bench基准，整合地面站通信和敏捷地球观测等多种调度机制，提供统一的智能体导向交互协议，并在多种最先进的开放和闭源智能体LLM系统上进行评估。

Result: 当前智能体在现实约束下的表现显著低于专用求解器，突显了通用规划器在现实约束下的关键局限性。

Conclusion: AstroReason-Bench为未来智能体研究提供了一个具有挑战性和诊断性的测试平台，有助于推动智能体在物理约束现实世界领域的发展。

Abstract: Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.

</details>


### [11] [Hyperparameter Optimization of Constraint Programming Solvers](https://arxiv.org/abs/2601.11389)
*Hedieh Haddad,Thibault Falque,Pierre Talbot,Pascal Bouvry*

Main category: cs.AI

TL;DR: 提出"探测与求解"两阶段框架，用于约束规划求解器的自动超参数优化，通过贝叶斯优化显著提升求解性能


<details>
  <summary>Details</summary>
Motivation: 约束规划求解器的性能对超参数配置高度敏感，手动寻找最佳配置需要专家知识且耗时费力，需要自动化方法来优化求解器配置

Method: 提出"探测与求解"两阶段框架：1) 探测阶段使用可配置的超参数优化方法探索不同参数集；2) 求解阶段使用找到的最佳配置在剩余时间内解决问题。在CPMpy库中实现并比较了贝叶斯优化和汉明距离搜索两种方法

Result: 贝叶斯优化方法显著优于默认配置：ACE求解器在25.4%的实例中性能提升，57.9%持平；Choco求解器在38.6%的实例中表现更优。贝叶斯优化也始终优于汉明距离搜索，证明了基于模型的探索优于简单局部搜索

Conclusion: "探测与求解"算法提供了一种实用、资源感知的约束求解器调优方法，能够在多种问题类型上实现稳健的性能改进，贝叶斯优化是该框架中更有效的超参数优化策略

Abstract: The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.
  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.
  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.

</details>


### [12] [Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs](https://arxiv.org/abs/2601.11468)
*Alessandro Padella,Massimiliano de Leoni,Marlon Dumas*

Main category: cs.AI

TL;DR: 本文扩展了基于LLM的预测性流程监控框架，从仅预测总时间扩展到评估其通用性、语义利用和推理机制，并在多个关键绩效指标上进行测试，证明在数据稀缺场景下LLM优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 预测性流程监控旨在预测正在进行的流程结果，传统方法使用机器学习和深度学习。本文旨在扩展先前基于LLM的预测性流程监控框架，该框架最初仅通过提示进行总时间预测，现在需要全面评估其通用性、语义利用和推理机制，并扩展到多个关键绩效指标。

Method: 扩展了基于LLM的预测性流程监控框架，从单一的总时间预测扩展到多个关键绩效指标（包括总时间和活动发生预测）。在三个不同的事件日志上进行实证评估，特别关注数据稀缺场景（仅100条轨迹）。通过实验分析LLM如何利用其先验知识和训练轨迹间的内部相关性，并检查模型使用的推理策略。

Result: 在数据稀缺设置（仅100条轨迹）下，LLM在总时间和活动发生预测这两个关键绩效指标上超越了基准方法。实验表明LLM同时利用了其先验知识和训练轨迹间的内部相关性。分析显示LLM并非简单复制现有预测方法，而是执行高阶推理来生成预测。

Conclusion: 基于LLM的预测性流程监控框架在数据稀缺场景下表现出色，能够有效利用语义信息和进行高阶推理，在多个关键绩效指标上优于传统方法，展示了LLM在流程预测任务中的潜力和优势。

Abstract: Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.

</details>


### [13] [Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning](https://arxiv.org/abs/2601.11479)
*Yohai Trabelsi,Guojun Xiong,Fentabil Getnet,Stéphane Verguet,Milind Tambe*

Main category: cs.AI

TL;DR: 提出LEG框架，结合可证明的近似算法与LLM驱动的迭代优化，在资源有限条件下优先升级埃塞俄比亚卫生站，最大化人口覆盖并整合专家定性指导


<details>
  <summary>Details</summary>
Motivation: 埃塞俄比亚卫生部升级卫生站以改善基本医疗服务可及性，但资源有限需要优先排序。传统优化方法需要明确量化目标，而利益相关者的标准通常用自然语言表达难以形式化，需要桥接专家知识与优化技术

Method: 开发LEG（大语言模型与扩展贪心）框架：结合用于人口覆盖优化的可证明近似算法与LLM驱动的迭代优化，通过人机对齐确保解决方案反映专家定性指导同时保持覆盖保证

Result: 在埃塞俄比亚三个地区的真实数据实验中验证了框架的有效性，展示了其支持公平、数据驱动的卫生系统规划的潜力

Conclusion: LEG框架成功整合专家知识与优化技术，为资源有限条件下卫生设施升级的优先排序提供了系统方法，平衡了定量覆盖目标与定性专家指导

Abstract: Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [14] [ICONIC-444: A 3.1-Million-Image Dataset for OOD Detection Research](https://arxiv.org/abs/2601.10802)
*Gerhard Krumpl,Henning Avenhaus,Horst Possegger*

Main category: cs.CV

TL;DR: ICONIC-444是一个专门用于OOD检测研究的大规模工业图像数据集，包含超过310万张RGB图像和444个类别，旨在解决现有数据集在OOD检测研究中的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前OOD检测研究的进展受到缺乏大规模、高质量数据集的限制，这些数据集需要具有明确定义的OOD类别（从近OOD到远OOD），并支持细粒度和粗粒度的计算机视觉任务。

Method: 使用原型工业分拣机采集数据，构建了包含超过310万张RGB图像、涵盖444个类别的ICONIC-444数据集。该数据集模拟真实世界任务，并定义了四个参考任务来基准测试OOD检测方法。

Result: 提供了22种最先进的后处理OOD检测方法的基准结果，为OOD检测研究提供了结构化和多样化的数据支持，能够进行跨任务复杂度的严格OOD评估。

Conclusion: ICONIC-444通过提供专门为OOD检测研究设计的大规模工业图像数据集，解决了现有数据集的局限性，为OOD检测研究的基准测试和进展提供了重要资源。

Abstract: Current progress in out-of-distribution (OOD) detection is limited by the lack of large, high-quality datasets with clearly defined OOD categories across varying difficulty levels (near- to far-OOD) that support both fine- and coarse-grained computer vision tasks. To address this limitation, we introduce ICONIC-444 (Image Classification and OOD Detection with Numerous Intricate Complexities), a specialized large-scale industrial image dataset containing over 3.1 million RGB images spanning 444 classes tailored for OOD detection research. Captured with a prototype industrial sorting machine, ICONIC-444 closely mimics real-world tasks. It complements existing datasets by offering structured, diverse data suited for rigorous OOD evaluation across a spectrum of task complexities. We define four reference tasks within ICONIC-444 to benchmark and advance OOD detection research and provide baseline results for 22 state-of-the-art post-hoc OOD detection methods.

</details>


### [15] [Can Vision-Language Models Understand Construction Workers? An Exploratory Study](https://arxiv.org/abs/2601.10835)
*Hieu Bui,Nathaniel E. Chodosh,Arash Tavakoli*

Main category: cs.CV

TL;DR: 评估GPT-4o、Florence 2和LLaVa-1.5三种视觉语言模型在建筑工地图像中识别工人行为和情绪的性能，GPT-4o表现最佳但仍有改进空间


<details>
  <summary>Details</summary>
Motivation: 随着机器人技术在建筑工作流程中的集成，需要能够理解和响应人类行为以实现安全有效协作。视觉语言模型(VLMs)在视觉理解任务中显示出潜力，能够在缺乏领域特定训练数据的情况下识别人类行为，这在标注数据稀缺的建筑领域尤为重要，监测工人行为和情绪状态对安全和生产力至关重要。

Method: 使用包含1000张图像的数据集，标注了10个行为类别和10个情绪类别，评估三种领先的VLM模型(GPT-4o、Florence 2和LLaVa-1.5)的性能。通过标准化的推理流程和多种评估指标(包括F1分数和准确率)进行分析，并进行混淆矩阵分析以识别模型在语义相近类别上的混淆情况。

Result: GPT-4o在两个任务中均表现最佳：行为识别平均F1分数0.756、准确率0.799；情绪识别F1分数0.712、准确率0.773。Florence 2表现中等：行为F1分数0.497、情绪0.414。LLaVa-1.5表现最低：行为F1分数0.466、情绪0.461。混淆矩阵分析显示所有模型在语义相近类别(如团队协作与主管沟通)上都存在困难。

Conclusion: 通用视觉语言模型能够为建筑环境中的人类行为识别提供基础能力，但需要进一步改进(如领域适应、时序建模或多模态感知)才能达到实际应用的可靠性要求。模型在区分语义相近类别方面存在挑战，表明需要更精细的建模方法。

Abstract: As robotics become increasingly integrated into construction workflows, their ability to interpret and respond to human behavior will be essential for enabling safe and effective collaboration. Vision-Language Models (VLMs) have emerged as a promising tool for visual understanding tasks and offer the potential to recognize human behaviors without extensive domain-specific training. This capability makes them particularly appealing in the construction domain, where labeled data is scarce and monitoring worker actions and emotional states is critical for safety and productivity. In this study, we evaluate the performance of three leading VLMs, GPT-4o, Florence 2, and LLaVa-1.5, in detecting construction worker actions and emotions from static site images. Using a curated dataset of 1,000 images annotated across ten action and ten emotion categories, we assess each model's outputs through standardized inference pipelines and multiple evaluation metrics. GPT-4o consistently achieved the highest scores across both tasks, with an average F1-score of 0.756 and accuracy of 0.799 in action recognition, and an F1-score of 0.712 and accuracy of 0.773 in emotion recognition. Florence 2 performed moderately, with F1-scores of 0.497 for action and 0.414 for emotion, while LLaVa-1.5 showed the lowest overall performance, with F1-scores of 0.466 for action and 0.461 for emotion. Confusion matrix analyses revealed that all models struggled to distinguish semantically close categories, such as collaborating in teams versus communicating with supervisors. While the results indicate that general-purpose VLMs can offer a baseline capability for human behavior recognition in construction environments, further improvements, such as domain adaptation, temporal modeling, or multimodal sensing, may be needed for real-world reliability.

</details>


### [16] [One Model, Many Behaviors: Training-Induced Effects on Out-of-Distribution Detection](https://arxiv.org/abs/2601.10836)
*Gerhard Krumpl,Henning Avenhaus,Horst Possegger*

Main category: cs.CV

TL;DR: 研究发现ID准确率与OOD检测性能呈非单调关系：初始随准确率提升而改善，但当训练方法将准确率推至基线以上时反而下降，且训练策略、检测器选择和OOD性能之间存在强相互依赖。


<details>
  <summary>Details</summary>
Motivation: 尽管OOD检测方法不断进步，但其与最大化ID准确率和泛化能力的现代训练流程之间的相互作用尚未充分探索。本文旨在通过实证研究揭示这一关联。

Method: 采用ResNet-50架构，对通过不同训练策略获得的56个ImageNet训练模型，评估21种后处理、最先进的OOD检测方法，并在8个OOD测试集上进行基准测试。

Result: 发现ID准确率与OOD检测性能呈非单调关系：初始随准确率提升而改善，但当高级训练方法将准确率推至基线以上时反而下降。同时观察到训练策略、检测器选择和OOD性能之间的强相互依赖，表明没有单一方法具有普适最优性。

Conclusion: OOD检测性能与ID准确率并非简单的正相关关系，而是受训练策略和检测器选择的复杂相互作用影响。这挑战了"更高ID准确率意味着更好OOD检测"的常见假设，强调了为特定训练流程选择适当OOD检测方法的重要性。

Abstract: Out-of-distribution (OOD) detection is crucial for deploying robust and reliable machine-learning systems in open-world settings. Despite steady advances in OOD detectors, their interplay with modern training pipelines that maximize in-distribution (ID) accuracy and generalization remains under-explored. We investigate this link through a comprehensive empirical study. Fixing the architecture to the widely adopted ResNet-50, we benchmark 21 post-hoc, state-of-the-art OOD detection methods across 56 ImageNet-trained models obtained via diverse training strategies and evaluate them on eight OOD test sets. Contrary to the common assumption that higher ID accuracy implies better OOD detection performance, we uncover a non-monotonic relationship: OOD performance initially improves with accuracy but declines once advanced training recipes push accuracy beyond the baseline. Moreover, we observe a strong interdependence between training strategy, detector choice, and resulting OOD performance, indicating that no single method is universally optimal.

</details>


### [17] [Effects of Different Attention Mechanisms Applied on 3D Models in Video Classification](https://arxiv.org/abs/2601.10854)
*Mohammad Rasras,Iuliana Marin,Serban Radu,Irina Mocanu*

Main category: cs.CV

TL;DR: 研究通过降低时间维度信息、增加帧分辨率，并引入多种注意力机制来改进3D ResNet动作识别模型，在UCF101上获得88.98%准确率


<details>
  <summary>Details</summary>
Motivation: 探索在减少时间数据捕获知识的同时增加帧分辨率对动作识别性能的影响，并研究不同注意力机制对受限时间模型的性能提升效果

Method: 1) 基于MC3、R3D和R(2+1)D三种3D ResNet模型创建带dropout的基准设计；2) 为每个基准设计开发10个变体，集成CBAM、TCN、多头注意力、通道注意力等机制；3) 在UCF101数据集上测试所有模型

Result: 在UCF101数据集上，改进的R(2+1)D模型结合多头注意力机制达到88.98%的最高准确率；不同变体在类别级准确率上表现各异，尽管整体性能提升相似

Conclusion: 时间特征的缺失对高分辨率模型的性能有显著影响，不同注意力机制对受限时间模型的性能提升效果不同，在类别级别上表现出差异性

Abstract: Human action recognition has become an important research focus in computer vision due to the wide range of applications where it is used. 3D Resnet-based CNN models, particularly MC3, R3D, and R(2+1)D, have different convolutional filters to extract spatiotemporal features. This paper investigates the impact of reducing the captured knowledge from temporal data, while increasing the resolution of the frames. To establish this experiment, we created similar designs to the three originals, but with a dropout layer added before the final classifier. Secondly, we then developed ten new versions for each one of these three designs. The variants include special attention blocks within their architecture, such as convolutional block attention module (CBAM), temporal convolution networks (TCN), in addition to multi-headed and channel attention mechanisms. The purpose behind that is to observe the extent of the influence each of these blocks has on performance for the restricted-temporal models. The results of testing all the models on UCF101 have shown accuracy of 88.98% for the variant with multiheaded attention added to the modified R(2+1)D. This paper concludes the significance of missing temporal features in the performance of the newly created increased resolution models. The variants had different behavior on class-level accuracy, despite the similarity of their enhancements to the overall performance.

</details>


### [18] [Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation](https://arxiv.org/abs/2601.10880)
*Chongcong Jiang,Tianxingjian Ding,Chuhan Song,Jiachen Tu,Ziyang Yan,Yihua Shao,Zhenyi Wang,Yuzhang Shang,Tianyu Han,Yu Tian*

Main category: cs.CV

TL;DR: Medical SAM3是基于SAM3的医学图像分割基础模型，通过在33个医学影像数据集上微调，解决了SAM3在医学图像分割中的领域偏移问题，实现了文本引导的通用医学图像分割。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM3等提示式分割基础模型在通用图像分割中表现出色，但在医学图像分割中存在严重局限性：领域偏移严重、缺乏空间提示、需要处理复杂的解剖结构和三维体积信息。原始SAM3在医学数据上性能显著下降，其竞争力主要依赖于强几何先验（如真实边界框），这促使需要进行全面的模型适应而非仅依赖提示工程。

Method: 通过在大规模、异构的2D和3D医学影像数据集上对SAM3进行完全微调，这些数据集包含配对的掩码分割和文本提示。使用了33个数据集，涵盖10种医学成像模态。该方法不仅进行提示工程，还对模型参数进行全面适应，使模型获得领域特定的表示能力，同时保留提示驱动的灵活性。

Result: 在器官、成像模态和维度上的广泛实验表明，Medical SAM3取得了显著且一致的性能提升，特别是在具有语义模糊性、复杂形态和长距离3D上下文等挑战性场景中。模型在医学图像分割任务上表现出强大的泛化能力，成为通用的文本引导分割基础模型。

Conclusion: Medical SAM3被确立为医学成像的通用文本引导分割基础模型，研究强调了在严重领域偏移下实现稳健提示驱动分割需要全面的模型适应，而不仅仅是提示工程。代码和模型将开源。

Abstract: Promptable segmentation foundation models such as SAM3 have demonstrated strong generalization capabilities through interactive and concept-based prompting. However, their direct applicability to medical image segmentation remains limited by severe domain shifts, the absence of privileged spatial prompts, and the need to reason over complex anatomical and volumetric structures. Here we present Medical SAM3, a foundation model for universal prompt-driven medical image segmentation, obtained by fully fine-tuning SAM3 on large-scale, heterogeneous 2D and 3D medical imaging datasets with paired segmentation masks and text prompts. Through a systematic analysis of vanilla SAM3, we observe that its performance degrades substantially on medical data, with its apparent competitiveness largely relying on strong geometric priors such as ground-truth-derived bounding boxes. These findings motivate full model adaptation beyond prompt engineering alone. By fine-tuning SAM3's model parameters on 33 datasets spanning 10 medical imaging modalities, Medical SAM3 acquires robust domain-specific representations while preserving prompt-driven flexibility. Extensive experiments across organs, imaging modalities, and dimensionalities demonstrate consistent and significant performance gains, particularly in challenging scenarios characterized by semantic ambiguity, complex morphology, and long-range 3D context. Our results establish Medical SAM3 as a universal, text-guided segmentation foundation model for medical imaging and highlight the importance of holistic model adaptation for achieving robust prompt-driven segmentation under severe domain shift. Code and model will be made available at https://github.com/AIM-Research-Lab/Medical-SAM3.

</details>


### [19] [FrankenMotion: Part-level Human Motion Generation and Composition](https://arxiv.org/abs/2601.10909)
*Chuqiao Li,Xianghui Xie,Yong Cao,Andreas Geiger,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: 提出了FrankenMotion：首个具有原子级、时间感知的部分级文本标注的运动数据集，以及基于扩散的部分感知运动生成框架，实现了对身体部位和原子动作的时空控制。


<details>
  <summary>Details</summary>
Motivation: 现有文本到运动生成方法主要依赖序列级或动作级描述，缺乏细粒度的部分级运动标注，限制了单个身体部位的可控性。需要构建具有原子级、时间感知的部分级文本标注的数据集来解决这一问题。

Method: 1. 利用大语言模型的推理能力构建高质量运动数据集，提供原子级、时间感知的部分级文本标注；2. 提出基于扩散的部分感知运动生成框架FrankenMotion，每个身体部分由其自身的时间结构化文本提示引导；3. 实现空间（身体部位）和时间（原子动作）的双重控制。

Result: FrankenMotion在实验设置中优于所有先前经过调整和重新训练的基线模型，并且能够组合训练中未见过的运动。构建的数据集提供了异步且语义上不同的部分运动在细时间分辨率上的标注。

Conclusion: 这是首个提供原子级、时间感知的部分级运动标注的工作，并开发了能够实现空间和时间双重控制的运动生成模型。代码和数据集将在发表后公开。

Abstract: Human motion generation from text prompts has made remarkable progress in recent years. However, existing methods primarily rely on either sequence-level or action-level descriptions due to the absence of fine-grained, part-level motion annotations. This limits their controllability over individual body parts. In this work, we construct a high-quality motion dataset with atomic, temporally-aware part-level text annotations, leveraging the reasoning capabilities of large language models (LLMs). Unlike prior datasets that either provide synchronized part captions with fixed time segments or rely solely on global sequence labels, our dataset captures asynchronous and semantically distinct part movements at fine temporal resolution. Based on this dataset, we introduce a diffusion-based part-aware motion generation framework, namely FrankenMotion, where each body part is guided by its own temporally-structured textual prompt. This is, to our knowledge, the first work to provide atomic, temporally-aware part-level motion annotations and have a model that allows motion generation with both spatial (body part) and temporal (atomic action) control. Experiments demonstrate that FrankenMotion outperforms all previous baseline models adapted and retrained for our setting, and our model can compose motions unseen during training. Our code and dataset will be publicly available upon publication.

</details>


### [20] [Classification of Chest XRay Diseases through image processing and analysis techniques](https://arxiv.org/abs/2601.10913)
*Santiago Martínez Novoa,María Catalina Ibáñez,Lina Gómez Mesa,Jeremias Kramer*

Main category: cs.CV

TL;DR: 该研究对多分类胸部X光图像诊断方法进行了综述，测试了包括DenseNet121在内的多种方法，并开发了开源Web应用进行性能比较和评估。


<details>
  <summary>Details</summary>
Motivation: 胸部X光图像是诊断胸部疾病最常用的放射学检查方法之一，需要有效的多分类方法来自动化诊断过程，提高诊断效率和准确性。

Method: 研究综述了多种多分类胸部X光图像诊断方法，包括DenseNet121等深度学习模型，并开发了一个开源Web应用程序来部署和测试这些方法。

Result: 研究测试了不同方法的性能表现，分析了所提出方法的弱点，并提出了改进建议。所有代码已开源在GitHub上。

Conclusion: 该研究为胸部X光图像多分类诊断提供了方法综述和实用工具，指出了现有方法的局限性，并为未来改进提供了方向。

Abstract: Multi-Classification Chest X-Ray Images are one of the most prevalent forms of radiological examination used for diagnosing thoracic diseases. In this study, we offer a concise overview of several methods employed for tackling this task, including DenseNet121. In addition, we deploy an open-source web-based application. In our study, we conduct tests to compare different methods and see how well they work. We also look closely at the weaknesses of the methods we propose and suggest ideas for making them better in the future. Our code is available at: https://github.com/AML4206-MINE20242/Proyecto_AML

</details>


### [21] [RobuMTL: Enhancing Multi-Task Learning Robustness Against Weather Conditions](https://arxiv.org/abs/2601.10921)
*Tasneem Shaffee,Sherief Reda*

Main category: cs.CV

TL;DR: RobuMTL：一种用于自动驾驶系统的鲁棒多任务学习架构，通过动态选择任务特定的分层LoRA模块和LoRA专家小队来适应视觉退化，在恶劣天气条件下显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在真实环境中运行时，恶劣天气条件会严重降低模型性能和可靠性。现有的多任务学习方法在视觉退化情况下表现不佳，需要一种能够自适应处理输入扰动的鲁棒架构。

Method: 提出RobuMTL架构，采用混合专家模式，根据输入扰动动态选择任务特定的分层低秩适应（LoRA）模块和LoRA专家小队。该框架能够基于输入特征进行自适应专业化，提高在不同真实环境条件下的鲁棒性。

Result: 在PASCAL数据集上，相比MTL基线，RobuMTL在单一扰动下实现+2.8%的平均相对提升，在混合天气条件下提升高达+44.4%。在NYUD-v2数据集上，跨任务平均相对提升+9.7%。

Conclusion: RobuMTL通过动态选择分层LoRA模块和专家小队，有效提升了多任务学习在视觉退化条件下的鲁棒性，为自动驾驶系统在恶劣天气环境中的可靠运行提供了解决方案。

Abstract: Robust Multi-Task Learning (MTL) is crucial for autonomous systems operating in real-world environments, where adverse weather conditions can severely degrade model performance and reliability. In this paper, we introduce RobuMTL, a novel architecture designed to adaptively address visual degradation by dynamically selecting task-specific hierarchical Low-Rank Adaptation (LoRA) modules and a LoRA expert squad based on input perturbations in a mixture-of-experts fashion. Our framework enables adaptive specialization based on input characteristics, improving robustness across diverse real-world conditions. To validate our approach, we evaluated it on the PASCAL and NYUD-v2 datasets and compared it against single-task models, standard MTL baselines, and state-of-the-art methods. On the PASCAL benchmark, RobuMTL delivers a +2.8% average relative improvement under single perturbations and up to +44.4% under mixed weather conditions compared to the MTL baseline. On NYUD-v2, RobuMTL achieves a +9.7% average relative improvement across tasks. The code is available at GitHub.

</details>


### [22] [Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images](https://arxiv.org/abs/2601.10931)
*David Szczecina,Hudson Sun,Anthony Bertnyk,Niloofar Azad,Kyle Gao,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 该研究评估了五种深度学习架构在仅有150张标注图像的极端数据稀缺条件下进行树冠检测的性能，发现基于卷积的预训练模型（YOLOv11、Mask R-CNN）比基于Transformer的模型（DeepLabv3、Swin-UNet、DINOv2）泛化能力显著更好。


<details>
  <summary>Details</summary>
Motivation: 树冠检测对于环境监测、城市规划和生态系统分析至关重要。Solafune树冠检测竞赛模拟了真实世界数据标注稀缺的场景，仅提供150张标注图像的小型不平衡数据集，这对训练深度学习模型而不产生严重过拟合提出了重大挑战。

Method: 研究评估了五种代表性架构：YOLOv11、Mask R-CNN、DeepLabv3、Swin-UNet和DINOv2，以评估它们在极端数据稀缺条件下进行树冠分割的适用性。详细分析了训练策略、数据增强策略以及在小数据约束下的模型行为。

Result: 实验表明，基于卷积的预训练模型（特别是YOLOv11和Mask R-CNN）比基于Transformer的预训练模型泛化能力显著更好。DeepLabv3、Swin-UNet和DINOv2表现不佳，可能原因是语义分割与实例分割任务的差异、Vision Transformers的高数据需求以及缺乏强归纳偏置。

Conclusion: Transformer架构在缺乏大量预训练或数据增强的低数据环境下表现不佳，语义分割与实例分割的差异进一步影响模型性能。轻量级CNN方法在有限图像数据上进行树冠检测仍然是最可靠的。

Abstract: Tree canopy detection from aerial imagery is an important task for environmental monitoring, urban planning, and ecosystem analysis. Simulating real-life data annotation scarcity, the Solafune Tree Canopy Detection competition provides a small and imbalanced dataset of only 150 annotated images, posing significant challenges for training deep models without severe overfitting. In this work, we evaluate five representative architectures, YOLOv11, Mask R-CNN, DeepLabv3, Swin-UNet, and DINOv2, to assess their suitability for canopy segmentation under extreme data scarcity. Our experiments show that pretrained convolution-based models, particularly YOLOv11 and Mask R-CNN, generalize significantly better than pretrained transformer-based models. DeeplabV3, Swin-UNet and DINOv2 underperform likely due to differences between semantic and instance segmentation tasks, the high data requirements of Vision Transformers, and the lack of strong inductive biases. These findings confirm that transformer-based architectures struggle in low-data regimes without substantial pretraining or augmentation and that differences between semantic and instance segmentation further affect model performance. We provide a detailed analysis of training strategies, augmentation policies, and model behavior under the small-data constraint and demonstrate that lightweight CNN-based methods remain the most reliable for canopy detection on limited imagery.

</details>


### [23] [PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis](https://arxiv.org/abs/2601.10945)
*K Lokesh,Abhirama Subramanyam Penamakuri,Uday Agarwal,Apoorva Challa,Shreya K Gowda,Somesh Gupta,Anand Mishra*

Main category: cs.CV

TL;DR: 提出预咨询对话框架(PCDF)，通过两个视觉语言模型模拟真实诊断对话：DocVLM基于图像和对话历史生成后续问题，PatientVLM使用真实诊断的症状档案进行回答，生成的多轮咨询数据用于微调DocVLM，显著提升诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 传统AI医学诊断研究主要集中于图像分析，但缺乏患者报告的症状信息限制了诊断准确性。需要模拟真实世界诊断过程，医生通过迭代询问患者症状来做出诊断。

Method: 提出预咨询对话框架(PCDF)，使用两个视觉语言模型：DocVLM基于医学图像和对话历史生成后续诊断问题；PatientVLM使用基于真实诊断构建的症状档案进行回答。通过小规模临床验证合成症状的临床相关性，并利用生成的对话数据微调DocVLM。

Result: 临床验证显示合成症状具有临床相关性、症状覆盖度和整体真实性。基于对话的监督训练相比仅使用图像的训练带来显著性能提升，证明现实症状采集对诊断的价值。

Conclusion: PCDF框架通过模拟真实诊断对话生成高质量训练数据，结合症状采集的对话监督显著提升诊断准确性，为医学AI诊断提供了更接近临床实践的训练方法。

Abstract: Traditionally, AI research in medical diagnosis has largely centered on image analysis. While this has led to notable advancements, the absence of patient-reported symptoms continues to hinder diagnostic accuracy. To address this, we propose a Pre-Consultation Dialogue Framework (PCDF) that mimics real-world diagnostic procedures, where doctors iteratively query patients before reaching a conclusion. Specifically, we simulate diagnostic dialogues between two vision-language models (VLMs): a DocVLM, which generates follow-up questions based on the image and dialogue history, and a PatientVLM, which responds using a symptom profile derived from the ground-truth diagnosis. We additionally conducted a small-scale clinical validation of the synthetic symptoms generated by our framework, with licensed clinicians confirming their clinical relevance, symptom coverage, and overall realism. These findings indicate that the resulting DocVLM-PatientVLM interactions form coherent, multi-turn consultations paired with images and diagnoses, which we then use to fine-tune the DocVLM. This dialogue-based supervision leads to substantial gains over image-only training, highlighting the value of realistic symptom elicitation for diagnosis.

</details>


### [24] [IDDR-NGP: Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field](https://arxiv.org/abs/2601.11030)
*Xianliang Huang,Jiajie Gou,Shuhang Chen,Zhizhou Zhong,Jihong Guan,Shuigeng Zhou*

Main category: cs.CV

TL;DR: IDDR-NGP是首个统一的干扰物去除方法，可直接在Instant-NGP上操作，能够去除多种3D场景干扰物（雪花、彩纸、落叶、花瓣等），而现有方法通常只针对特定类型干扰物。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景干扰物去除方法通常只针对特定类型的干扰物（如雪花），缺乏统一的解决方案。同时，在隐式3D表示中去除多种干扰物的研究缺乏基准数据集支持。

Method: 将隐式3D表示与2D检测器结合，设计LPIPS损失和多视角补偿损失（MVCL）联合优化渲染结果，能够从多视角受损图像中聚合信息。所有组件可端到端训练以合成高质量3D场景。

Result: 构建了包含合成和真实世界干扰物的新基准数据集。实验证明IDDR-NGP在去除多种类型干扰物方面具有有效性和鲁棒性，与现有SOTA去雪方法结果相当，能准确去除真实和合成干扰物。

Conclusion: IDDR-NGP是首个统一的3D场景干扰物去除方法，通过结合隐式3D表示和2D检测器，能够有效去除多种类型的干扰物，为隐式3D表示中的干扰物去除研究提供了新的解决方案和基准数据集。

Abstract: This paper presents the first unified distractor removal method, named IDDR-NGP, which directly operates on Instant-NPG. The method is able to remove a wide range of distractors in 3D scenes, such as snowflakes, confetti, defoliation and petals, whereas existing methods usually focus on a specific type of distractors. By incorporating implicit 3D representations with 2D detectors, we demonstrate that it is possible to efficiently restore 3D scenes from multiple corrupted images. We design the learned perceptual image patch similarity~( LPIPS) loss and the multi-view compensation loss (MVCL) to jointly optimize the rendering results of IDDR-NGP, which could aggregate information from multi-view corrupted images. All of them can be trained in an end-to-end manner to synthesize high-quality 3D scenes. To support the research on distractors removal in implicit 3D representations, we build a new benchmark dataset that consists of both synthetic and real-world distractors. To validate the effectiveness and robustness of IDDR-NGP, we provide a wide range of distractors with corresponding annotated labels added to both realistic and synthetic scenes. Extensive experimental results demonstrate the effectiveness and robustness of IDDR-NGP in removing multiple types of distractors. In addition, our approach achieves results comparable with the existing SOTA desnow methods and is capable of accurately removing both realistic and synthetic distractors.

</details>


### [25] [Your One-Stop Solution for AI-Generated Video Detection](https://arxiv.org/abs/2601.11035)
*Long Ma,Zihao Xue,Yan Wang,Zhiyuan Yan,Jin Xu,Xiaorui Jiang,Haiyang Yu,Yong Liao,Zhen Bi*

Main category: cs.CV

TL;DR: AIGVDBench是一个全面的AI生成视频检测基准，包含31个最先进生成模型、44万+视频，对33个检测器进行1500+次评估，提出8个深度分析和4个新发现。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成视频检测领域存在两个关键限制：1) 数据集角度：现有数据集规模有限，使用过时或范围狭窄的生成模型，难以捕捉现代生成技术的多样性和快速演变；2) 基准角度：当前基准主要停留在数据集创建阶段，缺乏对基本问题和深度分析的系统性探索。

Method: 提出AIGVDBench基准，覆盖31个最先进的生成模型和超过44万个视频，对属于四个不同类别的33个现有检测器执行超过1500次评估。

Result: 通过大规模评估，提出了8个从多个角度进行的深度分析，并识别出4个新颖的发现，为未来研究提供了有价值的见解。

Conclusion: AIGVDBench为推进AI生成视频检测领域提供了坚实的基础，该基准已开源，旨在解决现有数据集和基准的局限性。

Abstract: Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones and necessitating reliable detection methods.
  However, two key limitations hinder the development of this field.
  \textbf{From the dataset perspective}, existing datasets are often limited in scale and constructed using outdated or narrowly scoped generative models, making it difficult to capture the diversity and rapid evolution of modern generative techniques. Moreover, the dataset construction process frequently prioritizes quantity over quality, neglecting essential aspects such as semantic diversity, scenario coverage, and technological representativeness.
  \textbf{From the benchmark perspective}, current benchmarks largely remain at the stage of dataset creation, leaving many fundamental issues and in-depth analysis yet to be systematically explored.
  Addressing this gap, we propose AIGVDBench, a benchmark designed to be comprehensive and representative, covering \textbf{31} state-of-the-art generation models and over \textbf{440,000} videos. By executing more than \textbf{1,500} evaluations on \textbf{33} existing detectors belonging to four distinct categories. This work presents \textbf{8 in-depth analyses} from multiple perspectives and identifies \textbf{4 novel findings} that offer valuable insights for future research. We hope this work provides a solid foundation for advancing the field of AI-generated video detection.
  Our benchmark is open-sourced at https://github.com/LongMa-2025/AIGVDBench.

</details>


### [26] [M3DDM+: An improved video outpainting by a modified masking strategy](https://arxiv.org/abs/2601.11048)
*Takuya Murakawa,Takumi Fukuzawa,Ning Ding,Toru Tamaki*

Main category: cs.CV

TL;DR: M3DDM+通过改进训练-推理的掩码策略一致性，解决了M3DDM在相机运动有限或外推区域较大时出现的空间模糊和时间不一致问题，显著提升了视频外推质量。


<details>
  <summary>Details</summary>
Motivation: M3DDM在计算效率方面表现良好，但在相机运动有限或外推区域较大的挑战性场景中，会出现明显的质量下降（空间模糊和时间不一致）。研究发现这是由于训练和推理阶段的掩码策略不匹配导致的：训练时使用随机的掩码方向和宽度，而推理时需要在整个视频中保持一致的定向外推。

Method: 提出M3DDM+方法，在训练阶段对所有帧应用统一的掩码方向和宽度，然后对预训练的M3DDM模型进行微调。这种方法解决了训练-推理不匹配问题，同时保持了计算效率。

Result: 实验表明，M3DDM+在信息有限的场景中显著提高了视觉保真度和时间一致性，同时保持了计算效率。代码已开源。

Conclusion: 通过统一训练和推理阶段的掩码策略，M3DDM+有效解决了M3DDM在挑战性场景中的质量下降问题，为视频外推任务提供了更鲁棒的解决方案。

Abstract: M3DDM provides a computationally efficient framework for video outpainting via latent diffusion modeling. However, it exhibits significant quality degradation -- manifested as spatial blur and temporal inconsistency -- under challenging scenarios characterized by limited camera motion or large outpainting regions, where inter-frame information is limited. We identify the cause as a training-inference mismatch in the masking strategy: M3DDM's training applies random mask directions and widths across frames, whereas inference requires consistent directional outpainting throughout the video. To address this, we propose M3DDM+, which applies uniform mask direction and width across all frames during training, followed by fine-tuning of the pretrained M3DDM model. Experiments demonstrate that M3DDM+ substantially improves visual fidelity and temporal coherence in information-limited scenarios while maintaining computational efficiency. The code is available at https://github.com/tamaki-lab/M3DDM-Plus.

</details>


### [27] [PhysRVG: Physics-Aware Unified Reinforcement Learning for Video Generative Models](https://arxiv.org/abs/2601.11087)
*Qiyuan Zhang,Biao Gong,Shuai Tan,Zheng Zhang,Yujun Shen,Xing Zhu,Yuyuan Li,Kelu Yao,Chunhua Shen,Changqing Zou*

Main category: cs.CV

TL;DR: 提出首个物理感知强化学习范式用于视频生成，通过Mimicry-Discovery Cycle框架在保持模型能力的同时强制执行物理碰撞规则


<details>
  <summary>Details</summary>
Motivation: 当前基于transformer的视频生成方法忽视物理原理，特别是在刚体运动渲染方面存在严重缺陷。虽然计算机图形学和物理模拟器能轻松建模碰撞，但现代预训练-微调范式在像素级全局去噪过程中丢弃了物体刚性的概念，限制了生成视频的物理真实性。

Method: 引入物理感知强化学习范式，直接在视频生成模型中强制执行物理碰撞规则。进一步扩展为统一框架Mimicry-Discovery Cycle（MDcycle），该框架允许大量微调同时完全保留模型利用物理基础反馈的能力。

Result: 构建了新的基准测试PhysRVGBench，并通过广泛的定性和定量实验验证了方法的有效性。

Conclusion: 提出的物理感知强化学习范式和MDcycle框架首次将物理规则直接集成到视频生成模型中，显著提升了生成视频的物理真实性和刚体运动准确性。

Abstract: Physical principles are fundamental to realistic visual simulation, but remain a significant oversight in transformer-based video generation. This gap highlights a critical limitation in rendering rigid body motion, a core tenet of classical mechanics. While computer graphics and physics-based simulators can easily model such collisions using Newton formulas, modern pretrain-finetune paradigms discard the concept of object rigidity during pixel-level global denoising. Even perfectly correct mathematical constraints are treated as suboptimal solutions (i.e., conditions) during model optimization in post-training, fundamentally limiting the physical realism of generated videos. Motivated by these considerations, we introduce, for the first time, a physics-aware reinforcement learning paradigm for video generation models that enforces physical collision rules directly in high-dimensional spaces, ensuring the physics knowledge is strictly applied rather than treated as conditions. Subsequently, we extend this paradigm to a unified framework, termed Mimicry-Discovery Cycle (MDcycle), which allows substantial fine-tuning while fully preserving the model's ability to leverage physics-grounded feedback. To validate our approach, we construct new benchmark PhysRVGBench and perform extensive qualitative and quantitative experiments to thoroughly assess its effectiveness.

</details>


### [28] [CoDance: An Unbind-Rebind Paradigm for Robust Multi-Subject Animation](https://arxiv.org/abs/2601.11096)
*Shuai Tan,Biao Gong,Ke Ma,Yutong Feng,Qiyuan Zhang,Yan Wang,Yujun Shen,Hengshuang Zhao*

Main category: cs.CV

TL;DR: CoDance提出了一种Unbind-Rebind框架，用于解决多角色图像动画中任意角色数量、类型和空间错位的问题，通过解绑空间绑定和重新绑定运动到目标角色来实现灵活的多主体渲染。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单人动画方面表现出色，但难以处理任意数量的角色、多样化的角色类型以及参考图像与驱动姿势之间的空间错位问题。这些限制源于过于刚性的空间绑定（强制姿势与参考之间的像素级对齐）以及无法将运动一致地重新绑定到目标角色。

Method: 提出CoDance框架，包含两个核心模块：1) Unbind模块：使用新颖的姿势偏移编码器，通过对姿势及其潜在特征引入随机扰动，打破姿势与参考之间的刚性空间绑定，学习位置无关的运动表示；2) Rebind模块：利用文本提示的语义指导和主体掩码的空间指导，将学习到的运动引导到目标角色。同时引入了新的多主体评估基准CoDanceBench。

Result: 在CoDanceBench和现有数据集上的大量实验表明，CoDance实现了最先进的性能，在多样化角色和空间布局上表现出显著的泛化能力。代码和权重将开源。

Conclusion: CoDance通过Unbind-Rebind框架成功解决了多角色动画中的关键挑战，能够处理任意角色数量、类型和空间配置，为灵活的多主体渲染提供了有效解决方案。

Abstract: Character image animation is gaining significant importance across various domains, driven by the demand for robust and flexible multi-subject rendering. While existing methods excel in single-person animation, they struggle to handle arbitrary subject counts, diverse character types, and spatial misalignment between the reference image and the driving poses. We attribute these limitations to an overly rigid spatial binding that forces strict pixel-wise alignment between the pose and reference, and an inability to consistently rebind motion to intended subjects. To address these challenges, we propose CoDance, a novel Unbind-Rebind framework that enables the animation of arbitrary subject counts, types, and spatial configurations conditioned on a single, potentially misaligned pose sequence. Specifically, the Unbind module employs a novel pose shift encoder to break the rigid spatial binding between the pose and the reference by introducing stochastic perturbations to both poses and their latent features, thereby compelling the model to learn a location-agnostic motion representation. To ensure precise control and subject association, we then devise a Rebind module, leveraging semantic guidance from text prompts and spatial guidance from subject masks to direct the learned motion to intended characters. Furthermore, to facilitate comprehensive evaluation, we introduce a new multi-subject CoDanceBench. Extensive experiments on CoDanceBench and existing datasets show that CoDance achieves SOTA performance, exhibiting remarkable generalization across diverse subjects and spatial layouts. The code and weights will be open-sourced.

</details>


### [29] [Graph Smoothing for Enhanced Local Geometry Learning in Point Cloud Analysis](https://arxiv.org/abs/2601.11102)
*Shangbo Yuan,Jie Xu,Ping Hu,Xiaofeng Zhu,Na Zhao*

Main category: cs.CV

TL;DR: 提出一种结合图平滑模块和增强局部几何学习模块的新方法，用于解决3D点云分析中图结构在边界点和连接区域的稀疏与噪声连接问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的方法在3D点云分析中能有效捕捉点间关系，但常因边界点稀疏连接和连接区域噪声连接导致次优图结构，影响分析性能。

Method: 提出两个核心模块：1) 图平滑模块优化图结构，减少不可靠稀疏和噪声连接的负面影响；2) 增强局部几何学习模块，基于优化后的图结构改进特征提取，包括基于特征向量的自适应几何描述符提取形状特征，以及通过圆柱坐标变换获取分布特征。

Result: 在真实世界数据集上的实验验证了该方法在多种点云学习任务（分类、部件分割、语义分割）中的有效性。

Conclusion: 通过集成图平滑和增强局部几何学习，该方法能有效解决传统图结构在边界点和连接区域的局限性，提升3D点云分析性能。

Abstract: Graph-based methods have proven to be effective in capturing relationships among points for 3D point cloud analysis. However, these methods often suffer from suboptimal graph structures, particularly due to sparse connections at boundary points and noisy connections in junction areas. To address these challenges, we propose a novel method that integrates a graph smoothing module with an enhanced local geometry learning module. Specifically, we identify the limitations of conventional graph structures, particularly in handling boundary points and junction areas. In response, we introduce a graph smoothing module designed to optimize the graph structure and minimize the negative impact of unreliable sparse and noisy connections. Based on the optimized graph structure, we improve the feature extract function with local geometry information. These include shape features derived from adaptive geometric descriptors based on eigenvectors and distribution features obtained through cylindrical coordinate transformation. Experimental results on real-world datasets validate the effectiveness of our method in various point cloud learning tasks, i.e., classification, part segmentation, and semantic segmentation.

</details>


### [30] [Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning](https://arxiv.org/abs/2601.11109)
*Shaofeng Yin,Jiaxin Ge,Zora Zhiruo Wang,Xiuyu Li,Michael J. Black,Trevor Darrell,Angjoo Kanazawa,Haiwen Feng*

Main category: cs.CV

TL;DR: VIGA是一个视觉逆向图形智能体，通过"编写-运行-渲染-比较-修订"的闭环流程，从空场景开始重建或编辑图形程序，实现了任务无关和模型无关的视觉逆向图形生成。


<details>
  <summary>Details</summary>
Motivation: 当前强大的视觉语言模型缺乏细粒度的空间和物理基础能力，无法一次性实现视觉逆向图形（将图像重建为可编辑的图形程序）。需要一种能够进行交错多模态推理的方法来弥合这一差距。

Method: VIGA采用闭环的"编写-运行-渲染-比较-修订"流程，结合技能库（交替生成器和验证器角色）和演化上下文记忆（包含计划、代码差异和渲染历史），支持长视野推理。

Result: 在BlenderGym上提升35.32%，SlideBench上提升117.17%，BlenderBench上提升124.70%。VIGA是任务无关的（无需辅助模块），涵盖3D重建、多步场景编辑、4D物理交互和2D文档编辑等任务，同时也是模型无关的（无需微调）。

Conclusion: VIGA通过交错多模态推理和闭环执行验证机制，有效解决了视觉逆向图形问题，为评估异构基础视觉语言模型提供了统一协议，并在多个基准测试中显著优于一次性基线方法。

Abstract: Vision-as-inverse-graphics, the concept of reconstructing an image as an editable graphics program is a long-standing goal of computer vision. Yet even strong VLMs aren't able to achieve this in one-shot as they lack fine-grained spatial and physical grounding capability. Our key insight is that closing this gap requires interleaved multimodal reasoning through iterative execution and verification. Stemming from this, we present VIGA (Vision-as-Inverse-Graphic Agent) that starts from an empty world and reconstructs or edits scenes through a closed-loop write-run-render-compare-revise procedure. To support long-horizon reasoning, VIGA combines (i) a skill library that alternates generator and verifier roles and (ii) an evolving context memory that contains plans, code diffs, and render history. VIGA is task-agnostic as it doesn't require auxiliary modules, covering a wide range of tasks such as 3D reconstruction, multi-step scene editing, 4D physical interaction, and 2D document editing, etc. Empirically, we found VIGA substantially improves one-shot baselines on BlenderGym (35.32%) and SlideBench (117.17%). Moreover, VIGA is also model-agnostic as it doesn't require finetuning, enabling a unified protocol to evaluate heterogeneous foundation VLMs. To better support this protocol, we introduce BlenderBench, a challenging benchmark that stress-tests interleaved multimodal reasoning with graphics engine, where VIGA improves by 124.70%.

</details>


### [31] [Democratizing planetary-scale analysis: An ultra-lightweight Earth embedding database for accurate and flexible global land monitoring](https://arxiv.org/abs/2601.11183)
*Shuang Chen,Jie Wang,Shuai Yuan,Jiayang Li,Yu Xia,Yuanhong Liao,Junbo Wei,Jincheng Yuan,Xiaoqing Xu,Xiaolin Zhu,Peng Zhu,Hongsheng Zhang,Yuyu Zhou,Haohuan Fu,Huabing Huang,Bin Chen,Fan Dai,Peng Gong*

Main category: cs.CV

TL;DR: ESD是一个超轻量级的30米全球地球嵌入数据库，通过将多传感器卫星观测数据压缩为信息密集的量化潜在向量，实现340倍数据压缩，使全球陆地表面单年数据仅需2.4TB，可在标准工作站上进行十年尺度全球分析。


<details>
  <summary>Details</summary>
Motivation: 卫星地球观测系统产生了海量数据，但全球尺度分析的计算和存储需求巨大，阻碍了行星尺度研究的广泛应用。需要解决这些技术障碍，使全球分析更加普及。

Method: 使用ESDNet架构和有限标量量化（FSQ），将Landsat系列（5、7、8、9）和MODIS Terra的多传感器观测数据转换为信息密集的量化潜在向量，将年度物候周期压缩为12个时间步长。

Result: 实现约340倍数据压缩，全球陆地表面单年数据仅需约2.4TB；重建保真度高（MAE：0.0130；RMSE：0.0179；CC：0.8543）；土地覆盖分类准确率达79.74%（优于原始数据融合的76.92%）。

Conclusion: ESD通过超轻量级嵌入数据库解决了全球地球观测数据分析的存储和计算瓶颈，为普及行星尺度研究和推进下一代地理空间人工智能提供了多功能基础。

Abstract: The rapid evolution of satellite-borne Earth Observation (EO) systems has revolutionized terrestrial monitoring, yielding petabyte-scale archives. However, the immense computational and storage requirements for global-scale analysis often preclude widespread use, hindering planetary-scale studies. To address these barriers, we present Embedded Seamless Data (ESD), an ultra-lightweight, 30-m global Earth embedding database spanning the 25-year period from 2000 to 2024. By transforming high-dimensional, multi-sensor observations from the Landsat series (5, 7, 8, and 9) and MODIS Terra into information-dense, quantized latent vectors, ESD distills essential geophysical and semantic features into a unified latent space. Utilizing the ESDNet architecture and Finite Scalar Quantization (FSQ), the dataset achieves a transformative ~340-fold reduction in data volume compared to raw archives. This compression allows the entire global land surface for a single year to be encapsulated within approximately 2.4 TB, enabling decadal-scale global analysis on standard local workstations. Rigorous validation demonstrates high reconstructive fidelity (MAE: 0.0130; RMSE: 0.0179; CC: 0.8543). By condensing the annual phenological cycle into 12 temporal steps, the embeddings provide inherent denoising and a semantically organized space that outperforms raw reflectance in land-cover classification, achieving 79.74% accuracy (vs. 76.92% for raw fusion). With robust few-shot learning capabilities and longitudinal consistency, ESD provides a versatile foundation for democratizing planetary-scale research and advancing next-generation geospatial artificial intelligence.

</details>


### [32] [ATATA: One Algorithm to Align Them All](https://arxiv.org/abs/2601.11194)
*Boyi Pang,Savva Ignatyev,Vladimir Ippolitov,Ramil Khafizov,Yurii Melnik,Oleg Voynov,Maksim Nakhodnov,Aibek Alanov,Xiaopeng Fan,Peter Wonka,Evgeny Burnaev*

Main category: cs.CV

TL;DR: 提出一种基于Rectified Flow模型的多模态联合推理算法，用于生成结构对齐的配对样本，相比现有方法计算更快、质量更高


<details>
  <summary>Details</summary>
Motivation: 现有方法在联合生成配对样本时存在不足：一些方法采用依赖生成过程但未从结构对齐角度考虑问题；使用Score Distillation Sampling的方法计算耗时、易出现模式崩溃且结果卡通化。需要一种能高效生成高质量结构对齐样本的新方法

Method: 提出基于Rectified Flow模型的联合传输方法，在样本空间的片段上进行联合传输，可在结构化潜在空间上构建，支持任意Rectified Flow模型。该方法从结构对齐视角解决联合生成问题，实现快速推理

Result: 在图像、视频和3D形状生成领域验证了方法的有效性，与基于编辑和联合推理的基线方法相比，生成的样本对具有高度结构对齐性和视觉质量。在图像和视频生成方面改进了现有技术水平，在3D生成方面达到可比质量的同时计算速度快数个数量级

Conclusion: 提出的基于Rectified Flow的联合传输方法能够高效生成高质量的结构对齐配对样本，在多个模态领域都表现出优越性能，特别是在计算效率方面有显著优势

Abstract: We suggest a new multi-modal algorithm for joint inference of paired structurally aligned samples with Rectified Flow models. While some existing methods propose a codependent generation process, they do not view the problem of joint generation from a structural alignment perspective. Recent work uses Score Distillation Sampling to generate aligned 3D models, but SDS is known to be time-consuming, prone to mode collapse, and often provides cartoonish results. By contrast, our suggested approach relies on the joint transport of a segment in the sample space, yielding faster computation at inference time. Our approach can be built on top of an arbitrary Rectified Flow model operating on the structured latent space. We show the applicability of our method to the domains of image, video, and 3D shape generation using state-of-the-art baselines and evaluate it against both editing-based and joint inference-based competing approaches. We demonstrate a high degree of structural alignment for the sample pairs obtained with our method and a high visual quality of the samples. Our method improves the state-of-the-art for image and video generation pipelines. For 3D generation, it is able to show comparable quality while working orders of magnitude faster.

</details>


### [33] [Bio-inspired fine-tuning for selective transfer learning in image classification](https://arxiv.org/abs/2601.11235)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CV

TL;DR: BioTune是一种基于进化优化的自适应微调技术，通过优化选择冻结层和调整未冻结层学习率来提升迁移学习效果，在多种图像分类数据集和CNN架构上表现优异。


<details>
  <summary>Details</summary>
Motivation: 深度学习在图像分析中依赖大量标注数据，迁移学习虽能缓解此问题，但源域与目标域之间的差异会阻碍有效迁移。现有方法在处理不同数据特性和分布变化时存在局限性。

Method: 提出BioTune技术，采用进化优化方法自适应地确定哪些层应该冻结，并为未冻结层调整学习率，从而优化预训练模型到新任务的迁移过程。

Result: 在九个图像分类数据集（包括自然图像和医学影像等专业领域）上评估，BioTune在准确性和效率方面均优于AutoRGN、LoRA等最先进的微调方法。在四种不同CNN架构上均取得最佳性能，展示了其灵活性。

Conclusion: BioTune通过进化优化实现自适应微调，有效解决了迁移学习中源域与目标域不匹配的问题，在多种数据集和模型架构上表现出优越的适应性和性能，为有限标注数据下的深度学习应用提供了有效解决方案。

Abstract: Deep learning has significantly advanced image analysis across diverse domains but often depends on large, annotated datasets for success. Transfer learning addresses this challenge by utilizing pre-trained models to tackle new tasks with limited labeled data. However, discrepancies between source and target domains can hinder effective transfer learning. We introduce BioTune, a novel adaptive fine-tuning technique utilizing evolutionary optimization. BioTune enhances transfer learning by optimally choosing which layers to freeze and adjusting learning rates for unfrozen layers. Through extensive evaluation on nine image classification datasets, spanning natural and specialized domains such as medical imaging, BioTune demonstrates superior accuracy and efficiency over state-of-the-art fine-tuning methods, including AutoRGN and LoRA, highlighting its adaptability to various data characteristics and distribution changes. Additionally, BioTune consistently achieves top performance across four different CNN architectures, underscoring its flexibility. Ablation studies provide valuable insights into the impact of BioTune's key components on overall performance. The source code is available at https://github.com/davilac/BioTune.

</details>


### [34] [Image-Text Knowledge Modeling for Unsupervised Multi-Scenario Person Re-Identification](https://arxiv.org/abs/2601.11243)
*Zhiqi Pang,Lingling Zhao,Yang Liu,Chunyu Wang,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出无监督多场景行人重识别任务及图像-文本知识建模框架，通过三阶段方法利用视觉语言模型跨多种场景提升性能


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别方法通常针对单一场景设计，缺乏跨多种场景（如跨分辨率、换装等）的统一框架。需要开发能够同时处理多种场景的无监督方法，利用视觉语言模型的表征能力。

Method: 提出三阶段图像-文本知识建模框架：1）在图像编码器中引入场景嵌入并微调；2）优化学习文本嵌入，使用多场景分离损失增加场景间文本表示差异；3）引入聚类级和实例级异构匹配模块获取可靠异构正对，并提出动态文本表示更新策略保持文本与图像监督信号一致性。

Result: 实验结果表明ITKM在多个场景中表现出优越性和泛化能力，不仅超越现有场景特定方法，还能通过整合多场景知识提升整体性能。

Conclusion: 提出的无监督多场景行人重识别任务和ITKM框架有效扩展了ReID应用范围，通过利用视觉语言模型和创新的三阶段训练策略，实现了跨多种场景的统一高性能解决方案。

Abstract: We propose unsupervised multi-scenario (UMS) person re-identification (ReID) as a new task that expands ReID across diverse scenarios (cross-resolution, clothing change, etc.) within a single coherent framework. To tackle UMS-ReID, we introduce image-text knowledge modeling (ITKM) -- a three-stage framework that effectively exploits the representational power of vision-language models. We start with a pre-trained CLIP model with an image encoder and a text encoder. In Stage I, we introduce a scenario embedding in the image encoder and fine-tune the encoder to adaptively leverage knowledge from multiple scenarios. In Stage II, we optimize a set of learned text embeddings to associate with pseudo-labels from Stage I and introduce a multi-scenario separation loss to increase the divergence between inter-scenario text representations. In Stage III, we first introduce cluster-level and instance-level heterogeneous matching modules to obtain reliable heterogeneous positive pairs (e.g., a visible image and an infrared image of the same person) within each scenario. Next, we propose a dynamic text representation update strategy to maintain consistency between text and image supervision signals. Experimental results across multiple scenarios demonstrate the superiority and generalizability of ITKM; it not only outperforms existing scenario-specific methods but also enhances overall performance by integrating knowledge from multiple scenarios.

</details>


### [35] [Language-Agnostic Visual Embeddings for Cross-Script Handwriting Retrieval](https://arxiv.org/abs/2601.11248)
*Fangke Chen,Tianhao Dong,Sirry Chen,Guobin Zhang,Yishu Zhang,Yining Chen*

Main category: cs.CV

TL;DR: 提出轻量级非对称双编码器框架，用于跨语言手写词检索，通过联合优化实例级对齐和类级语义一致性，学习统一、风格不变的视觉嵌入，在参数大幅减少的情况下实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 手写词检索对数字档案至关重要，但由于手写变异性大和跨语言语义鸿沟而具有挑战性。现有大型视觉语言模型计算成本过高，难以在实际边缘设备部署。

Method: 提出轻量级非对称双编码器框架，学习统一、风格不变的视觉嵌入。通过联合优化实例级对齐和类级语义一致性，将视觉嵌入锚定到语言无关的语义原型，强制跨文字和书写风格的不变性。

Result: 在28个基线方法中表现最佳，在语言内检索基准上达到最先进准确率。在显式跨语言检索（查询语言与目标语言不同）中验证了学习到的跨语言表示的有效性。仅需现有模型参数的一小部分即可实现强大性能。

Conclusion: 该框架实现了准确且资源高效的跨文字手写检索，解决了手写变异性大和跨语言语义鸿沟的挑战，同时大幅降低了计算成本，适合边缘设备部署。

Abstract: Handwritten word retrieval is vital for digital archives but remains challenging due to large handwriting variability and cross-lingual semantic gaps. While large vision-language models offer potential solutions, their prohibitive computational costs hinder practical edge deployment. To address this, we propose a lightweight asymmetric dual-encoder framework that learns unified, style-invariant visual embeddings. By jointly optimizing instance-level alignment and class-level semantic consistency, our approach anchors visual embeddings to language-agnostic semantic prototypes, enforcing invariance across scripts and writing styles. Experiments show that our method outperforms 28 baselines and achieves state-of-the-art accuracy on within-language retrieval benchmarks. We further conduct explicit cross-lingual retrieval, where the query language differs from the target language, to validate the effectiveness of the learned cross-lingual representations. Achieving strong performance with only a fraction of the parameters required by existing models, our framework enables accurate and resource-efficient cross-script handwriting retrieval.

</details>


### [36] [X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning](https://arxiv.org/abs/2601.11269)
*Maanping Shao,Feihong Zhang,Gu Zhang,Baiye Cheng,Zhengrong Xue,Huazhe Xu*

Main category: cs.CV

TL;DR: X-Distill通过跨架构知识蒸馏将大型DINOv2 ViT的视觉表征迁移到紧凑的ResNet-18上，结合扩散策略头进行微调，在数据稀缺的机器人操作任务中实现高效学习


<details>
  <summary>Details</summary>
Motivation: 大型视觉Transformer在机器人学习中需要大量数据，而紧凑CNN在数据稀缺场景下更容易优化但泛化能力有限。需要一种方法结合两者的优势，在数据稀缺的机器人操作任务中实现高效学习

Method: 1. 离线跨架构知识蒸馏：在通用ImageNet数据集上将大型冻结DINOv2教师模型的丰富视觉表征迁移到紧凑ResNet-18学生模型；2. 联合微调：将蒸馏后的编码器与扩散策略头在目标操作任务上进行联合微调

Result: 在34个模拟基准和5个具有挑战性的真实世界任务上，X-Distill始终优于使用从头训练ResNet或微调DINOv2编码器的策略。值得注意的是，X-Distill甚至超越了使用特权点云观测或更大视觉语言模型的3D编码器

Conclusion: X-Distill通过简单而理论基础扎实的蒸馏策略，在数据高效的机器人操作中实现了最先进的性能，证明了跨架构知识蒸馏在结合大型ViT的泛化能力和紧凑CNN的数据效率方面的有效性

Abstract: Visuomotor policies often leverage large pre-trained Vision Transformers (ViTs) for their powerful generalization capabilities. However, their significant data requirements present a major challenge in the data-scarce context of most robotic learning settings, where compact CNNs with strong inductive biases can be more easily optimized. To address this trade-off, we introduce X-Distill, a simple yet highly effective method that synergizes the strengths of both architectures. Our approach involves an offline, cross-architecture knowledge distillation, transferring the rich visual representations of a large, frozen DINOv2 teacher to a compact ResNet-18 student on the general-purpose ImageNet dataset. This distilled encoder, now endowed with powerful visual priors, is then jointly fine-tuned with a diffusion policy head on the target manipulation tasks. Extensive experiments on $34$ simulated benchmarks and $5$ challenging real-world tasks demonstrate that our method consistently outperforms policies equipped with from-scratch ResNet or fine-tuned DINOv2 encoders. Notably, X-Distill also surpasses 3D encoders that utilize privileged point cloud observations or much larger Vision-Language Models. Our work highlights the efficacy of a simple, well-founded distillation strategy for achieving state-of-the-art performance in data-efficient robotic manipulation.

</details>


### [37] [SAMannot: A Memory-Efficient, Local, Open-source Framework for Interactive Video Instance Segmentation based on SAM2](https://arxiv.org/abs/2601.11301)
*Gergely Dinya,András Gelencsér,Krisztina Kupán,Clemens Küpper,Kristóf Karacs,Anna Gelencsér-Horváth*

Main category: cs.CV

TL;DR: SAMannot是一个开源本地框架，将Segment Anything Model 2集成到人机协同工作流中，用于高效、隐私保护的视频实例分割标注


<details>
  <summary>Details</summary>
Motivation: 当前视频分割研究流程面临困境：要么依赖劳动密集型人工标注，要么使用昂贵的商业平台，要么采用可能泄露隐私的云服务。高保真视频实例分割的需求常受限于手动标注的瓶颈和云工具带来的隐私担忧

Method: 开发了SAMannot开源本地框架，集成SAM2模型到人机协同工作流中。通过修改SAM2依赖并实现处理层来最小化计算开销、最大化吞吐量，确保高响应性用户界面。关键特性包括持久实例身份管理、带屏障帧的自动"锁定-精修"工作流，以及基于掩码骨架化的自动提示机制

Result: 工具能够生成研究就绪的YOLO和PNG格式数据集以及结构化交互日志。通过动物行为跟踪用例和LVOS、DAVIS基准数据集的子集验证，证明该工具为复杂视频标注任务提供了可扩展、隐私保护且经济高效的商业平台替代方案

Conclusion: SAMannot为视频实例分割标注提供了一个开源、本地化、高效的解决方案，解决了现有方法在成本、隐私和效率方面的限制，特别适用于研究场景

Abstract: Current research workflows for precise video segmentation are often forced into a compromise between labor-intensive manual curation, costly commercial platforms, and/or privacy-compromising cloud-based services. The demand for high-fidelity video instance segmentation in research is often hindered by the bottleneck of manual annotation and the privacy concerns of cloud-based tools. We present SAMannot, an open-source, local framework that integrates the Segment Anything Model 2 (SAM2) into a human-in-the-loop workflow. To address the high resource requirements of foundation models, we modified the SAM2 dependency and implemented a processing layer that minimizes computational overhead and maximizes throughput, ensuring a highly responsive user interface. Key features include persistent instance identity management, an automated ``lock-and-refine'' workflow with barrier frames, and a mask-skeletonization-based auto-prompting mechanism. SAMannot facilitates the generation of research-ready datasets in YOLO and PNG formats alongside structured interaction logs. Verified through animal behavior tracking use-cases and subsets of the LVOS and DAVIS benchmark datasets, the tool provides a scalable, private, and cost-effective alternative to commercial platforms for complex video annotation tasks.

</details>


### [38] [Context-Aware Semantic Segmentation via Stage-Wise Attention](https://arxiv.org/abs/2601.11310)
*Antoine Carreaud,Elias Naha,Arthur Chansel,Nina Lahellec,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

TL;DR: CASWiT是一种用于超高分辨率遥感图像语义分割的双分支Swin Transformer架构，通过上下文编码器和高分辨率编码器结合跨尺度融合模块，解决了Transformer在UHR图像中内存爆炸的问题，并采用SimMIM风格预训练提升性能。


<details>
  <summary>Details</summary>
Motivation: 超高分辨率遥感图像语义分割在航空测绘和环境监测中至关重要。传统Transformer模型在处理UHR图像时面临内存随token数量二次增长的问题，这限制了上下文范围或空间分辨率，需要一种既能捕获长距离依赖又能保持精细细节的高效架构。

Method: 提出CASWiT双分支架构：1) 上下文编码器处理下采样邻域捕获长距离依赖；2) 高分辨率编码器提取UHR补丁的精细特征；3) 跨尺度融合模块结合交叉注意力和门控特征注入，用上下文信息丰富高分辨率token。此外提出SimMIM风格预训练：掩蔽75%高分辨率图像token和对应的低分辨率中心区域，训练共享双编码器和小解码器重建原始UHR图像。

Result: 在IGN FLAIR-HUB航空数据集上达到65.83% mIoU，比RGB基线提升1.78个百分点。在URUR数据集上达到49.1% mIoU，比当前SOTA提升+0.9%。代码已在HuggingFace发布。

Conclusion: CASWiT通过双分支架构和跨尺度融合有效解决了Transformer在UHR图像分割中的内存限制问题，结合SimMIM预训练策略显著提升了语义分割性能，在多个遥感数据集上取得了SOTA结果。

Abstract: Semantic ultra high resolution image (UHR) segmentation is essential in remote sensing applications such as aerial mapping and environmental monitoring. Transformer-based models struggle in this setting because memory grows quadratically with token count, constraining either the contextual scope or the spatial resolution. We introduce CASWiT (Context-Aware Stage-Wise Transformer), a dual-branch, Swin-based architecture that injects global cues into fine-grained UHR features. A context encoder processes a downsampled neighborhood to capture long-range dependencies, while a high resolution encoder extracts detailed features from UHR patches. A cross-scale fusion module, combining cross-attention and gated feature injection, enriches high-resolution tokens with context. Beyond architecture, we propose a SimMIM-style pretraining. We mask 75% of the high-resolution image tokens and the low-resolution center region that spatially corresponds to the UHR patch, then train the shared dual-encoder with small decoder to reconstruct the UHR initial image. Extensive experiments on the large-scale IGN FLAIR-HUB aerial dataset demonstrate the effectiveness of CASWiT. Our method achieves 65.83% mIoU, outperforming RGB baselines by 1.78 points. On URUR, CASWiT achieves 49.1% mIoU, surpassing the current SoTA by +0.9% under the official evaluation protocol. All codes are provided on: https://huggingface.co/collections/heig-vd-geo/caswit.

</details>


### [39] [Enhancing Vision Language Models with Logic Reasoning for Situational Awareness](https://arxiv.org/abs/2601.11322)
*Pavana Pradeep,Krishna Kant,Suya Yu*

Main category: cs.CV

TL;DR: 提出了一种将视觉语言模型与传统计算机视觉方法通过显式逻辑推理相结合的方法，以增强态势感知能力，包括细粒度事件细节提取、智能微调策略和推理过程中的输出合理性验证。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型能够从图像和视频中生成复杂活动的高层可解释描述，适用于态势感知应用。但在态势感知场景中，需要高可靠性和准确性识别低频但重要的事件，同时提取细粒度细节并评估识别质量。

Method: 通过显式逻辑推理将视觉语言模型与传统计算机视觉方法集成，包括：(a) 提取细粒度事件细节；(b) 采用智能微调策略，相比无指导选择实现显著更高的准确性；(c) 在推理过程中为VLM输出生成合理性验证。

Result: 智能微调机制提高了准确性，并在推理过程中提供了有价值的手段：要么确认VLM输出的有效性，要么指示其可能存在的问题。

Conclusion: 提出的集成方法通过逻辑推理增强了视觉语言模型在态势感知应用中的能力，实现了细粒度细节提取、准确性提升和输出合理性验证，为可靠的事件识别提供了有效解决方案。

Abstract: Vision-Language Models (VLMs) offer the ability to generate high-level, interpretable descriptions of complex activities from images and videos, making them valuable for situational awareness (SA) applications. In such settings, the focus is on identifying infrequent but significant events with high reliability and accuracy, while also extracting fine-grained details and assessing recognition quality. In this paper, we propose an approach that integrates VLMs with traditional computer vision methods through explicit logic reasoning to enhance SA in three key ways: (a) extracting fine-grained event details, (b) employing an intelligent fine-tuning (FT) strategy that achieves substantially higher accuracy than uninformed selection, and (c) generating justifications for VLM outputs during inference. We demonstrate that our intelligent FT mechanism improves the accuracy and provides a valuable means, during inferencing, to either confirm the validity of the VLM output or indicate why it may be questionable.

</details>


### [40] [Beer-Lambert Autoencoder for Unsupervised Stain Representation Learning and Deconvolution in Multi-immunohistochemical Brightfield Histology Images](https://arxiv.org/abs/2601.11336)
*Mark Eastwood,Thomas McKee,Zedong Hu,Sabine Tejpar,Fayyaz Minhas*

Main category: cs.CV

TL;DR: 提出一种用于多路免疫组化RGB全切片图像的数据驱动编码器-解码器架构，学习队列特异性染色特征，生成清晰分离的染色浓度图，解决传统Beer-Lambert方法在K>3染色剂时的不确定性和不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 在免疫组化中，分离单个显色染料的贡献对于染色标准化、标记物表达的定量评估和细胞水平读数至关重要。传统的Beer-Lambert颜色反卷积方法在双染色或三染色设置中表现良好，但在K>3显色剂的多路免疫组化中变得不确定且不稳定。

Method: 提出简单的数据驱动编码器-解码器架构：编码器是紧凑的U-Net，预测K个非负浓度通道；解码器是可微分的Beer-Lambert前向模型，具有可学习的染色矩阵（从典型显色剂色调初始化）。训练是无监督的，使用感知重建目标，并通过损失项增强以防止不必要的染色混合。

Result: 在包含5种染色剂（H、CDX2、MUC2、MUC5、CD8）的结直肠多路免疫组化面板上，显示出优异的RGB重建效果，与基于矩阵的反卷积方法相比，显著减少了通道间串扰。

Conclusion: 该方法能够有效学习队列特异性染色特征，为多路免疫组化RGB全切片图像提供清晰分离的染色浓度图，解决了传统方法在K>3染色剂时的不稳定性问题，代码和模型已开源。

Abstract: Separating the contributions of individual chromogenic stains in RGB histology whole slide images (WSIs) is essential for stain normalization, quantitative assessment of marker expression, and cell-level readouts in immunohistochemistry (IHC). Classical Beer-Lambert (BL) color deconvolution is well-established for two- or three-stain settings, but becomes under-determined and unstable for multiplex IHC (mIHC) with K>3 chromogens. We present a simple, data-driven encoder-decoder architecture that learns cohort-specific stain characteristics for mIHC RGB WSIs and yields crisp, well-separated per-stain concentration maps. The encoder is a compact U-Net that predicts K nonnegative concentration channels; the decoder is a differentiable BL forward model with a learnable stain matrix initialized from typical chromogen hues. Training is unsupervised with a perceptual reconstruction objective augmented by loss terms that discourage unnecessary stain mixing. On a colorectal mIHC panel comprising 5 stains (H, CDX2, MUC2, MUC5, CD8) we show excellent RGB reconstruction, and significantly reduced inter-channel bleed-through compared with matrix-based deconvolution. Code and model are available at https://github.com/measty/StainQuant.git.

</details>


### [41] [Assessing Building Heat Resilience Using UAV and Street-View Imagery with Coupled Global Context Vision Transformer](https://arxiv.org/abs/2601.11357)
*Steffen Knoblauch,Ram Kumar Muthusamy,Hao Li,Iddy Chazua,Benedcto Adamu,Innocent Maholi,Alexander Zipf*

Main category: cs.CV

TL;DR: 提出一种融合无人机和街景图像的双模态机器学习框架，用于评估城市建筑的热相关属性及其对热暴露健康风险的影响，并在坦桑尼亚达累斯萨拉姆市验证了该方法识别热暴露不平等性的能力。


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧了人类热暴露风险，特别是在全球南方人口密集的城市中心。低成本建筑材料和高热质量表面进一步加剧了这一风险，但目前缺乏可扩展的方法来评估这些与热相关的建筑属性。

Method: 提出一个机器学习框架，通过耦合全局上下文视觉变换器（CGCViT）融合公开可用的无人机（UAV）和街景（SV）图像，学习城市结构的热相关表征。使用HotSat-1的热红外（TIR）测量来量化建筑属性与热相关健康风险之间的关系。

Result: 双模态跨视角学习方法比最佳单模态模型性能提升高达9.3%，表明无人机和街景图像提供了有价值的互补视角。建筑周围植被的存在、较亮的屋顶材料、以及混凝土/粘土/木材屋顶（相对于金属或防水布）都与较低的HotSat-1 TIR值显著相关。

Conclusion: 该框架展示了如何利用机器学习识别和解决家庭层面的热暴露不平等问题（通常与社会经济劣势相关并反映在建筑材料中）。研究结果强调了本地化、数据驱动的风险评估在制定公平气候适应策略中的关键作用。

Abstract: Climate change is intensifying human heat exposure, particularly in densely built urban centers of the Global South. Low-cost construction materials and high thermal-mass surfaces further exacerbate this risk. Yet scalable methods for assessing such heat-relevant building attributes remain scarce. We propose a machine learning framework that fuses openly available unmanned aerial vehicle (UAV) and street-view (SV) imagery via a coupled global context vision transformer (CGCViT) to learn heat-relevant representations of urban structures. Thermal infrared (TIR) measurements from HotSat-1 are used to quantify the relationship between building attributes and heat-associated health risks. Our dual-modality cross-view learning approach outperforms the best single-modality models by up to $9.3\%$, demonstrating that UAV and SV imagery provide valuable complementary perspectives on urban structures. The presence of vegetation surrounding buildings (versus no vegetation), brighter roofing (versus darker roofing), and roofing made of concrete, clay, or wood (versus metal or tarpaulin) are all significantly associated with lower HotSat-1 TIR values. Deployed across the city of Dar es Salaam, Tanzania, the proposed framework illustrates how household-level inequalities in heat exposure - often linked to socio-economic disadvantage and reflected in building materials - can be identified and addressed using machine learning. Our results point to the critical role of localized, data-driven risk assessment in shaping climate adaptation strategies that deliver equitable outcomes.

</details>


### [42] [Think-Clip-Sample: Slow-Fast Frame Selection for Video Understanding](https://arxiv.org/abs/2601.11359)
*Wenhui Tan,Ruihua Song,Jiaze Li,Jianzhong Ju,Zhenbo Luo*

Main category: cs.CV

TL;DR: TCS是一个无需训练的长视频理解框架，通过多查询推理和片段级快慢采样提升多模态大语言模型在长视频上的性能，在减少50%推理时间的同时达到可比精度。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在长视频理解上存在计算限制和帧选择次优的问题，需要更高效的框架来提升长视频理解能力。

Method: 提出Think-Clip-Sample框架，包含两个核心组件：1) 多查询推理，生成多个查询以捕捉问题和视频的互补方面；2) 片段级快慢采样，自适应平衡密集局部细节和稀疏全局上下文。

Result: 在MLVU、LongVideoBench和VideoMME数据集上的实验表明，TCS在不同MLLMs上一致提升性能，最高提升6.9%准确率，能以50%更少的推理时间达到可比精度。

Conclusion: TCS框架在长视频理解任务上展现出高效性和有效性，通过训练免费的方式显著提升了多模态大语言模型的性能。

Abstract: Recent progress in multi-modal large language models (MLLMs) has significantly advanced video understanding. However, their performance on long-form videos remains limited by computational constraints and suboptimal frame selection. We present Think-Clip-Sample (TCS), a training-free framework that enhances long video understanding through two key components: (i) Multi-Query Reasoning, which generates multiple queries to capture complementary aspects of the question and video; and (ii) Clip-level Slow-Fast Sampling, which adaptively balances dense local details and sparse global context. Extensive experiments on MLVU, LongVideoBench, and VideoMME demonstrate that TCS consistently improves performance across different MLLMs, boosting up to 6.9% accuracy, and is capable of achieving comparable accuracy with 50% fewer inference time cost, highlighting both efficiency and efficacy of TCS on long video understanding.

</details>


### [43] [Heterogeneous Uncertainty-Guided Composed Image Retrieval with Fine-Grained Probabilistic Learning](https://arxiv.org/abs/2601.11393)
*Haomiao Tang,Jinpeng Wang,Minyi Zhao,Guanghao Meng,Ruisheng Luo,Long Chen,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 本文提出HUG（异构不确定性引导）范式，通过细粒度概率学习框架解决组合图像检索中的内在噪声问题，使用高斯嵌入表示查询和目标，定制异构不确定性估计，并设计不确定性引导目标函数，在基准测试中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 组合图像检索（CIR）中三元组的内在噪声会导致内在不确定性，威胁模型鲁棒性。现有概率学习方法存在局限性：采用实例级整体建模，对查询和目标进行同质化处理，无法有效处理CIR任务。

Method: 提出HUG范式：1）使用高斯嵌入表示查询和目标，捕获细粒度概念和不确定性；2）为多模态查询和单模态目标定制异构不确定性估计；3）设计动态加权机制计算综合查询不确定性；4）设计不确定性引导目标函数，包括查询-目标整体对比和细粒度对比，配合全面负采样策略。

Result: 在基准测试中，HUG超越了现有最先进基线方法，实验分析验证了技术贡献的有效性。

Conclusion: HUG通过细粒度概率学习框架和异构不确定性引导，有效解决了CIR中的内在噪声问题，提高了模型鲁棒性和检索性能，为组合图像检索提供了新的解决方案。

Abstract: Composed Image Retrieval (CIR) enables image search by combining a reference image with modification text. Intrinsic noise in CIR triplets incurs intrinsic uncertainty and threatens the model's robustness. Probabilistic learning approaches have shown promise in addressing such issues; however, they fall short for CIR due to their instance-level holistic modeling and homogeneous treatment of queries and targets. This paper introduces a Heterogeneous Uncertainty-Guided (HUG) paradigm to overcome these limitations. HUG utilizes a fine-grained probabilistic learning framework, where queries and targets are represented by Gaussian embeddings that capture detailed concepts and uncertainties. We customize heterogeneous uncertainty estimations for multi-modal queries and uni-modal targets. Given a query, we capture uncertainties not only regarding uni-modal content quality but also multi-modal coordination, followed by a provable dynamic weighting mechanism to derive comprehensive query uncertainty. We further design uncertainty-guided objectives, including query-target holistic contrast and fine-grained contrasts with comprehensive negative sampling strategies, which effectively enhance discriminative learning. Experiments on benchmarks demonstrate HUG's effectiveness beyond state-of-the-art baselines, with faithful analysis justifying the technical contributions.

</details>


### [44] [SUG-Occ: An Explicit Semantics and Uncertainty Guided Sparse Learning Framework for Real-Time 3D Occupancy Prediction](https://arxiv.org/abs/2601.11396)
*Hanlin Wu,Pengfei Lin,Ehsan Javanmardi,Nanren Bao,Bo Qian,Hao Si,Manabu Tsukada*

Main category: cs.CV

TL;DR: SUG-Occ是一个基于语义和不确定性引导的稀疏学习3D占据预测框架，通过利用3D场景的固有稀疏性减少冗余计算，同时保持几何和语义完整性，在精度和效率上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 3D语义占据预测作为自动驾驶全场景理解的关键任务，虽然提供了体素级语义信息，但面临计算和内存开销过大的问题，阻碍了实时实际部署。现有方法在保持几何和语义完整性的同时难以实现高效计算。

Method: 1. 利用语义和不确定性先验抑制自由空间的投影，采用显式无符号距离编码增强几何一致性，生成结构一致的稀疏3D表示；2. 设计级联稀疏补全模块，通过超交叉稀疏卷积和生成式上采样实现从粗到细的推理；3. 提出基于对象上下文表示(OCR)的掩码解码器，聚合稀疏特征的全局语义上下文，通过轻量级查询-上下文交互细化体素预测，避免对体积特征的昂贵注意力操作。

Result: 在SemanticKITTI基准测试中，该方法在精度上比基线提高了7.34%，在效率上提升了57.8%，实现了精度和效率的双重优化。

Conclusion: SUG-Occ通过语义和不确定性引导的稀疏学习，有效解决了3D语义占据预测中的计算效率问题，为自动驾驶的实时场景理解提供了可行的解决方案，在保持几何和语义完整性的同时显著提升了推理效率。

Abstract: As autonomous driving moves toward full scene understanding, 3D semantic occupancy prediction has emerged as a crucial perception task, offering voxel-level semantics beyond traditional detection and segmentation paradigms. However, such a refined representation for scene understanding incurs prohibitive computation and memory overhead, posing a major barrier to practical real-time deployment. To address this, we propose SUG-Occ, an explicit Semantics and Uncertainty Guided Sparse Learning Enabled 3D Occupancy Prediction Framework, which exploits the inherent sparsity of 3D scenes to reduce redundant computation while maintaining geometric and semantic completeness. Specifically, we first utilize semantic and uncertainty priors to suppress projections from free space during view transformation while employing an explicit unsigned distance encoding to enhance geometric consistency, producing a structurally consistent sparse 3D representation. Secondly, we design an cascade sparse completion module via hyper cross sparse convolution and generative upsampling to enable efficiently coarse-to-fine reasoning. Finally, we devise an object contextual representation (OCR) based mask decoder that aggregates global semantic context from sparse features and refines voxel-wise predictions via lightweight query-context interactions, avoiding expensive attention operations over volumetric features. Extensive experiments on SemanticKITTI benchmark demonstrate that the proposed approach outperforms the baselines, achieving a 7.34/% improvement in accuracy and a 57.8\% gain in efficiency.

</details>


### [45] [Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model](https://arxiv.org/abs/2601.11400)
*Shuai Yuan,Tianwu Lin,Shuang Chen,Yu Xia,Peng Qin,Xiangyu Liu,Xiaoqing Xu,Nan Xu,Hongsheng Zhang,Jie Wang,Peng Gong*

Main category: cs.CV

TL;DR: WetSAM：基于SAM的湿地制图框架，利用卫星时序图像和稀疏点监督，通过双分支设计和双向一致性正则化实现高精度湿地分割


<details>
  <summary>Details</summary>
Motivation: 湿地制图需要密集像素级标注，成本高昂；实际应用中通常只有稀疏点标签，现有深度学习模型在此条件下表现不佳；湿地具有强烈的季节性和年际动态变化，单时相影像不足，导致制图误差大；SAM等基础模型虽然能从点提示泛化，但设计用于静态图像，无法建模时序信息，在异质性湿地中产生碎片化掩码

Method: 提出WetSAM框架：1）时序提示分支：通过层次适配器和动态时序聚合扩展SAM，从物候变异性中解耦湿地特征；2）空间分支：使用时序约束的区域生长策略生成可靠的密集伪标签；3）双向一致性正则化：联合优化两个分支

Result: 在8个全球区域（每个约5000平方公里）的广泛实验中，WetSAM显著优于最先进方法，平均F1分数达到85.58%，能够以最小标注工作量提供准确且结构一致的湿地分割

Conclusion: WetSAM展示了强大的泛化能力和可扩展性，为低成本、高分辨率湿地制图提供了有效解决方案，特别适用于稀疏点监督条件下的湿地监测应用

Abstract: Accurate wetland mapping is essential for ecosystem monitoring, yet dense pixel-level annotation is prohibitively expensive and practical applications usually rely on sparse point labels, under which existing deep learning models perform poorly, while strong seasonal and inter-annual wetland dynamics further render single-date imagery inadequate and lead to significant mapping errors; although foundation models such as SAM show promising generalization from point prompts, they are inherently designed for static images and fail to model temporal information, resulting in fragmented masks in heterogeneous wetlands. To overcome these limitations, we propose WetSAM, a SAM-based framework that integrates satellite image time series for wetland mapping from sparse point supervision through a dual-branch design, where a temporally prompted branch extends SAM with hierarchical adapters and dynamic temporal aggregation to disentangle wetland characteristics from phenological variability, and a spatial branch employs a temporally constrained region-growing strategy to generate reliable dense pseudo-labels, while a bidirectional consistency regularization jointly optimizes both branches. Extensive experiments across eight global regions of approximately 5,000 km2 each demonstrate that WetSAM substantially outperforms state-of-the-art methods, achieving an average F1-score of 85.58%, and delivering accurate and structurally consistent wetland segmentation with minimal labeling effort, highlighting its strong generalization capability and potential for scalable, low-cost, high-resolution wetland mapping.

</details>


### [46] [Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints](https://arxiv.org/abs/2601.11409)
*Wenxiao Li,Xue-Cheng Tai,Jun Liu*

Main category: cs.CV

TL;DR: 提出融合宽度信息的拓扑先验框架，改进图像分割中的拓扑结构保持能力


<details>
  <summary>Details</summary>
Motivation: 现有拓扑先验方法缺乏宽度信息（如厚度、长度），限制了图像分割中结构保持的实际效果

Method: 结合持续同调和PDE平滑概念，修改上水平集的局部极值，将宽度信息融入拓扑结构描述

Result: 方法能同时保持连通性、亏格数等拓扑不变量，并保留线宽、长度等宽度属性

Conclusion: 提出的数学框架成功将宽度信息整合到拓扑结构中，提升了图像分割的拓扑保真度和实用性

Abstract: Existing research highlights the crucial role of topological priors in image segmentation, particularly in preserving essential structures such as connectivity and genus. Accurately capturing these topological features often requires incorporating width-related information, including the thickness and length inherent to the image structures. However, traditional mathematical definitions of topological structures lack this dimensional width information, limiting methods like persistent homology from fully addressing practical segmentation needs. To overcome this limitation, we propose a novel mathematical framework that explicitly integrates width information into the characterization of topological structures. This method leverages persistent homology, complemented by smoothing concepts from partial differential equations (PDEs), to modify local extrema of upper-level sets. This approach enables the resulting topological structures to inherently capture width properties. We incorporate this enhanced topological description into variational image segmentation models. Using some proper loss functions, we are also able to design neural networks that can segment images with the required topological and width properties. Through variational constraints on the relevant topological energies, our approach successfully preserves essential topological invariants such as connectivity and genus counts, simultaneously ensuring that segmented structures retain critical width attributes, including line thickness and length. Numerical experiments demonstrate the effectiveness of our method, showcasing its capability to maintain topological fidelity while explicitly embedding width characteristics into segmented image structures.

</details>


### [47] [Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps](https://arxiv.org/abs/2601.11442)
*Xiangjun Gao,Zhensong Zhang,Dave Zhenyu Chen,Songcen Xu,Long Quan,Eduardo Pérez-Pellitero,Youngkyoon Jang*

Main category: cs.CV

TL;DR: Map2Thought是一个用于3D视觉语言模型的可解释空间推理框架，通过Metric-CogMap和Cog-CoT组件实现显式几何推理，在减少监督数据的情况下达到接近全数据集的性能。


<details>
  <summary>Details</summary>
Motivation: 当前3D视觉语言模型缺乏显式和可解释的空间推理能力，需要一种能够将空间理解与语言推理相结合的方法，提供透明的推理过程。

Method: 提出Map2Thought框架，包含两个核心组件：Metric-CogMap（结合离散网格和连续度量表示的统一空间表示）和Cog-CoT（通过向量操作、边界框距离和遮挡感知外观顺序等确定性操作进行显式几何推理）。

Result: 在VSI-Bench上，仅使用一半监督数据达到59.9%准确率，接近全数据集训练的60.9%基线；在10%、25%、50%训练子集上分别比最先进方法高出5.3%、4.8%、4.0%。

Conclusion: Map2Thought通过显式空间表示和确定性几何操作实现了可解释的3D理解，在减少监督需求的同时保持高性能，为3D视觉语言模型提供了透明的推理机制。

Abstract: We propose Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D VLMs. The framework is grounded in two key components: Metric Cognitive Map (Metric-CogMap) and Cognitive Chain-of-Thought (Cog-CoT). Metric-CogMap provides a unified spatial representation by integrating a discrete grid for relational reasoning with a continuous, metric-scale representation for precise geometric understanding. Building upon the Metric-CogMap, Cog-CoT performs explicit geometric reasoning through deterministic operations, including vector operations, bounding-box distances, and occlusion-aware appearance order cues, producing interpretable inference traces grounded in 3D structure. Experimental results show that Map2Thought enables explainable 3D understanding, achieving 59.9% accuracy using only half the supervision, closely matching the 60.9% baseline trained with the full dataset. It consistently outperforms state-of-the-art methods by 5.3%, 4.8%, and 4.0% under 10%, 25%, and 50% training subsets, respectively, on the VSI-Bench.

</details>


### [48] [MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models](https://arxiv.org/abs/2601.11464)
*Xiaoran Fan,Zhichao Sun,Tao Ji,Lixing Shen,Tao Gui*

Main category: cs.CV

TL;DR: MHA2MLA-VLM：一种参数高效的多模态感知框架，可将现成的视觉语言模型转换为多头部潜在注意力架构，显著减少KV缓存占用并加速推理


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型处理日益复杂的多模态任务，KV缓存的快速增长在推理过程中带来了显著的内存和计算瓶颈。虽然多头部潜在注意力（MLA）提供了压缩KV缓存和加速推理的有效手段，但如何在不进行昂贵预训练的情况下将现有VLM适配到MLA架构仍未被充分探索。

Method: 提出了MHA2MLA-VLM框架，包含两个核心技术：1）模态自适应部分RoPE策略，通过选择性屏蔽非必要维度来支持传统和多模态设置；2）模态解耦的低秩近似方法，独立压缩视觉和文本KV空间。此外，引入参数高效微调以最小化适配成本，并证明最小化输出激活误差（而非参数距离）可显著减少性能损失。

Result: 在三个代表性VLM上的广泛实验表明，MHA2MLA-VLM能够以最少的监督数据恢复原始模型性能，显著减少KV缓存占用，并能与KV量化无缝集成。

Conclusion: MHA2MLA-VLM为现有视觉语言模型提供了一种高效转换到MLA架构的解决方案，有效解决了KV缓存增长带来的推理瓶颈问题，同时保持了模型性能并支持进一步优化。

Abstract: As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. While Multi-Head Latent Attention (MLA) offers an effective means to compress the KV cache and accelerate inference, adapting existing VLMs to the MLA architecture without costly pretraining remains largely unexplored. In this work, we present MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to MLA. Our approach features two core techniques: (1) a modality-adaptive partial-RoPE strategy that supports both traditional and multimodal settings by selectively masking nonessential dimensions, and (2) a modality-decoupled low-rank approximation method that independently compresses the visual and textual KV spaces. Furthermore, we introduce parameter-efficient fine-tuning to minimize adaptation cost and demonstrate that minimizing output activation error, rather than parameter distance, substantially reduces performance loss. Extensive experiments on three representative VLMs show that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.

</details>


### [49] [Generative Scenario Rollouts for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.11475)
*Rajeev Yasarla,Deepti Hegde,Shizhong Han,Hsin-Pai Cheng,Yunxiao Shi,Meysam Sadeghigooghari,Shweta Mahajan,Apratim Bhattacharyya,Litian Liu,Risheek Garrepalli,Thomas Svantesson,Fatih Porikli,Hong Cai*

Main category: cs.CV

TL;DR: GeRo是一个用于视觉-语言-动作模型的即插即用框架，通过自回归展开策略联合执行规划和语言基础未来交通场景生成，显著提升自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型主要依赖稀疏轨迹标注的模仿学习，未能充分利用其作为生成模型的潜力。需要开发能够联合执行规划和场景生成的框架，以支持长时程推理和多智能体规划。

Method: 首先训练VLA模型将自车和智能体动态编码为潜在token，受规划、运动和语言任务监督。然后GeRo执行语言条件自回归生成：给定多视角图像、场景描述和自车动作问题，生成未来潜在token和文本响应以指导长时程展开。通过展开一致性损失稳定预测。

Result: 在Bench2Drive基准测试中，GeRo将驾驶分数和成功率分别提升+15.7和+26.2。通过集成强化学习和生成展开，实现了最先进的闭环和开环性能，展示了强大的零样本鲁棒性。

Conclusion: 生成式语言条件推理有望成为更安全、更可解释的端到端自动驾驶的基础，GeRo框架通过联合规划和场景生成实现了这一目标。

Abstract: Vision-Language-Action (VLA) models are emerging as highly effective planning models for end-to-end autonomous driving systems. However, current works mostly rely on imitation learning from sparse trajectory annotations and under-utilize their potential as generative models. We propose Generative Scenario Rollouts (GeRo), a plug-and-play framework for VLA models that jointly performs planning and generation of language-grounded future traffic scenes through an autoregressive rollout strategy. First, a VLA model is trained to encode ego vehicle and agent dynamics into latent tokens under supervision from planning, motion, and language tasks, facilitating text-aligned generation. Next, GeRo performs language-conditioned autoregressive generation. Given multi-view images, a scenario description, and ego-action questions, it generates future latent tokens and textual responses to guide long-horizon rollouts. A rollout-consistency loss stabilizes predictions using ground truth or pseudo-labels, mitigating drift and preserving text-action alignment. This design enables GeRo to perform temporally consistent, language-grounded rollouts that support long-horizon reasoning and multi-agent planning. On Bench2Drive, GeRo improves driving score and success rate by +15.7 and +26.2, respectively. By integrating reinforcement learning with generative rollouts, GeRo achieves state-of-the-art closed-loop and open-loop performance, demonstrating strong zero-shot robustness. These results highlight the promise of generative, language-conditioned reasoning as a foundation for safer and more interpretable end-to-end autonomous driving.

</details>


### [50] [ReScene4D: Temporally Consistent Semantic Instance Segmentation of Evolving Indoor 3D Scenes](https://arxiv.org/abs/2601.11508)
*Emily Steiner,Jianhao Zheng,Henry Howard-Jenkins,Chris Xie,Iro Armeni*

Main category: cs.CV

TL;DR: ReScene4D：一种用于稀疏4D室内语义实例分割的新方法，通过跨观测共享信息实现时间一致性实例跟踪，在3RScan数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 室内环境随时间动态变化（物体移动、出现、消失），现有方法存在局限：3DSIS方法缺乏时间推理需要离散匹配步骤，4D LiDAR方法依赖高频时间测量不适用于长期室内环境演化。需要一种能处理稀疏时间观测的4D室内语义实例分割方法。

Method: 提出ReScene4D方法，将3DSIS架构适配到4DSIS任务，无需密集观测。核心是探索跨观测共享信息的策略，通过共享上下文实现一致实例跟踪并提升标准3DSIS质量。定义了新评估指标t-mAP来奖励时间身份一致性。

Result: 在3RScan数据集上达到最先进性能，为理解演化室内场景建立了新基准。共享上下文不仅实现一致实例跟踪，还提升了标准3DSIS质量。

Conclusion: ReScene4D成功解决了稀疏4D室内语义实例分割任务，通过跨观测共享信息策略有效处理室内环境动态变化，为长期室内场景理解提供了有效解决方案。

Abstract: Indoor environments evolve as objects move, appear, or disappear. Capturing these dynamics requires maintaining temporally consistent instance identities across intermittently captured 3D scans, even when changes are unobserved. We introduce and formalize the task of temporally sparse 4D indoor semantic instance segmentation (SIS), which jointly segments, identifies, and temporally associates object instances. This setting poses a challenge for existing 3DSIS methods, which require a discrete matching step due to their lack of temporal reasoning, and for 4D LiDAR approaches, which perform poorly due to their reliance on high-frequency temporal measurements that are uncommon in the longer-horizon evolution of indoor environments. We propose ReScene4D, a novel method that adapts 3DSIS architectures for 4DSIS without needing dense observations. It explores strategies to share information across observations, demonstrating that this shared context not only enables consistent instance tracking but also improves standard 3DSIS quality. To evaluate this task, we define a new metric, t-mAP, that extends mAP to reward temporal identity consistency. ReScene4D achieves state-of-the-art performance on the 3RScan dataset, establishing a new benchmark for understanding evolving indoor scenes.

</details>


### [51] [ShapeR: Robust Conditional 3D Shape Generation from Casual Captures](https://arxiv.org/abs/2601.11514)
*Yawar Siddiqui,Duncan Frost,Samir Aroudj,Armen Avetisyan,Henry Howard-Jenkins,Daniel DeTone,Pierre Moulon,Qirui Wu,Zhengqin Li,Julian Straub,Richard Newcombe,Jakob Engel*

Main category: cs.CV

TL;DR: ShapeR：从随意拍摄的图像序列生成3D物体形状的新方法，通过整合SLAM、3D检测和视觉语言模型，在真实场景中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有3D形状生成方法依赖干净、无遮挡、良好分割的输入，这在真实场景中很少见。需要一种能从随意拍摄序列中生成3D物体形状的鲁棒方法。

Method: 使用现成的视觉-惯性SLAM、3D检测算法和视觉语言模型提取稀疏SLAM点、多视角图像和机器生成描述；训练整流流变换器有效利用这些模态生成高保真度量3D形状；采用组合增强、课程训练和处理背景杂波等技术确保鲁棒性。

Result: 在包含7个真实场景178个野外物体的新评估基准上，ShapeR显著优于现有方法，在倒角距离指标上比现有最佳方法提升2.7倍。

Conclusion: ShapeR展示了从随意拍摄序列生成高质量3D物体形状的可行性，通过整合多模态信息和鲁棒训练策略，在真实场景中取得了显著改进。

Abstract: Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs. Such conditions are rarely met in real-world scenarios. We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences. Given an image sequence, we leverage off-the-shelf visual-inertial SLAM, 3D detection algorithms, and vision-language models to extract, for each object, a set of sparse SLAM points, posed multi-view images, and machine-generated captions. A rectified flow transformer trained to effectively condition on these modalities then generates high-fidelity metric 3D shapes. To ensure robustness to the challenges of casually captured data, we employ a range of techniques including on-the-fly compositional augmentations, a curriculum training scheme spanning object- and scene-level datasets, and strategies to handle background clutter. Additionally, we introduce a new evaluation benchmark comprising 178 in-the-wild objects across 7 real-world scenes with geometry annotations. Experiments show that ShapeR significantly outperforms existing approaches in this challenging setting, achieving an improvement of 2.7x in Chamfer distance compared to state of the art.

</details>


### [52] [UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation](https://arxiv.org/abs/2601.11522)
*Ruiheng Zhang,Jingfeng Yao,Huangxuan Zhao,Hao Yan,Xiao He,Lei Chen,Zhou Wei,Yong Luo,Zengmao Wang,Lefei Zhang,Dacheng Tao,Bo Du*

Main category: cs.CV

TL;DR: UniX是一个统一的医学基础模型，通过解耦理解和生成任务，结合自回归和扩散分支，在胸部X光图像上实现了协同的理解与生成能力。


<details>
  <summary>Details</summary>
Motivation: 医学基础模型在处理视觉理解和生成任务时面临根本性冲突：语义抽象与像素级重建的目标矛盾。现有基于参数共享自回归架构的方法通常导致一个或两个任务的性能受损。

Method: 1. 将任务解耦为自回归分支（理解）和扩散分支（生成）；2. 引入跨模态自注意力机制，用理解特征动态指导生成过程；3. 采用严格的数据清洗流程和多阶段训练策略。

Result: 在两个代表性基准测试中，UniX在理解性能（Micro-F1）上提升了46.1%，在生成质量（FD-RadDino）上提升了24.2%，仅使用LLM-CXR四分之一参数的情况下，性能达到与任务专用模型相当的水平。

Conclusion: UniX通过解耦架构和跨模态指导机制，实现了医学图像理解与生成的协同合作，为协同医学图像理解与生成建立了可扩展的范式。

Abstract: Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation. UniX decouples the two tasks into an autoregressive branch for understanding and a diffusion branch for high-fidelity generation. Crucially, a cross-modal self-attention mechanism is introduced to dynamically guide the generation process with understanding features. Coupled with a rigorous data cleaning pipeline and a multi-stage training strategy, this architecture enables synergistic collaboration between tasks while leveraging the strengths of diffusion models for superior generation. On two representative benchmarks, UniX achieves a 46.1% improvement in understanding performance (Micro-F1) and a 24.2% gain in generation quality (FD-RadDino), using only a quarter of the parameters of LLM-CXR. By achieving performance on par with task-specific models, our work establishes a scalable paradigm for synergistic medical image understanding and generation. Codes and models are available at https://github.com/ZrH42/UniX.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [53] [Chatting with Confidants or Corporations? Privacy Management with AI Companions](https://arxiv.org/abs/2601.10754)
*Hsuen-Chi Chiu,Jeremy Foote*

Main category: cs.CR

TL;DR: 研究探讨AI情感伴侣聊天机器人如何模糊人际亲密与机构软件边界，基于隐私管理理论和水平/垂直隐私框架，通过用户访谈揭示用户混合人际习惯与机构意识的多层隐私管理策略。


<details>
  <summary>Details</summary>
Motivation: AI情感伴侣聊天机器人模糊了人际亲密关系与机构软件之间的界限，创造了一个复杂的多维隐私环境。研究者希望理解用户在这种新型人机关系中的隐私管理行为，特别是情感安全与机构风险之间的平衡。

Method: 采用沟通隐私管理理论和Masur的水平（用户-AI）/垂直（用户-平台）隐私框架，对15名使用Replika和Character.AI等伴侣AI平台的用户进行了深度访谈。

Result: 研究发现用户混合了人际习惯与机构意识：聊天机器人的非评判性和始终可用性促进了情感安全和自我表露，但用户仍意识到机构风险，并通过分层策略和选择性分享主动管理隐私。然而，许多用户对平台级数据控制感到不确定或无力。拟人化设计进一步模糊了隐私边界，有时导致无意的过度分享和隐私动荡。

Conclusion: 这些结果扩展了隐私理论，突出了人机伴侣关系中情感和机构隐私管理的独特相互作用。研究揭示了在AI情感伴侣背景下，用户如何在情感安全需求与机构隐私风险之间进行复杂平衡。

Abstract: AI chatbots designed as emotional companions blur the boundaries between interpersonal intimacy and institutional software, creating a complex, multi-dimensional privacy environment. Drawing on Communication Privacy Management theory and Masur's horizontal (user-AI) and vertical (user-platform) privacy framework, we conducted in-depth interviews with fifteen users of companion AI platforms such as Replika and Character.AI. Our findings reveal that users blend interpersonal habits with institutional awareness: while the non-judgmental, always-available nature of chatbots fosters emotional safety and encourages self-disclosure, users remain mindful of institutional risks and actively manage privacy through layered strategies and selective sharing. Despite this, many feel uncertain or powerless regarding platform-level data control. Anthropomorphic design further blurs privacy boundaries, sometimes leading to unintentional oversharing and privacy turbulence. These results extend privacy theory by highlighting the unique interplay of emotional and institutional privacy management in human-AI companionship.

</details>


### [54] [SecMLOps: A Comprehensive Framework for Integrating Security Throughout the MLOps Lifecycle](https://arxiv.org/abs/2601.10848)
*Xinrui Zhang,Pincan Zhao,Jason Jaskolka,Heng Li,Rongxing Lu*

Main category: cs.CR

TL;DR: 该论文提出了SecMLOps框架，将安全措施整合到整个MLOps生命周期中，以应对机器学习部署中的安全挑战，特别是对抗性攻击，并通过行人检测系统案例展示了安全与性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 机器学习在关键系统中的应用日益广泛，但部署过程中面临严重的安全挑战，特别是对抗性攻击会损害系统的完整性和可靠性。现有MLOps框架缺乏足够的安全考虑，需要将安全措施系统性地整合到整个ML生命周期中。

Method: 基于MLOps原则，提出了SecMLOps框架，将安全考虑嵌入从设计到部署和持续监控的整个MLOps生命周期。该框架专门针对MLOps生命周期各阶段的复杂攻击提供防护，并通过高级行人检测系统（PDS）用例进行实际验证。

Result: 通过广泛的实证评估，揭示了安全措施与系统性能之间的权衡关系，为在不影响操作效率的情况下优化安全提供了关键见解。研究强调了平衡方法的重要性，为实践者提供了在不同领域ML部署中实现安全与性能最优平衡的指导。

Conclusion: SecMLOps框架通过将安全措施整合到整个MLOps生命周期中，有效增强了机器学习应用的韧性和可信度。平衡安全与性能的方法对于实际部署至关重要，该研究为在不同领域实现安全可靠的ML部署提供了实用指导。

Abstract: Machine Learning (ML) has emerged as a pivotal technology in the operation of large and complex systems, driving advancements in fields such as autonomous vehicles, healthcare diagnostics, and financial fraud detection. Despite its benefits, the deployment of ML models brings significant security challenges, such as adversarial attacks, which can compromise the integrity and reliability of these systems. To address these challenges, this paper builds upon the concept of Secure Machine Learning Operations (SecMLOps), providing a comprehensive framework designed to integrate robust security measures throughout the entire ML operations (MLOps) lifecycle. SecMLOps builds on the principles of MLOps by embedding security considerations from the initial design phase through to deployment and continuous monitoring. This framework is particularly focused on safeguarding against sophisticated attacks that target various stages of the MLOps lifecycle, thereby enhancing the resilience and trustworthiness of ML applications. A detailed advanced pedestrian detection system (PDS) use case demonstrates the practical application of SecMLOps in securing critical MLOps. Through extensive empirical evaluations, we highlight the trade-offs between security measures and system performance, providing critical insights into optimizing security without unduly impacting operational efficiency. Our findings underscore the importance of a balanced approach, offering valuable guidance for practitioners on how to achieve an optimal balance between security and performance in ML deployments across various domains.

</details>


### [55] [Multi-Agent Taint Specification Extraction for Vulnerability Detection](https://arxiv.org/abs/2601.10865)
*Jonah Ghebremichael,Saastha Vasan,Saad Ullah,Greg Tystahl,David Adei,Christopher Kruegel,Giovanni Vigna,William Enck,Alexandros Kapravelos*

Main category: cs.CR

TL;DR: SemTaint：结合LLM语义理解与传统静态分析的JavaScript污点分析系统，通过多智能体架构提取污点规范，显著提升SAST工具的漏洞检测能力


<details>
  <summary>Details</summary>
Motivation: JavaScript静态污点分析面临两大挑战：1）JavaScript动态特性使数据流提取复杂化；2）npm庞大库生态系统难以识别相关源/汇并建立跨依赖污点传播。传统静态分析难以解决这些问题，需要结合语义理解能力

Method: 提出SemTaint多智能体系统，将LLM语义理解与传统静态程序分析策略性结合：1）使用静态分析计算调用图，LLM解析无法静态解析的调用边；2）LLM为给定CWE分类源和汇；3）生成包含源、汇、调用边和库流摘要的污点规范；4）将规范提供给SAST工具进行漏洞分析

Result: 1）集成CodeQL后检测到162个先前CodeQL无法检测的漏洞中的106个；2）在4个流行npm包中发现4个新漏洞；3）证明LLM能实际增强现有静态程序分析算法，结合符号推理和语义理解的优势

Conclusion: LLM能有效增强传统静态分析，通过语义理解解决JavaScript动态特性和npm生态系统的分析挑战。SemTaint展示了符号推理与语义理解结合在漏洞检测中的实用价值，为SAST工具提供了新的增强途径

Abstract: Static Application Security Testing (SAST) tools using taint analysis are widely viewed as providing higher-quality vulnerability detection results compared to traditional pattern-based approaches. However, performing static taint analysis for JavaScript poses two major challenges. First, JavaScript's dynamic features complicate data flow extraction required for taint tracking. Second, npm's large library ecosystem makes it difficult to identify relevant sources/sinks and establish taint propagation across dependencies. In this paper, we present SemTaint, a multi-agent system that strategically combines the semantic understanding of Large Language Models (LLMs) with traditional static program analysis to extract taint specifications, including sources, sinks, call edges, and library flow summaries tailored to each package. Conceptually, SemTaint uses static program analysis to calculate a call graph and defers to an LLM to resolve call edges that cannot be resolved statically. Further, it uses the LLM to classify sources and sinks for a given CWE. The resulting taint specification is then provided to a SAST tool, which performs vulnerability analysis. We integrate SemTaint with CodeQL, a state-of-the-art SAST tool, and demonstrate its effectiveness by detecting 106 of 162 vulnerabilities previously undetectable by CodeQL. Furthermore, we find 4 novel vulnerabilities in 4 popular npm packages. In doing so, we demonstrate that LLMs can practically enhance existing static program analysis algorithms, combining the strengths of both symbolic reasoning and semantic understanding for improved vulnerability detection.

</details>


### [56] [Adaptive Privacy Budgeting](https://arxiv.org/abs/2601.10866)
*Yuting Liang,Ke Yi*

Main category: cs.CR

TL;DR: 提出了一种在广义差分隐私下自适应隐私预算分配的框架，通过战略性地分配用户隐私预算来提升查询效用


<details>
  <summary>Details</summary>
Motivation: 在广义差分隐私场景下，用户数据的不同组件对查询的重要性不同，存在战略分配隐私预算的潜力，通过自适应预算分配可以在典型实例上实现更大的隐私节省

Method: 开发了一个自适应隐私预算分配框架，允许根据先前查询的输出动态调整隐私预算分配，战略性地在不同用户和查询间分配隐私预算

Result: 提出的自适应预算框架能够有效节省隐私预算，并将节省的预算用于提升后续查询的效用，通过多个应用实例验证了框架的适用性

Conclusion: 自适应隐私预算分配框架为广义差分隐私提供了一种有效的预算管理策略，能够在保护用户隐私的同时显著提升查询效用

Abstract: We study the problem of adaptive privacy budgeting under generalized differential privacy. Consider the setting where each user $i\in [n]$ holds a tuple $x_i\in U:=U_1\times \dotsb \times U_T$, where $x_i(l)\in U_l$ represents the $l$-th component of their data. For every $l\in [T]$ (or a subset), an untrusted analyst wishes to compute some $f_l(x_1(l),\dots,x_n(l))$, while respecting the privacy of each user. For many functions $f_l$, data from the users are not all equally important, and there is potential to use the privacy budgets of the users strategically, leading to privacy savings that can be used to improve the utility of later queries. In particular, the budgeting should be adaptive to the outputs of previous queries, so that greater savings can be achieved on more typical instances. In this paper, we provide such an adaptive budgeting framework, with various applications demonstrating its applicability.

</details>


### [57] [Hidden-in-Plain-Text: A Benchmark for Social-Web Indirect Prompt Injection in RAG](https://arxiv.org/abs/2601.10923)
*Haoze Guo,Ziqi Wei*

Main category: cs.CR

TL;DR: OpenRAG-Soc是一个用于评估网页RAG系统在间接提示注入和检索中毒攻击下的紧凑、可复现基准测试套件


<details>
  <summary>Details</summary>
Motivation: 随着检索增强生成系统越来越依赖网页用户生成内容作为响应基础，其攻击面也随之扩大，特别是间接提示注入和检索中毒攻击对网页原生载体构成严重威胁

Method: 构建包含社交语料库的基准套件，结合可互换的稀疏和密集检索器，提供HTML/Markdown净化、Unicode标准化和属性门控回答等可部署缓解措施，标准化从数据摄取到生成的端到端评估流程

Result: 该套件能够报告攻击响应时间、稀疏和密集检索器中的排名偏移、系统效用和延迟，支持在不同载体和防御措施之间进行公平比较

Conclusion: OpenRAG-Soc为需要快速、现实测试来跟踪风险并强化部署的实践者提供了一个实用的评估工具

Abstract: Retrieval-augmented generation (RAG) systems put more and more emphasis on grounding their responses in user-generated content found on the Web, amplifying both their usefulness and their attack surface. Most notably, indirect prompt injection and retrieval poisoning attack the web-native carriers that survive ingestion pipelines and are very concerning. We provide OpenRAG-Soc, a compact, reproducible benchmark-and-harness for web-facing RAG evaluation under these threats, in a discrete data package. The suite combines a social corpus with interchangeable sparse and dense retrievers and deployable mitigations - HTML/Markdown sanitization, Unicode normalization, and attribution-gated answered. It standardizes end-to-end evaluation from ingestion to generation and reports attacks time of one of the responses at answer time, rank shifts in both sparse and dense retrievers, utility and latency, allowing for apples-to-apples comparisons across carriers and defenses. OpenRAG-Soc targets practitioners who need fast, and realistic tests to track risk and harden deployments.

</details>


### [58] [Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents](https://arxiv.org/abs/2601.10955)
*Kaiyu Zhou,Yongsen Zheng,Yicheng He,Meng Xue,Xueluan Gong,Yuji Wang,Kwok-Yan Lam*

Main category: cs.CR

TL;DR: 提出针对LLM智能体工具通信循环的隐蔽多轮经济DoS攻击，通过修改MCP兼容工具服务器的文本字段和返回策略，引导智能体进行冗长的工具调用序列，显著增加计算成本和能耗，同时保持最终答案正确以逃避检测。


<details>
  <summary>Details</summary>
Motivation: 现有DoS攻击主要针对用户提示或RAG上下文注入，这些攻击本质上是单轮的，缺乏任务导向性，在目标导向工作流中容易被发现，且无法利用多轮智能体-工具交互的复合成本。智能体-工具通信循环是现代LLM智能体的关键攻击面，需要更隐蔽、多轮的经济DoS攻击方法。

Method: 在良性的MCP兼容工具服务器中调整文本可见字段和模板控制的返回策略，保持函数签名不变并保留最终有效载荷。使用蒙特卡洛树搜索优化器优化这些编辑，引导智能体进入长时间、冗长的工具调用序列，仅使用文本通知实现多轮攻击。

Result: 在ToolBench和BFCL基准测试的六个LLM上，攻击将任务扩展为超过60,000个令牌的轨迹，成本膨胀高达658倍，能耗增加100-560倍。GPU KV缓存占用率从<1%提升到35-74%，同时运行的吞吐量减少约50%。由于服务器保持协议兼容且任务结果正确，传统检查无法检测。

Conclusion: 智能体-工具接口应被视为首要安全边界，需要从验证最终答案转向监控整个智能体过程的经济和计算成本。该研究强调了多轮经济DoS攻击的严重威胁，要求范式转变来保护LLM智能体系统。

Abstract: The agent-tool communication loop is a critical attack surface in modern Large Language Model (LLM) agents. Existing Denial-of-Service (DoS) attacks, primarily triggered via user prompts or injected retrieval-augmented generation (RAG) context, are ineffective for this new paradigm. They are fundamentally single-turn and often lack a task-oriented approach, making them conspicuous in goal-oriented workflows and unable to exploit the compounding costs of multi-turn agent-tool interactions. We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task. Our method adjusts text-visible fields and a template-governed return policy in a benign, Model Context Protocol (MCP)-compatible tool server, optimizing these edits with a Monte Carlo Tree Search (MCTS) optimizer. These adjustments leave function signatures unchanged and preserve the final payload, steering the agent into prolonged, verbose tool-calling sequences using text-only notices. This compounds costs across turns, escaping single-turn caps while keeping the final answer correct to evade validation. Across six LLMs on the ToolBench and BFCL benchmarks, our attack expands tasks into trajectories exceeding 60,000 tokens, inflates costs by up to 658x, and raises energy by 100-560x. It drives GPU KV cache occupancy from <1% to 35-74% and cuts co-running throughput by approximately 50%. Because the server remains protocol-compatible and task outcomes are correct, conventional checks fail. These results elevate the agent-tool interface to a first-class security frontier, demanding a paradigm shift from validating final answers to monitoring the economic and computational cost of the entire agentic process.

</details>


### [59] [AJAR: Adaptive Jailbreak Architecture for Red-teaming](https://arxiv.org/abs/2601.10971)
*Yipu Dou,Wang Yang*

Main category: cs.CR

TL;DR: AJAR是一个用于红队测试的适应性越狱架构，通过协议驱动的认知编排来模拟复杂的多轮智能体攻击，填补了现有红队框架在静态文本攻击和复杂智能体利用之间的空白。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型从静态聊天机器人演变为能够执行工具调用的自主智能体，AI安全领域正从内容审核转向行动安全。现有红队框架存在分裂：要么专注于僵化的基于脚本的文本攻击，要么缺乏架构模块化来模拟复杂的多轮智能体利用。

Method: 提出AJAR框架，基于Petri运行时，利用模型上下文协议将对抗逻辑与执行循环解耦，将X-Teaming等先进算法封装为标准化的即插即用服务。采用协议驱动的认知编排架构，支持状态回溯和工具使用环境中的多轮攻击模拟。

Result: 通过受控的定性案例研究验证了AJAR的架构可行性，展示了其在工具使用环境中执行状态回溯的能力。初步探索揭示了"智能体间隙"的复杂安全动态：工具使用通过代码执行引入了新的注入向量，但参数格式化的认知负担可能无意中破坏基于角色的攻击。

Conclusion: AJAR为这一新兴攻击面的标准化、环境感知评估提供了框架，已开源以促进相关研究。该框架填补了现有红队测试方法的空白，能够更好地评估智能体环境中的安全风险。

Abstract: As Large Language Models (LLMs) evolve from static chatbots into autonomous agents capable of tool execution, the landscape of AI safety is shifting from content moderation to action security. However, existing red-teaming frameworks remain bifurcated: they either focus on rigid, script-based text attacks or lack the architectural modularity to simulate complex, multi-turn agentic exploitations. In this paper, we introduce AJAR (Adaptive Jailbreak Architecture for Red-teaming), a proof-of-concept framework designed to bridge this gap through Protocol-driven Cognitive Orchestration. Built upon the robust runtime of Petri, AJAR leverages the Model Context Protocol (MCP) to decouple adversarial logic from the execution loop, encapsulating state-of-the-art algorithms like X-Teaming as standardized, plug-and-play services. We validate the architectural feasibility of AJAR through a controlled qualitative case study, demonstrating its ability to perform stateful backtracking within a tool-use environment. Furthermore, our preliminary exploration of the "Agentic Gap" reveals a complex safety dynamic: while tool usage introduces new injection vectors via code execution, the cognitive load of parameter formatting can inadvertently disrupt persona-based attacks. AJAR is open-sourced to facilitate the standardized, environment-aware evaluation of this emerging attack surface. The code and data are available at https://github.com/douyipu/ajar.

</details>


### [60] [Shaping a Quantum-Resistant Future: Strategies for Post-Quantum PKI](https://arxiv.org/abs/2601.11104)
*Grazia D'Onghia,Diana Gratiela Berbecaru,Antonio Lioy*

Main category: cs.CR

TL;DR: 该论文探讨了在量子计算时代背景下，如何将公钥基础设施（PKI）过渡到抗量子算法，重点关注X.509证书格式的适应性调整。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算时代的临近，保护经典密码协议变得至关重要。公钥密码学广泛用于签名和密钥交换，但它是受量子计算威胁最大的密码类型。公钥证书作为签名数据结构，需要面对双重量子挑战：认证密钥和签名本身都需要抗量子保护。

Method: 论文介绍了选择鲁棒后量子算法的最新进展，并研究了它们在公钥基础设施（PKI）环境中的适用性。具体方法包括：定义安全过渡到抗量子PKI的要求，重点关注X.509证书格式的适应性调整；探索将证书撤销列表（CRL）和在线证书状态协议（OCSP）过渡到支持抗量子算法。

Result: 通过比较分析，论文阐明了向抗量子PKI过渡的复杂性。研究结果为构建量子安全的公钥基础设施提供了技术框架和实现路径。

Conclusion: 论文强调了向抗量子公钥基础设施过渡的紧迫性和复杂性，为应对量子计算对现有密码体系的威胁提供了系统性的解决方案和技术指导。

Abstract: As the quantum computing era approaches, securing classical cryptographic protocols becomes imperative. Public key cryptography is widely used for signature and key exchange but it is the type of cryptography more threatened by quantum computing. Its application typically requires support via a public-key certificate, which is a signed data structure and must therefore face twice the quantum challenge: for the certified keys and for the signature itself. We present the latest developments in selecting robust Post-Quantum algorithms and investigate their applicability in the Public Key Infrastructure context. Our contribution entails defining requirements for a secure transition to a quantum-resistant Public Key Infrastructure, with a focus on adaptations for the X.509 certificate format. Additionally, we explore transitioning Certificate Revocation List and Online Certificate Status Protocol to support quantum-resistant algorithms. Through comparative analysis, we elucidate the complex transition to a quantum-resistant PKI.

</details>


### [61] [Proving Circuit Functional Equivalence in Zero Knowledge](https://arxiv.org/abs/2601.11173)
*Sirui Shen,Zunchen Huang,Chenglu Jin*

Main category: cs.CR

TL;DR: ZK-CEC是首个结合形式验证和零知识证明的隐私保护硬件验证框架，可在不泄露设计机密的情况下验证IP正确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现代集成电路生态系统依赖第三方IP集成，这带来了硬件木马和安全漏洞风险。现有隐私保护硬件验证方法都是基于仿真的，缺乏形式化保证，需要在保护设计机密的同时解决IP供应商和系统集成商之间的信任僵局。

Method: 提出ZK-CEC框架，结合形式验证和零知识证明。首先提出证明秘密设计对公共约束不可满足性的蓝图，然后构建ZK-CEC系统，使证明者能在零知识条件下向验证者证明秘密IP功能与公共规范完全一致，仅泄露证明的长度和宽度。

Result: 实现了ZK-CEC并在多种电路上评估性能，包括算术单元和密码组件。实验结果表明ZK-CEC能在实际时间限制内成功验证实际设计，如AES S-Box。

Conclusion: ZK-CEC为硬件形式验证建立了首个隐私保护框架，解决了现有零知识协议在秘密公式验证中的安全性问题，为IP正确性和安全性验证提供了形式化保证而不泄露设计机密。

Abstract: The modern integrated circuit ecosystem is increasingly reliant on third-party intellectual property integration, which introduces security risks, including hardware Trojans and security vulnerabilities. Addressing the resulting trust deadlock between IP vendors and system integrators without exposing proprietary designs requires novel privacy-preserving verification techniques. However, existing privacy-preserving hardware verification methods are all simulation-based and fail to offer formal guarantees. In this paper, we propose ZK-CEC, the first privacy-preserving framework for hardware formal verification. By combining formal verification and zero-knowledge proof (ZKP), ZK-CEC establishes a foundation for formally verifying IP correctness and security without compromising the confidentiality of the designs.
  We observe that existing zero-knowledge protocols for formal verification are designed to prove statements of public formulas. However, in a privacy-preserving verification context where the formula is secret, these protocols cannot prevent a malicious prover from forging the formula, thereby compromising the soundness of the verification. To address these gaps, we first propose a blueprint for proving the unsatisfiability of a secret design against a public constraint, which is widely applicable to proving properties in software, hardware, and cyber-physical systems. Based on the proposed blueprint, we construct ZK-CEC, which enables a prover to convince the verifier that a secret IP's functionality aligns perfectly with the public specification in zero knowledge, revealing only the length and width of the proof. We implement ZK-CEC and evaluate its performance across various circuits, including arithmetic units and cryptographic components. Experimental results show that ZK-CEC successfully verifies practical designs, such as the AES S-Box, within practical time limits.

</details>


### [62] [SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.11199)
*Aiman Al Masoud,Marco Arazzi,Antonino Nocera*

Main category: cs.CR

TL;DR: SD-RAG：一种选择性披露的检索增强生成方法，通过在检索阶段而非生成阶段实施安全隐私约束，有效防止敏感信息泄露并抵抗提示注入攻击。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法大多忽视敏感或受控信息的泄露风险，少数依赖提示约束的方法易受提示注入攻击，需要更安全的选择性披露机制。

Method: 提出SD-RAG框架，将安全隐私约束执行与生成过程解耦，在检索阶段实施净化与披露控制；引入语义机制处理人类可读的动态安全隐私约束，采用优化的基于图的数据模型支持细粒度策略感知检索。

Result: 实验评估显示SD-RAG优于基线方法，隐私评分提升高达58%，对生成模型的提示注入攻击表现出强韧性。

Conclusion: SD-RAG通过在检索阶段而非生成阶段实施安全控制，为RAG系统提供了更可靠的选择性披露机制，有效平衡信息利用与隐私保护需求。

Abstract: Retrieval-Augmented Generation (RAG) has attracted significant attention due to its ability to combine the generative capabilities of Large Language Models (LLMs) with knowledge obtained through efficient retrieval mechanisms over large-scale data collections. Currently, the majority of existing approaches overlook the risks associated with exposing sensitive or access-controlled information directly to the generation model. Only a few approaches propose techniques to instruct the generative model to refrain from disclosing sensitive information; however, recent studies have also demonstrated that LLMs remain vulnerable to prompt injection attacks that can override intended behavioral constraints. For these reasons, we propose a novel approach to Selective Disclosure in Retrieval-Augmented Generation, called SD-RAG, which decouples the enforcement of security and privacy constraints from the generation process itself. Rather than relying on prompt-level safeguards, SD-RAG applies sanitization and disclosure controls during the retrieval phase, prior to augmenting the language model's input. Moreover, we introduce a semantic mechanism to allow the ingestion of human-readable dynamic security and privacy constraints together with an optimized graph-based data model that supports fine-grained, policy-aware retrieval. Our experimental evaluation demonstrates the superiority of SD-RAG over baseline existing approaches, achieving up to a $58\%$ improvement in the privacy score, while also showing a strong resilience to prompt injection attacks targeting the generative model.

</details>


### [63] [InterPUF: Distributed Authentication via Physically Unclonable Functions and Multi-party Computation for Reconfigurable Interposers](https://arxiv.org/abs/2601.11368)
*Ishraq Tashdid,Tasnuva Farheen,Sazadur Rahman*

Main category: cs.CR

TL;DR: InterPUF：一种紧凑可扩展的认证框架，利用可重构中介层中的路由差分延迟PUF和多方计算，为多厂商chiplet生态系统提供分布式信任根。


<details>
  <summary>Details</summary>
Motivation: 现代SiP平台采用可重构中介层实现chiplet即插即用集成，但这种灵活性带来了严重的信任挑战，传统认证方案无法在去中心化、后制造可编程环境中扩展和适应。

Method: 提出InterPUF框架：1) 在可重构互连中嵌入基于路由的差分延迟PUF；2) 使用多方计算保护认证过程，确保原始PUF签名永不暴露；3) 结合中介层驻留PUF原语、密码哈希和协作验证。

Result: 硬件评估显示仅0.23%面积和0.072%功耗开销，认证延迟保持在数十纳秒内。pyPUF仿真确认在工艺、电压、温度变化下具有强唯一性、可靠性和建模抵抗性。

Conclusion: InterPUF通过将中介层转化为分布式信任根，在不依赖中心化锚点的情况下实现了最小信任认证模型，为异构多厂商chiplet生态系统提供了安全可扩展的认证解决方案。

Abstract: Modern system-in-package (SiP) platforms increasingly adopt reconfigurable interposers to enable plug-and-play chiplet integration across heterogeneous multi-vendor ecosystems. However, this flexibility introduces severe trust challenges, as traditional authentication schemes fail to scale or adapt in decentralized, post-fabrication programmable environments. This paper presents InterPUF, a compact and scalable authentication framework that transforms the interposer into a distributed root of trust. InterPUF embeds a route-based differential delay physically unclonable function (PUF) across the reconfigurable interconnect and secures authentication using multi-party computation (MPC), ensuring raw PUF signatures are never exposed. Our hardware evaluation shows only 0.23% area and 0.072% power overhead across diverse chiplets while preserving authentication latency within tens of nanoseconds. Simulation results using pyPUF confirm strong uniqueness, reliability, and modeling resistance under process, voltage, and temperature variations. By combining interposer-resident PUF primitives with cryptographic hashing and collaborative verification, InterPUF enforces a minimal-trust authentication model without relying on a centralized anchor.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [64] [Mass Distribution versus Density Distribution in the Context of Clustering](https://arxiv.org/abs/2601.10759)
*Kai Ming Ting,Ye Zhu,Hang Zhang,Tianrun Liang*

Main category: stat.ML

TL;DR: 论文提出质量最大化聚类（MMC）算法，通过使用质量分布而非传统的密度分布来克服密度聚类中的高密度偏差问题，能够发现任意形状、大小和密度的簇。


<details>
  <summary>Details</summary>
Motivation: 传统密度分布作为数据描述符存在根本性局限——高密度偏差，这阻碍了发现任意形状、大小和密度的簇。现有密度聚类算法虽然采用不同技术手段来对抗这种偏差，但密度分布的根本限制仍然存在。

Method: 提出质量最大化聚类（MMC）算法，以质量分布作为更好的基础，最大化所有簇的总质量。算法可以轻松修改为最大化总密度，以便比较密度分布与质量分布的根本差异。

Result: MMC算法相比密度最大化聚类的主要优势在于，最大化过程不会偏向密集簇，从而能够更有效地发现任意形状、大小和密度的簇。

Conclusion: 质量分布比密度分布更适合作为聚类的基础描述符，MMC算法通过消除高密度偏差，为发现任意形状、大小和密度的簇提供了更有效的解决方案。

Abstract: This paper investigates two fundamental descriptors of data, i.e., density distribution versus mass distribution, in the context of clustering. Density distribution has been the de facto descriptor of data distribution since the introduction of statistics. We show that density distribution has its fundamental limitation -- high-density bias, irrespective of the algorithms used to perform clustering. Existing density-based clustering algorithms have employed different algorithmic means to counter the effect of the high-density bias with some success, but the fundamental limitation of using density distribution remains an obstacle to discovering clusters of arbitrary shapes, sizes and densities. Using the mass distribution as a better foundation, we propose a new algorithm which maximizes the total mass of all clusters, called mass-maximization clustering (MMC). The algorithm can be easily changed to maximize the total density of all clusters in order to examine the fundamental limitation of using density distribution versus mass distribution. The key advantage of the MMC over the density-maximization clustering is that the maximization is conducted without a bias towards dense clusters.

</details>


### [65] [Memorize Early, Then Query: Inlier-Memorization-Guided Active Outlier Detection](https://arxiv.org/abs/2601.10993)
*Minseo Kang,Seunghwan Park,Dongha Kim*

Main category: stat.ML

TL;DR: IMBoost：一种结合主动学习增强内点记忆效应（IM效应）的两阶段异常检测框架，通过主动查询标签来最大化内点和异常点之间的差异，显著提升检测性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于内点记忆效应（IM效应）的无监督异常检测方法在处理内点与异常点分离不明显或异常点形成密集簇时效果有限。需要一种能够有效利用有限标注预算来增强IM效应的方法。

Method: 提出IMBoost两阶段框架：1）预热阶段诱导和促进IM效应；2）极化阶段使用主动查询的样本来最大化内点和异常点得分之间的差异。设计了新颖的查询策略和定制损失函数来有效识别信息样本并充分利用有限标注预算。

Result: 在多个基准数据集上的实验表明，IMBoost不仅显著优于最先进的主动异常检测方法，而且计算成本大幅降低。理论分析证明IMBoost在训练过程中持续降低内点风险同时增加异常点风险，从而放大它们的分离度。

Conclusion: IMBoost通过主动学习增强内点记忆效应，有效解决了无监督异常检测中内点与异常点分离不明显的问题，提供了一种高效且计算成本低的异常检测解决方案。

Abstract: Outlier detection (OD) aims to identify abnormal instances, known as outliers or anomalies, by learning typical patterns of normal data, or inliers. Performing OD under an unsupervised regime-without any information about anomalous instances in the training data-is challenging. A recently observed phenomenon, known as the inlier-memorization (IM) effect, where deep generative models (DGMs) tend to memorize inlier patterns during early training, provides a promising signal for distinguishing outliers. However, existing unsupervised approaches that rely solely on the IM effect still struggle when inliers and outliers are not well-separated or when outliers form dense clusters. To address these limitations, we incorporate active learning to selectively acquire informative labels, and propose IMBoost, a novel framework that explicitly reinforces the IM effect to improve outlier detection. Our method consists of two stages: 1) a warm-up phase that induces and promotes the IM effect, and 2) a polarization phase in which actively queried samples are used to maximize the discrepancy between inlier and outlier scores. In particular, we propose a novel query strategy and tailored loss function in the polarization phase to effectively identify informative samples and fully leverage the limited labeling budget. We provide a theoretical analysis showing that the IMBoost consistently decreases inlier risk while increasing outlier risk throughout training, thereby amplifying their separation. Extensive experiments on diverse benchmark datasets demonstrate that IMBoost not only significantly outperforms state-of-the-art active OD methods but also requires substantially less computational cost.

</details>


### [66] [Contextual Distributionally Robust Optimization with Causal and Continuous Structure: An Interpretable and Tractable Approach](https://arxiv.org/abs/2601.11016)
*Fenglin Zhang,Jie Wang*

Main category: stat.ML

TL;DR: 提出基于因果Sinkhorn距离的上下文分布鲁棒优化框架，开发可解释且可处理的决策规则，通过软回归森林和高效算法实现优化


<details>
  <summary>Details</summary>
Motivation: 现有分布鲁棒优化方法往往忽略数据的因果结构和连续性特征，缺乏可解释性，需要开发既能考虑因果连续性结构又能提供可解释决策规则的框架

Method: 1) 引入因果Sinkhorn距离(CSD)，一种熵正则化的因果Wasserstein距离；2) 构建基于CSD的上下文DRO模型(Causal-SDRO)；3) 提出软回归森林(SRF)决策规则；4) 开发随机组合梯度算法求解

Result: 1) 推导出Causal-SDRO的强对偶重构，最坏分布表现为Gibbs分布的混合；2) SRF保持决策树可解释性同时具备参数化、可微、Lipschitz光滑特性；3) 算法以O(ε⁻⁴)收敛到ε-稳定点；4) 在合成和真实数据集上验证了优越性能和可解释性

Conclusion: 提出的Causal-SDRO框架成功整合了因果结构、连续性和可解释性，通过CSD、SRF和高效算法实现了既理论严谨又实用的分布鲁棒优化解决方案

Abstract: In this paper, we introduce a framework for contextual distributionally robust optimization (DRO) that considers the causal and continuous structure of the underlying distribution by developing interpretable and tractable decision rules that prescribe decisions using covariates. We first introduce the causal Sinkhorn discrepancy (CSD), an entropy-regularized causal Wasserstein distance that encourages continuous transport plans while preserving the causal consistency. We then formulate a contextual DRO model with a CSD-based ambiguity set, termed Causal Sinkhorn DRO (Causal-SDRO), and derive its strong dual reformulation where the worst-case distribution is characterized as a mixture of Gibbs distributions. To solve the corresponding infinite-dimensional policy optimization, we propose the Soft Regression Forest (SRF) decision rule, which approximates optimal policies within arbitrary measurable function spaces. The SRF preserves the interpretability of classical decision trees while being fully parametric, differentiable, and Lipschitz smooth, enabling intrinsic interpretation from both global and local perspectives. To solve the Causal-SDRO with parametric decision rules, we develop an efficient stochastic compositional gradient algorithm that converges to an $\varepsilon$-stationary point at a rate of $O(\varepsilon^{-4})$, matching the convergence rate of standard stochastic gradient descent. Finally, we validate our method through numerical experiments on synthetic and real-world datasets, demonstrating its superior performance and interpretability.

</details>


### [67] [Split-and-Conquer: Distributed Factor Modeling for High-Dimensional Matrix-Variate Time Series](https://arxiv.org/abs/2601.11091)
*Hangjin Jiang,Yuzhou Li,Zhaoxing Gao*

Main category: stat.ML

TL;DR: 提出了一种用于高维大规模异构矩阵时间序列数据的分布式降维框架，通过因子模型保持矩阵结构，支持行列聚类，并扩展到单位根非平稳序列。


<details>
  <summary>Details</summary>
Motivation: 处理高维、大规模、异构的矩阵时间序列数据时，现有分布式方法通常破坏矩阵的内在结构，导致计算效率低下和信息利用不足。需要一种能够保持矩阵潜在结构的分布式降维方法。

Method: 提出分布式框架：1）数据按列（或行）分区分配到节点服务器；2）各节点通过二维张量PCA估计行（或列）载荷矩阵；3）局部估计传输到中央服务器聚合；4）最终PCA步骤获得全局载荷矩阵估计；5）基于估计的载荷矩阵计算因子矩阵。还讨论了行列聚类程序，并扩展到单位根非平稳矩阵时间序列。

Result: 推导了在计算单元数据维度和样本大小T发散情况下的渐近性质。仿真结果表明所提框架在计算效率和估计精度方面表现优异，真实数据应用进一步验证了其预测性能。

Conclusion: 该分布式框架能够有效处理大规模矩阵时间序列数据，保持矩阵结构优势，提高计算效率和信息利用率，适用于平稳和非平稳序列，并支持未知分组情况下的聚类分析。

Abstract: In this paper, we propose a distributed framework for reducing the dimensionality of high-dimensional, large-scale, heterogeneous matrix-variate time series data using a factor model. The data are first partitioned column-wise (or row-wise) and allocated to node servers, where each node estimates the row (or column) loading matrix via two-dimensional tensor PCA. These local estimates are then transmitted to a central server and aggregated, followed by a final PCA step to obtain the global row (or column) loading matrix estimator. Given the estimated loading matrices, the corresponding factor matrices are subsequently computed. Unlike existing distributed approaches, our framework preserves the latent matrix structure, thereby improving computational efficiency and enhancing information utilization. We also discuss row- and column-wise clustering procedures for settings in which the group memberships are unknown. Furthermore, we extend the analysis to unit-root nonstationary matrix-variate time series. Asymptotic properties of the proposed method are derived for the diverging dimension of the data in each computing unit and the sample size $T$. Simulation results assess the computational efficiency and estimation accuracy of the proposed framework, and real data applications further validate its predictive performance.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [68] [Rigidity theory in statistical inference](https://arxiv.org/abs/2601.10864)
*Daniel Irving Bernstein*

Main category: math.ST

TL;DR: 关于高斯模型最大似然阈值的综述文章，特别关注其与刚性理论的联系


<details>
  <summary>Details</summary>
Motivation: 总结高斯模型最大似然阈值的研究现状，特别是该领域与刚性理论之间的重要联系，为相关研究者提供系统的知识框架

Method: 采用综述性研究方法，系统梳理和分析现有文献中关于高斯模型最大似然阈值的理论结果，重点关注与刚性理论的交叉联系

Result: 文章总结了高斯模型最大似然阈值的已知结果，揭示了该概念与刚性理论之间的深刻数学联系，为理解统计模型的可识别性和参数估计提供了理论框架

Conclusion: 高斯模型的最大似然阈值是一个重要的统计概念，其与刚性理论的联系为研究统计模型的可识别性和参数估计问题提供了新的视角和理论工具

Abstract: In this expository article, we summarize what is known about maximum likelihood thresholds of Gaussian models, paying special attention to connections with rigidity theory.

</details>


### [69] [Noise-resilient penalty operators based on statistical differentiation schemes](https://arxiv.org/abs/2601.11033)
*Marc Vidal,Yves Rosseel*

Main category: math.ST

TL;DR: 提出一种基于数据网格的直接惩罚平滑方法，通过统计校准的差分算子惩罚局部粗糙度，在最小平滑假设下对采样轨迹去噪


<details>
  <summary>Details</summary>
Motivation: 传统惩罚平滑方法通常依赖基函数或核展开，将估计器限制在固定范围内，并对离散观测数据施加可能过于严格的平滑假设。需要一种更灵活的方法来处理离散观测数据

Method: 引入一类直接在数据网格上操作的惩罚估计器，通过统计校准的差分算子惩罚局部粗糙度，在最小平滑假设下对采样轨迹去噪。建立与所得线性平滑器相关的样本对比统计量的分布和渐近性质

Result: 模拟结果表明，所提出的估计器在平滑和局部不规则设置下均表现出竞争力。在模型具有Hellinger可微性（无需函数空间的Fréchet可微性）条件下建立了相关统计性质

Conclusion: 提出了一种更灵活的惩罚平滑框架，直接处理离散数据网格，减少了对传统平滑假设的依赖，在多种数据场景下表现良好

Abstract: Penalized smoothing is a standard tool in regression analysis. Classical approaches often rely on basis or kernel expansions, which constrain the estimator to a fixed span and impose smoothness assumptions that may be restrictive for discretely observed data. We introduce a class of penalized estimators that operate directly on the data grid, denoising sampled trajectories under minimal smoothness assumptions by penalizing local roughness through statistically calibrated difference operators. Some distributional and asymptotic properties of sample-based contrast statistics associated with the resulting linear smoothers are established under Hellinger differentiability of the model, without requiring Fréchet differentiability in function space. Simulation results confirm that the proposed estimators perform competitively across both smooth and locally irregular settings.

</details>


### [70] [Optimal e-values for testing the mean of a bounded random variable against a composite alternative](https://arxiv.org/abs/2601.11347)
*Sebastian Arnold,Eugenio Clerico*

Main category: math.ST

TL;DR: 该论文推导了在测试有界随机变量均值时具有最优（相对）增长率的唯一e值，首次将Grünwald等人（2024）提出的（RE）GROW质量标准应用于非绝对连续假设的情况。


<details>
  <summary>Details</summary>
Motivation: 传统e值质量评估标准（GROW）在某些重要场景下会导致平凡解，需要更强大的质量标准（REGROW）来识别真正有意义的e变量，特别是在非绝对连续假设的测试问题中。

Method: 推导测试有界随机变量均值时在worst-case下具有最优相对增长率的唯一e值，明确表征了最难以检验的备择假设，并展示了REGROW标准在GROW失效场景下的有效性。

Result: 成功推导出具有最优增长率的唯一e值，明确识别了最难以检验的备择假设，并证明REGROW标准在GROW导致平凡解的两个重要示例中提供了强大的质量评估标准。

Conclusion: REGROW标准是比GROW更强大的e值质量评估工具，特别适用于非绝对连续假设的测试问题，能够识别真正有意义的e变量并避免平凡解。

Abstract: We derive the unique e-values with optimal (relative) growth rate in the worst case for testing the mean of a bounded random variable, hereby contributing with the first application beyond the assumption of mutually absolutely continuous hypotheses of the (RE)GROW quality criteria for e-values originally proposed by Grünwald et al. (2024). For both criteria, we characterise explicitly the alternatives for which it is most difficult to test against, which also admit a meaningful interpretation. We give two important examples of interest where REGROW provides a powerful quality criterion to choose optimal e-variables whereas GROW leads to trivial solutions.

</details>


### [71] [Stein's method for the matrix normal distribution](https://arxiv.org/abs/2601.11422)
*Robert E. Gaunt,Frédéric Ouimet,Donald Richards*

Main category: math.ST

TL;DR: 首次系统性地为矩阵分布开发Stein方法，建立矩阵正态逼近的基本框架，包括生成元Stein恒等式、半群解表示和正则性估计，并应用于三个统计问题。


<details>
  <summary>Details</summary>
Motivation: 为矩阵分布建立系统的Stein方法理论框架，填补该领域的空白，为矩阵正态逼近提供统一的数学工具。

Method: 从具有双边尺度的矩阵Ornstein-Uhlenbeck扩散推导生成元Stein恒等式，提供Stein方程的显式半群解表示，并建立解的正则性估计。

Result: 建立了矩阵正态逼近的完整Stein方法理论，包括基本恒等式、解表示和正则性估计，并成功应用于矩阵中心极限定理的Wasserstein距离界、矩阵T分布的矩阵正态逼近以及矩阵正态分布尺度参数的Stein矩估计。

Conclusion: 成功开发了矩阵分布的Stein方法理论，为矩阵正态逼近提供了系统框架，并在统计应用中展示了该方法的实用价值，为未来矩阵分布的理论和应用研究奠定了基础。

Abstract: This work presents the first systematic development of Stein's method for matrix distributions. We establish the basic essential ingredients of Stein's method for matrix normal approximation: we derive a generator-based Stein identity from a matrix Ornstein--Uhlenbeck diffusion with two-sided scales, provide an explicit semigroup representation for the solution of the Stein equation, and obtain regularity estimates for the solution. The new methodology is illustrated with three statistical applications, these being smooth Wasserstein distance bounds to quantify the matrix central limit theorem, a Wasserstein distance bound for the matrix normal approximation of the centered matrix $T$ distribution, and the derivation of Stein's method-of-moments estimators for scale parameters of the matrix normal distribution.

</details>


### [72] [Optimal transport based theory for latent structured models](https://arxiv.org/abs/2601.11465)
*XuanLong Nguyen,Yun Wei*

Main category: math.ST

TL;DR: 本文综述了隐结构模型学习中的最新理论进展，重点探讨最优传输距离在统计理论中的基础作用，特别是逆界（inverse bounds）这一核心概念。


<details>
  <summary>Details</summary>
Motivation: 本文旨在阐述隐结构模型学习中的最新理论进展，特别关注最优传输距离在统计理论中的基础作用。作者认为逆界（inverse bounds）是这一理论中最关键和创新的组成部分，需要深入探讨其动机、表述、推导和影响。

Method: 文章采用理论分析方法，重点阐述逆界这一结构不等式的集合。这些不等式连接了未观测结构兴趣的分布空间与观测数据的分布空间。理论通过经典混合模型以及现代层次模型进行说明，这些模型在贝叶斯统计、机器学习和相关领域中得到发展。

Result: 文章展示了最优传输距离在隐结构模型统计理论中的基础作用，系统阐述了逆界理论框架。该理论为连接隐结构分布空间与观测数据分布空间提供了数学基础，并在经典混合模型和现代层次模型中得到了验证。

Conclusion: 本文系统阐述了隐结构模型学习中的最新理论进展，特别是最优传输距离和逆界理论的核心作用。这一理论框架为理解隐结构模型的统计性质提供了重要工具，并在经典和现代模型中展现出广泛适用性。

Abstract: This article is an exposition on some recent theoretical advances in learning latent structured models, with a primary focus on the fundamental roles that optimal transport distances play in the statistical theory. We aim at what may be the most critical and novel ingredient in this theory: the motivation, formulation, derivation and ramification of inverse bounds, a rich collection of structural inequalities for latent structured models which connect the space of distributions of unobserved structures of interest to the space of distributions for observed data. This theory is illustrated on classical mixture models, as well as the more modern hierarchical models that have been developed in Bayesian statistics, machine learning and related fields.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [73] [When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models](https://arxiv.org/abs/2601.11444)
*Raphaël Razafindralambo,Rémy Sun,Frédéric Precioso,Damien Garreau,Pierre-Alexandre Mattei*

Main category: cs.LG

TL;DR: 扩散模型集成方法研究：虽然集成能改善分数匹配损失和模型似然，但无法一致提升图像生成质量指标（如FID），在表格数据中某些集成策略表现更优


<details>
  <summary>Details</summary>
Motivation: 尽管集成方法在监督学习中已被证明有效，但在无条件分数扩散模型中的应用仍未被充分探索。本研究旨在探究集成方法是否能给生成建模带来实际益处

Method: 使用深度集成、蒙特卡洛Dropout等多种集成策略，在CIFAR-10和FFHQ图像数据集上进行实验，同时通过随机森林在表格数据中验证不同集成策略的效果

Result: 集成分数模型通常能改善分数匹配损失和模型似然，但无法一致提升图像生成质量指标（如FID）。在表格数据中，某些集成策略表现优于其他方法

Conclusion: 扩散模型集成在理论指标上有效，但在实际感知质量提升方面有限。研究还提供了关于分数模型求和的理论见解，这些见解不仅适用于集成，也适用于其他模型组合技术（如引导）

Abstract: Diffusion models now generate high-quality, diverse samples, with an increasing focus on more powerful models. Although ensembling is a well-known way to improve supervised models, its application to unconditional score-based diffusion models remains largely unexplored. In this work we investigate whether it provides tangible benefits for generative modelling. We find that while ensembling the scores generally improves the score-matching loss and model likelihood, it fails to consistently enhance perceptual quality metrics such as FID on image datasets. We confirm this observation across a breadth of aggregation rules using Deep Ensembles, Monte Carlo Dropout, on CIFAR-10 and FFHQ. We attempt to explain this discrepancy by investigating possible explanations, such as the link between score estimation and image quality. We also look into tabular data through random forests, and find that one aggregation strategy outperforms the others. Finally, we provide theoretical insights into the summing of score models, which shed light not only on ensembling but also on several model composition techniques (e.g. guidance).

</details>


### [74] [FSL-BDP: Federated Survival Learning with Bayesian Differential Privacy for Credit Risk Modeling](https://arxiv.org/abs/2601.11134)
*Sultan Amed,Tanmay Sen,Sayantan Banerjee*

Main category: cs.LG

TL;DR: 提出了联邦生存学习框架FSL-BDP，在保护数据隐私的同时联合学习违约时间轨迹，解决了传统违约预测的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统信用风险模型面临两个主要问题：1) 二元分类忽略了违约时间，将早期违约者（高损失）与晚期违约者（低损失）等同对待；2) 集中式训练违反了日益严格的数据保护法规（如GDPR、CCPA），这些法规禁止跨境共享借款人数据，尽管跨机构学习对模型有益。

Method: 提出了联邦生存学习框架FSL-BDP，结合贝叶斯差分隐私。该框架在不集中敏感数据的情况下建模违约时间轨迹，提供贝叶斯（数据依赖）差分隐私保证，同时使金融机构能够联合学习风险动态。

Result: 在三个真实信用数据集（LendingClub、SBA、Bondora）上的实验表明：联邦学习从根本上改变了隐私机制的相对有效性。在集中式设置中，经典差分隐私优于贝叶斯差分隐私，但在联邦设置中，贝叶斯差分隐私获益显著更大（+7.0% vs +1.4%），达到接近非私有性能的水平，并在大多数参与客户端中优于经典差分隐私。

Conclusion: 隐私机制的选择应在目标部署架构中评估，而非基于集中式基准。这些发现为在受监管的多机构环境中设计隐私保护决策支持系统的从业者提供了可操作的指导。

Abstract: Credit risk models are a critical decision-support tool for financial institutions, yet tightening data-protection rules (e.g., GDPR, CCPA) increasingly prohibit cross-border sharing of borrower data, even as these models benefit from cross-institution learning. Traditional default prediction suffers from two limitations: binary classification ignores default timing, treating early defaulters (high loss) equivalently to late defaulters (low loss), and centralized training violates emerging regulatory constraints. We propose a Federated Survival Learning framework with Bayesian Differential Privacy (FSL-BDP) that models time-to-default trajectories without centralizing sensitive data. The framework provides Bayesian (data-dependent) differential privacy (DP) guarantees while enabling institutions to jointly learn risk dynamics. Experiments on three real-world credit datasets (LendingClub, SBA, Bondora) show that federation fundamentally alters the relative effectiveness of privacy mechanisms. While classical DP performs better than Bayesian DP in centralized settings, the latter benefits substantially more from federation (+7.0\% vs +1.4\%), achieving near parity of non-private performance and outperforming classical DP in the majority of participating clients. This ranking reversal yields a key decision-support insight: privacy mechanism selection should be evaluated in the target deployment architecture, rather than centralized benchmarks. These findings provide actionable guidance for practitioners designing privacy-preserving decision support systems in regulated, multi-institutional environments.

</details>


### [75] [Differentially Private Subspace Fine-Tuning for Large Language Models](https://arxiv.org/abs/2601.11113)
*Lele Zheng,Xiang Wang,Tao Zhang,Yang Cao,Ke Cheng,Yulong Shen*

Main category: cs.LG

TL;DR: DP-SFT：一种两阶段子空间微调方法，通过将DP噪声仅注入低维任务特定子空间，在保持差分隐私保证的同时显著降低噪声影响，提升模型性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在下游任务上的微调通常依赖敏感数据，引发隐私担忧。传统差分隐私方法在高维参数空间中注入噪声会产生大范数扰动，导致性能下降和训练不稳定

Method: 提出两阶段子空间微调方法：第一阶段通过分析主梯度方向识别低维任务特定子空间；第二阶段将完整梯度投影到该子空间，添加DP噪声，然后将扰动梯度映射回原始参数空间进行模型更新

Result: 在多个数据集上的实验表明，DP-SFT在严格的DP约束下提高了准确性和稳定性，加速了收敛速度，相比DP微调基线实现了显著性能提升

Conclusion: DP-SFT通过将DP噪声限制在任务相关的低维子空间，有效降低了噪声幅度同时保持形式化隐私保证，为解决隐私保护微调中的性能下降问题提供了有效方案

Abstract: Fine-tuning large language models on downstream tasks is crucial for realizing their cross-domain potential but often relies on sensitive data, raising privacy concerns. Differential privacy (DP) offers rigorous privacy guarantees and has been widely adopted in fine-tuning; however, naively injecting noise across the high-dimensional parameter space creates perturbations with large norms, degrading performance and destabilizing training. To address this issue, we propose DP-SFT, a two-stage subspace fine-tuning method that substantially reduces noise magnitude while preserving formal DP guarantees. Our intuition is that, during fine-tuning, significant parameter updates lie within a low-dimensional, task-specific subspace, while other directions change minimally. Hence, we only inject DP noise into this subspace to protect privacy without perturbing irrelevant parameters. In phase one, we identify the subspace by analyzing principal gradient directions to capture task-specific update signals. In phase two, we project full gradients onto this subspace, add DP noise, and map the perturbed gradients back to the original parameter space for model updates, markedly lowering noise impact. Experiments on multiple datasets demonstrate that DP-SFT enhances accuracy and stability under rigorous DP constraints, accelerates convergence, and achieves substantial gains over DP fine-tuning baselines.

</details>


### [76] [Analytic Bijections for Smooth and Interpretable Normalizing Flows](https://arxiv.org/abs/2601.10774)
*Mathis Gerdes,Miranda C. N. Cheng*

Main category: cs.LG

TL;DR: 提出了三种解析可逆的全局光滑双射函数（三次有理、双曲正弦、三次多项式）和径向流架构，在保持可逆性和雅可比行列式可处理的同时提高了表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有归一化流设计面临权衡：仿射变换平滑且解析可逆但表达能力有限；单调样条提供局部控制但仅分段平滑且定义在有界域上；残差流平滑但需要数值求逆。需要结合各种方法优点的全局平滑、解析可逆的双射函数。

Method: 1. 提出三种解析双射函数族：三次有理函数、双曲正弦函数、三次多项式函数，均全局光滑（C^∞）、定义在整个实数域、具有闭式解析逆。2. 开发径向流架构：通过直接参数化径向坐标变换同时保持角度方向，实现几何可解释的变换。

Result: 1. 在耦合流中作为即插即用替换，匹配或超越样条性能。2. 径向流表现出卓越的训练稳定性，产生几何可解释的变换，对于具有径向结构的目标，能以1000倍更少的参数达到与耦合流相当的质量。3. 在φ^4晶格场理论的高维物理问题中，提出的双射函数优于仿射基线，并能针对特定问题设计解决模式崩溃问题。

Conclusion: 提出的解析双射函数族和径向流架构成功结合了现有方法的优点，提供了全局平滑、解析可逆的解决方案，在保持训练稳定性和几何可解释性的同时显著提高了参数效率，为高维物理问题等应用提供了有效的归一化流设计工具。

Abstract: A key challenge in designing normalizing flows is finding expressive scalar bijections that remain invertible with tractable Jacobians. Existing approaches face trade-offs: affine transformations are smooth and analytically invertible but lack expressivity; monotonic splines offer local control but are only piecewise smooth and act on bounded domains; residual flows achieve smoothness but need numerical inversion. We introduce three families of analytic bijections -- cubic rational, sinh, and cubic polynomial -- that are globally smooth ($C^\infty$), defined on all of $\mathbb{R}$, and analytically invertible in closed form, combining the favorable properties of all prior approaches. These bijections serve as drop-in replacements in coupling flows, matching or exceeding spline performance. Beyond coupling layers, we develop radial flows: a novel architecture using direct parametrization that transforms the radial coordinate while preserving angular direction. Radial flows exhibit exceptional training stability, produce geometrically interpretable transformations, and on targets with radial structure can achieve comparable quality to coupling flows with $1000\times$ fewer parameters. We provide comprehensive evaluation on 1D and 2D benchmarks, and demonstrate applicability to higher-dimensional physics problems through experiments on $φ^4$ lattice field theory, where our bijections outperform affine baselines and enable problem-specific designs that address mode collapse.

</details>


### [77] [Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework](https://arxiv.org/abs/2601.10779)
*Qingyue Zhang,Chang Chu,Haohao Fu,Tianren Peng,Yanru Wu,Guanbo Huang,Yang Li,Shao-Lun Huang*

Main category: cs.LG

TL;DR: 提出UOWQ框架，统一优化多源迁移学习中的源权重和迁移数量，证明充分使用源样本总是最优的，并提供理论分析和实用算法


<details>
  <summary>Details</summary>
Motivation: 传统迁移学习方法通常只优化源权重或迁移数量，而忽略了二者的联合考虑；多源迁移中简单的均匀迁移可能导致负迁移，需要平衡异构源的贡献

Method: 提出UOWQ理论框架，将多源迁移学习建模为基于KL散度泛化误差渐近分析的参数估计问题，联合确定每个源任务的最优权重和最优迁移数量

Result: 理论证明：一旦权重适当调整，使用所有可用源样本总是最优的；单源场景有闭式解，多源场景通过凸优化数值求解；在DomainNet和Office-Home等真实基准测试中持续优于强基线

Conclusion: UOWQ框架为多源迁移学习提供了统一的理论基础和实践指导，通过联合优化权重和数量有效避免了负迁移，在理论和实验上都验证了其有效性

Abstract: Transfer learning plays a vital role in improving model performance in data-scarce scenarios. However, naive uniform transfer from multiple source tasks may result in negative transfer, highlighting the need to properly balance the contributions of heterogeneous sources. Moreover, existing transfer learning methods typically focus on optimizing either the source weights or the amount of transferred samples, while largely neglecting the joint consideration of the other. In this work, we propose a theoretical framework, Unified Optimization of Weights and Quantities (UOWQ), which formulates multi-source transfer learning as a parameter estimation problem grounded in an asymptotic analysis of a Kullback-Leibler divergence-based generalization error measure. The proposed framework jointly determines the optimal source weights and optimal transfer quantities for each source task. Firstly, we prove that using all available source samples is always optimal once the weights are properly adjusted, and we provide a theoretical explanation for this phenomenon. Moreover, to determine the optimal transfer weights, our analysis yields closed-form solutions in the single-source setting and develops a convex optimization-based numerical procedure for the multi-source case. Building on the theoretical results, we further propose practical algorithms for both multi-source transfer learning and multi-task learning settings. Extensive experiments on real-world benchmarks, including DomainNet and Office-Home, demonstrate that UOWQ consistently outperforms strong baselines. The results validate both the theoretical predictions and the practical effectiveness of our framework.

</details>


### [78] [Mugi: Value Level Parallelism For Efficient LLMs](https://arxiv.org/abs/2601.10823)
*Daniel Price,Prabhu Vellaisamy,John Shen,Di Wu*

Main category: cs.LG

TL;DR: 本文提出Mugi架构，通过扩展值级并行性(VLP)来优化大语言模型中的非线性操作和小批量GEMM，显著提升性能、能效和可持续性。


<details>
  <summary>Details</summary>
Motivation: 现有VLP主要针对大批量、低精度、对称激活-权重的GEMM操作，但Transformer大语言模型包含更复杂的非线性操作和小批量场景，需要扩展VLP的应用范围。

Method: 1) 将VLP推广到非线性近似，采用以值为中心的方法，为重要值分配更高精度；2) 优化VLP用于小批量、非对称输入的GEMM，结合权重量化、KV缓存量化和分组查询注意力等优化；3) 设计Mugi架构整合上述创新，支持完整LLM工作负载。

Result: Mugi在非线性softmax操作上实现吞吐量提升45倍、能效提升668倍；在LLM上实现吞吐量提升2.07倍、能效提升3.11倍；同时将运行碳排放降低1.45倍、隐含碳排放降低1.48倍。

Conclusion: 通过扩展VLP到非线性操作和小批量场景，Mugi架构显著提升LLM的性能、能效和可持续性，为高效LLM推理提供了有效的硬件架构解决方案。

Abstract: Value level parallelism (VLP) has been proposed to improve the efficiency of large-batch, low-precision general matrix multiply (GEMM) between symmetric activations and weights. In transformer based large language models (LLMs), there exist more sophisticated operations beyond activation-weight GEMM. In this paper, we explore how VLP benefits LLMs. First, we generalize VLP for nonlinear approximations, outperforming existing nonlinear approximations in end-to-end LLM accuracy, performance, and efficiency. Our VLP approximation follows a value-centric approach, where important values are assigned with greater accuracy. Second, we optimize VLP for small-batch GEMMs with asymmetric inputs efficiently, which leverages timely LLM optimizations, including weight-only quantization, key-value (KV) cache quantization, and group query attention. Finally, we design a new VLP architecture, Mugi, to encapsulate the innovations above and support full LLM workloads, while providing better performance, efficiency and sustainability. Our experimental results show that Mugi can offer significant improvements on throughput and energy efficiency, up to $45\times$ and $668\times$ for nonlinear softmax operations, and $2.07\times$ and $3.11\times$ for LLMs, and also decrease operational carbon for LLM operation by $1.45\times$ and embodied carbon by $1.48\times$.

</details>


### [79] [AI-Guided Human-In-the-Loop Inverse Design of High Performance Engineering Structures](https://arxiv.org/abs/2601.10859)
*Dat Quoc Ha,Md Ferdous Alam,Markus J. Buehler,Faez Ahmed,Josephine V. Carstensen*

Main category: cs.LG

TL;DR: 提出一种AI协同拓扑优化方法，通过机器学习预测用户偏好的修改区域，减少人工迭代次数，提高设计效率


<details>
  <summary>Details</summary>
Motivation: 传统拓扑优化计算时间长且黑箱特性阻碍用户交互，现有的人机协同方法依赖耗时的迭代区域选择，需要减少迭代次数

Method: 采用U-Net架构的图像分割模型，在合成数据集上训练预测用户偏好区域（最长拓扑构件或最复杂结构连接），作为AI推荐呈现给用户

Result: 模型成功预测合理的修改区域，在多样化和非标准拓扑优化问题中展现泛化能力，并表现出超出单区域选择训练数据的涌现行为

Conclusion: 集成AI协同的人机拓扑优化方法可改善可制造性或提高线性屈曲载荷39%，总设计时间仅增加15秒，相比传统方法显著提升效率

Abstract: Inverse design tools such as Topology Optimization (TO) can achieve new levels of improvement for high-performance engineered structures. However, widespread use is hindered by high computational times and a black-box nature that inhibits user interaction. Human-in-the-loop TO approaches are emerging that integrate human intuition into the design generation process. However, these rely on the time-consuming bottleneck of iterative region selection for design modifications. To reduce the number of iterative trials, this contribution presents an AI co-pilot that uses machine learning to predict the user's preferred regions. The prediction model is configured as an image segmentation task with a U-Net architecture. It is trained on synthetic datasets where human preferences either identify the longest topological member or the most complex structural connection. The model successfully predicts plausible regions for modification and presents them to the user as AI recommendations. The human preference model demonstrates generalization across diverse and non-standard TO problems and exhibits emergent behavior outside the single-region selection training data. Demonstration examples show that the new human-in-the-loop TO approach that integrates the AI co-pilot can improve manufacturability or improve the linear buckling load by 39% while only increasing the total design time by 15 sec compared to conventional simplistic TO.

</details>


### [80] [Beyond Accuracy: A Stability-Aware Metric for Multi-Horizon Forecasting](https://arxiv.org/abs/2601.10863)
*Chutian Ma,Grigorii Pomazkin,Giacinto Paolo Saggese,Paul Smith*

Main category: cs.LG

TL;DR: 提出了一种新的概率多步预测质量评估指标——预测准确性与一致性评分（AC评分），该指标同时考虑多步预测精度和稳定性，并允许用户自定义精度与一致性权重。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法仅优化预测精度，忽视了时间一致性（即随着预测起点变化，模型对同一未来事件预测的一致性）。这种单一目标忽略了预测稳定性在实际应用中的重要性。

Method: 引入预测准确性与一致性评分（AC评分），该评分可衡量概率多步预测质量，同时考虑多步预测精度和稳定性。评分允许用户指定权重来平衡精度和一致性要求。作为应用示例，将AC评分实现为可微目标函数，用于训练季节性ARIMA模型。

Result: 在M4 Hourly基准数据集上的评估结果显示，与传统最大似然估计相比，AC优化模型在保持相当或改进的点预测精度的同时，对相同目标时间戳的预测波动性降低了75%。

Conclusion: 提出的AC评分为概率多步预测提供了更全面的质量评估框架，既考虑预测精度又考虑时间一致性。通过将AC评分作为可微目标函数，能够显著提高预测稳定性而不牺牲精度，为时间序列预测提供了更实用的优化目标。

Abstract: Traditional time series forecasting methods optimize for accuracy alone. This objective neglects temporal consistency, in other words, how consistently a model predicts the same future event as the forecast origin changes. We introduce the forecast accuracy and coherence score (forecast AC score for short) for measuring the quality of probabilistic multi-horizon forecasts in a way that accounts for both multi-horizon accuracy and stability. Our score additionally provides for user-specified weights to balance accuracy and consistency requirements. As an example application, we implement the score as a differentiable objective function for training seasonal ARIMA models and evaluate it on the M4 Hourly benchmark dataset. Results demonstrate substantial improvements over traditional maximum likelihood estimation. Our AC-optimized models achieve a 75\% reduction in forecast volatility for the same target timestamps while maintaining comparable or improved point forecast accuracy.

</details>


### [81] [Action Shapley: A Training Data Selection Metric for World Model in Reinforcement Learning](https://arxiv.org/abs/2601.10905)
*Rajat Ghosh,Debojyoti Dutta*

Main category: cs.LG

TL;DR: 提出Action Shapley作为训练数据选择的公平度量，并设计随机动态算法以降低指数复杂度，在五个真实案例中验证了80%以上的计算效率提升和更好的数据选择效果。


<details>
  <summary>Details</summary>
Motivation: 在离线强化学习和基于模型的强化学习中，世界模型的质量对系统效能和可解释性至关重要，而训练数据质量直接影响世界模型性能。当直接与环境交互成本高、危险或不切实际时，需要一种公平、无偏的训练数据选择方法。

Method: 提出Action Shapley作为与模型无关的训练数据选择度量，并设计随机动态算法来降低传统Shapley值计算的指数复杂度。该算法通过随机化策略减少计算负担，同时保持选择质量。

Result: 在五个数据受限的真实世界案例研究中，算法相比传统指数时间计算实现了超过80%的计算效率提升。基于Action Shapley的训练数据选择策略持续优于临时性的数据选择方法。

Conclusion: Action Shapley为世界模型的训练数据选择提供了有效的公平度量，其随机动态算法显著降低了计算复杂度，在实际应用中展现出优越的计算效率和选择性能。

Abstract: Numerous offline and model-based reinforcement learning systems incorporate world models to emulate the inherent environments. A world model is particularly important in scenarios where direct interactions with the real environment is costly, dangerous, or impractical. The efficacy and interpretability of such world models are notably contingent upon the quality of the underlying training data. In this context, we introduce Action Shapley as an agnostic metric for the judicious and unbiased selection of training data. To facilitate the computation of Action Shapley, we present a randomized dynamic algorithm specifically designed to mitigate the exponential complexity inherent in traditional Shapley value computations. Through empirical validation across five data-constrained real-world case studies, the algorithm demonstrates a computational efficiency improvement exceeding 80\% in comparison to conventional exponential time computations. Furthermore, our Action Shapley-based training data selection policy consistently outperforms ad-hoc training data selection.

</details>


### [82] [Realistic Curriculum Reinforcement Learning for Autonomous and Sustainable Marine Vessel Navigation](https://arxiv.org/abs/2601.10911)
*Zhang Xiaocai,Xiao Zhe,Liang Maohan,Liu Tao,Li Haijiang,Zhang Wenbin*

Main category: cs.LG

TL;DR: 提出一个结合课程强化学习、数据驱动海洋仿真环境和机器学习燃料预测的框架，用于实现可持续和安全的海上船舶导航。


<details>
  <summary>Details</summary>
Motivation: 海上运输的可持续性日益重要，传统船舶导航依赖人工经验，缺乏自主性和排放意识，易出现人为错误影响安全和环境。

Method: 提出课程强化学习框架，集成数据驱动的海洋仿真环境（使用真实船舶运动数据和扩散模型模拟动态条件）、基于机器学习的燃料消耗预测模块、图像化环境表示，以及考虑安全、排放、时效性和目标完成的综合奖励机制。

Result: 在印度洋海域验证了该方法的有效性，能够实现可持续和安全的船舶导航。

Conclusion: 该框架通过渐进式学习处理复杂任务，在连续动作空间中实现稳定高效学习，为可持续海上运输提供了有效解决方案。

Abstract: Sustainability is becoming increasingly critical in the maritime transport, encompassing both environmental and social impacts, such as Greenhouse Gas (GHG) emissions and navigational safety. Traditional vessel navigation heavily relies on human experience, often lacking autonomy and emission awareness, and is prone to human errors that may compromise safety. In this paper, we propose a Curriculum Reinforcement Learning (CRL) framework integrated with a realistic, data-driven marine simulation environment and a machine learning-based fuel consumption prediction module. The simulation environment is constructed using real-world vessel movement data and enhanced with a Diffusion Model to simulate dynamic maritime conditions. Vessel fuel consumption is estimated using historical operational data and learning-based regression. The surrounding environment is represented as image-based inputs to capture spatial complexity. We design a lightweight, policy-based CRL agent with a comprehensive reward mechanism that considers safety, emissions, timeliness, and goal completion. This framework effectively handles complex tasks progressively while ensuring stable and efficient learning in continuous action spaces. We validate the proposed approach in a sea area of the Indian Ocean, demonstrating its efficacy in enabling sustainable and safe vessel navigation.

</details>


### [83] [FAConvLSTM: Factorized-Attention ConvLSTM for Efficient Feature Extraction in Multivariate Climate Data](https://arxiv.org/abs/2601.10914)
*Francis Ndikum Nji,Jianwu Wang*

Main category: cs.LG

TL;DR: FAConvLSTM是一种改进的ConvLSTM2D层，通过因子化注意力机制、多尺度深度可分离卷积和轴向空间注意力，在保持循环动态的同时显著降低计算成本，提升空间表达能力和物理可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统ConvLSTM2D在处理高分辨率多元地球观测数据时面临挑战：密集卷积门控计算成本高，局部感受野限制了对长程空间结构和解耦气候动态的建模。需要一种既能保持效率又能提升空间表达和物理可解释性的替代方案。

Method: 提出FAConvLSTM作为ConvLSTM2D的即插即用替代层，采用因子化门控计算（轻量级1×1瓶颈和共享深度空间混合）、多尺度扩张深度可分离分支、挤压-激励重校准、窥视孔连接、稀疏时间应用的轻量级轴向空间注意力机制，以及具有固定季节性位置编码的时间自注意力精炼的专用子空间头。

Result: 在多元时空气候数据上的实验表明，FAConvLSTM相比标准ConvLSTM能产生更稳定、可解释和鲁棒的潜在表示，同时显著降低计算开销。

Conclusion: FAConvLSTM通过因子化注意力设计有效解决了ConvLSTM2D在效率、空间表达和物理可解释性方面的局限性，为地球观测数据的时空表示学习提供了更优的解决方案。

Abstract: Learning physically meaningful spatiotemporal representations from high-resolution multivariate Earth observation data is challenging due to strong local dynamics, long-range teleconnections, multi-scale interactions, and nonstationarity. While ConvLSTM2D is a commonly used baseline, its dense convolutional gating incurs high computational cost and its strictly local receptive fields limit the modeling of long-range spatial structure and disentangled climate dynamics. To address these limitations, we propose FAConvLSTM, a Factorized-Attention ConvLSTM layer designed as a drop-in replacement for ConvLSTM2D that simultaneously improves efficiency, spatial expressiveness, and physical interpretability. FAConvLSTM factorizes recurrent gate computations using lightweight [1 times 1] bottlenecks and shared depthwise spatial mixing, substantially reducing channel complexity while preserving recurrent dynamics. Multi-scale dilated depthwise branches and squeeze-and-excitation recalibration enable efficient modeling of interacting physical processes across spatial scales, while peephole connections enhance temporal precision. To capture teleconnection-scale dependencies without incurring global attention cost, FAConvLSTM incorporates a lightweight axial spatial attention mechanism applied sparsely in time. A dedicated subspace head further produces compact per timestep embeddings refined through temporal self-attention with fixed seasonal positional encoding. Experiments on multivariate spatiotemporal climate data shows superiority demonstrating that FAConvLSTM yields more stable, interpretable, and robust latent representations than standard ConvLSTM, while significantly reducing computational overhead.

</details>


### [84] [HOSL: Hybrid-Order Split Learning for Memory-Constrained Edge Training](https://arxiv.org/abs/2601.10940)
*Aakriti,Zhe Li,Dandan Liang,Chao Huang,Rui Li,Haibo Yang*

Main category: cs.LG

TL;DR: HOSL：一种混合阶分割学习框架，通过在客户端使用零阶优化（减少内存）和服务器端使用一阶优化（保证性能），解决分割学习中内存效率与优化效果之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有分割学习系统主要依赖一阶优化，需要客户端存储激活值等中间量，导致内存开销大，削弱了模型分割的优势。零阶优化虽然减少内存使用，但收敛慢且性能下降。需要解决内存效率与优化效果之间的根本权衡。

Method: 提出HOSL混合阶分割学习框架：客户端采用内存高效的零阶梯度估计，消除反向传播和激活值存储；服务器端采用一阶优化确保快速收敛和竞争力性能。理论证明收敛率取决于客户端模型维度而非完整模型维度。

Result: 在OPT模型（125M和1.3B参数）的6个任务上实验表明：HOSL相比一阶方法减少客户端GPU内存达3.7倍，同时准确率仅比基线低0.20%-4.23%；相比零阶基线性能提升达15.55%，验证了混合策略在边缘设备内存高效训练中的有效性。

Conclusion: HOSL成功解决了分割学习中内存效率与优化效果之间的权衡，通过客户端零阶优化和服务器端一阶优化的混合策略，在显著减少客户端内存消耗的同时保持了接近一阶方法的性能，为资源受限边缘设备上的大语言模型协作训练提供了有效解决方案。

Abstract: Split learning (SL) enables collaborative training of large language models (LLMs) between resource-constrained edge devices and compute-rich servers by partitioning model computation across the network boundary. However, existing SL systems predominantly rely on first-order (FO) optimization, which requires clients to store intermediate quantities such as activations for backpropagation. This results in substantial memory overhead, largely negating benefits of model partitioning. In contrast, zeroth-order (ZO) optimization eliminates backpropagation and significantly reduces memory usage, but often suffers from slow convergence and degraded performance. In this work, we propose HOSL, a novel Hybrid-Order Split Learning framework that addresses this fundamental trade-off between memory efficiency and optimization effectiveness by strategically integrating ZO optimization on the client side with FO optimization on the server side. By employing memory-efficient ZO gradient estimation at the client, HOSL eliminates backpropagation and activation storage, reducing client memory consumption. Meanwhile, server-side FO optimization ensures fast convergence and competitive performance. Theoretically, we show that HOSL achieves a $\mathcal{O}(\sqrt{d_c/TQ})$ rate, which depends on client-side model dimension $d_c$ rather than the full model dimension $d$, demonstrating that convergence improves as more computation is offloaded to the server. Extensive experiments on OPT models (125M and 1.3B parameters) across 6 tasks demonstrate that HOSL reduces client GPU memory by up to 3.7$\times$ compared to the FO method while achieving accuracy within 0.20%-4.23% of this baseline. Furthermore, HOSL outperforms the ZO baseline by up to 15.55%, validating the effectiveness of our hybrid strategy for memory-efficient training on edge devices.

</details>


### [85] [Transient learning dynamics drive escape from sharp valleys in Stochastic Gradient Descent](https://arxiv.org/abs/2601.10962)
*Ning Yang,Yikuan Zhang,Qi Ouyang,Chao Tang,Yuhai Tu*

Main category: cs.LG

TL;DR: SGD通过非平衡机制选择平坦解：噪声重塑损失景观为有效势能，瞬态探索阶段后冻结机制将轨迹困于平坦区域，增强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 理解SGD偏好平坦、泛化能力强的解的动力学起源，揭示学习动力学、损失景观几何与泛化之间的物理联系。

Method: 通过数值实验分析SGD学习动力学，使用可处理的物理模型证明SGD噪声将损失景观重塑为有效势能，揭示瞬态冻结机制。

Result: SGD轨迹经历瞬态探索阶段，反复逃离尖锐谷并转向平坦区域；噪声重塑景观形成偏好平坦解的有效势能；随训练进行，能量壁垒增长导致冻结机制，将动态困于单个盆地；增加SGD噪声强度延迟冻结，促进收敛到更平坦极小值。

Conclusion: 研究提供了连接学习动力学、损失景观几何和泛化的统一物理框架，为设计更有效的优化算法提供了原理指导。

Abstract: Stochastic gradient descent (SGD) is central to deep learning, yet the dynamical origin of its preference for flatter, more generalizable solutions remains unclear. Here, by analyzing SGD learning dynamics, we identify a nonequilibrium mechanism governing solution selection. Numerical experiments reveal a transient exploratory phase in which SGD trajectories repeatedly escape sharp valleys and transition toward flatter regions of the loss landscape. By using a tractable physical model, we show that the SGD noise reshapes the landscape into an effective potential that favors flat solutions. Crucially, we uncover a transient freezing mechanism: as training proceeds, growing energy barriers suppress inter-valley transitions and ultimately trap the dynamics within a single basin. Increasing the SGD noise strength delays this freezing, which enhances convergence to flatter minima. Together, these results provide a unified physical framework linking learning dynamics, loss-landscape geometry, and generalization, and suggest principles for the design of more effective optimization algorithms.

</details>


### [86] [Toward Adaptive Grid Resilience: A Gradient-Free Meta-RL Framework for Critical Load Restoration](https://arxiv.org/abs/2601.10973)
*Zain ul Abdeen,Waris Gill,Ming Jin*

Main category: cs.LG

TL;DR: MGF-RL框架结合元学习和进化策略，实现无需梯度的可迁移策略初始化，快速适应新故障场景，提升配电网恢复的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 极端事件后恢复关键负荷需要自适应控制，但可再生能源不确定性、可调度资源有限以及非线性动态使得有效恢复困难。标准强化学习泛化能力差，需要大量重新训练适应新故障配置。

Method: 提出元引导无梯度强化学习框架，结合一阶元学习和进化策略，从历史故障经验中学习可迁移初始化策略，无需梯度计算即可快速适应未见场景，适应非线性约束的配电网动态。

Result: 在IEEE 13总线和IEEE 123总线测试系统中，MGF-RL在可靠性、恢复速度和适应效率方面优于标准RL、基于MAML的元RL和模型预测控制，泛化到未见故障和可再生能源模式，需要更少的微调回合。

Conclusion: MGF-RL通过元学习和进化策略的结合，提供了可证明的亚线性遗憾界，支持其在可再生能源丰富的配电网中实时负荷恢复的应用，展示了优越的适应效率和泛化能力。

Abstract: Restoring critical loads after extreme events demands adaptive control to maintain distribution-grid resilience, yet uncertainty in renewable generation, limited dispatchable resources, and nonlinear dynamics make effective restoration difficult. Reinforcement learning (RL) can optimize sequential decisions under uncertainty, but standard RL often generalizes poorly and requires extensive retraining for new outage configurations or generation patterns. We propose a meta-guided gradient-free RL (MGF-RL) framework that learns a transferable initialization from historical outage experiences and rapidly adapts to unseen scenarios with minimal task-specific tuning. MGF-RL couples first-order meta-learning with evolutionary strategies, enabling scalable policy search without gradient computation while accommodating nonlinear, constrained distribution-system dynamics. Experiments on IEEE 13-bus and IEEE 123-bus test systems show that MGF-RL outperforms standard RL, MAML-based meta-RL, and model predictive control across reliability, restoration speed, and adaptation efficiency under renewable forecast errors. MGF-RL generalizes to unseen outages and renewable patterns while requiring substantially fewer fine-tuning episodes than conventional RL. We also provide sublinear regret bounds that relate adaptation efficiency to task similarity and environmental variation, supporting the empirical gains and motivating MGF-RL for real-time load restoration in renewable-rich distribution grids.

</details>


### [87] [Reasoning Distillation for Lightweight Automated Program Repair](https://arxiv.org/abs/2601.10987)
*Aanand Balasubramanian,Sashank Silwal*

Main category: cs.LG

TL;DR: 轻量级符号推理监督能提升紧凑型自动程序修复模型中的修复类型分类性能


<details>
  <summary>Details</summary>
Motivation: 小型代码模型适合资源受限环境，但通常只产生单一预测，不清楚它们是否学习有意义的程序结构还是依赖浅层相关性

Method: 提出推理蒸馏方法：大型教师模型提供结构化符号推理标签和修复类型标签；在IntroClass基准上训练CodeT5学生模型，比较纯标签训练和推理蒸馏训练

Result: 推理监督持续提升宏观平均性能，特别是在较少出现的错误类别上，且不增加模型大小或复杂度；正确推理轨迹与正确预测强相关但不完全决定预测

Conclusion: 符号推理蒸馏是提升轻量级程序修复模型可解释性和鲁棒性的实用方法

Abstract: We study whether lightweight symbolic reasoning supervision can improve fix type classification in compact automated program repair models. Small code models are attractive for resource-constrained settings, but they typically produce only a single prediction, making it unclear whether they learn meaningful program structure or rely on shallow correlations. We propose a reasoning distillation approach in which a large teacher model provides structured symbolic reasoning tags alongside fix-type labels. These tags capture high-level causal properties of bugs without relying on free-form explanations. We train a CodeT5-based student model under label-only and reasoning-distilled settings on the IntroClass benchmark. Reasoning supervision consistently improves macro averaged performance, particularly on less frequent bug categories, without increasing model size or complexity. We further analyze the relationship between reasoning accuracy and fix-type prediction, showing that correct reasoning traces strongly correlate with correct predictions, while not fully determining them. Our results suggest that symbolic reasoning distillation is a practical way to improve interpretability and robustness in lightweight program repair models.

</details>


### [88] [Constant Metric Scaling in Riemannian Computation](https://arxiv.org/abs/2601.10992)
*Kisung You*

Main category: cs.LG

TL;DR: 该论文澄清了黎曼度量常数缩放的计算意义：区分了会变化的量（范数、距离、体积、梯度大小）和不变的几何对象（联络、测地线、指数映射等），并讨论了在黎曼优化中缩放可解释为步长调整而非几何修改。


<details>
  <summary>Details</summary>
Motivation: 在计算设置中，黎曼度量的常数缩放经常出现，但实践中其后果并不总是清晰，可能与曲率变化、流形结构变化或坐标表示变化混淆。作者旨在澄清常数缩放如何在不改变几何结构的情况下引入到黎曼计算中。

Method: 作者提供了关于任意黎曼流形上常数度量缩放的简短、自包含的论述。通过理论分析区分了在常数缩放下变化的量和不变量，并讨论了这些区分在黎曼优化中的具体含义。

Result: 明确了常数度量缩放的影响：范数、距离、体积元素、梯度大小会按比例变化；而Levi-Civita联络、测地线、指数和对数映射、平行移动等几何对象保持不变。在黎曼优化中，这种缩放可解释为步长的全局重新缩放。

Conclusion: 常数度量缩放可以在不改变底层几何结构的情况下引入黎曼计算中。该说明旨在澄清全局度量尺度参数如何在不影响黎曼方法所依赖的几何结构的前提下被引入，这对黎曼优化等计算应用具有重要意义。

Abstract: Constant rescaling of a Riemannian metric appears in many computational settings, often through a global scale parameter that is introduced either explicitly or implicitly. Although this operation is elementary, its consequences are not always made clear in practice and may be confused with changes in curvature, manifold structure, or coordinate representation. In this note we provide a short, self-contained account of constant metric scaling on arbitrary Riemannian manifolds. We distinguish between quantities that change under such a scaling, including norms, distances, volume elements, and gradient magnitudes, and geometric objects that remain invariant, such as the Levi--Civita connection, geodesics, exponential and logarithmic maps, and parallel transport. We also discuss implications for Riemannian optimization, where constant metric scaling can often be interpreted as a global rescaling of step sizes rather than a modification of the underlying geometry. The goal of this note is purely expository and is intended to clarify how a global metric scale parameter can be introduced in Riemannian computation without altering the geometric structures on which these methods rely.

</details>


### [89] [Backdoor Attacks on Multi-modal Contrastive Learning](https://arxiv.org/abs/2601.11006)
*Simi D Kuniyilh,Rita Machacy*

Main category: cs.LG

TL;DR: 本文对对比学习中的后门攻击进行了全面比较性综述，分析了威胁模型、攻击方法、目标领域和现有防御措施，强调了对比学习的特定脆弱性并讨论了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 对比学习已成为跨领域自监督表示学习的主流方法，但近期研究表明其易受后门和数据投毒攻击。攻击者可通过操纵预训练数据或模型更新插入恶意行为，这对工业和分布式环境中的系统安全部署构成严重威胁。

Method: 采用系统性文献综述方法，对对比学习中的后门攻击进行综合分析。通过比较不同威胁模型、攻击技术、目标领域（视觉、多模态、图、联邦学习等）和防御策略，构建完整的攻击-防御框架。

Result: 总结了该领域最新进展，识别了对比学习特有的脆弱性（如自监督预训练阶段的攻击面更广），揭示了现有防御措施的局限性，并建立了系统的攻击分类和分析框架。

Conclusion: 对比学习的后门攻击研究对安全部署至关重要。本文通过全面综述为研究者提供了清晰的领域概览，指出了当前挑战（如攻击检测困难、防御有效性有限），并提出了未来研究方向，包括更鲁棒的对比学习框架和自适应防御机制。

Abstract: Contrastive learning has become a leading self- supervised approach to representation learning across domains, including vision, multimodal settings, graphs, and federated learning. However, recent studies have shown that contrastive learning is susceptible to backdoor and data poisoning attacks. In these attacks, adversaries can manipulate pretraining data or model updates to insert hidden malicious behavior. This paper offers a thorough and comparative review of backdoor attacks in contrastive learning. It analyzes threat models, attack methods, target domains, and available defenses. We summarize recent advancements in this area, underline the specific vulnerabilities inherent to contrastive learning, and discuss the challenges and future research directions. Our findings have significant implications for the secure deployment of systems in industrial and distributed environments.

</details>


### [90] [Combating Spurious Correlations in Graph Interpretability via Self-Reflection](https://arxiv.org/abs/2601.11021)
*Kecheng Cai,Chenyang Xu,Chao Peng*

Main category: cs.LG

TL;DR: 本文提出了一种自反思框架，用于提升图学习模型在具有虚假相关性的Spurious-Motif基准数据集上的可解释性，通过反馈机制迭代评估节点和边的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有可解释图学习方法在包含虚假相关性的Spurious-Motif基准上表现显著较差，需要开发能够更好区分真实相关结构与误导性模式的方法。

Method: 提出自反思框架，将现有方法的节点和边重要性评分反馈回原始方法进行第二轮评估，模仿大语言模型的自反思提示机制，并基于此反馈机制提出微调训练方法。

Result: 自反思技术能有效提升模型在具有强虚假相关性数据集上的可解释性表现，通过迭代评估改善重要性评分的准确性。

Conclusion: 自反思框架可集成到现有可解释图学习方法中，通过反馈机制增强模型对虚假相关性的鲁棒性，为图表示学习提供了新的改进方向。

Abstract: Interpretable graph learning has recently emerged as a popular research topic in machine learning. The goal is to identify the important nodes and edges of an input graph that are crucial for performing a specific graph reasoning task. A number of studies have been conducted in this area, and various benchmark datasets have been proposed to facilitate evaluation. Among them, one of the most challenging is the Spurious-Motif benchmark, introduced at ICLR 2022. The datasets in this synthetic benchmark are deliberately designed to include spurious correlations, making it particularly difficult for models to distinguish truly relevant structures from misleading patterns. As a result, existing methods exhibit significantly worse performance on this benchmark compared to others.
  In this paper, we focus on improving interpretability on the challenging Spurious-Motif datasets. We demonstrate that the self-reflection technique, commonly used in large language models to tackle complex tasks, can also be effectively adapted to enhance interpretability in datasets with strong spurious correlations. Specifically, we propose a self-reflection framework that can be integrated with existing interpretable graph learning methods. When such a method produces importance scores for each node and edge, our framework feeds these predictions back into the original method to perform a second round of evaluation. This iterative process mirrors how large language models employ self-reflective prompting to reassess their previous outputs. We further analyze the reasons behind this improvement from the perspective of graph representation learning, which motivates us to propose a fine-tuning training method based on this feedback mechanism.

</details>


### [91] [AVP-Pro: An Adaptive Multi-Modal Fusion and Contrastive Learning Approach for Comprehensive Two-Stage Antiviral Peptide Identification](https://arxiv.org/abs/2601.11028)
*Xinru Wen,Weizhong Lin,zi liu,Xuan Xiao*

Main category: cs.LG

TL;DR: AVP-Pro：基于自适应特征融合和对比学习的抗病毒肽预测框架，通过两阶段方法实现高精度识别和功能亚型分类


<details>
  <summary>Details</summary>
Motivation: 现有抗病毒肽（AVP）识别方法在捕捉复杂序列依赖性和区分高相似度样本方面存在局限，需要更有效的预测工具来支持新型药物开发

Method: 提出两阶段预测框架：第一阶段采用全景特征空间（10种描述符）和分层融合架构（自注意力+自适应门控机制）整合CNN局部基序和BiLSTM全局依赖；第二阶段采用BLOSUM62增强的OHEM对比学习策略，结合迁移学习实现小样本条件下的功能亚型分类

Result: 第一阶段通用AVP识别准确率0.9531，MCC 0.9064，优于现有SOTA方法；第二阶段成功分类6个病毒家族和8种特定病毒；提供用户友好的Web界面

Conclusion: AVP-Pro为抗病毒药物高通量筛选提供了强大且可解释的新工具，通过自适应特征融合和对比学习有效解决了序列依赖性和样本相似性问题

Abstract: The accurate identification of antiviral peptides (AVPs) is crucial for novel drug development. However, existing methods still have limitations in capturing complex sequence dependencies and distinguishing confusing samples with high similarity. To address these challenges, we propose AVP-Pro, a novel two-stage predictive framework that integrates adaptive feature fusion and contrastive learning. To comprehensively capture the physicochemical properties and deep-seated patterns of peptide sequences, we constructed a panoramic feature space encompassing 10 distinct descriptors and designed a hierarchical fusion architecture. This architecture integrates self-attention and adaptive gating mechanisms to dynamically modulate the weights of local motifs extracted by CNNs and global dependencies captured by BiLSTMs based on sequence context. Targeting the blurred decision boundary caused by the high similarity between positive and negative sample sequences, we adopted an Online Hard Example Mining (OHEM)-driven contrastive learning strategy enhanced by BLOSUM62. This approach significantly sharpened the model's discriminative power. Model evaluation results show that in the first stage of general AVP identification, the model achieved an accuracy of 0.9531 and an MCC of 0.9064, outperforming existing state-of-the-art (SOTA) methods. In the second stage of functional subtype prediction, combined with a transfer learning strategy, the model realized accurate classification of 6 viral families and 8 specific viruses under small-sample conditions. AVP-Pro provides a powerful and interpretable new tool for the high-throughput screening of antiviral drugs. To further enhance accessibility for users, we have developed a user-friendly web interface, which is available at https://wwwy1031-avp-pro.hf.space.

</details>


### [92] [OpFML: Pipeline for ML-based Operational Forecasting](https://arxiv.org/abs/2601.11046)
*Shahbaz Alvi,Giusy Fedele,Gabriele Accarino,Italo Epicoco,Ilenia Manco,Pasquale Schiano*

Main category: cs.LG

TL;DR: OpFML是一个用于周期性预测的可配置机器学习管道，应用于火灾危险指数预测


<details>
  <summary>Details</summary>
Motivation: 机器学习在气候和地球科学中应用日益广泛，传统野火风险评估方法常高估风险，需要更有效的操作预测系统

Method: 开发了OpFML：一个可配置、可适应的机器学习管道，用于周期性预测，并应用于每日火灾危险指数预测

Result: 提出了OpFML管道，展示了其在火灾危险指数预测中的应用能力，并概述了其各种功能特性

Conclusion: OpFML为基于机器学习的操作预测提供了一个灵活、可配置的解决方案，特别适用于野火危险评估等周期性预测任务

Abstract: Machine learning is finding its application in a multitude of areas in science and research, and Climate and Earth Sciences is no exception to this trend. Operational forecasting systems based on data-driven approaches and machine learning methods deploy models for periodic forecasting. Wildfire danger assessment using machine learning has garnered significant interest in the last decade, as conventional methods often overestimate the risk of wildfires. In this work, we present the code OpFML: Operational Forecasting with Machine Learning. OpFML is a configurable and adaptable pipeline that can be utilized to serve a machine learning model for periodic forecasting. We further demonstrate the capabilities of the pipeline through its application to daily Fire Danger Index forecasting and outline its various features.

</details>


### [93] [Soft Bayesian Context Tree Models for Real-Valued Time Series](https://arxiv.org/abs/2601.11079)
*Shota Saito,Yuta Nakahara,Toshiyasu Matsushima*

Main category: cs.LG

TL;DR: 提出Soft-BCT模型，这是一种用于实值时间序列的新型贝叶斯上下文树模型，采用软（概率）分割而非硬分割，基于变分推断进行学习，在真实数据集上表现优于或与先前BCT相当。


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯上下文树（BCT）模型对实值时间序列使用硬（确定性）上下文空间分割，这可能限制了模型的灵活性和表达能力。需要一种能够进行软（概率）分割的模型来更好地捕捉时间序列的复杂依赖结构。

Method: 提出Soft-BCT模型，采用概率分割而非确定性分割上下文空间。基于变分推断开发学习算法，通过概率方式处理上下文划分，提高模型灵活性。

Result: 在多个真实世界数据集上，Soft-BCT表现出与先前BCT相当或更优的性能，验证了软分割方法的有效性。

Conclusion: Soft-BCT通过引入软分割机制扩展了BCT模型在实值时间序列中的应用，提供了更灵活的概率建模框架，在实际应用中表现出良好性能。

Abstract: This paper proposes the soft Bayesian context tree model (Soft-BCT), which is a novel BCT model for real-valued time series. The Soft-BCT considers soft (probabilistic) splits of the context space, instead of hard (deterministic) splits of the context space as in the previous BCT for real-valued time series. A learning algorithm of the Soft-BCT is proposed based on the variational inference. For some real-world datasets, the Soft-BCT demonstrates almost the same or superior performance to the previous BCT.

</details>


### [94] [Optimized Algorithms for Text Clustering with LLM-Generated Constraints](https://arxiv.org/abs/2601.11118)
*Chaoqi Jia,Weihong Wu,Longkun Guo,Zhigang Lu,Chao Chen,Kok-Leong Ong*

Main category: cs.LG

TL;DR: 提出了一种基于大语言模型（LLM）的约束生成方法，通过生成约束集而非传统成对约束来降低资源消耗，并设计了针对LLM生成约束特性的聚类算法，在保持聚类精度的同时将LLM查询次数减少20倍以上。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法通过人工标注的must-link和cannot-link约束来提升精度，但人工标注成本高。随着大语言模型的发展，研究者开始探索利用LLM自动生成约束，但现有方法存在资源消耗大、查询效率低的问题。

Method: 1. 提出新颖的约束生成方法，生成约束集而非成对约束，提高查询效率和约束准确性；2. 设计专门的约束聚类算法，包含置信度阈值和惩罚机制来处理可能不准确的约束；3. 在五个文本数据集上评估，同时考虑约束生成成本和整体聚类性能。

Result: 在五个文本数据集上的实验表明，该方法在保持与最先进算法相当的聚类精度的同时，将LLM查询次数减少了20倍以上，显著降低了资源消耗。

Conclusion: 提出的基于LLM的约束生成和聚类方法能够有效降低资源消耗，同时保持高质量的聚类结果，为文本分析中的约束聚类提供了高效实用的解决方案。

Abstract: Clustering is a fundamental tool that has garnered significant interest across a wide range of applications including text analysis. To improve clustering accuracy, many researchers have incorporated background knowledge, typically in the form of must-link and cannot-link constraints, to guide the clustering process. With the recent advent of large language models (LLMs), there is growing interest in improving clustering quality through LLM-based automatic constraint generation. In this paper, we propose a novel constraint-generation approach that reduces resource consumption by generating constraint sets rather than using traditional pairwise constraints. This approach improves both query efficiency and constraint accuracy compared to state-of-the-art methods. We further introduce a constrained clustering algorithm tailored to the characteristics of LLM-generated constraints. Our method incorporates a confidence threshold and a penalty mechanism to address potentially inaccurate constraints. We evaluate our approach on five text datasets, considering both the cost of constraint generation and the overall clustering performance. The results show that our method achieves clustering accuracy comparable to the state-of-the-art algorithms while reducing the number of LLM queries by more than 20 times.

</details>


### [95] [Shape-morphing programming of soft materials on complex geometries via neural operator](https://arxiv.org/abs/2601.11126)
*Lu Chen,Gengxiang Chen,Xu Liu,Jingyan Su,Xuhao Lyu,Lihui Wang,Yingguang Li*

Main category: cs.LG

TL;DR: 提出S2NO神经算子，通过谱空间编码和空间卷积实现复杂几何体上的高保真形变预测，结合进化算法优化材料分布，实现超分辨率形变设计


<details>
  <summary>Details</summary>
Motivation: 现有形状变形软材料设计主要针对简单几何体，难以在复杂几何体上实现精确多样的形变设计，限制了在共形植入部署、空气动力学变形等高级应用中的潜力

Method: 提出谱空间神经算子(S2NO)，集成拉普拉斯特征函数编码和空间卷积，有效捕捉不规则计算域上的全局和局部形变行为；结合进化算法进行体素级材料分布优化

Result: S2NO能够在各种复杂几何体（不规则边界形状、多孔结构、薄壁结构）上实现高保真形变预测；神经算子的离散不变性支持超分辨率材料分布设计，显著扩展形变设计的多样性和复杂性

Conclusion: S2NO方法显著提高了复杂形状变形编程的效率和能力，为高级应用如共形植入部署和空气动力学变形提供了有效的设计工具

Abstract: Shape-morphing soft materials can enable diverse target morphologies through voxel-level material distribution design, offering significant potential for various applications. Despite progress in basic shape-morphing design with simple geometries, achieving advanced applications such as conformal implant deployment or aerodynamic morphing requires accurate and diverse morphing designs on complex geometries, which remains challenging. Here, we present a Spectral and Spatial Neural Operator (S2NO), which enables high-fidelity morphing prediction on complex geometries. S2NO effectively captures global and local morphing behaviours on irregular computational domains by integrating Laplacian eigenfunction encoding and spatial convolutions. Combining S2NO with evolutionary algorithms enables voxel-level optimisation of material distributions for shape morphing programming on various complex geometries, including irregular-boundary shapes, porous structures, and thin-walled structures. Furthermore, the neural operator's discretisation-invariant property enables super-resolution material distribution design, further expanding the diversity and complexity of morphing design. These advancements significantly improve the efficiency and capability of programming complex shape morphing.

</details>


### [96] [Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction](https://arxiv.org/abs/2601.11135)
*Van Thuy Hoang,O-Joun Lee*

Main category: cs.LG

TL;DR: CaMol是一个基于因果推断的上下文感知图学习框架，用于小样本分子性质预测，通过编码化学知识、解耦因果子结构和应用后门调整来提高预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前基于上下文学习的分子性质预测方法存在两个主要局限：1) 未能充分利用与性质因果相关的官能团先验知识；2) 难以识别与性质直接相关的关键子结构。需要一种能够从因果推断角度解决这些挑战的框架。

Method: CaMol采用三阶段方法：1) 构建编码化学知识的上下文图，连接官能团、分子和性质以指导因果子结构发现；2) 提出可学习的原子掩码策略，将因果子结构与混淆子结构解耦；3) 引入分布干预器，通过将因果子结构与化学基础的混淆因子结合应用后门调整，从真实化学变异中解耦因果效应。

Result: 在多个分子数据集上的实验表明，CaMol在小样本任务中实现了优越的准确性和样本效率，显示出对未见性质的泛化能力。发现的因果子结构与官能团的化学知识高度一致，支持模型的可解释性。

Conclusion: CaMol通过因果推断视角成功解决了小样本分子性质预测中的关键挑战，不仅提高了预测性能，还提供了与化学知识一致的因果解释，为基于Web的分子服务（如蛋白质结构预测和药物发现）提供了有效的解决方案。

Abstract: Molecular property prediction is becoming one of the major applications of graph learning in Web-based services, e.g., online protein structure prediction and drug discovery. A key challenge arises in few-shot scenarios, where only a few labeled molecules are available for predicting unseen properties. Recently, several studies have used in-context learning to capture relationships among molecules and properties, but they face two limitations in: (1) exploiting prior knowledge of functional groups that are causally linked to properties and (2) identifying key substructures directly correlated with properties. We propose CaMol, a context-aware graph causality inference framework, to address these challenges by using a causal inference perspective, assuming that each molecule consists of a latent causal structure that determines a specific property. First, we introduce a context graph that encodes chemical knowledge by linking functional groups, molecules, and properties to guide the discovery of causal substructures. Second, we propose a learnable atom masking strategy to disentangle causal substructures from confounding ones. Third, we introduce a distribution intervener that applies backdoor adjustment by combining causal substructures with chemically grounded confounders, disentangling causal effects from real-world chemical variations. Experiments on diverse molecular datasets showed that CaMol achieved superior accuracy and sample efficiency in few-shot tasks, showing its generalizability to unseen properties. Also, the discovered causal substructures were strongly aligned with chemical knowledge about functional groups, supporting the model interpretability.

</details>


### [97] [GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling](https://arxiv.org/abs/2601.11161)
*Pascal Schlachter,Bin Yang*

Main category: cs.LG

TL;DR: GMM-COMET：首个持续源自由通用域自适应方法，通过高斯混合模型伪标签和均值教师框架处理多目标域序列适应问题


<details>
  <summary>Details</summary>
Motivation: 现实场景中，源数据在适应过程中可能不再可用，且目标域标签空间可能与源域不同。现有SF-UniDA方法仅假设单一域偏移，而实际应用中模型需要顺序适应多个不同的未标记目标域，因此需要研究持续SF-UniDA问题。

Method: 结合先前在线SF-UniDA方法的关键思想，将基于高斯混合模型的伪标签集成到均值教师框架中，以提高长期适应序列的稳定性。同时引入一致性损失以增强鲁棒性。

Result: GMM-COMET为持续SF-UniDA提供了强大的首个基线，是实验中唯一在所有评估场景下持续改进源模型性能的方法。

Conclusion: 该方法成功解决了持续源自由通用域自适应问题，通过高斯混合模型伪标签和均值教师框架的组合，在多个不同未标记目标域的序列适应中表现出稳定性和有效性。

Abstract: Unsupervised domain adaptation tackles the problem that domain shifts between training and test data impair the performance of neural networks in many real-world applications. Thereby, in realistic scenarios, the source data may no longer be available during adaptation, and the label space of the target domain may differ from the source label space. This setting, known as source-free universal domain adaptation (SF-UniDA), has recently gained attention, but all existing approaches only assume a single domain shift from source to target. In this work, we present the first study on continual SF-UniDA, where the model must adapt sequentially to a stream of multiple different unlabeled target domains. Building upon our previous methods for online SF-UniDA, we combine their key ideas by integrating Gaussian mixture model-based pseudo-labeling within a mean teacher framework for improved stability over long adaptation sequences. Additionally, we introduce consistency losses for further robustness. The resulting method GMM-COMET provides a strong first baseline for continual SF-UniDA and is the only approach in our experiments to consistently improve upon the source-only model across all evaluated scenarios. Our code is available at https://github.com/pascalschlachter/GMM-COMET.

</details>


### [98] [Assesing the Viability of Unsupervised Learning with Autoencoders for Predictive Maintenance in Helicopter Engines](https://arxiv.org/abs/2601.11154)
*P. Sánchez,K. Reyes,B. Radu,E. Fernández*

Main category: cs.LG

TL;DR: 比较直升机发动机预测性维护的两种方法：有监督分类与基于自编码器的无监督异常检测，评估它们在真实数据集上的表现和适用场景。


<details>
  <summary>Details</summary>
Motivation: 直升机发动机的非计划性故障会导致严重的运营中断、安全隐患和高昂维修成本，需要有效的预测性维护策略来降低这些风险。

Method: 研究比较了两种方法：1）有监督分类管道，依赖正常和故障行为的标记示例；2）基于自编码器的无监督异常检测，仅使用健康发动机数据学习正常操作模型，将偏差标记为潜在故障。两种方法均在包含直升机发动机遥测标记快照的真实数据集上进行评估。

Result: 有监督模型在可获得标注故障数据时表现出色，而自编码器无需故障标签即可实现有效检测，特别适用于故障数据稀缺或不完整的场景。研究突出了准确性、数据可用性和部署可行性之间的实际权衡。

Conclusion: 无监督学习作为航空航天应用中早期故障检测的可行解决方案具有潜力，特别是在故障数据有限的情况下。研究强调了根据数据可用性和实际需求选择适当预测性维护策略的重要性。

Abstract: Unplanned engine failures in helicopters can lead to severe operational disruptions, safety hazards, and costly repairs. To mitigate these risks, this study compares two predictive maintenance strategies for helicopter engines: a supervised classification pipeline and an unsupervised anomaly detection approach based on autoencoders (AEs). The supervised method relies on labelled examples of both normal and faulty behaviour, while the unsupervised approach learns a model of normal operation using only healthy engine data, flagging deviations as potential faults. Both methods are evaluated on a real-world dataset comprising labelled snapshots of helicopter engine telemetry. While supervised models demonstrate strong performance when annotated failures are available, the AE achieves effective detection without requiring fault labels, making it particularly well suited for settings where failure data are scarce or incomplete. The comparison highlights the practical trade-offs between accuracy, data availability, and deployment feasibility, and underscores the potential of unsupervised learning as a viable solution for early fault detection in aerospace applications.

</details>


### [99] [Theoretically and Practically Efficient Resistance Distance Computation on Large Graphs](https://arxiv.org/abs/2601.11159)
*Yichun Yang,Longlong Lin,Rong-Hua Li,Meihao Liao,Guoren Wang*

Main category: cs.LG

TL;DR: 提出两种基于Lanczos方法的算法（Lanczos Iteration和Lanczos Push）来高效计算大图上的电阻距离，显著降低对图拉普拉斯矩阵条件数κ的依赖。


<details>
  <summary>Details</summary>
Motivation: 电阻距离计算在图分析中至关重要，但现有方法在条件数κ较大时收敛缓慢，缺乏针对大图的高效算法。

Method: 提出两种基于经典Lanczos方法的算法：Lanczos Iteration（近线性时间全局算法）和Lanczos Push（时间复杂度与图大小无关的局部算法）。

Result: Lanczos Iteration时间复杂度为Õ(√κ m)，比基于幂迭代的全局方法加速√κ倍；Lanczos Push时间复杂度为Õ(κ^{2.75})，比基于随机游走的局部方法提升κ^{0.25}倍。在八个真实数据集上的实验验证了算法在效率和精度上的优越性。

Conclusion: 提出的Lanczos方法显著改进了电阻距离计算的效率，降低了对条件数κ的依赖，为大规模图分析提供了有效的解决方案。

Abstract: The computation of resistance distance is pivotal in a wide range of graph analysis applications, including graph clustering, link prediction, and graph neural networks. Despite its foundational importance, efficient algorithms for computing resistance distances on large graphs are still lacking. Existing state-of-the-art (SOTA) methods, including power iteration-based algorithms and random walk-based local approaches, often struggle with slow convergence rates, particularly when the condition number of the graph Laplacian matrix, denoted by $κ$, is large. To tackle this challenge, we propose two novel and efficient algorithms inspired by the classic Lanczos method: Lanczos Iteration and Lanczos Push, both designed to reduce dependence on $κ$. Among them, Lanczos Iteration is a near-linear time global algorithm, whereas Lanczos Push is a local algorithm with a time complexity independent of the size of the graph. More specifically, we prove that the time complexity of Lanczos Iteration is $\tilde{O}(\sqrtκ m)$ ($m$ is the number of edges of the graph and $\tilde{O}$ means the complexity omitting the $\log$ terms) which achieves a speedup of $\sqrtκ$ compared to previous power iteration-based global methods. For Lanczos Push, we demonstrate that its time complexity is $\tilde{O}(κ^{2.75})$ under certain mild and frequently established assumptions, which represents a significant improvement of $κ^{0.25}$ over the SOTA random walk-based local algorithms. We validate our algorithms through extensive experiments on eight real-world datasets of varying sizes and statistical properties, demonstrating that Lanczos Iteration and Lanczos Push significantly outperform SOTA methods in terms of both efficiency and accuracy.

</details>


### [100] [Clustering High-dimensional Data: Balancing Abstraction and Representation Tutorial at AAAI 2026](https://arxiv.org/abs/2601.11160)
*Claudia Plant,Lena G. M. Bauer,Christian Böhm*

Main category: cs.LG

TL;DR: 该论文探讨聚类算法中抽象与表示之间的平衡，分析K-means、子空间聚类和深度聚类等方法如何实现这一平衡，并展望未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 聚类需要在抽象和表示之间取得平衡：既要抽象掉个体对象的冗余细节，又需要丰富的表示来突出区分不同对象组的关键特征。现有聚类算法在这两个目标之间存在冲突，需要系统性地研究如何优化这一平衡。

Method: 通过对比分析不同聚类方法：经典K-means（高抽象、简单表示）、子空间聚类（学习聚类相关和无关的两个潜在空间）、深度聚类（通过基于质心和密度的聚类损失强制抽象）。探讨了这些方法如何在目标函数中平衡抽象和表示。

Result: 分析表明：1）K-means实现高抽象但表示简单；2）子空间和深度聚类支持高维复杂数据，但需要显式强制抽象以防止仅进行表示学习；3）子空间聚类通过分离聚类相关和无关信息来帮助平衡；4）当前深度聚类通过特定损失函数强制抽象。

Conclusion: 聚类算法的核心挑战是平衡抽象与表示。未来研究需要更自适应地平衡这两个目标以提高性能、能效和可解释性。人脑在聚类和相关任务中表现出色，说明算法仍有很大改进空间。

Abstract: How to find a natural grouping of a large real data set? Clustering requires a balance between abstraction and representation. To identify clusters, we need to abstract from superfluous details of individual objects. But we also need a rich representation that emphasizes the key features shared by groups of objects that distinguish them from other groups of objects.
  Each clustering algorithm implements a different trade-off between abstraction and representation. Classical K-means implements a high level of abstraction - details are simply averaged out - combined with a very simple representation - all clusters are Gaussians in the original data space. We will see how approaches to subspace and deep clustering support high-dimensional and complex data by allowing richer representations. However, with increasing representational expressiveness comes the need to explicitly enforce abstraction in the objective function to ensure that the resulting method performs clustering and not just representation learning. We will see how current deep clustering methods define and enforce abstraction through centroid-based and density-based clustering losses. Balancing the conflicting goals of abstraction and representation is challenging. Ideas from subspace clustering help by learning one latent space for the information that is relevant to clustering and another latent space to capture all other information in the data.
  The tutorial ends with an outlook on future research in clustering. Future methods will more adaptively balance abstraction and representation to improve performance, energy efficiency and interpretability. By automatically finding the sweet spot between abstraction and representation, the human brain is very good at clustering and other related tasks such as single-shot learning. So, there is still much room for improvement.

</details>


### [101] [LSTM VS. Feed-Forward Autoencoders for Unsupervised Fault Detection in Hydraulic Pumps](https://arxiv.org/abs/2601.11163)
*P. Sánchez,K. Reyes,B. Radu,E. Fernández*

Main category: cs.LG

TL;DR: 基于无监督自编码器的工业液压泵早期故障检测方法研究


<details>
  <summary>Details</summary>
Motivation: 工业液压泵的意外故障会导致生产中断和巨大成本，需要有效的早期故障检测方法

Method: 提出两种无监督自编码器方案：1）前馈模型分析单个传感器快照；2）LSTM模型捕捉短期时间窗口。仅使用健康数据训练，基于52个传感器通道的分钟级日志

Result: 尽管训练时没有故障样本，两种模型在包含7个标注故障区间的独立测试集上都实现了高可靠性

Conclusion: 无监督自编码器方法能够有效检测工业液压泵的早期故障，即使仅使用健康数据训练也能达到高可靠性

Abstract: Unplanned failures in industrial hydraulic pumps can halt production and incur substantial costs. We explore two unsupervised autoencoder (AE) schemes for early fault detection: a feed-forward model that analyses individual sensor snapshots and a Long Short-Term Memory (LSTM) model that captures short temporal windows. Both networks are trained only on healthy data drawn from a minute-level log of 52 sensor channels; evaluation uses a separate set that contains seven annotated fault intervals. Despite the absence of fault samples during training, the models achieve high reliability.

</details>


### [102] [TimeMar: Multi-Scale Autoregressive Modeling for Unconditional Time Series Generation](https://arxiv.org/abs/2601.11184)
*Xiangyu Xu,Qingsong Zhong,Jilin Hu*

Main category: cs.LG

TL;DR: 提出了一种结构解耦的多尺度时间序列生成框架，通过双路径VQ-VAE解耦趋势和季节性成分，采用从粗到细的自回归生成方式，在保持层次依赖的同时显著减少参数量。


<details>
  <summary>Details</summary>
Motivation: 时间序列分析面临数据稀缺和隐私挑战，生成建模提供了有前景的解决方案。然而，时间序列的结构复杂性（包括多尺度时间模式和异质成分）尚未得到充分解决。

Method: 1. 将序列编码为多个时间分辨率的离散标记，采用从粗到细的自回归生成方式；2. 引入双路径VQ-VAE解耦趋势和季节性成分，学习语义一致的潜在表示；3. 提出基于指导的重建策略，利用粗粒度季节性信号作为先验指导细粒度季节性模式的重建。

Result: 在六个数据集上的实验表明，该方法比现有方法生成更高质量的时间序列。模型在显著减少参数量的情况下仍能实现强性能，并在生成长期序列方面表现出卓越能力。

Conclusion: 该结构解耦的多尺度生成框架有效解决了时间序列的结构复杂性，通过成分解耦和层次化生成策略，在保持高质量生成的同时实现了参数效率，为时间序列生成建模提供了新的解决方案。

Abstract: Generative modeling offers a promising solution to data scarcity and privacy challenges in time series analysis. However, the structural complexity of time series, characterized by multi-scale temporal patterns and heterogeneous components, remains insufficiently addressed. In this work, we propose a structure-disentangled multiscale generation framework for time series. Our approach encodes sequences into discrete tokens at multiple temporal resolutions and performs autoregressive generation in a coarse-to-fine manner, thereby preserving hierarchical dependencies. To tackle structural heterogeneity, we introduce a dual-path VQ-VAE that disentangles trend and seasonal components, enabling the learning of semantically consistent latent representations. Additionally, we present a guidance-based reconstruction strategy, where coarse seasonal signals are utilized as priors to guide the reconstruction of fine-grained seasonal patterns. Experiments on six datasets show that our approach produces higher-quality time series than existing methods. Notably, our model achieves strong performance with a significantly reduced parameter count and exhibits superior capability in generating high-quality long-term sequences. Our implementation is available at https://anonymous.4open.science/r/TimeMAR-BC5B.

</details>


### [103] [FAQ: Mitigating Quantization Error via Regenerating Calibration Data with Family-Aware Quantization](https://arxiv.org/abs/2601.11200)
*Haiyang Xiao,Weiqing Li,Jinyue Guo,Guochao Jiang,Guohua Liu,Yuewei Zhang*

Main category: cs.LG

TL;DR: FAQ是一种基于同家族大语言模型先验知识的校准数据再生框架，通过生成高保真校准样本来提升后训练量化的精度，相比基线方法可减少高达28.5%的精度损失。


<details>
  <summary>Details</summary>
Motivation: 后训练量化（PTQ）在资源受限设备上部署大语言模型时，校准数据的代表性和普适性是决定量化参数精度的核心瓶颈。传统PTQ方法依赖有限样本，难以捕捉推理阶段的激活分布，导致量化参数存在偏差。

Method: FAQ框架首先将原始校准样本输入到与目标模型同家族的更大LLM中，利用高度一致的知识系统再生一系列高保真校准数据。这些数据携带思维链推理并符合预期激活分布，随后在专家指导下进行组间竞争以选择最佳样本，最后重新归一化以增强标准PTQ的效果。

Result: 在包括Qwen3-8B在内的多个模型系列上的实验表明，FAQ相比使用原始校准数据的基线方法，可将精度损失减少高达28.5%。

Conclusion: FAQ通过利用同家族LLM的先验知识生成高质量校准数据，有效解决了传统PTQ校准数据不足的问题，显著提升了量化精度，展示了其在后训练量化领域的强大潜力和贡献。

Abstract: Although post-training quantization (PTQ) provides an efficient numerical compression scheme for deploying large language models (LLMs) on resource-constrained devices, the representativeness and universality of calibration data remain a core bottleneck in determining the accuracy of quantization parameters. Traditional PTQ methods typically rely on limited samples, making it difficult to capture the activation distribution during the inference phase, leading to biases in quantization parameters. To address this, we propose \textbf{FAQ} (Family-Aware Quantization), a calibration data regeneration framework that leverages prior knowledge from LLMs of the same family to generate high-fidelity calibration samples. Specifically, FAQ first inputs the original calibration samples into a larger LLM from the same family as the target model, regenerating a series of high-fidelity calibration data using a highly consistent knowledge system. Subsequently, this data, carrying Chain-of-Thought reasoning and conforming to the expected activation distribution, undergoes group competition under expert guidance to select the best samples, which are then re-normalized to enhance the effectiveness of standard PTQ. Experiments on multiple model series, including Qwen3-8B, show that FAQ reduces accuracy loss by up to 28.5\% compared to the baseline with original calibration data, demonstrating its powerful potential and contribution.

</details>


### [104] [SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients](https://arxiv.org/abs/2601.11219)
*Zhikang Shen,Jianrong Lu,Haiyuan Wan,Jianhai Chen*

Main category: cs.LG

TL;DR: SDFLoRA：一种解决联邦学习中LoRA适配器秩异构问题的选择性双模块方法，通过分离全局和本地模块实现鲁棒聚合与隐私保护


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的LoRA方法面临秩异构问题，不同客户端使用不同的低秩配置导致直接聚合存在偏差和不稳定性。现有解决方案强制统一秩或将异构更新对齐到共享子空间，这会过度约束客户端特定语义、限制个性化，并在差分隐私噪声下提供较弱的本地信息保护。

Method: 提出选择性双模块联邦LoRA（SDFLoRA），将每个客户端适配器分解为全局模块和本地模块。全局模块捕获可转移知识，在客户端间选择性对齐和聚合；本地模块保留客户端特定适配，保持私有。该设计支持在秩异构下的鲁棒学习，并通过仅在全局模块注入差分隐私噪声实现隐私感知优化。

Result: 在GLUE基准测试上的实验表明，SDFLoRA优于代表性的联邦LoRA基线方法，并实现了更好的效用-隐私权衡。

Conclusion: SDFLoRA通过分离全局和本地模块有效解决了联邦学习中LoRA适配器的秩异构问题，实现了鲁棒聚合、个性化保留和增强的隐私保护，为实际部署提供了实用解决方案。

Abstract: Federated learning (FL) for large language models (LLMs) has attracted increasing attention as a way to enable privacy-preserving adaptation over distributed data. Parameter-efficient methods such as LoRA are widely adopted to reduce communication and memory costs. Despite these advances, practical FL deployments often exhibit rank heterogeneity, since different clients may use different low-rank configurations. This makes direct aggregation of LoRA updates biased and unstable. Existing solutions typically enforce unified ranks or align heterogeneous updates into a shared subspace, which over-constrains client-specific semantics, limits personalization, and provides weak protection of local client information under differential privacy noise. To address this issue, we propose Selective Dual-module Federated LoRA (SDFLoRA), which decomposes each client adapter into a global module that captures transferable knowledge and a local module that preserves client-specific adaptations. The global module is selectively aligned and aggregated across clients, while local modules remain private. This design enables robust learning under rank heterogeneity and supports privacy-aware optimization by injecting differential privacy noise exclusively into the global module. Experiments on GLUE benchmarks demonstrate that SDFLoRA outperforms representative federated LoRA baselines and achieves a better utility-privacy trade-off.

</details>


### [105] [Operator learning on domain boundary through combining fundamental solution-based artificial data and boundary integral techniques](https://arxiv.org/abs/2601.11222)
*Haochen Wu,Heng Wu,Benzhuo Lu*

Main category: cs.LG

TL;DR: 提出MAD-BNO框架，仅使用边界数据学习线性PDE的边界到边界映射，通过边界积分恢复内部解，无需全域采样或数值模拟。


<details>
  <summary>Details</summary>
Motivation: 针对已知基本解的线性偏微分方程，传统算子学习方法需要全域采样数据，而实际应用中边界数据更易获取。本文旨在开发仅依赖边界数据的算子学习框架，避免昂贵的数值模拟或实验测量。

Method: 结合数学人工数据(MAD)方法，从目标问题的基本解直接合成边界训练数据（解值和法向导数），学习边界到边界映射。训练后通过边界积分公式高效恢复任意内部位置的解，支持Dirichlet、Neumann、混合边界条件和一般源项。

Result: 在二维Laplace、Poisson和Helmholtz方程的基准算子学习任务上验证，达到或优于现有神经算子方法的精度，同时显著减少训练时间。框架可自然扩展到三维问题和复杂几何形状。

Conclusion: MAD-BNO为已知基本解的线性PDE提供了一种高效、完全数据驱动的算子学习框架，仅需边界数据即可实现准确求解，具有扩展到更复杂问题的潜力。

Abstract: For linear partial differential equations with known fundamental solutions, this work introduces a novel operator learning framework that relies exclusively on domain boundary data, including solution values and normal derivatives, rather than full-domain sampling. By integrating the previously developed Mathematical Artificial Data (MAD) method, which enforces physical consistency, all training data are synthesized directly from the fundamental solutions of the target problems, resulting in a fully data-driven pipeline without the need for external measurements or numerical simulations. We refer to this approach as the Mathematical Artificial Data Boundary Neural Operator (MAD-BNO), which learns boundary-to-boundary mappings using MAD-generated Dirichlet-Neumann data pairs. Once trained, the interior solution at arbitrary locations can be efficiently recovered through boundary integral formulations, supporting Dirichlet, Neumann, and mixed boundary conditions as well as general source terms. The proposed method is validated on benchmark operator learning tasks for two-dimensional Laplace, Poisson, and Helmholtz equations, where it achieves accuracy comparable to or better than existing neural operator approaches while significantly reducing training time. The framework is naturally extensible to three-dimensional problems and complex geometries.

</details>


### [106] [Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation](https://arxiv.org/abs/2601.11258)
*Pingzhi Tang,Yiding Wang,Muhan Zhang*

Main category: cs.LG

TL;DR: 提出PaST框架，通过提取领域无关的技能向量，在线性注入知识操作技能，解决LLM知识更新中SFT和RL的局限性，实现高效知识适应。


<details>
  <summary>Details</summary>
Motivation: LLM面临"知识截止"挑战，其冻结的参数化记忆无法直接内化新信息。SFT常用于更新模型知识，但往往只更新事实内容而未能可靠提升模型使用新信息进行问答或决策的能力。RL对于获取推理技能至关重要，但其高计算成本使其难以实现高效的在线适应。实证发现SFT和RL诱导的参数更新几乎正交，这为模块化技能转移提供了机会。

Method: 提出参数化技能转移（PaST）框架，支持模块化技能转移以实现高效有效的知识适应。方法包括：1）从源领域提取领域无关的技能向量；2）在目标模型经过轻量级SFT学习新数据后，线性注入知识操作技能。该方法允许将在一个领域获得的推理技能转移到其他领域，而无需昂贵的RL训练。

Result: 在多个基准测试中验证了方法的有效性：1）在SQuAD知识整合QA上，PaST比最先进的自编辑SFT基线高出9.9分；2）在LooGLE长上下文QA上，获得8.0分的绝对准确率提升；3）在ToolBench工具使用基准上，零样本成功率平均提高+10.3分，且在不同工具类别中均有一致的提升。结果表明技能向量具有良好的可扩展性和跨领域可转移性。

Conclusion: PaST框架通过分离知识获取和知识操作技能，实现了高效的知识适应。该方法不仅显著提升了模型在新知识上的表现，还展示了技能向量的跨领域可转移性，为LLM的知识更新提供了一种计算效率高的解决方案。

Abstract: Large Language Models (LLMs) face the "knowledge cutoff" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.

</details>


### [107] [Sample-Near-Optimal Agnostic Boosting with Improved Running Time](https://arxiv.org/abs/2601.11265)
*Arthur da Cunha,Miakel Møller Høgsgaard,Andrea Paudice*

Main category: cs.LG

TL;DR: 提出首个具有接近最优样本复杂度的不可知提升算法，在固定其他参数时具有多项式运行时间


<details>
  <summary>Details</summary>
Motivation: 提升方法能将弱学习器转化为高精度强学习器，但在不可知设置下（不对数据做任何假设）理解较少。现有算法虽然解决了样本复杂度问题，但运行时间是指数级的。

Method: 提出新的不可知提升算法，在固定其他参数时，运行时间相对于样本大小是多项式的，同时保持接近最优的样本复杂度。

Result: 首次实现了具有接近最优样本复杂度的不可知提升算法，且运行时间在固定其他参数时是多项式级别的。

Conclusion: 该工作填补了不可知提升算法在高效实现方面的空白，为实际应用提供了可行的算法框架。

Abstract: Boosting is a powerful method that turns weak learners, which perform only slightly better than random guessing, into strong learners with high accuracy. While boosting is well understood in the classic setting, it is less so in the agnostic case, where no assumptions are made about the data. Indeed, only recently was the sample complexity of agnostic boosting nearly settled arXiv:2503.09384, but the known algorithm achieving this bound has exponential running time. In this work, we propose the first agnostic boosting algorithm with near-optimal sample complexity, running in time polynomial in the sample size when considering the other parameters of the problem fixed.

</details>


### [108] [Metabolomic Biomarker Discovery for ADHD Diagnosis Using Interpretable Machine Learning](https://arxiv.org/abs/2601.11283)
*Nabil Belacel,Mohamed Rachid Boulassel*

Main category: cs.LG

TL;DR: 该研究通过整合尿液代谢组学和可解释机器学习框架，开发了一种基于14种代谢物的ADHD客观诊断方法，AUC>0.97，为精准精神病学提供了生物学基础的诊断策略。


<details>
  <summary>Details</summary>
Motivation: ADHD作为一种普遍的神经发育障碍，目前缺乏客观的诊断工具，迫切需要基于生物学的客观诊断框架来推动精准精神病学的发展。

Method: 研究整合了尿液代谢组学与可解释机器学习框架，使用最相似度（CR）分类器结合嵌入式特征选择，分析了52名ADHD患者和46名对照参与者的靶向代谢组学数据。

Result: CR模型优于随机森林和K近邻分类器，基于14种代谢物（包括多巴胺4-硫酸盐、N-乙酰天冬氨酰谷氨酸和瓜氨酸）实现了AUC>0.97的优异性能，这些代谢物映射到多巴胺能神经传递和氨基酸代谢通路。

Conclusion: 该工作展示了一个结合代谢组学和可解释机器学习的转化框架，为ADHD提供了客观、生物学信息的诊断策略，其透明决策边界和低计算成本支持集成到靶向代谢组学检测和未来即时诊断平台中。

Abstract: Attention Deficit Hyperactivity Disorder (ADHD) is a prevalent neurodevelopmental disorder with limited objective diagnostic tools, highlighting the urgent need for objective, biology-based diagnostic frameworks in precision psychiatry. We integrate urinary metabolomics with an interpretable machine learning framework to identify biochemical signatures associated with ADHD. Targeted metabolomic profiles from 52 ADHD and 46 control participants were analyzed using a Closest Resemblance (CR) classifier with embedded feature selection. The CR model outperformed Random Forest and K-Nearest Neighbor classifiers, achieving an AUC > 0.97 based on a reduced panel of 14 metabolites. These metabolites including dopamine 4-sulfate, N-acetylaspartylglutamic acid, and citrulline map to dopaminergic neurotransmission and amino acid metabolism pathways, offering mechanistic insight into ADHD pathophysiology. The CR classifier's transparent decision boundaries and low computational cost support integration into targeted metabolomic assays and future point of care diagnostic platforms. Overall, this work demonstrates a translational framework combining metabolomics and interpretable machine learning to advance objective, biologically informed diagnostic strategies for ADHD.

</details>


### [109] [FORESTLLM: Large Language Models Make Random Forest Great on Few-shot Tabular Learning](https://arxiv.org/abs/2601.11311)
*Zhihan Yang,Jiaqi Wei,Xiang Zhang,Haoyu Dong,Yiwen Wang,Xiaoke Guo,Pengkun Zhang,Yiwei Xu,Chenyu You*

Main category: cs.LG

TL;DR: FORESTLLM：结合决策森林结构偏置与LLM语义推理的少样本表格学习框架，训练时使用LLM设计轻量级可解释森林模型，测试时无需LLM推理


<details>
  <summary>Details</summary>
Motivation: 表格数据在金融、医疗等关键领域决策中至关重要，但少样本场景下的有效学习仍具挑战。传统树方法在统计纯度指标不稳定时容易过拟合，而直接应用LLM常忽略数据结构导致性能不佳

Method: 1. 语义分割准则：LLM基于标注和未标注数据评估候选分割的语义连贯性，构建更鲁棒的树结构；2. 一次性上下文推理机制：LLM将决策路径和支持样本蒸馏为确定性预测，替代噪声经验估计

Result: 在多样化的少样本分类和回归基准测试中，FORESTLLM实现了最先进的性能

Conclusion: FORESTLLM通过将LLM作为离线模型设计器，统一了决策森林的结构偏置与LLM的语义推理能力，在少样本表格学习中取得了突破性进展

Abstract: Tabular data high-stakes critical decision-making in domains such as finance, healthcare, and scientific discovery. Yet, learning effectively from tabular data in few-shot settings, where labeled examples are scarce, remains a fundamental challenge. Traditional tree-based methods often falter in these regimes due to their reliance on statistical purity metrics, which become unstable and prone to overfitting with limited supervision. At the same time, direct applications of large language models (LLMs) often overlook its inherent structure, leading to suboptimal performance. To overcome these limitations, we propose FORESTLLM, a novel framework that unifies the structural inductive biases of decision forests with the semantic reasoning capabilities of LLMs. Crucially, FORESTLLM leverages the LLM only during training, treating it as an offline model designer that encodes rich, contextual knowledge into a lightweight, interpretable forest model, eliminating the need for LLM inference at test time. Our method is two-fold. First, we introduce a semantic splitting criterion in which the LLM evaluates candidate partitions based on their coherence over both labeled and unlabeled data, enabling the induction of more robust and generalizable tree structures under few-shot supervision. Second, we propose a one-time in-context inference mechanism for leaf node stabilization, where the LLM distills the decision path and its supporting examples into a concise, deterministic prediction, replacing noisy empirical estimates with semantically informed outputs. Across a diverse suite of few-shot classification and regression benchmarks, FORESTLLM achieves state-of-the-art performance.

</details>


### [110] [Unlocking the Potentials of Retrieval-Augmented Generation for Diffusion Language Models](https://arxiv.org/abs/2601.11342)
*Chuanyue Yu,Jiahui Wang,Yuhan Li,Heng Chang,Ge Lan,Qingyun Sun,Jia Li,Jianxin Li,Ziwei Zhang*

Main category: cs.LG

TL;DR: 本文提出SPREAD框架，通过查询相关性引导的去噪策略解决扩散语言模型在检索增强生成中的语义漂移问题，显著提升生成精度。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在自然语言处理任务中表现出色，但其在检索增强生成框架中的潜力尚未充分探索。现有方法存在响应语义漂移问题，导致生成内容精度有限。

Method: 提出SPREAD框架，引入查询相关性引导的去噪策略。该策略主动引导去噪轨迹，确保生成过程始终锚定查询语义，有效抑制语义漂移。

Result: 实验结果表明，SPREAD显著提升了RAG框架中生成答案的精度，有效缓解了响应语义漂移问题。

Conclusion: SPREAD框架成功解决了扩散语言模型在检索增强生成中的语义漂移问题，为DLM-RAG系统的实际应用提供了有效解决方案。

Abstract: Diffusion Language Models (DLMs) have recently demonstrated remarkable capabilities in natural language processing tasks. However, the potential of Retrieval-Augmented Generation (RAG), which shows great successes for enhancing large language models (LLMs), has not been well explored, due to the fundamental difference between LLM and DLM decoding. To fill this critical gap, we systematically test the performance of DLMs within the RAG framework. Our findings reveal that DLMs coupled with RAG show promising potentials with stronger dependency on contextual information, but suffer from limited generation precision. We identify a key underlying issue: Response Semantic Drift (RSD), where the generated answer progressively deviates from the query's original semantics, leading to low precision content. We trace this problem to the denoising strategies in DLMs, which fail to maintain semantic alignment with the query throughout the iterative denoising process. To address this, we propose Semantic-Preserving REtrieval-Augmented Diffusion (SPREAD), a novel framework that introduces a query-relevance-guided denoising strategy. By actively guiding the denoising trajectory, SPREAD ensures the generation remains anchored to the query's semantics and effectively suppresses drift. Experimental results demonstrate that SPREAD significantly enhances the precision and effectively mitigates RSD of generated answers within the RAG framework.

</details>


### [111] [FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting](https://arxiv.org/abs/2601.11350)
*Jaehoon Lee,Seungwoo Lee,Younghwi Kim,Dohee Kim,Sunghyun Sim*

Main category: cs.LG

TL;DR: FEATHer是一种用于边缘设备上时间序列预测的超轻量级模型，通过傅里叶高效自适应时间层次结构实现长期预测，参数可低至400个，在严格资源限制下优于现有基准。


<details>
  <summary>Details</summary>
Motivation: 工业领域（如制造和智能工厂）的时间序列预测需要部署在边缘设备（PLC、微控制器）上，这些设备有严格的延迟和内存限制（参数通常限制在几千个），传统深度架构在此场景下不实用。

Method: FEATHer包含四个核心组件：(1) 超轻量级多尺度频率路径分解；(2) 共享密集时间核（投影-深度卷积-投影结构，无循环或注意力机制）；(3) 基于频谱特征的频率感知分支门控自适应融合；(4) 稀疏周期核通过周期下采样重建输出以捕获季节性。

Result: 在八个基准测试中，FEATHer获得最佳排名，记录了60个第一名结果，平均排名为2.05。模型参数可低至400个，在严格资源限制下优于基线方法。

Conclusion: 可靠的长期预测在受限边缘硬件上是可行的，FEATHer为工业实时推理提供了实用方向，证明了超轻量级架构在边缘设备时间序列预测中的有效性。

Abstract: Time-series forecasting is fundamental in industrial domains like manufacturing and smart factories. As systems evolve toward automation, models must operate on edge devices (e.g., PLCs, microcontrollers) with strict constraints on latency and memory, limiting parameters to a few thousand. Conventional deep architectures are often impractical here. We propose the Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer) for accurate long-term forecasting under severe limits. FEATHer introduces: (i) ultra-lightweight multiscale decomposition into frequency pathways; (ii) a shared Dense Temporal Kernel using projection-depthwise convolution-projection without recurrence or attention; (iii) frequency-aware branch gating that adaptively fuses representations based on spectral characteristics; and (iv) a Sparse Period Kernel reconstructing outputs via period-wise downsampling to capture seasonality. FEATHer maintains a compact architecture (as few as 400 parameters) while outperforming baselines. Across eight benchmarks, it achieves the best ranking, recording 60 first-place results with an average rank of 2.05. These results demonstrate that reliable long-range forecasting is achievable on constrained edge hardware, offering a practical direction for industrial real-time inference.

</details>


### [112] [Offline Reinforcement-Learning-Based Power Control for Application-Agnostic Energy Efficiency](https://arxiv.org/abs/2601.11352)
*Akhilesh Raj,Swann Perarnau,Aniruddha Gokhale,Solomon Bekele Abera*

Main category: cs.LG

TL;DR: 使用离线强化学习设计CPU功率控制器，通过预收集的数据集训练，在保证性能的前提下显著降低并行应用的能耗


<details>
  <summary>Details</summary>
Motivation: 现代计算基础设施设计中能效已成为关键因素，虽然强化学习适合设计能效控制系统，但在线训练存在挑战：缺乏合适的模拟环境模型、噪声干扰以及在实时系统上部署的可靠性问题

Method: 采用离线强化学习方法设计自主CPU功率控制器，结合灰盒方法，使用在线应用无关性能数据（如心跳）和硬件性能计数器，通过预收集的策略状态转移数据集进行训练

Result: 在各种计算密集型与内存密集型基准测试中，通过Intel的Running Average Power Limit控制实时系统功率，离线训练的智能体能够显著降低能耗，同时保持可容忍的性能下降

Conclusion: 离线强化学习是设计CPU功率控制器的有效替代方案，能够在不严重影响性能的情况下提高并行应用的运行时能效，避免了在线训练的各种问题

Abstract: Energy efficiency has become an integral aspect of modern computing infrastructure design, impacting the performance, cost, scalability, and durability of production systems. The incorporation of power actuation and sensing capabilities in CPU designs is indicative of this, enabling the deployment of system software that can actively monitor and adjust energy consumption and performance at runtime. While reinforcement learning (RL) would seem ideal for the design of such energy efficiency control systems, online training presents challenges ranging from the lack of proper models for setting up an adequate simulated environment, to perturbation (noise) and reliability issues, if training is deployed on a live system.
  In this paper we discuss the use of offline reinforcement learning as an alternative approach for the design of an autonomous CPU power controller, with the goal of improving the energy efficiency of parallel applications at runtime without unduly impacting their performance. Offline RL sidesteps the issues incurred by online RL training by leveraging a dataset of state transitions collected from arbitrary policies prior to training.
  Our methodology applies offline RL to a gray-box approach to energy efficiency, combining online application-agnostic performance data (e.g., heartbeats) and hardware performance counters to ensure that the scientific objectives are met with limited performance degradation. Evaluating our method on a variety of compute-bound and memory-bound benchmarks and controlling power on a live system through Intel's Running Average Power Limit, we demonstrate that such an offline-trained agent can substantially reduce energy consumption at a tolerable performance degradation cost.

</details>


### [113] [Latent Space Inference via Paired Autoencoders](https://arxiv.org/abs/2601.11397)
*Emma Hart,Bas Peters,Julianne Chung,Matthias Chung*

Main category: cs.LG

TL;DR: 提出基于配对自编码器的数据驱动隐空间推理框架，用于处理观测不一致性时的反问题求解


<details>
  <summary>Details</summary>
Motivation: 解决反问题中观测数据不一致性（如部分、噪声或分布外数据）的挑战，同时保持与底层物理模型的一致性

Method: 使用两个自编码器分别处理参数空间和观测空间，通过学习隐空间之间的映射关系，在低维信息隐空间中进行正则化反演和优化

Result: 相比单独使用配对自编码器和相同架构的端到端编码器-解码器，该方法在数据不一致场景下能产生更准确的重建结果

Conclusion: 该框架在医学层析成像和地球物理地震波形反演中得到验证，可广泛应用于科学和工程中的各种反问题

Abstract: This work describes a novel data-driven latent space inference framework built on paired autoencoders to handle observational inconsistencies when solving inverse problems. Our approach uses two autoencoders, one for the parameter space and one for the observation space, connected by learned mappings between the autoencoders' latent spaces. These mappings enable a surrogate for regularized inversion and optimization in low-dimensional, informative latent spaces. Our flexible framework can work with partial, noisy, or out-of-distribution data, all while maintaining consistency with the underlying physical models. The paired autoencoders enable reconstruction of corrupted data, and then use the reconstructed data for parameter estimation, which produces more accurate reconstructions compared to paired autoencoders alone and end-to-end encoder-decoders of the same architecture, especially in scenarios with data inconsistencies. We demonstrate our approaches on two imaging examples in medical tomography and geophysical seismic-waveform inversion, but the described approaches are broadly applicable to a variety of inverse problems in scientific and engineering applications.

</details>


### [114] [Factored Value Functions for Graph-Based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.11401)
*Ahmed Rashwan,Keith Briggs,Chris Budd,Lisa Kreusser*

Main category: cs.LG

TL;DR: 提出扩散价值函数(DVF)作为图马尔可夫决策过程(GMDP)的分解价值函数，通过时空衰减在影响图上扩散奖励，解决多智能体强化学习中的信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的信用分配问题在大规模结构化局部交互系统中尤为突出。图马尔可夫决策过程能捕捉此类设置，但现有批评函数与图结构不匹配：全局价值函数提供弱学习信号，局部构造难以估计且在无限时域中表现不佳。

Method: 提出扩散价值函数(DVF)，通过在影响图上进行时间折扣和空间衰减来扩散奖励，为每个智能体分配价值分量。证明DVF具有良好定义、贝尔曼不动点和平均分解性质。基于DVF提出扩散A2C(DA2C)算法和稀疏消息传递执行器LD-GNN，用于通信成本下的分散算法学习。

Result: 在消防基准测试和三个分布式计算任务（向量图着色和两个发射功率优化问题）中，DA2C持续优于局部和全局批评函数基线，平均奖励提升高达11%。

Conclusion: 扩散价值函数为图结构多智能体系统提供了一种结构对齐的信用分配方法，能够有效分解全局价值并实现可扩展学习，在多个实际任务中展现出优越性能。

Abstract: Credit assignment is a core challenge in multi-agent reinforcement learning (MARL), especially in large-scale systems with structured, local interactions. Graph-based Markov decision processes (GMDPs) capture such settings via an influence graph, but standard critics are poorly aligned with this structure: global value functions provide weak per-agent learning signals, while existing local constructions can be difficult to estimate and ill-behaved in infinite-horizon settings. We introduce the Diffusion Value Function (DVF), a factored value function for GMDPs that assigns to each agent a value component by diffusing rewards over the influence graph with temporal discounting and spatial attenuation. We show that DVF is well-defined, admits a Bellman fixed point, and decomposes the global discounted value via an averaging property. DVF can be used as a drop-in critic in standard RL algorithms and estimated scalably with graph neural networks. Building on DVF, we propose Diffusion A2C (DA2C) and a sparse message-passing actor, Learned DropEdge GNN (LD-GNN), for learning decentralised algorithms under communication costs. Across the firefighting benchmark and three distributed computation tasks (vector graph colouring and two transmit power optimisation problems), DA2C consistently outperforms local and global critic baselines, improving average reward by up to 11%.

</details>


### [115] [Forcing and Diagnosing Failure Modes of Fourier Neural Operators Across Diverse PDE Families](https://arxiv.org/abs/2601.11428)
*Lennon Shikhman*

Main category: cs.LG

TL;DR: 本文提出了一个系统性的压力测试框架，用于评估傅里叶神经算子（FNOs）在五种不同类型偏微分方程下的鲁棒性，揭示了其在分布偏移、边界条件变化和分辨率外推等方面的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 傅里叶神经算子在求解偏微分方程解映射方面表现出色，但其在分布偏移、长时间推演和结构扰动下的鲁棒性尚未得到充分理解。需要系统性地评估FNOs的失效模式，为算子学习的鲁棒性改进提供指导。

Method: 设计了系统性压力测试框架，在五种不同类型的偏微分方程族（色散、椭圆、多尺度流体、金融、混沌系统）上进行评估。测试包括参数偏移、边界/终端条件变化、分辨率外推与谱分析、迭代推演等控制性压力测试，而非优化分布内精度。共训练了1000个模型进行大规模评估。

Result: 参数或边界条件的分布偏移可使误差增加一个数量级以上；分辨率变化主要将误差集中在高频模式；输入扰动通常不会放大误差，但最坏情况（如局部泊松扰动）仍具挑战性。研究揭示了谱偏差、复合积分误差和边界条件过拟合等脆弱性。

Conclusion: 该研究提供了算子学习的比较性失效模式图谱和可操作的改进见解，强调了在分布偏移和边界条件变化下FNOs的鲁棒性不足，为未来算子学习方法的设计和评估提供了重要参考。

Abstract: Fourier Neural Operators (FNOs) have shown strong performance in learning solution maps of partial differential equations (PDEs), but their robustness under distribution shifts, long-horizon rollouts, and structural perturbations remains poorly understood. We present a systematic stress-testing framework that probes failure modes of FNOs across five qualitatively different PDE families: dispersive, elliptic, multi-scale fluid, financial, and chaotic systems. Rather than optimizing in-distribution accuracy, we design controlled stress tests--including parameter shifts, boundary or terminal condition changes, resolution extrapolation with spectral analysis, and iterative rollouts--to expose vulnerabilities such as spectral bias, compounding integration errors, and overfitting to restricted boundary regimes. Our large-scale evaluation (1{,}000 trained models) reveals that distribution shifts in parameters or boundary conditions can inflate errors by more than an order of magnitude, while resolution changes primarily concentrate error in high-frequency modes. Input perturbations generally do not amplify error, though worst-case scenarios (e.g., localized Poisson perturbations) remain challenging. These findings provide a comparative failure-mode atlas and actionable insights for improving robustness in operator learning.

</details>


### [116] [GenDA: Generative Data Assimilation on Complex Urban Areas via Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2601.11440)
*Francisco Giral,Álvaro Manzano,Ignacio Gómez,Ricardo Vinuesa,Soledad Le Clainche*

Main category: cs.LG

TL;DR: GenDA：基于生成扩散的几何感知数据同化框架，从稀疏观测重建城市风场


<details>
  <summary>Details</summary>
Motivation: 城市风场重建对空气质量评估、热量扩散和行人舒适度至关重要，但仅凭稀疏传感器数据难以实现高精度重建。现有方法在处理复杂几何结构、泛化到未见场景方面存在局限。

Method: 提出GenDA框架，采用多尺度图基扩散架构，在CFD模拟数据上训练。将无分类器引导解释为学习后验重建机制：无条件分支学习几何感知流场先验，传感器条件分支在采样时注入观测约束。支持稀疏固定传感器和轨迹观测两种模式。

Result: 在布里斯托尔真实城区的RANS模拟数据上评估（Re≈2×10^7），相比监督GNN基线和经典降阶数据同化方法，相对均方根误差降低25-57%，结构相似性指数提高23-33%。模型能够泛化到未见几何、风向和网格分辨率。

Conclusion: GenDA为复杂环境监测提供了一种可扩展的生成式、几何感知数据同化路径，实现了从稀疏观测到高分辨率风场的准确重建，具有实际应用价值。

Abstract: Urban wind flow reconstruction is essential for assessing air quality, heat dispersion, and pedestrian comfort, yet remains challenging when only sparse sensor data are available. We propose GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields on unstructured meshes from limited observations. The model employs a multiscale graph-based diffusion architecture trained on computational fluid dynamics (CFD) simulations and interprets classifier-free guidance as a learned posterior reconstruction mechanism: the unconditional branch learns a geometry-aware flow prior, while the sensor-conditioned branch injects observational constraints during sampling. This formulation enables obstacle-aware reconstruction and generalization across unseen geometries, wind directions, and mesh resolutions without retraining. We consider both sparse fixed sensors and trajectory-based observations using the same reconstruction procedure. When evaluated against supervised graph neural network (GNN) baselines and classical reduced-order data assimilation methods, GenDA reduces the relative root-mean-square error (RRMSE) by 25-57% and increases the structural similarity index (SSIM) by 23-33% across the tested meshes. Experiments are conducted on Reynolds-averaged Navier-Stokes (RANS) simulations of a real urban neighbourhood in Bristol, United Kingdom, at a characteristic Reynolds number of $\mathrm{Re}\approx2\times10^{7}$, featuring complex building geometry and irregular terrain. The proposed framework provides a scalable path toward generative, geometry-aware data assimilation for environmental monitoring in complex domains.

</details>


### [117] [Low-Rank Key Value Attention](https://arxiv.org/abs/2601.11471)
*James O'Neill,Robert Clancy,Mariia Matskevichus,Fergal Reid*

Main category: cs.LG

TL;DR: LRKV是一种通过低秩残差共享KV投影来减少Transformer KV缓存内存的注意力机制，在保持全token分辨率的同时显著降低计算需求。


<details>
  <summary>Details</summary>
Motivation: Transformer预训练面临内存和计算限制，其中KV缓存成为训练和自回归解码的主要瓶颈，需要一种既能减少内存占用又能保持模型性能的解决方案。

Method: 提出低秩KV适应（LRKV），在多头注意力中使用共享的全秩KV投影，并添加低秩、头特定的残差，在完全共享和完全独立注意力之间提供连续权衡。

Result: 在2.5B规模实验中，LRKV使用约一半KV缓存即可超越标准注意力性能，达到同等模型质量时训练计算减少20-25%，在损失降低速度、验证困惑度和下游任务性能上均优于标准注意力、MQA/GQA和MLA。

Conclusion: LRKV是一种实用有效的注意力机制，可在内存和计算受限的情况下扩展Transformer预训练，通过保留注意力头多样性实现性能提升，相比激进的KV共享机制更具优势。

Abstract: Transformer pretraining is increasingly constrained by memory and compute requirements, with the key-value (KV) cache emerging as a dominant bottleneck during training and autoregressive decoding. We propose \textit{low-rank KV adaptation} (LRKV), a simple modification of multi-head attention that reduces KV cache memory by exploiting redundancy across attention heads while preserving full token-level resolution. Each layer uses a shared full-rank KV projection augmented with low-rank, head-specific residuals, yielding a continuous trade-off between complete sharing and fully independent attention.
  LRKV is a drop-in replacement for standard multi-head attention and directly subsumes query-sharing approaches such as multi-query and grouped-query attention, while remaining distinct from latent-compression methods such as multi-latent attention (MLA). Across large-scale pretraining experiments, LRKV consistently achieves faster loss reduction, lower validation perplexity, and stronger downstream task performance than standard attention, MQA/GQA, and MLA. At the 2.5B scale, LRKV outperforms standard attention while using roughly half the KV cache, and reaches equivalent model quality with up to \textbf{20-25\% less training compute} when measured in cumulative FLOPs. To explain these gains, we analyze attention head structure in operator space and show that LRKV preserves nearly all functional head diversity relative to standard attention, whereas more aggressive KV-sharing mechanisms rely on compensatory query specialization. Together, these results establish LRKV as a practical and effective attention mechanism for scaling Transformer pretraining under memory- and compute-constrained regimes.

</details>


### [118] [MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management](https://arxiv.org/abs/2601.11505)
*Miriam K. Wolff,Peter Calhoun,Eleonora Maria Aiello,Yao Qin,Sam F. Royston*

Main category: cs.LG

TL;DR: 提出MetaboNet数据集，整合多个公开T1D数据集，包含3135名受试者和1228患者年的CGM与胰岛素数据，提供标准化格式和两种访问途径


<details>
  <summary>Details</summary>
Motivation: 现有T1D管理数据集存在碎片化、缺乏标准化的问题，数据结构差异大，访问和处理耗时，阻碍了数据整合，降低了算法开发的可比性和泛化性

Method: 整合多个公开T1D数据集，要求同时包含连续血糖监测数据和胰岛素泵剂量记录，保留碳水化合物摄入和体力活动等辅助信息，提供标准化处理流程

Result: 创建了包含3135名受试者和1228患者年重叠CGM与胰岛素数据的MetaboNet数据集，规模远超现有独立基准数据集，提供公开可下载子集和DUA限制子集

Conclusion: 建立了统一的T1D研究公共数据集，覆盖广泛的血糖谱和人口统计学特征，相比单个数据集能产生更具泛化性的算法性能

Abstract: Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/ , and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets.

</details>
