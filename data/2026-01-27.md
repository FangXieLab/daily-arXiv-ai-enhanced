<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 12]
- [cs.CV](#cs.CV) [Total: 15]
- [cs.CR](#cs.CR) [Total: 7]
- [stat.ML](#stat.ML) [Total: 1]
- [math.ST](#math.ST) [Total: 2]
- [cs.LG](#cs.LG) [Total: 19]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success](https://arxiv.org/abs/2601.18175)
*Daniel Russo*

Main category: cs.AI

TL;DR: 成功条件化（success conditioning）是一种广泛使用的策略改进技术，通过收集轨迹、识别成功轨迹并模仿其行动来更新策略。本文证明该方法精确解决了信任域优化问题，在自动确定的χ²散度约束下最大化策略改进。


<details>
  <summary>Details</summary>
Motivation: 成功条件化技术在不同领域有多种名称（拒绝采样+SFT、目标条件RL、决策变换器），但其解决的优化问题本质一直不明确。本文旨在揭示该方法的数学基础，证明其精确对应一个信任域优化问题。

Method: 通过理论分析证明成功条件化精确解决了一个信任域优化问题：在χ²散度约束下最大化策略改进，约束半径由数据自动确定。建立了相对策略改进、策略变化幅度和行动影响（action-influence）之间的恒等式。

Result: 成功条件化被证明是一种保守改进算子，不会降低性能或引发危险的分布偏移。当失败时，它会通过几乎不改变策略来可观察地失败。理论应用于回报阈值化实践，显示其能放大改进但可能偏离真实目标。

Conclusion: 成功条件化技术具有坚实的数学基础，精确对应信任域优化问题，是一种安全可靠的策略改进方法。该方法在失败时具有可观察性，为实际应用提供了理论保障。

Abstract: A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.

</details>


### [2] [High-Fidelity Longitudinal Patient Simulation Using Real-World Data](https://arxiv.org/abs/2601.17310)
*Yu Akagi,Tomohisa Seki,Hiromasa Ito,Toru Takiguchi,Kazuhiko Ohe,Yoshimasa Kawazoe*

Main category: cs.AI

TL;DR: 利用真实世界临床记录开发生成式模拟器，可基于患者历史生成高保真未来临床轨迹，在超过2亿条记录上预训练，准确预测事件发生率和时间动态。


<details>
  <summary>Details</summary>
Motivation: 模拟在临床医学中具有变革潜力，可用于个性化治疗规划和虚拟临床试验。然而，由于复杂的生物和社会文化影响，模拟患者轨迹具有挑战性。本研究旨在利用真实世界临床记录经验性地建模患者时间线。

Method: 开发了一个生成式模拟器模型，以患者历史为输入，合成细粒度、真实的未来轨迹。模型在超过2亿条临床记录上进行预训练，能够生成高保真未来时间线。

Result: 模型生成的时间线与真实患者未来数据高度匹配，包括事件发生率、实验室检测结果和时间动态。准确估计未来事件概率，观察值与预期值比率在不同结果和时间范围内均接近1.0。

Conclusion: 研究揭示了电子健康记录中真实世界数据的未开发价值，并引入了一个可扩展的临床护理计算机模拟框架，为个性化医疗和虚拟临床试验提供了新工具。

Abstract: Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.

</details>


### [3] [Phase Transition for Budgeted Multi-Agent Synergy](https://arxiv.org/abs/2601.17311)
*Bang Liu,Linglong Kong,Jian Pei*

Main category: cs.AI

TL;DR: 该论文提出了一个可校准的理论框架，用于预测多智能体系统在固定推理预算下的性能表现，识别出帮助、饱和和崩溃三种机制，并推导出预算协同的精确条件。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统理论上能提高可靠性，但在固定推理预算下，其性能可能呈现帮助、饱和甚至崩溃三种不同机制。现有研究缺乏能够统一解释这些现象并指导系统设计的理论框架。

Method: 建立了一个最小化且可校准的理论模型，包含三个关键约束：有限上下文窗口、有损的智能体间通信、相似智能体间的共享故障。通过定义智能体计算性能缩放指数β、消息长度保真度曲线γ(m)、有效共享误差相关性ρ和上下文窗口W等参数，分析深度b叉树结构中的多数聚合任务。

Result: 证明了深度b叉树在相关输入和有损通信下存在尖锐的相变：单个标量αρ（结合γ(m)、ρ和扇入b）决定弱信号是被放大到非平凡固定点还是被洗牌到随机水平。在放大机制中，推导出组织指数s，并证明当s>β时出现预算协同（即系统在相同总预算下优于最佳单个智能体），得到了封闭形式的计算分配规则和明确的预算阈值。进一步通过混合深度表征饱和现象，并提供了在增长和饱和阶段都保持准确的保守裁剪预测器。

Conclusion: 该理论框架成功预测了多智能体系统的性能边界，解释了近期大规模匹配预算研究中观察到的LLM智能体系统缩放的主要瓶颈，为系统设计提供了明确的指导原则和可计算的权衡。

Abstract: Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $β$; communication is captured by a message-length fidelity curve $γ(m)$; dependence is captured by an effective shared-error correlation $ρ$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $α_ρ$ (combining $γ(m)$, $ρ$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>β$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.

</details>


### [4] [TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow](https://arxiv.org/abs/2601.17332)
*Yicheng Tao,Hongteng Xu*

Main category: cs.AI

TL;DR: TheoremForge是一个低成本的形式数学数据合成管道，通过解耦提取策略从失败轨迹中恢复有效训练信号，显著降低形式化数学数据生成成本。


<details>
  <summary>Details</summary>
Motivation: 形式数学中智能体工作流的高成本阻碍了大规模数据合成，加剧了开源语料库的稀缺性，需要一种成本效益高的解决方案。

Method: 将形式化过程分解为五个子任务：陈述形式化、证明生成、前提选择、证明修正和证明草图；采用解耦提取策略从全局失败轨迹中恢复有效训练信号。

Result: 在2000个问题的基准测试中，TheoremForge实现了12.6%的验证率（优于8.6%的基线），每个成功轨迹的平均成本仅为0.481美元；解耦策略使证明生成的数据产量提高了1.6倍。

Conclusion: TheoremForge为构建数据飞轮以训练未来专家模型提供了一个可扩展的框架，有效解决了形式数学数据合成的成本问题。

Abstract: The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \textit{statement formalization}, \textit{proof generation}, \textit{premise selection}, \textit{proof correction} and \textit{proof sketching}. By implementing a \textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\%, surpassing the 8.6\% baseline, at an average cost of only \textbf{\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \textbf{1.6$\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \href{https://github.com/timechess/TheoremForge}{here}.

</details>


### [5] [Lattice: Generative Guardrails for Conversational Agents](https://arxiv.org/abs/2601.17481)
*Emily Broadhurst,Tawab Safi,Joseph Edell,Vashisht Ganesh,Karime Maamari*

Main category: cs.AI

TL;DR: Lattice框架通过两阶段自构建和持续改进机制，为对话AI系统创建自适应防护栏，显著优于现有静态方法


<details>
  <summary>Details</summary>
Motivation: 现有对话AI防护栏使用静态规则，无法适应新威胁和部署环境变化，需要能够自我构建和持续改进的自适应防护框架

Method: Lattice框架包含两个阶段：构建阶段通过迭代模拟和优化从标注示例创建初始防护栏；持续改进阶段通过风险评估、对抗测试和整合来自主适应已部署的防护栏

Result: 在ProsocialDialog数据集上，Lattice在保留数据上达到91% F1分数，比关键词基线高43个百分点，比LlamaGuard高25个百分点，比NeMo高4个百分点；持续改进阶段通过闭环优化在跨域数据上实现7个百分点F1提升

Conclusion: Lattice框架证明通过迭代优化可以自构建有效的防护栏，为对话AI系统提供了自适应、可持续改进的防护解决方案

Abstract: Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.

</details>


### [6] [EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents](https://arxiv.org/abs/2601.17722)
*Ying Mo,Yu Bai,Dapeng Sun,Yuqian Shi,Yukai Miao,Li Chen,Dan Li*

Main category: cs.AI

TL;DR: EntWorld是一个大规模企业级基准测试，包含1,756个任务，涵盖六个企业领域，用于评估多模态大语言模型在复杂企业工作流中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要针对消费级场景（如电商、旅行预订），无法捕捉专业企业工作流的复杂性和严谨性。企业系统具有高密度用户界面、严格业务逻辑约束和精确状态一致性要求等独特挑战，当前通用智能体在这些场景中表现不佳。

Method: 采用基于模式的任务生成框架，直接从底层数据库模式逆向工程业务逻辑，合成真实的长时程工作流。提出基于SQL的确定性验证机制，用严格的状态转换验证替代模糊的视觉匹配。

Result: 实验结果显示，最先进模型（如GPT-4.1）在EntWorld上的成功率仅为47.61%，远低于人类表现，突显了当前智能体在企业领域的显著差距。

Conclusion: EntWorld作为一个严谨的测试平台，有助于促进下一代企业级数字智能体的开发和评估，强调了开发领域特定智能体的必要性。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.

</details>


### [7] [Neuro-Symbolic Verification on Instruction Following of LLMs](https://arxiv.org/abs/2601.17789)
*Yiming Su,Kunzhao Xu,Yanjie Gao,Fan Yang,Cheng Li,Mao Yang,Tianyin Xu*

Main category: cs.AI

TL;DR: NSVIF是一个神经符号框架，用于验证LLM输出是否遵循指令，将指令遵循验证建模为约束满足问题，显著优于基于LLM的方法并提供可解释反馈。


<details>
  <summary>Details</summary>
Motivation: LLM并不总是遵循指令，且违规行为难以观察或检查。在基于LLM的智能体工作流中，此类违规会沿推理链传播放大，导致任务失败和系统事故。需要一种通用、通用的验证器来确保LLM输出遵循指令。

Method: NSVIF将指令遵循验证建模为约束满足问题，将用户指令建模为约束。框架同时建模逻辑约束和语义约束，通过统一求解器协调逻辑推理和语义分析来解决约束。开发了VIFBENCH基准测试来评估验证器性能。

Result: 实验表明NSVIF显著优于基于LLM的方法，并提供可解释的反馈。NSVIF的反馈还能在不进行后训练的情况下帮助提高LLM的指令遵循能力。

Conclusion: NSVIF是一个有效的神经符号框架，能够可靠地验证LLM输出是否遵循指令，为解决LLM指令遵循问题提供了通用解决方案，并通过可解释反馈帮助改进LLM性能。

Abstract: A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.

</details>


### [8] [Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation](https://arxiv.org/abs/2601.17915)
*Saurabh Jha,Rohan Arora,Bhavya,Noah Zheutlin,Paulina Toro Isaza,Laura Shwartz,Yu Deng,Daby Sow,Ruchi Mahindru,Ruchir Puri*

Main category: cs.AI

TL;DR: EoG框架通过将调查任务建模为依赖图上的溯因推理，分离LLM的局部证据挖掘与确定性控制器的图遍历管理，解决了ReAct智能体在开放式调查中的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在处理开放式调查任务时存在严重缺陷：上下文窗口有限导致关键证据可能被过早丢弃；ReAct风格的智能体对探索顺序敏感且结果不稳定；缺乏明确的信念簿记和修正机制；语义推理与控制职责纠缠导致执行错误影响推理质量。

Method: 提出EoG（Explanations over Graphs）框架：1）将调查任务形式化为依赖图上的溯因推理；2）分离LLM与控制器的职责——LLM负责有界的局部证据挖掘和标注（原因vs症状），确定性控制器管理图遍历、状态维护和信念传播；3）计算最小解释边界。

Result: 在ITBench诊断任务上，EoG相比ReAct基线显著提升了准确性和运行间一致性，特别是实体F1的Majority-at-k指标平均提升了7倍。

Conclusion: 通过将开放式调查任务分解为依赖图上的溯因推理，并分离LLM的局部推理与控制器的全局管理，EoG框架能够更可靠、一致地处理需要从海量异构数据中迭代挖掘证据的复杂调查任务。

Abstract: LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.
  We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.

</details>


### [9] [Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges](https://arxiv.org/abs/2601.17920)
*Xuanzhou Chen,Audrey Wang,Stanley Yin,Hanyang Jiang,Dong Zhang*

Main category: cs.AI

TL;DR: 本文综述了自主实验室（SDL）中的人工智能问题，将其框架化为智能体-环境交互问题，回顾了主要方法家族，提出了能力驱动的分类法，并总结了实际部署中的经验教训和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 自主实验室为在昂贵操作、噪声延迟反馈、严格可行性和安全约束以及非平稳性条件下测试智能体AI提供了苛刻的测试平台。本文旨在系统性地分析SDL中的人工智能问题，建立统一的框架来连接常见的SDL流程与成熟的AI原理。

Method: 将SDL自主性框架化为具有明确观测、动作、成本和约束的智能体-环境交互问题。回顾了实现闭环实验的主要方法家族：用于样本高效实验选择的贝叶斯优化和主动学习、用于长时程协议优化的规划和强化学习，以及用于协调异构仪器和软件的工具使用智能体。提出了基于决策时域、不确定性建模、动作参数化、约束处理、故障恢复和人类参与等维度的能力驱动分类法。

Result: 建立了连接SDL流程与AI原理的统一框架，提出了系统性的分类法来组织SDL系统。合成了基准任务模板和评估指标，优先考虑成本感知性能、对漂移的鲁棒性、约束违反行为和可重复性。从已部署的SDL中提炼了实际经验教训。

Conclusion: 自主实验室代表了AI在现实世界复杂环境中的重要应用领域。本文提供了系统性的分析框架，强调了可验证和溯源感知策略的重要性。未来开放挑战包括多模态表示、校准不确定性、安全探索和共享基准基础设施等方面。

Abstract: Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.

</details>


### [10] [Sentipolis: Emotion-Aware Agents for Social Simulations](https://arxiv.org/abs/2601.18027)
*Chiyuan Fu,Lyuhao Chen,Yunze Xiao,Weihao Xuan,Carlos Busso,Mona Diab*

Main category: cs.AI

TL;DR: Sentipolis框架为LLM智能体提供情感状态管理，通过PAD情感表示、双速情感动态和情感-记忆耦合，提升社交模拟中的情感连续性和真实性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在社交模拟中常将情感视为瞬时线索，导致情感遗忘和长期连续性不足，需要更系统化的情感状态管理框架。

Method: 提出Sentipolis框架，包含：1）连续愉悦-唤醒-支配（PAD）情感表示；2）双速情感动态机制；3）情感-记忆耦合系统。

Result: 在数千次交互中，Sentipolis显著提升情感基础行为、沟通能力和情感连续性。效果模型依赖：高容量模型可信度提升，小模型可能下降；情感意识轻微降低社会规范遵从度。

Conclusion: Sentipolis为社交模拟提供情感状态管理框架，支持累积社会动态研究（如联盟形成、关系渐变），揭示情感驱动行为与社会规范遵从之间的人类式张力。

Abstract: LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.

</details>


### [11] [RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents](https://arxiv.org/abs/2601.18130)
*Jize Wang,Han Wu,Zhiyuan You,Yiming Song,Yijun Wang,Zifei Shan,Yining Li,Songyang Zhang,Xinyi Le,Cailian Chen,Xinping Guan,Dacheng Tao*

Main category: cs.AI

TL;DR: RouteMoA：一种基于动态路由的高效混合智能体框架，通过轻量级评分器和混合裁判机制，在无需全模型推理的情况下筛选候选模型，大幅降低成本和延迟


<details>
  <summary>Details</summary>
Motivation: 现有混合智能体（MoA）方法采用密集拓扑结构导致成本和延迟过高，且使用LLM裁判筛选响应时仍需所有模型先进行推理，无法有效降低成本。同时缺乏模型选择标准，在大规模模型池中面临成本过高和上下文限制问题

Method: 1. 轻量级评分器：基于查询预测粗略性能，无需推理即可筛选高潜力候选模型子集；2. 混合裁判机制：通过轻量级自评估和交叉评估对现有模型输出进行后验校正；3. 模型排名机制：平衡性能、成本和延迟进行模型选择

Result: RouteMoA在不同任务和模型池规模下均优于传统MoA，在大规模模型池中实现成本降低89.8%、延迟降低63.6%

Conclusion: RouteMoA通过动态路由机制有效解决了混合智能体框架的成本和延迟问题，实现了高效的大规模模型协作，为实际部署提供了可行方案

Abstract: Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.

</details>


### [12] [Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models](https://arxiv.org/abs/2601.18383)
*Zhenyuan Guo,Tong Chen,Wenlong Meng,Chen Gong,Xin Yu,Chengkun Wei,Wenzhi Chen*

Main category: cs.AI

TL;DR: DynTS方法通过注意力图分析推理轨迹，识别关键决策token并选择性保留其KV缓存，优化大型推理模型的效率


<details>
  <summary>Details</summary>
Motivation: 大型推理模型生成详细推理轨迹时会产生大量内存占用和计算开销，成为效率瓶颈。研究发现推理轨迹中只有部分关键token对最终答案有决定性影响，其余token贡献可忽略

Method: 提出动态思维token选择（DynTS）方法：1）使用注意力图分析推理轨迹中各token的影响；2）识别决策关键token；3）在推理过程中仅保留这些关键token的KV缓存状态，淘汰冗余条目

Result: 通过选择性保留关键token的KV缓存，显著减少了内存占用和计算开销，优化了大型推理模型的推理效率

Conclusion: 推理轨迹中存在大量冗余token，DynTS方法通过注意力分析识别关键决策token并优化KV缓存管理，为大型推理模型提供了有效的效率优化方案

Abstract: Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [13] [Feature-Space Generative Models for One-Shot Class-Incremental Learning](https://arxiv.org/abs/2601.17905)
*Jack Foster,Kirill Paramonov,Mete Ozay,Umberto Michieli*

Main category: cs.CV

TL;DR: Gen1S：一种基于生成模型的单样本类增量学习方法，通过将嵌入空间映射到残差空间并学习残差分布来提升新类识别能力


<details>
  <summary>Details</summary>
Motivation: 解决单样本类增量学习（FSCIL）的挑战性问题，特别是在每个新类只有一个样本且不允许后续训练或模型修改的严格条件下，如何有效识别新类

Method: 提出Gen1S方法：1）将原始嵌入空间映射到残差空间（减去类别原型）；2）使用VAE或扩散模型学习基类残差的多模态分布；3）利用该结构先验提升新类识别

Result: Gen1S在多个基准测试和骨干架构上一致地超越了现有技术水平，显著提升了新类识别性能

Conclusion: 通过将嵌入空间映射到残差空间并利用生成模型学习结构先验，可以有效解决严格条件下的单样本类增量学习问题，为FSCIL提供了新的解决方案

Abstract: Few-shot class-incremental learning (FSCIL) is a paradigm where a model, initially trained on a dataset of base classes, must adapt to an expanding problem space by recognizing novel classes with limited data. We focus on the challenging FSCIL setup where a model receives only a single sample (1-shot) for each novel class and no further training or model alterations are allowed after the base training phase. This makes generalization to novel classes particularly difficult. We propose a novel approach predicated on the hypothesis that base and novel class embeddings have structural similarity. We map the original embedding space into a residual space by subtracting the class prototype (i.e., the average class embedding) of input samples. Then, we leverage generative modeling with VAE or diffusion models to learn the multi-modal distribution of residuals over the base classes, and we use this as a valuable structural prior to improve recognition of novel classes. Our approach, Gen1S, consistently improves novel class recognition over the state of the art across multiple benchmarks and backbone architectures.

</details>


### [14] [Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing](https://arxiv.org/abs/2601.18252)
*Chao Wang,Xuanying Li,Cheng Dai,Jinglei Feng,Yuxiang Luo,Yuqi Ouyang,Hao Qin*

Main category: cs.CV

TL;DR: Co-PLNet：一种点线协同框架，通过空间提示编码和交叉引导解码实现线框解析，提高准确性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有线框解析方法分别预测线段和连接点，然后进行后处理协调，导致不匹配和鲁棒性降低。需要一种协同框架来同时处理点和线，确保几何一致性。

Method: 提出Co-PLNet点线协同框架：1）点线提示编码器（PLP-Encoder）将早期检测转换为空间提示，编码几何属性为紧凑的空间对齐图；2）交叉引导线段解码器（CGL-Decoder）使用稀疏注意力机制，基于互补提示细化预测，强制点线一致性并提高效率。

Result: 在Wireframe和YorkUrban数据集上的实验显示，该方法在准确性和鲁棒性方面均有持续改进，同时具有良好的实时效率，证明了其在结构化几何感知中的有效性。

Conclusion: Co-PLNet通过点线协同框架解决了现有线框解析方法的局限性，实现了更准确、鲁棒的线段和连接点检测，为SLAM等下游任务提供了更好的结构化几何表示。

Abstract: Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.

</details>


### [15] [MANGO: A Global Single-Date Paired Dataset for Mangrove Segmentation](https://arxiv.org/abs/2601.17039)
*Junhyuk Heo,Beomkyu Choi,Hyunjin Shin,Darongsae Kwon*

Main category: cs.CV

TL;DR: 提出MANGO数据集：包含42,703个标注图像-掩码对的全球红树林数据集，覆盖124个国家，基于2020年Sentinel-2影像构建，采用目标检测驱动方法选择最佳单日期观测


<details>
  <summary>Details</summary>
Motivation: 现有红树林监测数据集存在局限性：仅提供年度地图产品而非单日期图像-掩码对、局限于特定区域而非全球覆盖、或未公开可用，这阻碍了深度学习在红树林检测中的进展

Method: 检索2020年红树林区域所有可用Sentinel-2影像，采用目标检测驱动方法选择与年度红树林掩码对齐的最佳单日期观测，利用像素级坐标参考确保自适应和代表性的图像-掩码配对

Result: 构建了MANGO数据集，包含42,703个标注图像-掩码对，覆盖124个国家，并在多种语义分割架构下建立了基于国家不相交划分的基准

Conclusion: MANGO数据集解决了现有红树林监测数据的局限性，为可扩展和可靠的全球红树林监测建立了基础，推动了深度学习在红树林检测中的应用

Abstract: Mangroves are critical for climate-change mitigation, requiring reliable monitoring for effective conservation. While deep learning has emerged as a powerful tool for mangrove detection, its progress is hindered by the limitations of existing datasets. In particular, many resources provide only annual map products without curated single-date image-mask pairs, limited to specific regions rather than global coverage, or remain inaccessible to the public. To address these challenges, we introduce MANGO, a large-scale global dataset comprising 42,703 labeled image-mask pairs across 124 countries. To construct this dataset, we retrieve all available Sentinel-2 imagery within the year 2020 for mangrove regions and select the best single-date observations that align with the mangrove annual mask. This selection is performed using a target detection-driven approach that leverages pixel-wise coordinate references to ensure adaptive and representative image-mask pairings. We also provide a benchmark across diverse semantic segmentation architectures under a country-disjoint split, establishing a foundation for scalable and reliable global mangrove monitoring.

</details>


### [16] [FP-THD: Full page transcription of historical documents](https://arxiv.org/abs/2601.17040)
*H Neji,J Nogueras-Iso,J Lacasta,MÁ Latre,FJ García-Marco*

Main category: cs.CV

TL;DR: 提出一个用于转录15-16世纪拉丁文历史文献的流程，通过布局分析模型提取文本行，再使用OCR模型进行识别，保留特殊字符和符号以维持历史文本的原始风格和意义。


<details>
  <summary>Details</summary>
Motivation: 15-16世纪拉丁文历史文献的转录面临特殊挑战，需要保留具有特定含义的字符和特殊符号，以确保历史文本保持其原始风格和重要性。现有方法在处理这些特殊特征方面存在不足。

Method: 提出一个流程，扩展现有的文本行识别方法，结合布局分析模型。首先使用布局分析模型分析历史文本图像以提取文本行，然后通过OCR模型处理这些文本行，生成完全数字化的页面。该方法利用掩码自编码器有效处理不同类型的文本。

Result: 该流程促进了页面处理并产生了高效结果。在多个数据集上的评估表明，掩码自编码器能够有效处理不同类型的文本，包括手写体、印刷体和多语言文本。

Conclusion: 提出的流程成功解决了历史文献转录中保留特殊字符和符号的挑战，通过结合布局分析和OCR模型，能够有效处理15-16世纪拉丁文历史文档，保持其原始风格和意义。

Abstract: The transcription of historical documents written in Latin in XV and XVI centuries has special challenges as it must maintain the characters and special symbols that have distinct meanings to ensure that historical texts retain their original style and significance. This work proposes a pipeline for the transcription of historical documents preserving these special features. We propose to extend an existing text line recognition method with a layout analysis model. We analyze historical text images using a layout analysis model to extract text lines, which are then processed by an OCR model to generate a fully digitized page. We showed that our pipeline facilitates the processing of the page and produces an efficient result. We evaluated our approach on multiple datasets and demonstrate that the masked autoencoder effectively processes different types of text, including handwritten, printed and multi-language.

</details>


### [17] [Interpretable and Sparse Linear Attention with Decoupled Membership-Subspace Modeling via MCR2 Objective](https://arxiv.org/abs/2601.17042)
*Tianyuan Liu,Libin Hou,Linyuan Wang,Bin Yan*

Main category: cs.CV

TL;DR: 提出解耦成员矩阵与子空间矩阵的MCR2驱动白盒Transformer，通过梯度展开得到可解释稀疏线性注意力算子DMSA，在视觉任务中实现更高效率和性能


<details>
  <summary>Details</summary>
Motivation: 现有MCR2驱动的白盒Transformer设计中，成员矩阵与子空间矩阵U紧密耦合，导致在错误的token投影下产生冗余编码，需要解耦这种功能关系以提高效率和可解释性

Method: 解耦MCR2目标中的成员矩阵与子空间U的功能关系，直接从输入学习成员矩阵，然后从全空间S推导稀疏子空间，通过优化目标的梯度展开得到可解释稀疏线性注意力算子DMSA

Result: 在Token Statistics Transformer中替换注意力模块为DMSA（称为DMST），在ImageNet-1K上比ToST提升1.08%-1.45%的top-1准确率，实现更快的编码降维率，相比传统Transformer具有显著更高的计算效率和可解释性

Conclusion: 提出的解耦成员-子空间注意力机制有效解决了MCR2中的冗余编码问题，通过梯度展开得到的稀疏线性注意力算子DMSA在保持白盒可解释性的同时，显著提升了视觉建模的性能和效率

Abstract: Maximal Coding Rate Reduction (MCR2)-driven white-box transformer, grounded in structured representation learning, unifies interpretability and efficiency, providing a reliable white-box solution for visual modeling. However, in existing designs, tight coupling between "membership matrix" and "subspace matrix U" in MCR2 causes redundant coding under incorrect token projection. To this end, we decouple the functional relationship between the "membership matrix" and "subspaces U" in the MCR2 objective and derive an interpretable sparse linear attention operator from unrolled gradient descent of the optimized objective. Specifically, we propose to directly learn the membership matrix from inputs and subsequently derive sparse subspaces from the fullspace S. Consequently, gradient unrolling of the optimized MCR2 objective yields an interpretable sparse linear attention operator: Decoupled Membership-Subspace Attention (DMSA). Experimental results on visual tasks show that simply replacing the attention module in Token Statistics Transformer (ToST) with DMSA (we refer to as DMST) not only achieves a faster coding reduction rate but also outperforms ToST by 1.08%-1.45% in top-1 accuracy on the ImageNet-1K dataset. Compared with vanilla Transformer architectures, DMST exhibits significantly higher computational efficiency and interpretability.

</details>


### [18] [GlassesGB: Controllable 2D GAN-Based Eyewear Personalization for 3D Gaussian Blendshapes Head Avatars](https://arxiv.org/abs/2601.17088)
*Rui-Yang Ju,Jen-Shiun Chiang*

Main category: cs.CV

TL;DR: GlassesGB：一个将2D生成式眼镜定制与3D头部化身渲染相结合的可定制眼镜生成框架


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试戴系统大多基于预定义模板，缺乏细粒度用户驱动定制。虽然GlassesGAN支持个性化2D眼镜设计，但仅限于2D图像生成。需要将2D生成式定制能力扩展到3D头部化身，以支持VR应用中的个性化眼镜设计。

Method: 整合3D高斯混合形状（用于头部重建）与2D生成技术，提出GlassesGB框架。该框架有效桥接2D生成式定制与3D头部化身渲染，支持3D头部化身的可定制眼镜生成。

Result: 成功开发了支持3D头部化身可定制眼镜生成的框架，解决了VR应用中个性化眼镜设计的挑战。代码已在GitHub上开源。

Conclusion: GlassesGB通过整合3D高斯混合形状和2D生成技术，实现了从2D生成式定制到3D头部化身渲染的有效桥接，为VR应用提供了可定制的眼镜生成解决方案。

Abstract: Virtual try-on systems allow users to interactively try different products within VR scenarios. However, most existing VTON methods operate only on predefined eyewear templates and lack support for fine-grained, user-driven customization. While GlassesGAN enables personalized 2D eyewear design, its capability remains limited to 2D image generation. Motivated by the success of 3D Gaussian Blendshapes in head reconstruction, we integrate these two techniques and propose GlassesGB, a framework that supports customizable eyewear generation for 3D head avatars. GlassesGB effectively bridges 2D generative customization with 3D head avatar rendering, addressing the challenge in achieving personalized eyewear design for VR applications. The implementation code is available at https://ruiyangju.github.io/GlassesGB.

</details>


### [19] [PhaSR: Generalized Image Shadow Removal with Physically Aligned Priors](https://arxiv.org/abs/2601.17470)
*Chia-Ming Lee,Yu-Fan Lin,Yu-Jou Hsiao,Jing-Hui Jung,Yu-Lun Liu,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: PhaSR通过物理对齐的双级先验解决多样化光照条件下的阴影去除问题，包括物理对齐归一化和几何语义矫正注意力机制，在单光源到多源环境光照下均表现鲁棒。


<details>
  <summary>Details</summary>
Motivation: 在多样化光照条件下进行阴影去除需要将光照与内在反射率解耦，当物理先验未正确对齐时这一挑战尤为突出。传统方法在多源环境光照下表现不佳。

Method: 提出PhaSR框架，包含两个核心组件：1) 物理对齐归一化(PAN)：通过灰世界归一化、对数域Retinex分解和动态范围重组进行闭式光照校正，抑制色偏；2) 几何语义矫正注意力(GSRA)：将差分注意力扩展到跨模态对齐，协调深度导出的几何信息与DINO-v2语义嵌入，解决不同光照下的模态冲突。

Result: 实验显示在阴影去除任务上具有竞争力，计算复杂度更低，并能泛化到环境光照场景，在多源光照下传统方法失效时仍能有效工作。

Conclusion: PhaSR通过物理对齐的双级先验实现了从单光源阴影到多源环境光照的鲁棒阴影去除，解决了模态冲突和色偏问题，为多样化光照条件下的阴影去除提供了有效解决方案。

Abstract: Shadow removal under diverse lighting conditions requires disentangling illumination from intrinsic reflectance, a challenge compounded when physical priors are not properly aligned. We propose PhaSR (Physically Aligned Shadow Removal), addressing this through dual-level prior alignment to enable robust performance from single-light shadows to multi-source ambient lighting. First, Physically Aligned Normalization (PAN) performs closed-form illumination correction via Gray-world normalization, log-domain Retinex decomposition, and dynamic range recombination, suppressing chromatic bias. Second, Geometric-Semantic Rectification Attention (GSRA) extends differential attention to cross-modal alignment, harmonizing depth-derived geometry with DINO-v2 semantic embeddings to resolve modal conflicts under varying illumination. Experiments show competitive performance in shadow removal with lower complexity and generalization to ambient lighting where traditional methods fail under multi-source illumination. Our source code is available at https://github.com/ming053l/PhaSR.

</details>


### [20] [SPACE-CLIP: Spatial Perception via Adaptive CLIP Embeddings for Monocular Depth Estimation](https://arxiv.org/abs/2601.17657)
*Taewan Cho,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.CV

TL;DR: SPACE-CLIP是一种直接从冻结的CLIP视觉编码器提取几何知识的双路径解码器架构，无需文本编码器和文本提示，显著提升了深度估计性能


<details>
  <summary>Details</summary>
Motivation: CLIP在语义理解方面表现出色，但固有地难以感知几何结构。现有方法通过文本提示查询CLIP来弥补这一差距，但这种方法间接且低效。需要一种更直接、高效的方法来解锁CLIP中的几何知识。

Method: 提出SPACE-CLIP架构，采用双路径解码器：1) 语义路径解释高级特征，使用特征级线性调制(FiLM)根据全局上下文动态调节；2) 结构路径从早期层提取细粒度空间细节。两条互补路径通过分层融合实现语义上下文和精确几何的鲁棒合成。

Result: 在KITTI基准测试上的广泛实验表明，SPACE-CLIP显著优于之前的CLIP基方法。消融研究验证了双路径协同融合对成功的关键作用。

Conclusion: SPACE-CLIP为重新利用大规模视觉模型提供了一个新颖、高效且架构优雅的蓝图。该方法不仅是一个独立的深度估计器，更是下一代具身AI系统（如视觉-语言-动作模型）中易于集成的空间感知模块。

Abstract: Contrastive Language-Image Pre-training (CLIP) has accomplished extraordinary success for semantic understanding but inherently struggles to perceive geometric structure. Existing methods attempt to bridge this gap by querying CLIP with textual prompts, a process that is often indirect and inefficient. This paper introduces a fundamentally different approach using a dual-pathway decoder. We present SPACE-CLIP, an architecture that unlocks and interprets latent geometric knowledge directly from a frozen CLIP vision encoder, completely bypassing the text encoder and its associated textual prompts. A semantic pathway interprets high-level features, dynamically conditioned on global context using feature-wise linear modulation (FiLM). In addition, a structural pathway extracts fine-grained spatial details from early layers. These complementary streams are hierarchically fused, enabling a robust synthesis of semantic context and precise geometry. Extensive experiments on the KITTI benchmark show that SPACE-CLIP dramatically outperforms previous CLIP-based methods. Our ablation studies validate that the synergistic fusion of our dual pathways is critical to this success. SPACE-CLIP offers a new, efficient, and architecturally elegant blueprint for repurposing large-scale vision models. The proposed method is not just a standalone depth estimator, but a readily integrable spatial perception module for the next generation of embodied AI systems, such as vision-language-action (VLA) models. Our model is available at https://github.com/taewan2002/space-clip

</details>


### [21] [Training-Free Text-to-Image Compositional Food Generation via Prompt Grafting](https://arxiv.org/abs/2601.17666)
*Xinyue Pan,Yuhao Chen,Fengqing Zhu*

Main category: cs.CV

TL;DR: 提出Prompt Grafting框架，通过两阶段布局引导解决多食物图像生成中的物体纠缠问题，实现可控的食物分离与混合


<details>
  <summary>Details</summary>
Motivation: 现实世界餐食图像通常包含多种食物，但现有文本到图像扩散模型在多食物生成时存在物体纠缠问题（如米饭和汤融合），这影响了基于图像的膳食评估和食谱可视化等应用

Method: 提出Prompt Grafting训练免费框架，结合文本中的显式空间线索和采样过程中的隐式布局引导。采用两阶段过程：首先使用布局提示建立不同区域，待布局稳定后将目标提示嫁接。通过编辑布局排列实现食物纠缠控制

Result: 在两个食物数据集上，该方法显著提高了目标物体的存在率，并提供了可控分离的定性证据

Conclusion: Prompt Grafting框架有效解决了多食物图像生成中的物体纠缠问题，实现了可控的食物分离与混合，为图像式膳食评估和食谱可视化等应用提供了可靠的多食物数据增强方案

Abstract: Real-world meal images often contain multiple food items, making reliable compositional food image generation important for applications such as image-based dietary assessment, where multi-food data augmentation is needed, and recipe visualization. However, modern text-to-image diffusion models struggle to generate accurate multi-food images due to object entanglement, where adjacent foods (e.g., rice and soup) fuse together because many foods do not have clear boundaries. To address this challenge, we introduce Prompt Grafting (PG), a training-free framework that combines explicit spatial cues in text with implicit layout guidance during sampling. PG runs a two-stage process where a layout prompt first establishes distinct regions and the target prompt is grafted once layout formation stabilizes. The framework enables food entanglement control: users can specify which food items should remain separated or be intentionally mixed by editing the arrangement of layouts. Across two food datasets, our method significantly improves the presence of target objects and provides qualitative evidence of controllable separation.

</details>


### [22] [Learning Sewing Patterns via Latent Flow Matching of Implicit Fields](https://arxiv.org/abs/2601.17740)
*Cong Cao,Ren Li,Corentin Dumery,Hao Li*

Main category: cs.CV

TL;DR: 提出基于隐式表示的缝纫图案建模方法，使用符号距离场表示面板边界，无符号距离场标识缝端点，通过连续潜在空间实现可微分网格化，支持复杂结构的缝纫图案生成与估计。


<details>
  <summary>Details</summary>
Motivation: 缝纫图案定义了服装的结构基础，对时尚设计、制作和物理模拟至关重要。尽管自动图案生成有进展，但由于面板几何形状和缝线排列的广泛变异性，准确建模缝纫图案仍然困难。

Method: 基于隐式表示的方法：1) 使用符号距离场表示面板边界，无符号距离场标识缝端点；2) 将这些场编码到连续潜在空间实现可微分网格化；3) 潜在流匹配模型学习面板组合分布；4) 缝线预测模块从提取的边缘段恢复缝线关系。

Result: 该方法能够准确建模和生成具有复杂结构的缝纫图案。相比现有方法，从图像估计缝纫图案的准确性有所提高，并支持图案补全和重新适配等应用。

Conclusion: 该方法为数字时尚设计提供了实用工具，通过隐式表示和潜在流匹配实现了复杂缝纫图案的准确建模与生成，支持多种实际应用场景。

Abstract: Sewing patterns define the structural foundation of garments and are essential for applications such as fashion design, fabrication, and physical simulation. Despite progress in automated pattern generation, accurately modeling sewing patterns remains difficult due to the broad variability in panel geometry and seam arrangements. In this work, we introduce a sewing pattern modeling method based on an implicit representation. We represent each panel using a signed distance field that defines its boundary and an unsigned distance field that identifies seam endpoints, and encode these fields into a continuous latent space that enables differentiable meshing. A latent flow matching model learns distributions over panel combinations in this representation, and a stitching prediction module recovers seam relations from extracted edge segments. This formulation allows accurate modeling and generation of sewing patterns with complex structures. We further show that it can be used to estimate sewing patterns from images with improved accuracy relative to existing approaches, and supports applications such as pattern completion and refitting, providing a practical tool for digital fashion design.

</details>


### [23] [VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding](https://arxiv.org/abs/2601.17868)
*Zhihao He,Tieyuan Chen,Kangyu Wang,Ziran Qin,Yang Shao,Chaofan Gan,Shijie Li,Zuxuan Wu,Weiyao Lin*

Main category: cs.CV

TL;DR: VidLaDA是一种基于扩散语言模型的视频大语言模型，采用双向注意力机制捕获双向依赖关系，并通过MARS-Cache框架解决大规模视频token扩散解码的推理瓶颈，实现12倍加速且保持推理精度。


<details>
  <summary>Details</summary>
Motivation: 标准自回归视频LLM存在因果掩码偏差，阻碍全局时空建模，导致理解效率低下。需要一种能够捕获双向依赖关系并解决大规模视频token推理瓶颈的方法。

Method: 提出VidLaDA，基于扩散语言模型利用双向注意力捕获双向依赖。引入MARS-Cache框架，结合异步视觉缓存刷新和帧级分块注意力，通过锚点token保持全局连接性，有效剪枝冗余。

Result: VidLaDA在实验中优于扩散基线模型，并与最先进的自回归模型（如Qwen2.5-VL和LLaVA-Video）相当。MARS-Cache实现超过12倍的推理加速，且不损害推理准确性。

Conclusion: VidLaDA通过扩散语言模型和双向注意力机制解决了自回归视频LLM的因果掩码偏差问题，MARS-Cache框架有效解决了大规模视频token的推理瓶颈，在性能和效率上均取得显著提升。

Abstract: Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.

</details>


### [24] [Text-Pass Filter: An Efficient Scene Text Detector](https://arxiv.org/abs/2601.18098)
*Chuang Yang,Haozhao Ma,Xu Han,Yuan Yuan,Qi Wang*

Main category: cs.CV

TL;DR: TPF是一种用于任意形状文本检测的新方法，通过模拟带通滤波器原理直接分割整个文本区域，避免了传统收缩-掩码扩展策略的固有局限性，并能自然分离粘连文本而无需复杂解码或后处理。


<details>
  <summary>Details</summary>
Motivation: 现有文本检测方法采用收缩-掩码扩展策略，但收缩操作会丢失文本边缘的视觉特征并混淆前景背景差异，这给文本特征识别带来了固有局限性。需要一种能直接分割整个文本区域且能自然分离粘连文本的方法。

Method: TPF模拟带通滤波器原理，为每个文本构建独特的特征-滤波器对。在推理阶段，每个滤波器通过传递其通带特征并阻挡其他特征来提取对应的匹配文本。此外，设计了REU增强同一文本的特征一致性并扩大滤波器的识别范围，以及FPU鼓励TPF区分前景背景差异以提高特征-滤波器对质量。

Result: 实验证明了REU和FPU的有效性，并展示了TPF的优越性能。该方法能够自然分离粘连文本，无需复杂解码或后处理，为实时文本检测提供了可能。

Conclusion: TPF通过模拟带通滤波器原理，提供了一种直接分割整个文本区域的新方法，克服了传统收缩-掩码扩展策略的固有局限性，能够自然分离粘连文本，为高效、实时的任意形状文本检测提供了有效解决方案。

Abstract: To pursue an efficient text assembling process, existing methods detect texts via the shrink-mask expansion strategy. However, the shrinking operation loses the visual features of text margins and confuses the foreground and background difference, which brings intrinsic limitations to recognize text features. We follow this issue and design Text-Pass Filter (TPF) for arbitrary-shaped text detection. It segments the whole text directly, which avoids the intrinsic limitations. It is noteworthy that different from previous whole text region-based methods, TPF can separate adhesive texts naturally without complex decoding or post-processing processes, which makes it possible for real-time text detection. Concretely, we find that the band-pass filter allows through components in a specified band of frequencies, called its passband but blocks components with frequencies above or below this band. It provides a natural idea for extracting whole texts separately. By simulating the band-pass filter, TPF constructs a unique feature-filter pair for each text. In the inference stage, every filter extracts the corresponding matched text by passing its pass-feature and blocking other features. Meanwhile, considering the large aspect ratio problem of ribbon-like texts makes it hard to recognize texts wholly, a Reinforcement Ensemble Unit (REU) is designed to enhance the feature consistency of the same text and to enlarge the filter's recognition field to help recognize whole texts. Furthermore, a Foreground Prior Unit (FPU) is introduced to encourage TPF to discriminate the difference between the foreground and background, which improves the feature-filter pair quality. Experiments demonstrate the effectiveness of REU and FPU while showing the TPF's superiority.

</details>


### [25] [A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification](https://arxiv.org/abs/2601.18330)
*Muhammad Ali Shah,Muhammad Mansoor Alam,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 该研究提出了一种高效的密集Swin混合（EDSH）框架用于脑肿瘤MRI分析，通过两个肿瘤感知实验设置联合捕捉细粒度纹理模式和长距离上下文依赖关系，在大型MRI数据集上取得了98.50%的准确率和召回率。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤MRI分析需要同时捕捉细粒度纹理模式和长距离上下文依赖关系，但现有方法难以有效结合局部特征学习和全局形态建模。针对不同肿瘤类型（弥漫性胶质瘤、脑膜瘤、垂体瘤）的诊断挑战需要专门的设计来应对。

Method: 提出了两种肿瘤感知实验设置：1）增强特征空间（BFS）设置，通过独立定制的DenseNet和Swin分支学习互补的局部和全局表示，进行维度对齐、融合和增强；2）分层DenseNet-Swin架构，具有深度特征提取和双残差连接（DFE和DR），DenseNet作为主干CNN学习结构化局部特征，Swin_t建模全局肿瘤形态。DenseNet在输入级别定制以匹配MRI空间特性，Swin_t通过任务对齐的补丁嵌入和移位窗口自注意力机制定制。

Result: 在大型MRI数据集（40,260张图像，四个肿瘤类别）上进行广泛评估，结果显示EDSH框架在测试未见数据集上实现了98.50%的准确率和召回率，一致优于独立的CNN、Vision Transformer和混合方法。

Conclusion: EDSH框架通过联合学习局部纹理和全局上下文特征，有效解决了脑肿瘤MRI分析中的诊断挑战，在弥漫性胶质瘤检测和脑膜瘤/垂体瘤分类方面表现出色，为医学影像分析提供了高效可靠的解决方案。

Abstract: This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.

</details>


### [26] [Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray](https://arxiv.org/abs/2601.18555)
*Roberto Di Via,Vito Paolo Pastore,Francesca Odone,Siôn Glyn-Jones,Irina Voiculescu*

Main category: cs.CV

TL;DR: 该研究验证了使用标准热图回归架构在MRI上实现与X射线相当的髋臼撞击症(FAI)标志点检测和诊断准确性，支持将自动化FAI评估整合到常规MRI工作流程中。


<details>
  <summary>Details</summary>
Motivation: 临床筛查决策常基于角度测量，特别是FAI筛查传统上依赖X射线测量角度。然而，评估撞击区域的高度和范围需要MRI扫描的3D视图。两种模态为外科医生提供不同方面的信息，需要验证MRI是否也能达到与X射线相当的定位和诊断准确性。

Method: 采用匹配队列验证研究（89名患者，配对MRI/X射线），使用标准热图回归架构评估跨模态临床等效性。研究在3D MRI体积的冠状视图中进行FAI评估，通过标志点检测方法实现定位。

Result: MRI在cam型撞击症的定位和诊断准确性方面达到与X射线等效的水平。该方法在3D MRI体积的冠状视图中展示了临床可行性，为通过放置更多标志点进行体积分析开辟了可能性。

Conclusion: 研究结果支持将自动化FAI评估整合到常规MRI工作流程中。MRI在FAI评估中具有与X射线相当的临床价值，为未来进行更全面的体积分析奠定了基础。

Abstract: Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions

</details>


### [27] [SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification](https://arxiv.org/abs/2601.18739)
*Ignacio Antequera-Sánchez,Juan Luis Suárez-Díaz,Rosana Montes,Francisco Herrera*

Main category: cs.CV

TL;DR: 提出SeNeDiF-OOD方法，基于语义嵌套二分融合的层次化框架，有效处理开放世界中从低级损坏到语义偏移的异构OOD数据，在MonuMAI建筑风格识别系统中验证了优越性能。


<details>
  <summary>Details</summary>
Motivation: 开放世界AI应用中，OOD检测是可靠部署的基本要求。然而，OOD数据的异构性（从低级损坏到语义偏移）使得单阶段检测器难以有效处理，需要新的方法来解决这一复杂挑战。

Method: 提出SeNeDiF-OOD方法，基于语义嵌套二分融合框架。该方法将检测任务分解为层次化的二元融合节点结构，每一层设计用于整合与特定语义抽象级别对齐的决策边界。

Result: 在MonuMAI建筑风格识别系统的实际案例研究中，该方法面对非纪念碑图像、未知建筑风格和对抗攻击等多种输入，实验结果表明层次化融合方法显著优于传统基线，能有效过滤这些多样化的OOD类别，同时保持分布内性能。

Conclusion: SeNeDiF-OOD通过语义嵌套二分融合的层次化框架，成功解决了异构OOD数据检测的复杂挑战，在开放世界环境中实现了可靠的OOD检测，为AI系统的实际部署提供了有效解决方案。

Abstract: Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [28] [A Systemic Evaluation of Multimodal RAG Privacy](https://arxiv.org/abs/2601.17644)
*Ali Al-Lawati,Suhang Wang*

Main category: cs.CR

TL;DR: 对多模态检索增强生成（mRAG）管道在视觉任务中的隐私风险进行实证研究，分析通过标准模型提示泄露私有图像及其元数据（如标题）的风险


<details>
  <summary>Details</summary>
Motivation: 随着mRAG在视觉中心任务（如视觉问答）中的广泛应用，虽然它能够连接私有数据集提升模型性能，但也带来了重要的隐私挑战，存在在推理过程中泄露私有信息的风险

Method: 通过实证研究分析mRAG管道中的隐私风险，实施案例研究，尝试推断视觉资产（如图像）是否包含在mRAG中，如果存在则泄露其相关元数据（如标题）

Result: 研究发现mRAG管道存在显著的隐私风险，通过标准模型提示可能泄露私有视觉资产及其元数据

Conclusion: 研究结果强调了隐私保护机制的必要性，并推动未来对mRAG隐私的进一步研究

Abstract: The growing adoption of multimodal Retrieval-Augmented Generation (mRAG) pipelines for vision-centric tasks (e.g. visual QA) introduces important privacy challenges. In particular, while mRAG provides a practical capability to connect private datasets to improve model performance, it risks the leakage of private information from these datasets during inference. In this paper, we perform an empirical study to analyze the privacy risks inherent in the mRAG pipeline observed through standard model prompting. Specifically, we implement a case study that attempts to infer the inclusion of a visual asset, e.g. image, in the mRAG, and if present leak the metadata, e.g. caption, related to it. Our findings highlight the need for privacy-preserving mechanisms and motivate future research on mRAG privacy.

</details>


### [29] [A PUF-Based Security Framework for Fault and Intrusion Detection](https://arxiv.org/abs/2601.17661)
*Ahmed Oun,Rishabh Das,Clay Hess,Aakriti Barat,Savas Kaya*

Main category: cs.CR

TL;DR: 该研究提出了一种基于硬件信任根的传感器认证架构，通过在测量层嵌入物理不可克隆函数来验证工业控制系统中的传感器读数，能够检测各种注入异常和硬件木马攻击。


<details>
  <summary>Details</summary>
Motivation: 工业控制系统依赖传感器反馈来确保安全关键过程在操作限值内运行，但传感器读数可能受到信号退化或供应链攻击的威胁，需要一种可靠的认证机制来保障系统安全。

Method: 采用硬件信任根架构，在测量层嵌入物理不可克隆函数，结合电压指纹和时间认证技术，与标准工业控制系统架构集成。通过基于Simulink的PUF仿真器在硬件在环水箱测试平台上进行原型实现。

Result: 系统在5.18小时正常操作期间保持99.97%的准确率，能够标记所有注入的异常，包括尖峰故障、硬过故障以及将系统推向不安全操作状态的硬件木马场景。

Conclusion: 该架构提供了一种过程感知、供应商无关的方法，可与遗留工厂集成，检测传感器信号退化或复杂的供应链攻击，为工业控制系统提供增强的安全保障。

Abstract: Industrial Control Systems (ICS) rely on sensor feedback to keep safety-critical processes within operational limits. This research presents a hardware-root-of-trust that embeds a Physically Unclonable Function (PUF) at the measurement layer to authenticate sensor readings. The architecture combines voltage fingerprinting with a temporal authentication that integrates with standard industrial control system architecture. The research prototypes the PUF integration on a hardware-in-the-loop (HIL) water tank testbed using a Simulink-based PUF emulator. The system maintains 99.97% accuracy over a 5.18-hour period of normal operation and flags all injected anomalies, including spike faults, hard-over faults, and hardware trojan scenarios that push the system over to an unsafe operational state. The proposed architecture provides a process-aware, vendor-agnostic approach that can integrate with legacy plants to detect sensor signal degradation or sophisticated supply chain attacks.

</details>


### [30] [Performance Analysis of Quantum-Secure Digital Signature Algorithms in Blockchain](https://arxiv.org/abs/2601.17785)
*Tushar Jain*

Main category: cs.CR

TL;DR: 该论文提出了一个支持多种后量子安全签名算法的区块链原型系统，重点关注基于格的CRYSTALS-Dilithium、Falcon和Hawk算法，评估了它们在区块链环境中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 当前大多数加密货币和区块链平台依赖椭圆曲线密码学，而Shor算法使其易受量子攻击威胁。为确保区块链的长期安全性，需要研究后量子数字签名在实际区块链系统中的表现。

Method: 设计并实现了一个支持多种量子安全签名算法的区块链原型系统，重点关注基于格的签名方案（CRYSTALS-Dilithium、Falcon、Hawk），评估了密钥生成、签名、验证时间、密钥大小和签名大小等性能指标。

Result: 提供了量子安全签名在区块链环境中的详细性能比较，包括对CRYSTALS-Dilithium、Falcon、Hawk以及HAETAE等方案的分析，展示了不同后量子签名算法在区块链应用中的实际性能数据。

Conclusion: 后量子数字签名对于区块链的长期安全至关重要，基于格的签名方案在区块链环境中具有可行性，但需要在实际部署中考虑性能权衡和具体实现细节。

Abstract: The long-term security of public blockchains strictly depends on the hardness assumptions of the underlying digital signature schemes. In the current scenario, most deployed cryptocurrencies and blockchain platforms rely on elliptic-curve cryptography, which is vulnerable to quantum attacks due to Shor's algorithm. Therefore, it is important to understand how post-quantum (PQ) digital signatures behave when integrated into real blockchain systems. This report presents a blockchain prototype that supports multiple quantum-secure signature algorithms, focusing on CRYSTALS-Dilithium, Falcon and Hawk as lattice-based schemes. This report also describes the design of the prototype and discusses the performance metrics, which include key generation, signing, verification times, key sizes and signature sizes. This report covers the problem, background, and experimental methodology, also providing a detailed comparison of quantum-secure signatures in a blockchain context and extending the analysis to schemes such as HAETAE.

</details>


### [31] [FARM: Few-shot Adaptive Malware Family Classification under Concept Drift](https://arxiv.org/abs/2601.17907)
*Numan Halit Guldemir,Oluwafemi Olukoya,Jesús Martínez-del-Rincón*

Main category: cs.CR

TL;DR: FARM框架通过三元组自编码器、DBSCAN聚类和原型分类，实现恶意软件分类中的概念漂移检测与少样本自适应学习


<details>
  <summary>Details</summary>
Motivation: 恶意软件分类模型面临概念漂移问题，包括协变量漂移和标签漂移，导致性能下降。现有方法难以在动态威胁环境中有效检测和适应这些变化，特别是在监督数据有限的情况下。

Method: 1. 使用三元组自编码器将样本投影到判别性潜在空间；2. 通过DBSCAN聚类和动态阈值进行无监督漂移检测；3. 采用基于原型的少样本学习进行快速适应；4. 当积累足够漂移样本时支持完全重新训练以更新潜在空间。

Result: 在BenchMFC数据集上，FARM在协变量漂移下将分类性能提升5.6%，仅使用少样本适应在未见恶意软件家族上达到平均F1分数0.85，重新训练后进一步提升至0.94。

Conclusion: FARM框架在有限监督下展现出对动态恶意软件检测环境的鲁棒性和适应性，能够有效处理概念漂移问题，为恶意软件分类提供了实用的自适应解决方案。

Abstract: Malware classification models often face performance degradation due to concept drift, arising from evolving threat landscapes and the emergence of novel malware families. This paper presents FARM (Few-shot Adaptive Recognition of Malware), a framework designed to detect and adapt to both covariate and label drift in Windows Portable Executable (PE) malware classification. FARM leverages a triplet autoencoder to project samples into a discriminative latent space, enabling unsupervised drift detection via DBSCAN clustering and dynamic thresholding. For rapid adaptation, it employs few-shot learning using prototype-based classification, requiring only a handful of labeled samples. FARM also supports full retraining when enough drifted samples accumulate, updating the latent space for long-term integration. Experiments on the BenchMFC dataset demonstrate that FARM improves classification performance under covariate drift by 5.6\%, and achieves an average F1 score of 0.85 on unseen malware families using only few-shot adaptation, which further increases to 0.94 after retraining. These results highlight FARM's robustness and adaptability in dynamic malware detection environments under limited supervision.

</details>


### [32] [From Statistical Disclosure Control to Fair AI: Navigating Fundamental Tradeoffs in Differential Privacy](https://arxiv.org/abs/2601.17909)
*Adriana Watson*

Main category: cs.CR

TL;DR: 该论文系统分析了隐私、效用和公平性之间的三方权衡，揭示了同时实现这三者的基本限制，为部署隐私保护公平学习系统提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 当前差分隐私研究过度关注隐私-效用权衡，而忽视了公平性约束。需要系统性地连接Dalenius语义隐私不可能性、Dwork差分隐私可实现性以及加入公平性要求后的新不可能性结果，为实践者和政策制定者提供统一框架。

Method: 通过具体示例和技术分析，展示隐私、效用和公平性之间的三方帕累托前沿，表征这些基本限制，展示对少数群体的影响，并提供导航这些权衡的实用指导。

Result: 揭示了隐私、效用和公平性之间存在基本权衡限制，这些限制无法同时被满足，特别是对少数群体有显著影响。构建了统一框架来综合分散的研究结果。

Conclusion: 隐私保护公平学习系统面临根本性的三方权衡限制，需要实践者和政策制定者在部署时做出明智权衡决策。该框架为理解和导航这些权衡提供了系统指导。

Abstract: Differential privacy has become the gold standard for privacy-preserving machine learning systems. Unfortunately, subsequent work has primarily fixated on the privacy-utility tradeoff, leaving the subject of fairness constraints undervalued and under-researched. This paper provides a systematic treatment connecting three threads: (1) Dalenius's impossibility results for semantic privacy, (2) Dwork's differential privacy as an achievable alternative, and (3) emerging impossibility results from the addition of a fairness requirement. Through concrete examples and technical analysis, the three-way Pareto frontier between privacy, utility, and fairness is demonstrated to showcase the fundamental limits on what can be simultaneously achieved. In this work, these limits are characterized, the impact on minority groups is demonstrated, and practical guidance for navigating these tradeoffs are provided. This forms a unified framework synthesizing scattered results to help practitioners and policymakers make informed decisions when deploying private fair learning systems.

</details>


### [33] [Prompt Injection Evaluations: Refusal Boundary Instability and Artifact-Dependent Compliance in GPT-4-Series Models](https://arxiv.org/abs/2601.17911)
*Thomas Heverin*

Main category: cs.CR

TL;DR: 研究挑战了将拒绝视为稳定二元安全指标的范式，通过建模拒绝为局部决策边界并检验其在结构化扰动下的稳定性，发现拒绝行为是概率性、依赖特定内容的边界现象而非稳定二元属性。


<details>
  <summary>Details</summary>
Motivation: 当前提示注入评估通常将拒绝视为稳定、二元的安全指标，但本研究质疑这一范式，认为拒绝行为可能是不稳定的，需要更深入理解其作为决策边界的特性。

Method: 评估GPT-4.1和GPT-4o两个模型，使用3,274次扰动运行（源自拒绝诱导的提示注入尝试）。每个基础提示受到25次跨五个结构化家族的扰动，结果手动编码为拒绝、部分合规或完全合规。使用卡方检验、逻辑回归、混合效应模型和新型拒绝边界熵(RBE)指标进行分析。

Result: 虽然两个模型拒绝率均超过94%，但拒绝不稳定性持续存在且不均匀。约三分之一初始拒绝诱导提示表现出至少一次"拒绝逃逸"（扰动下转向合规）。文本类内容（如勒索软件说明）不稳定性显著更高，翻转率超过20%；而可执行恶意软件内容在两个模型中均显示零拒绝逃逸。GPT-4o表现出更严格的拒绝执行和更低的RBE，但未消除内容依赖风险。

Conclusion: 拒绝行为是概率性、依赖特定内容的边界现象而非稳定二元属性，单提示评估系统性高估安全鲁棒性，需要改变LLM安全测量和审计方式。

Abstract: Prompt injection evaluations typically treat refusal as a stable, binary indicator of safety. This study challenges that paradigm by modeling refusal as a local decision boundary and examining its stability under structured perturbations. We evaluated two models, GPT-4.1 and GPT-4o, using 3,274 perturbation runs derived from refusal-inducing prompt injection attempts. Each base prompt was subjected to 25 perturbations across five structured families, with outcomes manually coded as Refusal, Partial Compliance, or Full Compliance.
  Using chi-square tests, logistic regression, mixed-effects modeling, and a novel Refusal Boundary Entropy (RBE) metric, we demonstrate that while both models refuse >94% of attempts, refusal instability is persistent and non-uniform. Approximately one-third of initial refusal-inducing prompts exhibited at least one "refusal escape," a transition to compliance under perturbation. We find that artifact type is a stronger predictor of refusal failure than perturbation style. Textual artifacts, such as ransomware notes, exhibited significantly higher instability, with flip rates exceeding 20%. Conversely, executable malware artifacts showed zero refusal escapes in both models. While GPT-4o demonstrated tighter refusal enforcement and lower RBE than GPT-4.1, it did not eliminate artifact-dependent risks. These findings suggest that single-prompt evaluations systematically overestimate safety robustness. We conclude that refusal behavior is a probabilistic, artifact-dependent boundary phenomenon rather than a stable binary property, requiring a shift in how LLM safety is measured and audited.

</details>


### [34] [Data Siphoning Through Advanced Persistent Transmission Attacks At The Physical Layer](https://arxiv.org/abs/2601.17967)
*Alon Hillel-Tuch*

Main category: cs.CR

TL;DR: 研究开发物理层感知与完整性协议以缓解侧信道攻击的可行性，这些攻击会导致数据窃听和拒绝服务


<details>
  <summary>Details</summary>
Motivation: 物理层传输介质（铜缆、光纤、无线）存在攻击向量，威胁数据机密性和可用性。现有协议和加密标准难以保护数据类型和目的地安全，对机密性和完整性的洞察有限。

Method: 研究开发一种感知与完整性协议，专门针对物理侧信道攻击进行缓解，包括窃听和拒绝服务攻击。

Result: 论文探讨了该协议的可行性，但未提供具体实验结果或性能数据。

Conclusion: 需要开发专门的物理层感知与完整性协议来应对侧信道攻击，以增强数据通信的安全性。

Abstract: Data at the physical layer transmits via media such as copper cable, fiber optic, or wireless. Physical attack vectors exist that challenge data confidentiality and availability. Protocols and encryption standards help obfuscate but often cannot keep the data type and destination secure, with limited insight into confidentiality and integrity. We will investigate the feasibility of developing an awareness and integrity protocol to help mitigate physical side-channel attacks that lead to eavesdropping of data communication and denial-of-service.
  Keywords: data confidentiality, siphoning, eavesdropping, person-in-the-middle, denial-of-service, physical layer attacks, nation-states

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [35] [Exact Minimum-Volume Confidence Set Intersection for Multinomial Outcomes](https://arxiv.org/abs/2601.18145)
*Heguang Lin,Binhao Chen,Mengze Li,Daniel Pimentel-Alarcón,Matthew L. Malloy*

Main category: stat.ML

TL;DR: 提出了一种认证算法，用于判断两个观察到的多项分布结果的最小体积置信集(MVCs)是否相交，解决了A/B测试中的核心决策问题。


<details>
  <summary>Details</summary>
Motivation: 最小体积置信集(MVCs)在多项分布参数推断中是最优的，但其几何形状复杂且难以计算。实际应用中需要解决一个核心决策问题：给定两个观察结果，能否认证它们的MVCs是否相交？这直接关系到A/B测试中的决策可靠性。

Method: 利用似然排序在对数几率坐标中产生半空间约束，通过参数空间的自适应几何划分，计算每个单元上p值的可计算上下界。对于三类别情况，开发了高效且可证明可靠的算法，能够认证交集、认证不相交，或在决策处于预设边界内时返回不确定结果。

Result: 该方法在三类别情况下实现了高效可靠的认证算法，并展示了如何扩展到更高维度。结果表明，尽管MVCs具有不规则的几何形状，但对于A/B测试中的核心任务仍可设计可靠的认证决策程序。

Conclusion: 尽管最小体积置信集的几何形状复杂，但通过利用似然排序在对数几率坐标中的半空间约束特性，可以开发出可靠的认证决策程序来解决MVCs交集问题，这对于A/B测试等实际应用具有重要意义。

Abstract: Computation of confidence sets is central to data science and machine learning, serving as the workhorse of A/B testing and underpinning the operation and analysis of reinforcement learning algorithms. Among all valid confidence sets for the multinomial parameter, minimum-volume confidence sets (MVCs) are optimal in that they minimize average volume, but they are defined as level sets of an exact p-value that is discontinuous and difficult to compute. Rather than attempting to characterize the geometry of MVCs directly, this paper studies a practically motivated decision problem: given two observed multinomial outcomes, can one certify whether their MVCs intersect? We present a certified, tolerance-aware algorithm for this intersection problem. The method exploits the fact that likelihood ordering induces halfspace constraints in log-odds coordinates, enabling adaptive geometric partitioning of parameter space and computable lower and upper bounds on p-values over each cell. For three categories, this yields an efficient and provably sound algorithm that either certifies intersection, certifies disjointness, or returns an indeterminate result when the decision lies within a prescribed margin. We further show how the approach extends to higher dimensions. The results demonstrate that, despite their irregular geometry, MVCs admit reliable certified decision procedures for core tasks in A/B testing.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [36] [Tighter confidence intervals for quantiles of heterogeneous data](https://arxiv.org/abs/2601.17302)
*John H. J. Einmahl,Yi He*

Main category: math.ST

TL;DR: 提出一种新的方差估计方法，用于在异质性数据中构建分位数的渐近正确置信区间，相比i.i.d.情况能显著缩短区间长度


<details>
  <summary>Details</summary>
Motivation: 在异质性数据中，样本分位数的渐近方差相比i.i.d.设置可以降低，但目前缺乏渐近正确的置信区间构建方法

Method: 提出一种新颖且一致的方差估计器，用于估计从观测组计算分位数时产生的降低的渐近方差，从而构建渐近正确的置信区间

Result: 模拟研究表明，提出的置信区间相比i.i.d.情况显著缩短，并在广泛的异质性设置中达到接近正确的覆盖率

Conclusion: 该方法成功解决了异质性数据中分位数置信区间构建的问题，提供了更精确的统计推断工具

Abstract: It is well known that the asymptotic variance of sample quantiles can be reduced under heterogeneity relative to the i.i.d. setting. However, asymptotically correct confidence intervals for quantiles are not yet available. We propose a novel, consistent estimator of the reduced asymptotic variance arising when quantiles are computed from groups of observations, leading to asymptotically correct confidence intervals. Simulation studies show that our confidence intervals are substantially shorter than those in the i.i.d. case and attain nearly correct coverage across a wide range of heterogeneous settings.

</details>


### [37] [Nonparametric inference for spot volatility in pure-jump semimartingales](https://arxiv.org/abs/2601.18371)
*Chengxin Yan,Dachuan Chen,Jia Li*

Main category: math.ST

TL;DR: 该论文分析了纯跳跃半鞅中现货波动率推断的两种渐近框架：固定k（每个局部窗口使用固定观测数）和大k（观测数随采样频率增长），发现在两种跳跃活动性设置下，固定k渐近方法在有限样本精度上显著更优。


<details>
  <summary>Details</summary>
Motivation: 研究纯跳跃半鞅中现货波动率推断的渐近理论，比较固定k和大k两种渐近框架的性能差异，为实际应用提供理论指导。

Method: 采用两种渐近设置：固定k渐近（每个局部窗口使用固定数量的观测值）和大k渐近（局部窗口观测数随采样频率增长）。在活跃跳跃和可能非活跃跳跃两种设置下，推导非标准、通常非高斯的极限分布，并建立有效的推断方法，包括当跳跃活动指数被一致估计时的情况。

Result: 对于两种跳跃活动性设置，都推导出了通常非标准、非高斯的极限分布。模拟结果显示，固定k渐近方法在有限样本精度上显著优于大k渐近方法，具有更好的实际应用价值。

Conclusion: 固定k渐近框架为纯跳跃半鞅中的非参数现货波动率推断提供了更优越的有限样本性能，在实际应用中具有明显优势。

Abstract: We provide a comprehensive analysis of spot volatility inference in pure-jump semimartingales under two asymptotic settings: fixed-$k$, where each local window uses a fixed number of observations, and large-$k$, where this number grows with sampling frequency. For both active- and possibly inactive-jump settings, we derive generally nonstandard, typically non-Gaussian limit distributions and establish valid inference, including when the jump-activity index is consistently estimated. Simulations show that fixed-$k$ asymptotics offer markedly better finite-sample accuracy, underscoring their practical advantage for nonparametric spot volatility inference.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [38] [Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning](https://arxiv.org/abs/2601.18626)
*Yingxiao Huo,Satya Prakash Dash,Radu Stoican,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 提出一种基于秩-1近似的自然策略优化方法，通过近似逆Fisher信息矩阵实现高效的自然梯度计算，在多种环境中优于标准actor-critic和信任域基线方法。


<details>
  <summary>Details</summary>
Motivation: 自然梯度在深度强化学习中具有快速收敛特性，但计算自然梯度需要每次迭代都求逆Fisher信息矩阵(FIM)，这在计算上是不可行的。需要开发一种高效且可扩展的自然策略优化技术。

Method: 提出一种利用秩-1近似来近似完整逆FIM的自然策略优化技术。该方法通过低秩近似避免了直接计算逆FIM的高计算成本，同时保持了自然梯度的优势。

Result: 理论分析表明，在特定条件下，秩-1近似逆FIM比策略梯度收敛更快，在某些条件下具有与随机策略梯度方法相同的样本复杂度。在多样化环境中的实验表明，该方法优于标准actor-critic和信任域基线方法。

Conclusion: 提出的秩-1近似自然策略优化方法在保持自然梯度优势的同时，显著降低了计算复杂度，实现了高效且可扩展的自然梯度计算，在多种强化学习任务中表现出优越性能。

Abstract: Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.

</details>


### [39] [Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models](https://arxiv.org/abs/2601.15801)
*Fengheng Chu,Jiahao Chen,Yuhong Wang,Jun Wang,Zhihui Fu,Shouling Ji,Songze Li*

Main category: cs.LG

TL;DR: GOSV框架通过全局优化识别LLM中的安全关键注意力头，发现恶意注入向量和安全抑制向量两种空间分离的安全向量，并基于此开发了新的白盒越狱攻击方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖局部、贪婪的属性归因，假设组件贡献独立，忽视了LLM中不同组件（如注意力头）之间的协同交互作用，这些组件共同构成安全机制。这导致对安全组件理解有限，安全护栏脆弱易受越狱攻击。

Method: 提出GOSV（全局优化安全向量提取）框架，通过全局优化同时考虑所有注意力头来识别安全关键注意力头。采用两种互补的激活重补丁策略：有害补丁和零消融。这些策略识别出空间上不同的两组安全向量：恶意注入向量和安全抑制向量。

Result: 发现对齐的LLM为安全目的维持着分离的功能通路。系统分析表明，当约30%的总头被重补丁时，所有模型都会出现完全的安全崩溃。基于这些洞察，开发了一种新颖的推理时白盒越狱方法，通过激活重补丁利用识别的安全向量。该攻击在所有测试模型上显著优于现有白盒攻击。

Conclusion: GOSV框架在LLM安全可解释性方面提供了强有力的证据，通过全局优化方法揭示了LLM安全机制中组件间的协同作用，并基于此开发了更有效的越狱攻击方法，加深了对LLM安全组件的理解。

Abstract: While Large Language Models (LLMs) are aligned to mitigate risks, their safety guardrails remain fragile against jailbreak attacks. This reveals limited understanding of components governing safety. Existing methods rely on local, greedy attribution that assumes independent component contributions. However, they overlook the cooperative interactions between different components in LLMs, such as attention heads, which jointly contribute to safety mechanisms. We propose \textbf{G}lobal \textbf{O}ptimization for \textbf{S}afety \textbf{V}ector Extraction (GOSV), a framework that identifies safety-critical attention heads through global optimization over all heads simultaneously. We employ two complementary activation repatching strategies: Harmful Patching and Zero Ablation. These strategies identify two spatially distinct sets of safety vectors with consistently low overlap, termed Malicious Injection Vectors and Safety Suppression Vectors, demonstrating that aligned LLMs maintain separate functional pathways for safety purposes. Through systematic analyses, we find that complete safety breakdown occurs when approximately 30\% of total heads are repatched across all models. Building on these insights, we develop a novel inference-time white-box jailbreak method that exploits the identified safety vectors through activation repatching. Our attack substantially outperforms existing white-box attacks across all test models, providing strong evidence for the effectiveness of the proposed GOSV framework on LLM safety interpretability.

</details>


### [40] [Robust Privacy: Inference-Time Privacy through Certified Robustness](https://arxiv.org/abs/2601.17360)
*Jiankai Jin,Xiangzheng Zhang,Zhao Liu,Deyue Zhang,Quanchen Zou*

Main category: cs.LG

TL;DR: 论文提出鲁棒隐私（RP）概念，通过模型预测在输入邻域内的不变性来提供推理时隐私保护，并开发属性隐私增强（APE）将输入级不变性转化为属性级隐私效果。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统可能产生个性化的输出，使攻击者能够在推理时推断敏感输入属性。现有隐私保护方法在推理时保护不足，需要一种新的推理时隐私概念来防止基于模型输出的敏感属性推断。

Method: 引入鲁棒隐私（RP）概念，类似于认证鲁棒性：如果模型预测在输入x的半径R邻域内（如ℓ₂范数下）具有可证明的不变性，则x享有R-鲁棒隐私。开发属性隐私增强（APE）将输入级不变性转化为属性级隐私效果。通过添加噪声实现预测不变性，并在受控推荐任务中验证方法。

Result: 在依赖敏感属性的推荐任务中，RP扩展了与正推荐兼容的敏感属性值集合，扩大了推断区间。实验表明，即使在小噪声水平（σ=0.1）下，RP将模型反转攻击（MIA）的成功率从73%降至4%，同时部分模型性能下降。RP也可在不降低模型性能的情况下部分缓解MIA（如攻击成功率降至44%）。

Conclusion: 鲁棒隐私（RP）提供了一种有效的推理时隐私保护框架，通过确保模型预测在输入邻域内的不变性来防止敏感属性推断。该方法能够显著降低模型反转攻击的成功率，同时保持模型性能的可接受水平，为机器学习系统的隐私保护提供了新思路。

Abstract: Machine learning systems can produce personalized outputs that allow an adversary to infer sensitive input attributes at inference time. We introduce Robust Privacy (RP), an inference-time privacy notion inspired by certified robustness: if a model's prediction is provably invariant within a radius-$R$ neighborhood around an input $x$ (e.g., under the $\ell_2$ norm), then $x$ enjoys $R$-Robust Privacy, i.e., observing the prediction cannot distinguish $x$ from any input within distance $R$ of $x$. We further develop Attribute Privacy Enhancement (APE) to translate input-level invariance into an attribute-level privacy effect. In a controlled recommendation task where the decision depends primarily on a sensitive attribute, we show that RP expands the set of sensitive-attribute values compatible with a positive recommendation, expanding the inference interval accordingly. Finally, we empirically demonstrate that RP also mitigates model inversion attacks (MIAs) by masking fine-grained input-output dependence. Even at small noise levels ($σ=0.1$), RP reduces the attack success rate (ASR) from 73% to 4% with partial model performance degradation. RP can also partially mitigate MIAs (e.g., ASR drops to 44%) with no model performance degradation.

</details>


### [41] [FlashMoE: Reducing SSD I/O Bottlenecks via ML-Based Cache Replacement for Mixture-of-Experts Inference on Edge Devices](https://arxiv.org/abs/2601.17063)
*Byeongju Kim,Jungwan Lee,Donghyeon Han,Hoi-Jun Yoo,Sangyeob Kim*

Main category: cs.LG

TL;DR: FlashMoE：一个将非活跃专家卸载到SSD的系统，用于在有限RAM下实现高效的MoE推理，通过ML缓存策略提升专家重用率，在真实硬件上相比现有系统实现最高2.6倍加速。


<details>
  <summary>Details</summary>
Motivation: MoE模型虽然通过稀疏激活实现高效推理，但现有DRAM卸载方案（如Fiddler、DAOP）不适合内存受限的端侧设备环境。随着MoE模型增长到数百GB，RAM卸载方案变得不切实际，需要新的解决方案。

Method: 提出FlashMoE系统，将非活跃专家卸载到SSD，支持有限RAM下的高效MoE推理。系统包含轻量级ML缓存策略，自适应结合最近使用和频率信号以最大化专家重用，显著减少存储I/O。同时构建用户级桌面平台验证实用性。

Result: 在真实硬件设置上，FlashMoE相比LRU和LFU等常见卸载策略，缓存命中率提升最高达51%。相比现有MoE推理系统，实现最高2.6倍加速。

Conclusion: FlashMoE通过SSD卸载和智能缓存策略，解决了大模型MoE在内存受限设备上的推理挑战，为端侧设备部署大型MoE模型提供了实用解决方案。

Abstract: Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.

</details>


### [42] [The Viscosity of Logic: Phase Transitions and Hysteresis in DPO Alignment](https://arxiv.org/abs/2601.17260)
*Marco Pollanen*

Main category: cs.LG

TL;DR: DPO的β参数不应被视为简单的对齐压力控制，而是需要密集扫描的控制参数。研究发现不同架构对β变化呈现不同响应模式，偏好边界可能与推理能力负相关，且存在训练路径依赖的滞后效应。


<details>
  <summary>Details</summary>
Motivation: 传统观点将DPO中的β参数视为对齐压力的简单控制，认为增加β会持续改善模型行为。本研究挑战这一观点，旨在系统探索β参数对模型能力的影响，揭示不同架构的响应差异，并评估偏好边界与推理能力的关系。

Method: 对三个7B开源模型家族（Mistral、Llama、Qwen）在固定DPO配方下密集扫描β参数。使用逻辑探针评估推理能力，分析能力与偏好边界的关系（Pearson相关系数），并研究训练路径依赖（滞后效应）。

Result: 1. Mistral能力呈尖锐非单调性：逻辑探针边界仅在β≈10⁻²附近窄带内为正，且边界点对随机种子敏感。2. 不同架构响应模式不同：Mistral呈现尖锐重组，Llama选择性变化，Qwen平滑权衡。3. DPO偏好边界与推理能力可能负相关（Llama逻辑任务r=-0.91）。4. 高β训练会导致能力损失，即使降低β也无法恢复（滞后效应）。

Conclusion: DPO的β参数需要在整个参数空间进行能力解析评估，而非依赖偏好边界或聚合基准。不同架构对β变化呈现本质不同的响应模式，偏好边界可能误导模型选择。训练历史对最终能力有持久影响，强调需要系统探索β景观。

Abstract: Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $β$) yields progressively "better" behavior. We instead treat $β$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $β\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $β$ induces capability losses that persist even after $β$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $β$ landscape rather than reliance on margins or aggregate benchmarks.

</details>


### [43] [PAR: Plausibility-aware Amortized Recourse Generation](https://arxiv.org/abs/2601.17309)
*Anagha Sabu,Vidhya S,Narayanan C Krishnan*

Main category: cs.LG

TL;DR: PAR：基于约束最大后验推理的概率性算法补救方法，通过摊销近似推理高效生成高似然度的可行补救方案


<details>
  <summary>Details</summary>
Motivation: 现有算法补救方法在生成现实可行且高似然度的补救方案方面存在不足，需要一种能够同时满足有效性、相似性、稀疏性和高似然度要求的系统方法

Method: 将补救问题形式化为约束最大后验推理问题，提出摊销近似推理程序PAR，使用可精确计算似然的可处理概率模型，通过最大化接受类分布似然、最小化拒绝类分布似然以及编码其他约束的损失函数进行训练，并引入基于邻域的调节机制实现个性化补救生成

Result: 在广泛使用的算法补救数据集上验证了PAR的高效性，生成的补救方案在有效性、与事实的相似性、稀疏性和高似然度方面优于现有最先进方法

Conclusion: PAR通过概率建模和摊销推理框架，能够高效生成高质量、个性化的算法补救方案，为算法补救领域提供了有效的解决方案

Abstract: Algorithmic recourse aims to recommend actionable changes to a factual's attributes that flip an unfavorable model decision while remaining realistic and feasible. We formulate recourse as a Constrained Maximum A-Posteriori (MAP) inference problem under the accepted-class data distribution seeking counterfactuals with high likelihood while respecting other recourse constraints. We present PAR, an amortized approximate inference procedure that generates highly likely recourses efficiently. Recourse likelihood is estimated directly using tractable probabilistic models that admit exact likelihood evaluation and efficient gradient propagation that is useful during training. The recourse generator is trained with the objective of maximizing the likelihood under the accepted-class distribution while minimizing the likelihood under the denied-class distribution and other losses that encode recourse constraints. Furthermore, PAR includes a neighborhood-based conditioning mechanism to promote recourse generation that is customized to a factual. We validate PAR on widely used algorithmic recourse datasets and demonstrate its efficiency in generating recourses that are valid, similar to the factual, sparse, and highly plausible, yielding superior performance over existing state-of-the-art approaches.

</details>


### [44] [Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment](https://arxiv.org/abs/2601.17329)
*Tiejin Chen,Xiaoou Liu,Vishnu Nandam,Kuan-Ru Liou,Hua Wei*

Main category: cs.LG

TL;DR: CFA利用保形预测量化答案可靠性，将答案级不确定性纳入偏好对齐，提升RLHF的鲁棒性和数据效率


<details>
  <summary>Details</summary>
Motivation: 现有基于不确定性的偏好对齐方法只关注偏好权重，忽略了被比较答案本身的可靠性，而人类反馈标签通常存在噪声和不一致性

Method: 提出Conformal Feedback Alignment (CFA)框架，利用保形预测构建具有可控覆盖率的预测集来量化答案级可靠性，并将这些可靠性聚合为DPO和PPO风格训练的权重

Result: 在不同数据集上的实验表明，CFA提高了对齐的鲁棒性和数据效率，证明建模答案侧不确定性可以补充偏好级加权

Conclusion: CFA通过保形预测的统计保证将答案可靠性纳入偏好加权，为偏好对齐提供了更稳健、数据高效的解决方案

Abstract: Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.

</details>


### [45] [Diversified Scaling Inference in Time Series Foundation Models](https://arxiv.org/abs/2601.17376)
*Ruijin Hua,Zichuan Liu,Kun Zhang,Yiyuan Yang*

Main category: cs.LG

TL;DR: 该论文系统研究了时间序列基础模型（TSFMs）的推理时计算潜力，发现标准采样推理存在局限性，提出通过多样化推理扩展来提升性能，并理论分析了多样性-保真度权衡。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型主要依赖大规模预训练，但推理时计算潜力尚未充分挖掘。论文旨在探索两个核心问题：TSFMs在标准采样推理下的行为特性，以及通过控制采样多样性是否能提升性能。

Method: 首先分析TSFMs在标准采样下的特性，发现其因解决方案空间探索不足而难以遵循缩放定律。然后通过定制的时间序列扰动实现多样化推理扩展，扩展生成分布的支撑集。理论分析多样性-保真度权衡，推导多样化采样优于标准采样的临界样本阈值。

Result: 跨多种TSFMs和数据集的广泛实验表明，适当的多样化推理扩展能在不更新参数的情况下带来显著性能提升。提出RobustMSE指标来量化固定预算下TSFMs的性能上限。

Conclusion: 推理设计是TSFM优化的关键计算效率维度。研究阐明了这些因素的相互作用，使得在不重新训练TSFMs的情况下，通过并行环境中的多样化大规模推理时间序列实现可靠性能成为可能。

Abstract: The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.

</details>


### [46] [Data-driven Clustering and Merging of Adapters for On-device Large Language Models](https://arxiv.org/abs/2601.17441)
*Ondrej Bohdal,Taha Ceritli,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli*

Main category: cs.LG

TL;DR: 提出D2C方法，通过少量任务示例进行适配器聚类，合并同簇适配器创建多任务适配器，解决移动设备存储限制下的适配器选择问题。


<details>
  <summary>Details</summary>
Motivation: 移动设备上存储所有任务特定适配器不现实，但设备有足够容量存储有限数量的适配器参数。现有文献未探索如何选择具有良好跨任务泛化能力的代表性适配器。

Method: 提出D2C适配器聚类方法，利用少量任务特定示例（如每个任务10个），采用迭代优化过程细化簇分配，合并每个簇内的适配器创建多任务适配器。

Result: 实验结果表明，该方法在考虑存储预算的情况下有效提升了性能。

Conclusion: D2C方法通过适配器聚类和合并，为资源受限设备提供了有效的多任务适配器部署方案，解决了移动设备上适配器选择的挑战。

Abstract: On-device large language models commonly employ task-specific adapters (e.g., LoRAs) to deliver strong performance on downstream tasks. While storing all available adapters is impractical due to memory constraints, mobile devices typically have sufficient capacity to store a limited number of these parameters. This raises a critical challenge: how to select representative adapters that generalize well across multiple tasks - a problem that remains unexplored in existing literature. We propose a novel method D2C for adapter clustering that leverages minimal task-specific examples (e.g., 10 per task) and employs an iterative optimization process to refine cluster assignments. The adapters within each cluster are merged, creating multi-task adapters deployable on resource-constrained devices. Experimental results demonstrate that our method effectively boosts performance for considered storage budgets.

</details>


### [47] [Harnessing Reasoning Trajectories for Hallucination Detection via Answer-agreement Representation Shaping](https://arxiv.org/abs/2601.17467)
*Jianxiong Zhang,Bing Guo,Yuming Jiang,Haobo Wang,Bo An,Xuefeng Du*

Main category: cs.LG

TL;DR: ARS方法通过学习答案一致性表征来检测大型推理模型的幻觉，通过潜在干预生成反事实答案并学习表征，无需人工标注即可提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）经常生成看似连贯但答案错误的推理轨迹，使得幻觉检测变得困难。现有方法直接使用轨迹文本或原始隐藏状态进行检测存在脆弱性：轨迹形式多变，检测器容易过拟合到表面模式而非答案有效性。

Method: 提出答案一致性表征塑形（ARS）方法：通过小规模潜在干预（扰动轨迹边界嵌入）生成反事实答案，根据扰动后答案是否与原答案一致进行标注，学习将答案一致的隐藏状态聚合、答案不一致的状态分离的表征，从而暴露指示幻觉风险的潜在不稳定性。

Result: 实验表明ARS持续改进检测性能，相比强基线方法取得显著提升。塑形后的嵌入可与现有基于嵌入的检测器即插即用，训练过程中无需人工标注。

Conclusion: ARS通过显式编码答案稳定性来学习检测友好的轨迹条件表征，有效解决了大型推理模型幻觉检测的挑战，提供了一种无需人工标注的鲁棒检测方法。

Abstract: Large reasoning models (LRMs) often generate long, seemingly coherent reasoning traces yet still produce incorrect answers, making hallucination detection challenging. Although trajectories contain useful signals, directly using trace text or vanilla hidden states for detection is brittle: traces vary in form and detectors can overfit to superficial patterns rather than answer validity. We introduce Answer-agreement Representation Shaping (ARS), which learns detection-friendly trace-conditioned representations by explicitly encoding answer stability. ARS generates counterfactual answers through small latent interventions, specifically, perturbing the trace-boundary embedding, and labels each perturbation by whether the resulting answer agrees with the original. It then learns representations that bring answer-agreeing states together and separate answer-disagreeing ones, exposing latent instability indicative of hallucination risk. The shaped embeddings are plug-and-play with existing embedding-based detectors and require no human annotations during training. Experiments demonstrate that ARS consistently improves detection and achieves substantial gains over strong baselines.

</details>


### [48] [PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems](https://arxiv.org/abs/2601.17495)
*Ruiyu Zhang,Lin Nie,Wai-Fung Lam,Qihao Wang,Xin Zhao*

Main category: cs.LG

TL;DR: PEARL是一种标签高效的表示学习方法，通过原型增强对齐来改善嵌入空间的局部邻域结构，提升相似性检索性能，特别是在标签稀缺场景下效果显著。


<details>
  <summary>Details</summary>
Motivation: 现实部署系统中，基于嵌入的最近邻检索经常失败，问题不在于语言模型本身，而在于嵌入空间的最近邻对应错误案例。现有系统依赖固定预训练嵌入，但标签稀缺、领域漂移且重新训练编码器成本高，导致下游性能严重依赖嵌入几何结构。原始嵌入通常与最近邻检索所需的局部邻域结构对齐不佳。

Method: 提出PEARL（原型增强对齐表示学习），利用有限监督通过软对齐将嵌入向类原型对齐。该方法重塑局部邻域几何结构，同时保持维度不变，避免激进投影或坍缩。旨在填补纯无监督后处理（增益有限且不一致）和完全监督投影（需要大量标注数据）之间的空白。

Result: 在从极端标签稀缺到较高标签设置的控制标签机制下评估PEARL。在标签稀缺条件下，PEARL显著改善局部邻域质量，相比原始嵌入获得25.7%的提升，相比强无监督后处理获得超过21.1%的提升，在基于相似性的系统最脆弱的场景中表现优异。

Conclusion: PEARL提供了一种标签高效的解决方案，通过原型增强对齐改善嵌入空间的局部几何结构，在标签稀缺的现实部署场景中有效提升基于嵌入的检索和分类系统性能。

Abstract: In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.

</details>


### [49] [One-Shot Federated Clustering of Non-Independent Completely Distributed Data](https://arxiv.org/abs/2601.17512)
*Yiqun Zhang,Shenghong Cai,Zihua Yang,Sen Feng,Yuzhu Ji,Haijun Zhang*

Main category: cs.LG

TL;DR: 该论文提出GOLD框架，解决联邦聚类中Non-IID数据导致的集群碎片化问题，通过全局导向的局部分布学习提升聚类性能。


<details>
  <summary>Details</summary>
Motivation: 联邦聚类在处理边缘设备无标签数据时面临Non-IID问题的挑战，特别是不同客户端可能将同一集群碎片化，现有方法性能受限。需要解决如何融合Non-IID客户端的模式知识、客户端间集群分布关系及其与全局知识融合的关联。

Method: 提出GOLD框架：1）精细探索客户端潜在的不完整局部集群分布；2）将分布摘要上传至服务器进行全局融合；3）在全局分布指导下进行局部集群增强。引入更广义的Non-ICD概念描述集群碎片化现象。

Result: 通过显著性检验、消融研究、可扩展性评估和定性结果等广泛实验验证了GOLD的优越性，表明其能有效解决联邦聚类中的Non-IID挑战。

Conclusion: GOLD框架通过全局导向的局部分布学习，成功解决了联邦聚类中Non-IID数据导致的集群碎片化问题，为分布式隐私保护物联网系统中的无监督学习提供了有效解决方案。

Abstract: Federated Learning (FL) that extracts data knowledge while protecting the privacy of multiple clients has achieved remarkable results in distributed privacy-preserving IoT systems, including smart traffic flow monitoring, smart grid load balancing, and so on. Since most data collected from edge devices are unlabeled, unsupervised Federated Clustering (FC) is becoming increasingly popular for exploring pattern knowledge from complex distributed data. However, due to the lack of label guidance, the common Non-Independent and Identically Distributed (Non-IID) issue of clients have greatly challenged FC by posing the following problems: How to fuse pattern knowledge (i.e., cluster distribution) from Non-IID clients; How are the cluster distributions among clients related; and How does this relationship connect with the global knowledge fusion? In this paper, a more tricky but overlooked phenomenon in Non-IID is revealed, which bottlenecks the clustering performance of the existing FC approaches. That is, different clients could fragment a cluster, and accordingly, a more generalized Non-IID concept, i.e., Non-ICD (Non-Independent Completely Distributed), is derived. To tackle the above FC challenges, a new framework named GOLD (Global Oriented Local Distribution Learning) is proposed. GOLD first finely explores the potential incomplete local cluster distributions of clients, then uploads the distribution summarization to the server for global fusion, and finally performs local cluster enhancement under the guidance of the global distribution. Extensive experiments, including significance tests, ablation studies, scalability evaluations, qualitative results, etc., have been conducted to show the superiority of GOLD.

</details>


### [50] [Towards Generalisable Imitation Learning Through Conditioned Transition Estimation and Online Behaviour Alignment](https://arxiv.org/abs/2601.17563)
*Nathan Gavenski,Matteo Leonetti,Odinaldo Rodrigues*

Main category: cs.LG

TL;DR: 提出无监督观察模仿学习（UfO），通过两阶段学习过程解决现有ILfO方法需要动作监督、假设状态有单一最优动作、不考虑环境状态完整性的限制。


<details>
  <summary>Details</summary>
Motivation: 现有观察模仿学习方法存在三个主要限制：1）需要基于动作的监督优化；2）假设状态有单一最优动作；3）倾向于直接应用教师动作而不充分考虑实际环境状态。虽然真实信息存在于观察到的轨迹中，但现有方法难以在没有监督的情况下提取这些信息。

Method: 提出UfO方法，采用两阶段学习过程：第一阶段从观察到的状态转移中近似教师的真实动作；第二阶段通过调整智能体轨迹使其与教师轨迹紧密对齐来进一步优化学习策略。

Result: 在五个广泛使用的环境中进行实验，UfO不仅超越了教师和所有其他ILfO方法，而且显示出最小的标准差。标准差的减少表明在未见场景中具有更好的泛化能力。

Conclusion: UfO成功解决了现有ILfO方法的三个主要限制，实现了无监督的观察模仿学习，在性能上超越了教师和其他方法，并展现出更好的泛化能力。

Abstract: State-of-the-art imitation learning from observation methods (ILfO) have recently made significant progress, but they still have some limitations: they need action-based supervised optimisation, assume that states have a single optimal action, and tend to apply teacher actions without full consideration of the actual environment state. While the truth may be out there in observed trajectories, existing methods struggle to extract it without supervision. In this work, we propose Unsupervised Imitation Learning from Observation (UfO) that addresses all of these limitations. UfO learns a policy through a two-stage process, in which the agent first obtains an approximation of the teacher's true actions in the observed state transitions, and then refines the learned policy further by adjusting agent trajectories to closely align them with the teacher's. Experiments we conducted in five widely used environments show that UfO not only outperforms the teacher and all other ILfO methods but also displays the smallest standard deviation. This reduction in standard deviation indicates better generalisation in unseen scenarios.

</details>


### [51] [From LLMs to LRMs: Rethinking Pruning for Reasoning-Centric Models](https://arxiv.org/abs/2601.18091)
*Longwei Ding,Anhao Zhao,Fanghua Ye,Ziyang Chen,Xiaoyu Shen*

Main category: cs.LG

TL;DR: 该研究系统比较了指令遵循型LLM和推理增强型LLM的剪枝策略差异，发现剪枝效果高度依赖于模型范式，需要针对推理增强模型设计专门的剪枝方法。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝研究主要关注指令遵循型LLM，但推理增强型LLM会生成长中间推理轨迹，其剪枝特性尚不明确。需要系统研究不同范式LLM的剪枝行为差异。

Method: 采用对照研究设计，分别对指令遵循型(LLM-instruct)和推理增强型(LLM-think)模型进行剪枝。为隔离剪枝效应，将剪枝校准和剪枝后恢复数据与各模型原始训练分布对齐。评估静态深度剪枝、静态宽度剪枝和动态剪枝三种策略，在17个涵盖分类、生成和推理的任务上进行测试。

Result: 发现明显的范式依赖性差异：深度剪枝在分类任务上表现更好，而宽度剪枝在生成和推理任务上更稳健。静态剪枝能更好地保持推理性能，动态剪枝在分类和生成任务上表现优异，但对长链推理仍具挑战性。

Conclusion: 推理增强型LLM需要专门考虑其特性的剪枝策略，不能简单沿用指令遵循型LLM的剪枝方法。研究强调了针对不同LLM范式设计定制化剪枝方案的重要性。

Abstract: Large language models (LLMs) are increasingly costly to deploy, motivating extensive research on model pruning. However, most existing studies focus on instruction-following LLMs, leaving it unclear whether established pruning strategies transfer to reasoning-augmented models that explicitly generate long intermediate reasoning traces. In this work, we conduct a controlled study of pruning for both instruction-following ($\textbf{LLM-instruct}$) and reasoning-augmented ($\textbf{LLM-think}$) models. To isolate the effects of pruning, we align pruning calibration and post-pruning recovery data with each model's original training distribution, which we show yields more stable and reliable pruning behavior. We evaluate static depth pruning, static width pruning, and dynamic pruning across 17 tasks spanning classification, generation, and reasoning. Our results reveal clear paradigm-dependent differences: depth pruning outperforms width pruning on classification tasks, while width pruning is more robust for generation and reasoning. Moreover, static pruning better preserves reasoning performance, whereas dynamic pruning excels on classification and generation but remains challenging for long-chain reasoning. These findings underscore the need for pruning strategies that explicitly account for the distinct characteristics of reasoning-augmented LLMs. Our code is publicly available at https://github.com/EIT-NLP/LRM-Pruning.

</details>


### [52] [Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions](https://arxiv.org/abs/2601.18107)
*Pedram Agand,Mo Chen*

Main category: cs.LG

TL;DR: MoReBRAC：基于模型的不确定性感知离线强化学习框架，通过双重循环世界模型合成高保真度转移数据，并采用分层不确定性管道确保合成数据可靠性，在D4RL基准上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在工业机器人等安全关键领域具有巨大潜力，但静态数据集与学习策略之间的分布偏移问题导致需要高度保守性，限制了策略改进潜力。需要解决这一限制以提升离线强化学习的性能

Method: 提出MoReBRAC框架：1）使用双重循环世界模型合成高保真度转移数据以扩展训练流形；2）实施分层不确定性管道，集成变分自编码器流形检测、模型敏感性分析和蒙特卡洛dropout，确保只使用学习动态高置信区域的转移数据

Result: 在D4RL Gym-MuJoCo基准测试中显示出显著的性能提升，特别是在"随机"和"次优"数据机制中。进一步分析了VAE作为几何锚点的作用，并讨论了从接近最优数据集中学习时的分布权衡

Conclusion: MoReBRAC通过不确定性感知潜在合成有效解决了离线强化学习中的分布偏移问题，减少了保守性限制，在挑战性数据机制中实现了更好的性能，为安全关键领域的离线强化学习应用提供了有前景的解决方案

Abstract: Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.

</details>


### [53] [Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection](https://arxiv.org/abs/2601.18329)
*Chuhan Feng,Jing Li,Jie Li,Lu Lv,Fengkui Gong*

Main category: cs.LG

TL;DR: 提出基于可区分性驱动的空间-通道选择和梯度范数的无人机信号分布外检测算法，通过量化协议特定时频特征进行自适应加权，结合梯度范数度量扰动敏感性，与基于能量的分数融合进行联合推断。


<details>
  <summary>Details</summary>
Motivation: 无人机信号的分布外检测面临挑战，需要有效区分已知协议和未知协议信号。现有方法在空间和通道维度特征利用不足，且对OOD样本内在不稳定性捕捉不够。

Method: 1. 基于协议特定时频特征量化类间相似性和方差，自适应加权时频图像特征的空间和通道维度；2. 引入梯度范数度量扰动敏感性，捕捉OOD样本内在不稳定性；3. 将梯度范数度量与基于能量的分数融合进行联合推断。

Result: 仿真结果表明，该算法在信噪比和多种无人机类型下表现出优异的判别能力和鲁棒性能，优于现有方法。

Conclusion: 提出的基于可区分性驱动的空间-通道选择和梯度范数的OOD检测算法能有效识别未知无人机信号，为无人机信号识别提供了一种鲁棒的分布外检测解决方案。

Abstract: We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types.

</details>


### [54] [Closing the Modality Gap Aligns Group-Wise Semantics](https://arxiv.org/abs/2601.18525)
*Eleonora Grassucci,Giordano Cicchetti,Emanuele Frasca,Aurelio Uncini,Danilo Comminiello*

Main category: cs.LG

TL;DR: 论文提出模态间隙对群体级任务（如聚类）影响显著，而传统实例级任务（如检索）影响有限，并介绍了一种减少模态间隙的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP在多模态学习中建立了共享潜在空间，但模态间隙（结构不匹配）仍然存在。虽然模态间隙对实例级任务影响有限，但作者认为其对群体级任务有显著影响，需要系统研究。

Method: 提出了一种新颖方法，专门设计用于在双模态设置中一致地减少模态间隙，并可简单扩展到n模态情况。该方法旨在解决模态间的结构不匹配问题。

Result: 通过广泛评估发现：减少模态间隙对传统实例级任务仅提供边际或不一致的改进，但对群体级任务（如聚类）有显著提升。这揭示了模态间隙在语义分组任务中的关键作用。

Conclusion: 模态间隙的影响在群体级任务中比实例级任务更为显著，这一发现可能重塑对模态间隙的理解，强调其在改善需要语义分组的任务性能中的关键作用。

Abstract: In multimodal learning, CLIP has been recognized as the \textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.

</details>


### [55] [PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation](https://arxiv.org/abs/2601.18777)
*Abhishek Divekar,Anirban Majumder*

Main category: cs.LG

TL;DR: 提出PRECISE框架，结合少量人工标注和LLM判断来评估搜索、排序和RAG系统质量，显著减少标注需求


<details>
  <summary>Details</summary>
Motivation: 传统搜索、排序和RAG系统评估需要大量人工相关性标注，而LLM作为自动评估工具存在固有偏差，需要一种结合两者优势的统计框架

Method: 扩展预测驱动推理(PPI)框架，结合少量人工标注查询(100个)和大量未标注示例(10,000个)，通过重新定义指标集成空间将计算复杂度从O(2^|C|)降低到O(2^K)

Result: 在多个检索数据集上的实验表明，该方法降低了关键业务指标Precision@K的估计方差，并在低资源设置下有效校正了LLM偏差

Conclusion: PRECISE框架通过结合少量人工标注和LLM判断，为需要子实例标注的指标提供了可靠的估计方法，显著减少了标注需求并校正了LLM偏差

Abstract: Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.

</details>


### [56] [Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes](https://arxiv.org/abs/2601.18795)
*Amrith Setlur,Zijian Wang,Andrew Cohen,Paria Rashidinejad,Sang Michael Xie*

Main category: cs.LG

TL;DR: PrefixRL：通过重用离策略轨迹的前缀来提升大语言模型推理任务的强化学习效率，避免离策略不稳定性，实现2倍训练加速和3倍最终奖励提升。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在处理困难推理问题时效率低下，因为正确的在线策略轨迹稀少、策略梯度消失导致学习停滞。需要重用先前推理或RL训练中产生的离策略轨迹计算资源来提升效率。

Method: 提出PrefixRL方法：基于成功离策略轨迹的前缀进行条件化，然后运行在线RL来完成剩余部分。通过调节前缀长度来调整问题难度，避免离策略不稳定性。使用基础模型通过拒绝采样获取离策略轨迹，形成自我改进循环。

Result: 在困难推理问题上，PrefixRL达到相同训练奖励的速度比最强基线（在离策略数据上进行SFT然后RL）快2倍，即使考虑初始拒绝采样的计算成本。最终奖励提升3倍。发现后泛化现象：仅在带前缀问题上训练能泛化到无前缀的分布外性能。当离策略轨迹来自不同模型族时仍有效。

Conclusion: PrefixRL通过重用离策略轨迹的前缀有效提升RL训练效率，避免离策略不稳定性，在困难推理问题上实现显著加速和性能提升，具有实际应用的灵活性。

Abstract: Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.

</details>
