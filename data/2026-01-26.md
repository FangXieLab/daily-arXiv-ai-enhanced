<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Semi-Supervised Hierarchical Open-Set Classification](https://arxiv.org/abs/2601.16541)
*Erik Wallin,Fredrik Kahl,Lars Hammarstrand*

Main category: cs.CV

TL;DR: 提出一种基于伪标签的师生框架，用于半监督层次开放集分类，通过子树伪标签和年龄门控机制处理未知类别数据


<details>
  <summary>Details</summary>
Motivation: 将层次开放集分类扩展到半监督设置，利用包含已知和未知类别的大规模未标注数据集来提升层次开放集性能

Method: 提出基于伪标签的师生框架，包含两个关键组件：1) 子树伪标签，在存在未知数据时提供可靠监督；2) 年龄门控机制，缓解伪标签的过度自信问题

Result: 在iNaturalist19基准测试中，框架性能优于自监督预训练加监督适应方法，且仅使用每类20个标注样本时性能与全监督方法相当

Conclusion: 提出的半监督层次开放集分类框架能有效利用未标注数据提升性能，在有限标注数据下达到与全监督方法相当的效果

Abstract: Hierarchical open-set classification handles previously unseen classes by assigning them to the most appropriate high-level category in a class taxonomy. We extend this paradigm to the semi-supervised setting, enabling the use of large-scale, uncurated datasets containing a mixture of known and unknown classes to improve the hierarchical open-set performance. To this end, we propose a teacher-student framework based on pseudo-labeling. Two key components are introduced: 1) subtree pseudo-labels, which provide reliable supervision in the presence of unknown data, and 2) age-gating, a mechanism that mitigates overconfidence in pseudo-labels. Experiments show that our framework outperforms self-supervised pretraining followed by supervised adaptation, and even matches the fully supervised counterpart when using only 20 labeled samples per class on the iNaturalist19 benchmark. Our code is available at https://github.com/walline/semihoc.

</details>


### [2] [GPA-VGGT:Adapting VGGT to Large scale Localization by self-Supervised learning with Geometry and Physics Aware loss](https://arxiv.org/abs/2601.16885)
*Yangfan Xu,Lilian Zhang,Xiaofeng He,Pengdong Wu,Wenqi Wu,Jun Mao*

Main category: cs.CV

TL;DR: 提出自监督框架训练VGGT模型，通过序列几何约束和联合优化损失，无需标注数据即可提升大规模场景定位能力


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的视觉几何框架（VGGT）在相机姿态估计和3D重建方面表现良好，但通常依赖标注数据进行训练，难以适应无标注和未见场景。需要开发自监督方法以增强模型在大规模环境中的定位能力。

Method: 1. 将传统成对关系扩展到序列几何约束进行自监督学习；2. 在每个序列中采样多个源帧并将其几何投影到不同目标帧，提升时序特征一致性；3. 将物理光度一致性和几何约束公式化为联合优化损失，避免对硬标签的需求；4. 通过该方法训练模型，使局部和全局跨视图注意力层以及相机和深度头能够有效捕捉底层多视图几何。

Result: 实验表明，模型在数百次迭代内收敛，并在大规模定位任务中取得显著改进。代码将在GitHub上开源。

Conclusion: 提出的自监督框架成功解决了VGGT模型对标注数据的依赖问题，通过序列几何约束和联合优化损失，实现了在无标注数据上的有效训练，显著提升了大尺度场景的定位性能。

Abstract: Transformer-based general visual geometry frameworks have shown promising performance in camera pose estimation and 3D scene understanding. Recent advancements in Visual Geometry Grounded Transformer (VGGT) models have shown great promise in camera pose estimation and 3D reconstruction. However, these models typically rely on ground truth labels for training, posing challenges when adapting to unlabeled and unseen scenes. In this paper, we propose a self-supervised framework to train VGGT with unlabeled data, thereby enhancing its localization capability in large-scale environments. To achieve this, we extend conventional pair-wise relations to sequence-wise geometric constraints for self-supervised learning. Specifically, in each sequence, we sample multiple source frames and geometrically project them onto different target frames, which improves temporal feature consistency. We formulate physical photometric consistency and geometric constraints as a joint optimization loss to circumvent the requirement for hard labels. By training the model with this proposed method, not only the local and global cross-view attention layers but also the camera and depth heads can effectively capture the underlying multi-view geometry. Experiments demonstrate that the model converges within hundreds of iterations and achieves significant improvements in large-scale localization. Our code will be released at https://github.com/X-yangfan/GPA-VGGT.

</details>


### [3] [Domain-invariant Mixed-domain Semi-supervised Medical Image Segmentation with Clustered Maximum Mean Discrepancy Alignment](https://arxiv.org/abs/2601.16954)
*Ba-Thinh Lam,Thanh-Huy Nguyen,Hoang-Thien Nguyen,Quang-Khai Bui-Tran,Nguyen Lan Vi Vu,Phat K. Huynh,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: 提出了一种用于混合域半监督医学图像分割的域不变框架，通过跨域复制粘贴机制增强数据多样性，并使用聚类最大均值差异块对齐特征，在标注稀缺且存在未知域差异的情况下实现鲁棒分割。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中，深度学习需要大量专家标注和一致的数据分布，但实际应用中标注稀缺且图像来自多个扫描仪或中心，导致混合域设置中存在未知域标签和严重域差异。现有半监督或域适应方法通常假设单一域偏移或需要显式域索引，这在现实部署中很少成立。

Method: 提出域不变混合域半监督分割框架：1) 复制粘贴机制(CPM)通过跨域转移信息区域增强训练集；2) 聚类最大均值差异(CMMD)块聚类未标注特征并通过MMD目标与标注锚点对齐，鼓励域不变表示；3) 集成在师生框架中实现鲁棒分割。

Result: 在Fundus和M&Ms基准测试上的实验表明，该方法在仅有少量标注样本和多个未知域差异的情况下，一致优于半监督和域适应方法，实现了鲁棒且精确的分割。

Conclusion: 该方法为混合域半监督医学图像分割提供了一个潜在解决方案，能够有效增强数据多样性并减轻域偏差，在现实世界部署中具有应用价值。

Abstract: Deep learning has shown remarkable progress in medical image semantic segmentation, yet its success heavily depends on large-scale expert annotations and consistent data distributions. In practice, annotations are scarce, and images are collected from multiple scanners or centers, leading to mixed-domain settings with unknown domain labels and severe domain gaps. Existing semi-supervised or domain adaptation approaches typically assume either a single domain shift or access to explicit domain indices, which rarely hold in real-world deployment. In this paper, we propose a domain-invariant mixed-domain semi-supervised segmentation framework that jointly enhances data diversity and mitigates domain bias. A Copy-Paste Mechanism (CPM) augments the training set by transferring informative regions across domains, while a Cluster Maximum Mean Discrepancy (CMMD) block clusters unlabeled features and aligns them with labeled anchors via an MMD objective, encouraging domain-invariant representations. Integrated within a teacher-student framework, our method achieves robust and precise segmentation even with very few labeled examples and multiple unknown domain discrepancies. Experiments on Fundus and M&Ms benchmarks demonstrate that our approach consistently surpasses semi-supervised and domain adaptation methods, establishing a potential solution for mixed-domain semi-supervised medical image segmentation.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [4] [Building a Robust Risk-Based Access Control System to Combat Ransomware's Capability to Encrypt: A Machine Learning Approach](https://arxiv.org/abs/2601.16795)
*Kenan Begovic,Abdulaziz Al-Ali,Qutaibah Malluhi*

Main category: cs.CR

TL;DR: 基于机器学习的风险访问控制架构，通过函数级追踪和SELinux策略实时监管Linux加密操作，在保持合法加密的同时阻止勒索软件攻击


<details>
  <summary>Details</summary>
Motivation: 勒索软件的核心能力是未经授权的加密，需要能够识别和阻止恶意加密活动而不干扰合法使用的控制机制。现有方法如沙箱、虚拟机自省或粗粒度系统调用遥测存在性能开销或检测粒度不足的问题。

Method: 采用概率性、基于风险的访问控制架构，结合机器学习推理和强制访问控制。使用ftrace框架的function_graph追踪器构建高分辨率内核函数执行轨迹数据集，包含资源和I/O计数器。基于该数据集训练监督分类器并提取可解释规则，通过轻量级布尔值驱动SELinux策略，在加密开始时进行上下文敏感的许可/拒绝决策。

Result: 双层组合（机器学习分类器+可解释规则）保持了模型级检测质量，同时提供类似规则的响应速度。评估了操作开销，并提出了减少CPU和内存开销的工程步骤。当前用户空间原型在突发I/O下有一定开销，生产级内核空间解决方案需要进一步优化。

Conclusion: 该研究提供了一条从行为追踪和学习到可执行、可解释、风险成比例的加密控制的实用路径，能够在生产Linux系统上实现细粒度加密监管，有效区分合法加密和勒索软件攻击。

Abstract: Ransomware core capability, unauthorized encryption, demands controls that identify and block malicious cryptographic activity without disrupting legitimate use. We present a probabilistic, risk-based access control architecture that couples machine learning inference with mandatory access control to regulate encryption on Linux in real time. The system builds a specialized dataset from the native ftrace framework using the function_graph tracer, yielding high-resolution kernel-function execution traces augmented with resource and I/O counters. These traces support both a supervised classifier and interpretable rules that drive an SELinux policy via lightweight booleans, enabling context-sensitive permit/deny decisions at the moment encryption begins. Compared to approaches centered on sandboxing, hypervisor introspection, or coarse system-call telemetry, the function-level tracing we adopt provides finer behavioral granularity than syscall-only telemetry while avoiding the virtualization/VMI overhead of sandbox-based approaches. Our current user-space prototype has a non-trivial footprint under burst I/O; we quantify it and recognize that a production kernel-space solution should aim to address this. We detail dataset construction, model training and rule extraction, and the run-time integration that gates file writes for suspect encryption while preserving benign cryptographic workflows. During evaluation, the two-layer composition retains model-level detection quality while delivering rule-like responsiveness; we also quantify operational footprint and outline engineering steps to reduce CPU and memory overhead for enterprise deployment. The result is a practical path from behavioral tracing and learning to enforceable, explainable, and risk-proportionate encryption control on production Linux systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)
*Felipe Tobar,Elsa Cazelles*

Main category: cs.LG

TL;DR: 提出一种用于高斯过程的新训练目标——投影似然（PL），通过数据低维线性投影构建，在精度和计算效率上优于精确GP训练和变分稀疏GP方法。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程在大规模数据集上计算复杂度高，需要开发更高效且保持准确性的训练方法。现有稀疏GP方法如变分自由能虽然能降低计算成本，但在某些情况下可能牺牲准确性。

Method: 提出投影似然（PL）训练目标，使用数据的低维线性投影构建高斯过程。推导了PL信息损失的闭式表达式，并经验性证明通过单位球上的随机投影可以减少这种损失。

Result: 在中等规模数据集上，PL方法在不同优化器、核函数和数据集上都表现出优于精确GP训练和变分稀疏GP方法的性能，在准确性和计算效率方面均有优势。

Conclusion: 投影似然是一种有效的高斯过程训练方法，通过低维投影平衡了计算效率和模型准确性，为大规模高斯过程应用提供了有前景的解决方案。

Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.

</details>


### [6] [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)
*Sihan Zeng,Sujay Bhatt,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 提出一种单循环一阶actor-critic算法，通过惩罚重构和衰减熵正则化解决双层优化问题，其中上层优化平滑函数，下层是MDP中的策略优化。


<details>
  <summary>Details</summary>
Motivation: 现有双层优化和强化学习方法需要二阶信息、强正则化或低效的嵌套循环过程，需要更高效的算法来解决上层目标依赖于下层MDP最优策略的结构化双层优化问题。

Method: 提出单循环一阶actor-critic算法，通过惩罚重构优化双层目标，在下层RL目标中引入衰减熵正则化，实现渐近无偏的上层超梯度估计，无需精确求解未正则化RL问题。

Result: 在特殊类型的Polyak-Lojasiewicz条件下，通过新颖的下层残差分析，建立了算法对原始未正则化双层优化问题平稳点的有限时间和有限样本收敛性。

Conclusion: 该方法在GridWorld目标位置问题和基于人类反馈的强化学习(RLHF)快乐推文生成实验中验证了性能，为结构化双层优化提供了高效的单循环解决方案。

Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).

</details>


### [7] [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)
*Zhaochun Li,Mingyang Yi,Yue Wang,Shisheng Cui,Yong Liu*

Main category: cs.LG

TL;DR: 本文为基于人类反馈的强化学习（RLHF）在大型语言模型对齐中的应用建立了泛化理论，在线性奖励模型假设下，通过算法稳定性框架证明了策略模型的经验最优解具有O(n^{-1/2})阶的泛化界。


<details>
  <summary>Details</summary>
Motivation: RLHF及其变体已成为对齐大型语言模型与人类意图的主要方法，虽然经验上有效，但其在高维设置下的理论泛化特性尚未得到充分探索。现有工作主要基于奖励模型最大似然估计的一致性，而本文旨在构建与实践中端到端学习框架一致的理论分析。

Method: 在线性奖励模型假设下，通过算法稳定性框架分析RLHF的泛化特性。在关键的特征覆盖条件下，证明了策略模型经验最优解的泛化界为O(n^{-1/2})，并将结果推广到基于梯度的学习算法（梯度上升和随机梯度上升）获得的参数。

Result: 证明了在特征覆盖条件下，策略模型经验最优解具有O(n^{-1/2})阶的泛化界，且该结果可推广到梯度上升和随机梯度上升算法获得的参数，为RLHF后大型语言模型观察到的经验泛化提供了新的理论证据。

Conclusion: 本文为RLHF在大型语言模型对齐中的泛化特性提供了理论分析框架，通过算法稳定性在线性奖励模型下建立了泛化界，填补了现有理论研究的空白，为实践中观察到的RLHF泛化现象提供了理论支持。

Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.

</details>


### [8] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: R-NCE自监督学习框架从结构MRI中提取比传统FreeSurfer特征更强大的AD生物标志物，在疾病分类、转化预测和淀粉样蛋白状态预测方面表现更优，且具有生物学相关性。


<details>
  <summary>Details</summary>
Motivation: 当前阿尔茨海默病生物标志物发现主要依赖手工特征（如皮层厚度、体积），自监督学习方法在相同数据上表现不佳。需要开发能提取更强大生物标志物的自监督学习框架。

Method: 提出残差噪声对比估计（R-NCE）框架，整合辅助FreeSurfer特征，同时最大化增强不变性信息。通过脑年龄差距（BAG）评估生物学相关性，并进行全基因组关联研究。

Result: R-NCE在AD转化预测等多个基准测试中优于传统特征和现有SSL方法。R-NCE-BAG显示高遗传性，与MAPT和IRAG1基因相关，在星形胶质细胞和少突胶质细胞中富集，表明对神经退行性和脑血管过程敏感。

Conclusion: R-NCE自监督学习框架能从结构MRI中发现比传统手工特征更强大且具有生物学意义的AD生物标志物，为早期检测和监测提供了新方法。

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [9] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 提出一种利用动态请求专家知识（包括LLM）来集成多种因果发现算法的灵活模型平均方法，在干净和噪声数据上验证了有效性


<details>
  <summary>Details</summary>
Motivation: 医疗领域需要准确的因果模型来增强预测模型的可解释性，支持反事实和干预推理以及治疗效果估计。但现有因果发现算法众多且没有明确最佳选择，同时现实应用经常违反常见算法的假设，过度依赖专家知识

Method: 提出灵活的模型平均方法，利用动态请求的专家知识（包括LLM作为专家）来集成多样化的因果发现算法。该方法结合了最近关于动态请求专家知识和LLM作为专家的研究成果

Result: 实验证明该方法在干净和噪声数据上对不完美专家（如LLM）都有效。分析了不同专家正确程度的影响，并评估了LLM在临床因果发现中的能力，为实践者提供了有价值的见解

Conclusion: 提出的集成方法能够有效利用专家知识（包括LLM）来提升因果发现的鲁棒性和实用性，特别是在现实世界应用面临算法假设违反挑战的情况下

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [10] [3D Molecule Generation from Rigid Motifs via SE(3) Flows](https://arxiv.org/abs/2601.16955)
*Roman Poletukhin,Marcel Kollovieh,Eike Eberhard,Stephan Günnemann*

Main category: cs.LG

TL;DR: 该论文提出了一种基于刚性基元的三维分子生成方法，将分子表示为刚性基元集合，使用SE(3)-等变生成模型进行从头分子生成，相比传统原子级方法在生成步骤和表示压缩方面有显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有三维分子生成通常在原子级别进行，而分子图生成技术常考虑片段作为结构单元。受基于框架的蛋白质结构生成进展启发，作者希望将片段化思想扩展到三维空间，将一般分子视为刚性基元集合，以改进生成效率和表示压缩。

Method: 将分子表示为刚性基元（刚性体基序）集合，采用SE(3)-等变生成模型进行三维分子生成。该方法基于片段化表示，利用刚性基元作为结构单元，而不是传统的原子级表示。

Result: 在基准测试中取得与最先进方法相当或更优的结果，在GEOM-Drugs上原子稳定性超过现有方法。生成步骤减少2-10倍，分子表示相比标准原子级方法压缩3.5倍。

Conclusion: 基于刚性基元的三维分子生成方法在保持或提升生成质量的同时，显著提高了生成效率和表示压缩率，为分子设计提供了更高效的框架。

Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.

</details>
