<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]
- [cs.CV](#cs.CV) [Total: 187]
- [cs.CR](#cs.CR) [Total: 46]
- [stat.ML](#stat.ML) [Total: 8]
- [math.ST](#math.ST) [Total: 10]
- [cs.LG](#cs.LG) [Total: 113]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning](https://arxiv.org/abs/2601.11905)
*Junyu Cao,Ruijiang Gao,Esmaeil Keyvanshokooh,Jianhao Ma*

Main category: cs.AI

TL;DR: 提出了一个将算法追索、上下文赌博机和大型语言模型统一起来的框架，用于高风险顺序决策，如个性化医疗。提出了追索赌博机问题和GLRB算法，以及结合LLM领域知识和赌博机统计严谨性的LIBRA算法。


<details>
  <summary>Details</summary>
Motivation: 在高风险顺序决策场景（如个性化医疗）中，需要同时选择治疗行动和可行的最小患者特征修改，这需要结合算法追索、上下文赌博机和大型语言模型的优势，实现可信赖的LLM-赌博机协作。

Method: 首先提出追索赌博机问题，开发了广义线性追索赌博机（GLRB）算法。在此基础上，提出了语言模型知情赌博机追索算法（LIBRA），该算法策略性地将LLM的领域知识与赌博机学习的统计严谨性相结合。

Result: LIBRA提供三个关键保证：1）热启动保证，当LLM推荐接近最优时显著减少初始遗憾；2）LLM努力保证，算法仅咨询LLM O(log²T)次；3）鲁棒性保证，即使LLM不可靠，LIBRA性能也不差于纯赌博机算法。建立了匹配的下界，证明了算法的最优性。实验表明GLRB和LIBRA在遗憾、治疗质量和样本效率方面优于标准上下文赌博机和纯LLM基准。

Conclusion: 追索感知、LLM辅助的赌博机算法在个性化高风险决策中具有前景，能够实现可信赖的LLM-赌博机协作，为高风险顺序决策提供了统一的框架和有效的算法解决方案。

Abstract: We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.

</details>


### [2] [MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?](https://arxiv.org/abs/2601.11559)
*Zilal Eiz AlDin,John Wu,Jeffrey Paul Fung,Jennifer King,Mya Watts,Lauren ONeill,Adam Richard Cross,Jimeng Sun*

Main category: cs.AI

TL;DR: 该研究创建了MIMIC-RD基准测试，通过将临床文本直接映射到Orphanet罕见病数据库来评估LLM在罕见病鉴别诊断中的表现，发现当前最先进的LLM在此任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 罕见病影响大量人群但鉴别诊断困难，现有评估LLM在罕见病诊断中的方法存在两个关键局限：1) 依赖理想化的临床案例研究，无法捕捉真实世界的临床复杂性；2) 使用ICD代码作为疾病标签，但许多罕见病缺乏与Orphanet等综合罕见病数据库的直接映射，导致严重低估罕见病数量。

Method: 开发MIMIC-RD罕见病鉴别诊断基准：1) 通过LLM挖掘临床文本实体；2) 由四位医学标注者验证确认识别的实体是真正的罕见病；3) 将临床文本实体直接映射到Orphanet数据库；4) 在145名患者的数据集上评估各种模型。

Result: 当前最先进的大型语言模型在罕见病鉴别诊断任务上表现不佳，突显出现有能力与临床需求之间的巨大差距。

Conclusion: 研究揭示了LLM在罕见病诊断中的局限性，并提出了改进罕见病鉴别诊断的未来研究方向。

Abstract: Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.

</details>


### [3] [Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models](https://arxiv.org/abs/2601.11622)
*Hassan Ugail,Newton Howard*

Main category: cs.AI

TL;DR: 该研究将神经科学中的时间整合与亚稳态概念应用于Transformer模型，提出了一种复合动力学指标来量化LLM在自回归生成过程中的时间组织特征，发现结构化推理任务相比重复、噪声和扰动条件表现出显著更高的动力学复杂度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通过高维内部动力学进行文本生成，但这些动力学的时间组织特征仍未被充分理解。现有可解释性方法多关注静态表示或因果干预，缺乏对时间结构的探索。研究者借鉴神经科学中作为神经组织核心标志的时间整合与亚稳态概念，试图将这些概念应用于Transformer模型，以揭示不同功能状态下模型内部动力学的时间组织差异。

Method: 研究提出了一种基于激活时间序列的复合动力学指标，在GPT-2-medium模型上进行评估。设计了五种实验条件：结构化推理、强制重复、高温噪声采样、注意力头剪枝和权重噪声注入。通过自回归生成过程中的激活时间序列计算动力学指标，使用单因素方差分析(ANOVA)进行统计检验，并评估了该指标对层选择、通道子采样和随机种子的鲁棒性。

Result: 结构化推理条件相比重复、噪声和扰动条件表现出显著更高的动力学指标。统计检验显示组间存在显著差异，关键比较中效应量较大。这些结果对层选择、通道子采样和随机种子具有鲁棒性。结果表明，结构化推理任务中模型的内部动力学表现出更复杂的时间组织特征。

Conclusion: 神经科学启发的动力学指标能够可靠地表征大型语言模型在不同功能状态下的计算组织差异。该指标捕捉的是形式化的动力学特性，而非主观体验。研究为理解LLM内部动力学的时间组织提供了新视角，并展示了跨学科概念迁移在AI可解释性研究中的潜力。

Abstract: Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.

</details>


### [4] [Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance](https://arxiv.org/abs/2601.11625)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 该论文提出了一种训练时解释性方法，通过跟踪微调过程中token级归因的变化来监控模型决策依据的演变，定义了"解释漂移"和"推理稳定点"的概念。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型微调虽然能提升任务性能，但会微妙地改变模型依赖的证据依据。现有方法缺乏对微调过程中模型推理依据如何演变的监控手段。

Method: 提出训练时解释性视角，跟踪微调各epoch中token级归因的变化。定义"解释漂移"为固定探测集上归一化token归因的epoch间变化，引入"推理稳定点"作为漂移首次进入持续低水平状态的最早epoch。

Result: 在多个轻量级transformer分类器和基准分类任务中，漂移通常在训练早期就进入低稳定状态，而验证准确率仅发生边际变化。在受控的捷径设置中，归因动态揭示了模型对标签相关触发token的依赖增加，即使验证准确率保持竞争力。

Conclusion: 解释漂移提供了一种简单、低成本的诊断工具，用于监控微调过程中决策依据的演变，并可在稳定证据机制中选择检查点。

Abstract: Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.

</details>


### [5] [Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion](https://arxiv.org/abs/2601.11979)
*Ang Gao,Changshuo Zhang,Xiao Zhang,Deyang Li,Minjun Zhao,Fangchao Liu,Xinyu Zhang*

Main category: cs.AI

TL;DR: 提出Process In-Context Learning (PICL)框架，通过动态插入相关演示来解决数学推理中的实时困惑点，提升推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有ICL方法在数学推理等需要逐步逻辑推导的任务中存在局限性，它们使用静态的演示示例，无法适应推理过程中出现的动态困惑点（如模糊计算或逻辑漏洞），这些未解决的困惑点会导致级联错误，降低最终准确性。

Method: PICL采用两阶段框架：1) 通过分析推理过程中的语义和熵来识别潜在困惑点，并总结其核心特征；2) 当遇到这些困惑点时，从演示池中检索与困惑上下文匹配的相关演示，并将其直接插入到正在进行的推理过程中，以指导后续步骤。

Result: 实验表明PICL优于基线方法，通过缓解推理过程中的困惑点，证明了自适应演示插入在复杂数学推理中的价值。

Conclusion: PICL框架通过动态集成演示来响应实时推理需求，有效解决了数学推理中的动态困惑点问题，为需要逐步逻辑推导的任务提供了更有效的ICL方法。

Abstract: In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.

</details>


### [6] [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259)
*Jiashuo Liu,Siyuan Chen,Zaiyuan Wang,Zhiyuan Zeng,Jiacheng Guo,Liang Hu,Lingyue Yin,Suozhi Huang,Wenxin Hao,Yang Yang,Zerui Cheng,Zixin Yao,Lingyue Yin,Haoxin Liu,Jiayi Cheng,Yuzhen Li,Zezhong Ma,Bingjie Wang,Bingsen Qiu,Xiao Liu,Zeyang Zhang,Zijian Liu,Jinpeng Wang,Mingren Yin,Tianci He,Yali Liao,Yixiao Tian,Zhenwei Zhu,Anqi Dai,Ge Zhang,Jingkai Liu,Kaiyuan Zhang,Wenlong Wu,Xiang Gao,Xinjie Chen,Zhixin Yao,Zhoufutu Wen,B. Aditya Prakash,Jose Blanchet,Mengdi Wang,Nian Si,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX-Pro扩展了FutureX基准，为金融、零售、公共卫生和自然灾害四个高价值垂直领域构建了专门的未来预测框架，评估当前SOTA智能体LLM在这些关键领域的工业部署能力。


<details>
  <summary>Details</summary>
Motivation: 虽然通用智能体在开放领域搜索中表现出色，但在资本密集型和安全关键行业的可靠性尚未充分探索。需要评估当前最先进的智能体LLM是否具备工业部署所需的领域基础。

Method: 基于FutureX的无污染实时评估管道，构建了包含五个子领域的FutureX-Pro框架：FutureX-Finance、FutureX-Retail、FutureX-PublicHealth、FutureX-NaturalDisaster和FutureX-Search。在四个关键垂直领域（金融、零售、公共卫生、自然灾害）上对智能体LLM进行基准测试，涵盖市场指标预测、供应链需求预测、流行病趋势跟踪和自然灾害监测等基础预测任务。

Result: 研究发现当前最先进的智能体LLM在通用推理能力与高价值垂直应用所需精度之间存在性能差距，揭示了这些模型在工业部署中面临的挑战。

Conclusion: FutureX-Pro为评估智能体LLM在关键垂直领域的预测能力提供了专门框架，揭示了当前模型在工业应用中的局限性，强调了领域基础对于高价值应用的重要性。

Abstract: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.

</details>


### [7] [Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck](https://arxiv.org/abs/2601.12499)
*Meiru Zhang,Zaiqiao Meng,Nigel Collier*

Main category: cs.AI

TL;DR: 论文提出MFAI语义探针，揭示了LLMs在多跳推理中的"最弱环节定律"：性能取决于最不可见证据的位置，而非事实间的线性距离，并发现注意力引导的双重性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs拥有大规模上下文窗口，但在多跳推理中存在位置偏见，导致忽略某些位置的信息。需要区分这种失败是由于无法定位证据（识别失败）还是无法整合证据（综合失败）。

Method: 引入多焦点注意力指令（MFAI）作为语义探针，通过显式引导注意力到选定位置来解耦识别和综合机制。在5个LLMs上对两个多跳QA任务（MuSiQue和NeoQA）进行实验。

Result: 发现"最弱环节定律"：多跳推理性能崩溃到最不可见证据的性能水平。失败由绝对位置而非事实间线性距离决定（性能方差<3%）。匹配的MFAI可解决识别瓶颈，在低可见性位置提高准确率达11.5%；误导性MFAI在真实任务中引发混淆但在合成任务中被过滤。使用System-2推理的"思考"模型能有效定位和整合信息。

Conclusion: LLMs的多跳推理失败主要由位置偏见导致的识别失败驱动，而非综合失败。注意力引导具有双重性，而System-2推理模型能有效克服这些限制，在嘈杂长上下文环境中匹配黄金基准。

Abstract: Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the "Weakest Link Law": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that "thinking" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.

</details>


### [8] [Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts](https://arxiv.org/abs/2601.12711)
*Kevin Wang,Neel P. Bhatt,Cong Liu,Junbo Li,Runjin Chen,Yihan Xi,Timothy Barclay,Alvaro Velasquez,Ufuk Topcu,Zhangyang Wang*

Main category: cs.AI

TL;DR: 提出神经符号LoRA框架，动态结合参数微调与符号编辑，在保持内存效率的同时提升LLM适应能力


<details>
  <summary>Details</summary>
Motivation: 传统LLM适应方法存在局限性：数值微调擅长注入新事实知识但需要重训练，符号操作能灵活控制风格但对事实重构能力有限。需要结合两者优势实现更全面的模型适应

Method: 提出神经符号LoRA框架，包含统一监控信号和基于奖励的分类器，动态决策何时使用LoRA进行深度事实重构，何时使用TextGrad进行token级编辑。通过外部LLM按需处理符号转换保持内存效率

Result: 在多个LLM骨干上的实验表明，神经符号LoRA始终优于纯数值或纯符号基线，展现出更优的适应性和性能提升。符号编辑过程中生成的精炼提示可作为高质量可重用训练数据

Conclusion: 数值更新与符号更新的交织结合为语言模型微调解锁了新的多功能性水平，神经符号LoRA框架展示了这种混合方法的显著价值

Abstract: Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.

</details>


### [9] [SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability](https://arxiv.org/abs/2601.12804)
*Hanwei Zhang,Luo Cheng,Rui Wen,Yang Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.AI

TL;DR: SL-CBM通过引入语义局部性增强概念瓶颈模型，生成空间一致的概念和类别显著图，提高局部忠实性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型缺乏局部忠实性，无法将概念与有意义的图像区域空间对齐，限制了可解释性和可靠性。

Method: 提出SL-CBM，集成1x1卷积层和交叉注意力机制，在概念和类别层面生成空间一致的显著图，使用对比和基于熵的正则化平衡准确性、稀疏性和忠实性。

Result: 在图像数据集上显著提高了局部忠实性、解释质量和干预效果，同时保持竞争力的分类准确性。

Conclusion: SL-CBM弥合了基于概念的推理和空间可解释性之间的差距，为可解释和可信的概念模型设立了新标准。

Abstract: Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.

</details>


### [10] [Actionable Interpretability Must Be Defined in Terms of Symmetries](https://arxiv.org/abs/2601.12913)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Francesco Giannini,Alberto Termine,Filippo Bonchi,Mateja Jamnik,Giuseppe Marra*

Main category: cs.AI

TL;DR: 该论文认为当前AI可解释性研究存在根本性问题，因为现有定义缺乏可操作性，无法推导出具体的建模和推理规则。作者提出基于对称性的可操作性定义，并假设四种对称性足以解决可解释性的核心问题。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能可解释性研究存在根本性缺陷，因为现有的可解释性定义缺乏可操作性——它们未能提供可以推导出具体建模和推理规则的形式化原则。这导致可解释性研究缺乏坚实的理论基础和统一的框架。

Method: 提出基于对称性的可操作性定义框架。假设四种对称性足以：(1) 激发核心可解释性属性；(2) 刻画可解释模型类别；(3) 推导统一的可解释推理形式化表述（如对齐、干预和反事实推理），将其视为贝叶斯逆问题。

Result: 论文提出了一个基于对称性的可解释性理论框架，该框架能够为可解释性提供可操作的定义，统一解释对齐、干预和反事实推理等概念，并为可解释模型的分类提供形式化基础。

Conclusion: 可解释性研究需要基于对称性的可操作性定义才能成为严谨的科学领域。四种对称性假设为解决可解释性的核心问题提供了统一的数学框架，将可解释推理形式化为贝叶斯逆问题，为未来研究奠定了理论基础。

Abstract: This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.

</details>


### [11] [The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models](https://arxiv.org/abs/2601.13358)
*Samuel Cyrenius Anderson*

Main category: cs.AI

TL;DR: 研究发现模型规模不会均匀提升推理能力，而是重构推理过程。通过分析25,000+思维链轨迹发现，神经缩放定律触发领域特定的相变而非均匀能力提升，推理几何结构决定可学习性。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为模型规模会均匀提升所有推理能力，但本文旨在探究规模如何具体影响不同领域的推理过程，揭示神经缩放定律的实际作用机制。

Method: 分析25,000+思维链轨迹，涵盖法律、科学、代码、数学四个领域和8B、70B两种规模。使用几何分析方法测量表示维度、轨迹对齐、流形解缠等指标。引入神经推理算子作为从初始到最终隐藏状态的映射。

Result: 法律推理经历"结晶化"：表示维度下降45%，轨迹对齐增加31%，流形解缠提升10倍。科学和数学推理保持"液态"几何不变。代码推理形成离散"晶格"结构。神经推理算子在法律推理上通过探针解码达到63.6%准确率。发现跨领域和规模的通用振荡特征（相干性~-0.4）。

Conclusion: 思维成本由流形几何而非任务难度决定，为拓扑结构允许的推理加速提供了蓝图。推理能力提升不是均匀的，而是通过领域特定的相变实现，几何结构可预测可学习性。

Abstract: Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.

</details>


### [12] [Reasoning is a Modality](https://arxiv.org/abs/2601.13562)
*Zhiguang Liu,Yi Shang*

Main category: cs.AI

TL;DR: 论文提出将推理视为独立模态，设计角色分离的Transformer块来区分全局控制器token和网格工作空间token，在ARC视觉推理任务上超越人类平均表现。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统（如LLMs和ViTs）主要作为行为序列预测机器运行，通过建模token统计来匹配可观察行为，但没有持久、可读的内心状态。这与人类行为存在差距：人类可以通过解码内部状态来解释行动，而AI系统可以产生流畅的事后合理化，但这些解释并不基于这样的内部状态。作者假设推理是一种模态：推理应该作为一个独立于应用规则的低级工作空间的通道存在。

Method: 设计了一种新颖的角色分离Transformer块，将全局控制器token与网格工作空间token分开，实现迭代规则执行。该方法在VARC视觉中心协议下进行训练和评估，专门用于解决ARC任务作为视觉推理问题。

Result: 在ARC-1上达到62.6%的准确率，超过了人类平均表现（60.2%），并显著优于先前的方法。定性分析显示，与密集的ViT基线相比，模型展现出更连贯的规则应用结构，从"合理的概率斑块"转向控制器驱动的推理。

Conclusion: 研究支持了推理作为独立模态的假设，通过角色分离的Transformer架构实现了更接近人类推理的抽象推理能力，在ARC任务上超越了人类平均表现，为AI系统实现更可解释、基于状态的推理提供了新方向。

Abstract: The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.

</details>


### [13] [Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance](https://arxiv.org/abs/2601.13770)
*Mostapha Benhenda*

Main category: cs.AI

TL;DR: Look-Ahead-Bench是一个标准化基准，用于评估金融工作流中PiT大语言模型的look-ahead偏差，通过分析不同市场机制下的性能衰减来区分真实预测能力与记忆性表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过问答测试内部前瞻知识，缺乏对实际应用场景中模型行为的评估。需要建立标准化基准来衡量金融LLM中的时间偏差，为实际部署提供实用框架。

Method: 创建Look-Ahead-Bench基准，在现实金融工作流中评估PiT LLM。通过分析不同时间市场机制下的性能衰减来区分预测能力与记忆，使用多个量化基线建立性能阈值。评估开源LLM（Llama 3.1 8B/70B、DeepSeek 3.2）与PiT-Inference模型家族（Pitinf-Small、Pitinf-Medium、Pitinf-Large）。

Result: 标准LLM显示出显著的look-ahead偏差（通过alpha衰减测量），而Pitinf模型随着规模扩大展现出改进的泛化和推理能力。Pitinf模型在时间偏差方面表现优于标准LLM。

Conclusion: 该工作为金融LLM时间偏差的标准化评估奠定了基础，提供了识别适合实际部署模型的实用框架。Pitinf模型在减少look-ahead偏差方面表现优异，为金融应用提供了更可靠的解决方案。

Abstract: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench

</details>


### [14] [Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments](https://arxiv.org/abs/2601.13846)
*Glinskaya Maria*

Main category: cs.AI

TL;DR: 论文提出Virtual Urbanism (VU)框架，通过AI生成合成城市复制品来量化城市身份，以东京九个区域为案例验证可行性，获得约81%的识别准确率


<details>
  <summary>Details</summary>
Motivation: 开发计算可处理的量化城市身份指标框架，通过合成城市复制品来分析和测量城市身份的核心形成要素

Method: 整合Stable Diffusion和LoRA模型生成东京九个区域的动态合成城市序列，排除现有导向标记以提取核心身份要素；通过人类评估实验：(I)评估复制品感知合法性，(II)量化区域级身份，(III)推导核心身份形成要素

Result: 复制品识别准确率平均约81%，验证了复制品的有效性；Urban Identity Level (UIL)指标能评估各区域身份水平；语义分析揭示文化嵌入的类型学作为核心身份形成要素

Conclusion: VU是AI增强城市分析的可行框架，为自动化、多参数身份指标的发展奠定了基础

Abstract: This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.

</details>


### [15] [VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781)
*Hyejin Park,Junhyuk Kwon,Suha Kwak,Jungseul Ok*

Main category: cs.AI

TL;DR: VIRO框架通过集成轻量级验证器到神经符号推理步骤中，解决REC中因中间步骤错误导致的级联错误问题，在目标存在和不存在场景下实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号REC方法依赖LLM和VLM进行组合推理，但假设中间推理步骤准确，导致级联错误：错误检测和无效关系在推理链中传播，即使图像中没有目标也会产生高置信度的假阳性结果。

Method: 提出验证集成推理算子（VIRO）框架，在推理步骤中嵌入轻量级的算子级验证器。每个算子执行并验证其输出（如对象存在性或空间关系），当验证条件不满足时能够鲁棒地处理无目标情况。

Result: 在目标存在和无目标设置下达到61.1%的平衡准确率，实现最先进性能；在真实世界自我中心数据上展示泛化能力；计算效率高（吞吐量）、可靠性强（程序失败率低于0.3%），通过解耦程序生成与执行实现可扩展性。

Conclusion: VIRO通过集成验证机制有效解决了神经符号REC中的级联错误问题，在保持解释性推理和零样本泛化优势的同时，显著提升了系统鲁棒性、可靠性和效率。

Abstract: Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [16] [Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study](https://arxiv.org/abs/2601.11612)
*Arnav S. Sonavane*

Main category: cs.CV

TL;DR: 农业病害分类中，领域特定的自监督预训练（SimCLR）仅需3000张无标签农业图像即可带来+4.57%准确率提升，超过了层次架构设计带来的+3.70%增益，且该优势与架构无关。


<details>
  <summary>Details</summary>
Motivation: 研究领域特定自监督预训练对农业病害分类的影响，探索在有限标注数据下如何通过无标签数据提升模型性能，并比较架构设计与数据收集的相对重要性。

Method: 使用SimCLR在3000张无标签农业图像上进行自监督预训练，然后应用于多种视觉Transformer架构（HierarchicalViT、Swin-Base、ViT-Base）。提出HierarchicalViT（HVT），一种Swin风格的层次Transformer，在三个农业病害数据集（Cotton Leaf Disease、PlantVillage、PlantDoc）上进行评估，并进行了校准分析。

Result: SimCLR预训练带来显著性能提升：HVT +4.57%，Swin-Base +4.08%，ViT-Base +4.20%。在相同参数量下，HVT-Base（78M）达到88.91%，优于Swin-Base（88M）的87.23%（+1.68%）。HVT的校准误差为3.56% ECE，经过温度缩放后降至1.52%。

Conclusion: 领域特定的自监督预训练比架构设计更为重要，实践者应优先考虑领域数据收集而非架构选择。HierarchicalViT在农业病害分类中表现出色，且具有良好的校准特性。

Abstract: We investigate the impact of domain-specific self-supervised pre-training on agricultural disease classification using hierarchical vision transformers. Our key finding is that SimCLR pre-training on just 3,000 unlabeled agricultural images provides a +4.57% accuracy improvement--exceeding the +3.70% gain from hierarchical architecture design. Critically, we show this SSL benefit is architecture-agnostic: applying the same pre-training to Swin-Base yields +4.08%, to ViT-Base +4.20%, confirming practitioners should prioritize domain data collection over architectural choices. Using HierarchicalViT (HVT), a Swin-style hierarchical transformer, we evaluate on three datasets: Cotton Leaf Disease (7 classes, 90.24%), PlantVillage (38 classes, 96.3%), and PlantDoc (27 classes, 87.1%). At matched parameter counts, HVT-Base (78M) achieves 88.91% vs. Swin-Base (88M) at 87.23%, a +1.68% improvement. For deployment reliability, we report calibration analysis showing HVT achieves 3.56% ECE (1.52% after temperature scaling). Code: https://github.com/w2sg-arnav/HierarchicalViT

</details>


### [17] [Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning](https://arxiv.org/abs/2601.11614)
*Jason Qiu*

Main category: cs.CV

TL;DR: 提出3D TransUNet框架从T1w MRI预测扩散MRI指标（FA和MD），提升阿尔茨海默病早期检测准确性


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期检测至关重要，但T1w MRI只能检测晚期宏观变化，扩散MRI能检测早期微观异常但扫描时间长、易受运动伪影影响，限制了临床常规使用。需要从常规T1w MRI中提取扩散MRI信息。

Method: 开发3D TransUNet图像合成框架，直接从T1w MRI预测分数各向异性（FA）和平均扩散率（MD）图。模型生成高质量扩散指标图，并集成到多模态诊断模型中。

Result: 合成FA和MD图的结构相似性指数（SSIM）超过0.93，与真实扩散MRI的皮尔逊相关系数>0.94。在多模态诊断模型中，AD分类准确率提升5%（78.75%→83.75%），轻度认知障碍检测提升12.5%。

Conclusion: 从常规T1w MRI可以推断高质量的扩散微观结构信息，将多模态成像的优势转移到无法获取扩散数据的临床场景。该方法通过减少扫描时间同时保留互补的结构和微观结构信息，有望提高AD诊断的可及性、效率和准确性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder in which pathological changes begin many years before the onset of clinical symptoms, making early detection essential for timely intervention. T1-weighted (T1w) Magnetic Resonance Imaging (MRI) is routinely used in clinical practice to identify macroscopic brain alterations, but these changes typically emerge relatively late in the disease course. Diffusion MRI (dMRI), in contrast, is sensitive to earlier microstructural abnormalities by probing water diffusion in brain tissue. dMRI metrics, including fractional anisotropy (FA) and mean diffusivity (MD), provide complementary information about white matter integrity and neurodegeneration. However, dMRI acquisitions are time-consuming and susceptible to motion artifacts, limiting their routine use in clinical populations. To bridge this gap, I propose a 3D TransUNet image synthesis framework that predicts FA and MD maps directly from T1w MRI. My model generates high-fidelity maps, achieving a structural similarity index (SSIM) exceeding 0.93 and a strong Pearson correlation (>0.94) with ground-truth dMRI. When integrated into a multi-modal diagnostic model, these synthetic features boost AD classification accuracy by 5% (78.75%->83.75%) and, most importantly, improve mild cognitive impairment (MCI) detection by 12.5%. This study demonstrates that high-quality diffusion microstructural information can be inferred from routinely acquired T1w MRI, effectively transferring the benefits of multi-modality imaging to settings where diffusion data are unavailable. By reducing scan time while preserving complementary structural and microstructural information, the proposed approach has the potential to improve the accessibility, efficiency, and accuracy of AD diagnosis in clinical practice.

</details>


### [18] [PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM](https://arxiv.org/abs/2601.11617)
*Xu Wang,Boyao Han,Xiaojun Chen,Ying Liu,Ruihui Li*

Main category: cs.CV

TL;DR: PointSLAM++是一个基于神经高斯表示的RGB-D SLAM系统，通过分层约束保持结构一致性，采用渐进位姿优化减少深度噪声，使用动态神经表示图适应场景复杂度，实现高精度3D重建和逼真渲染。


<details>
  <summary>Details</summary>
Motivation: 当前SLAM方法在深度噪声存在时难以保持结构一致性和鲁棒的位姿估计，限制了实时3D重建在机器人和增强现实中的应用。

Method: 1. 分层约束神经高斯表示：保持结构关系同时生成高斯基元进行场景建图；2. 渐进位姿优化：减轻深度传感器噪声，提升定位精度；3. 动态神经表示图：根据局部几何复杂度调整高斯节点分布，实时适应复杂场景细节。

Result: PointSLAM++在重建精度和渲染质量上优于现有的基于3DGS的SLAM方法，在大规模AR和机器人应用中展现出优势。

Conclusion: PointSLAM++通过创新的神经高斯表示和优化策略，解决了深度噪声下的结构一致性和位姿估计问题，实现了高质量的实时3D重建，适用于机器人和增强现实应用。

Abstract: Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics.

</details>


### [19] [Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings](https://arxiv.org/abs/2601.11627)
*Hassan Ugail,Jan Ritch-Frel,Irina Matuzava*

Main category: cs.CV

TL;DR: 提出基于单类自编码器的历史素描认证框架，使用手工特征在稀缺数据下实现艺术家作品验证，在900次测试中达到83.3%真接受率和9.5%假接受率。


<details>
  <summary>Details</summary>
Motivation: 解决文化遗产领域纸质作品认证和归属的持久挑战，特别是在参考语料库小、风格线索主要通过线条和有限色调变化表达的情况下，需要一种能够补充传统鉴赏方法的计算框架。

Method: 采用基于单类自编码器的验证框架，训练十个艺术家特定的验证器。使用手工特征向量，包括傅里叶域能量、香农熵、全局对比度、基于GLCM的同质性以及盒计数估计的分形复杂度。数据来自多个博物馆的认证素描收藏。

Result: 在900次验证决策（90次真实试验和810次冒名试验）中，系统在选定操作点达到83.3%的真接受率和9.5%的假接受率。性能因艺术家而异，部分验证器假接受率接近零，而其他验证器存在混淆。错误接受呈现结构化模式，与风格接近性和共享绘画惯例一致。

Conclusion: 该方法旨在补充而非取代传统鉴赏，为历史素描归属中常见的数据稀缺环境提供可重复的定量证据。错误分析揭示了风格接近性导致的系统误差，同时提示需要更好地控制数字化伪影和阈值校准。

Abstract: Authentication and attribution of works on paper remain persistent challenges in cultural heritage, particularly when the available reference corpus is small and stylistic cues are primarily expressed through line and limited tonal variation. We present a verification-based computational framework for historical drawing authentication using one-class autoencoders trained on a compact set of interpretable handcrafted features. Ten artist-specific verifiers are trained using authenticated sketches from the Metropolitan Museum of Art open-access collection, the Ashmolean Collections Catalogue, the Morgan Library and Museum, the Royal Collection Trust (UK), the Victoria and Albert Museum Collections, and an online catalogue of the Casa Buonarroti collection and evaluated under a biometric-style protocol with genuine and impostor trials. Feature vectors comprise Fourier-domain energy, Shannon entropy, global contrast, GLCM-based homogeneity, and a box-counting estimate of fractal complexity. Across 900 verification decisions (90 genuine and 810 impostor trials), the pooled system achieves a True Acceptance Rate of 83.3% with a False Acceptance Rate of 9.5% at the chosen operating point. Performance varies substantially by artist, with near-zero false acceptance for some verifiers and elevated confusability for others. A pairwise attribution of false accepts indicates structured error pathways consistent with stylistic proximity and shared drawing conventions, whilst also motivating tighter control of digitisation artefacts and threshold calibration. The proposed methodology is designed to complement, rather than replace, connoisseurship by providing reproducible, quantitative evidence suitable for data-scarce settings common in historical sketch attribution.

</details>


### [20] [A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow](https://arxiv.org/abs/2601.11630)
*Haonan Wei,Linyuan Wang,Nuolin Sun,Zhizhong Zheng,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: 提出SLT（单层Transformer），通过知识蒸馏将28层FreeFlow模型压缩为单个共享DiT块，参数量从675M降至4.3M，并利用其快速采样能力在噪声空间筛选高质量初始点，提升一步生成的质量和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前流匹配方法旨在将扩散模型的迭代生成过程压缩到少数甚至单步，但现有方法如FreeFlow仍使用28层Transformer架构。观察到该架构可视为沿深度轴的ODE欧拉离散化方案，因此希望通过知识蒸馏大幅压缩模型规模，同时利用小模型的快速采样能力筛选高质量噪声初始点，提升一步生成的稳定性和质量。

Method: 将FreeFlow的28层Transformer架构视为ODE的欧拉离散化方案，沿相同推导逻辑进行知识蒸馏。提出SLT（单层Transformer），使用单个共享DiT块近似28层教师模型的深度特征演化。训练时在多个深度补丁匹配教师中间特征，融合这些补丁级表示，同时对齐教师的最终速度预测。通过蒸馏训练将28个独立Transformer块压缩为单个块。

Result: 成功将教师模型DiT-XL/2从675M参数压缩到4.3M（28个独立Transformer块→单个共享块）。在相当于教师模型两次随机采样的时间预算内，可进行超过100次噪声筛选，并使用选定点通过教师模型生成高质量样本。有效避免了有限FreeFlow采样调用下低质量初始噪声导致的质量波动，显著提升了一步生成的稳定性和平均生成质量。

Conclusion: SLT通过知识蒸馏大幅压缩流匹配模型规模，同时利用小模型的快速采样能力进行噪声空间筛选，为教师模型提供高质量初始点。该方法在保持生成质量的同时显著提升采样效率，为一步生成提供了更稳定高效的解决方案，展示了模型压缩与采样策略协同优化的有效性。

Abstract: Currently, Flow matching methods aim to compress the iterative generation process of diffusion models into a few or even a single step, with MeanFlow and FreeFlow being representative achievements of one-step generation based on Ordinary Differential Equations (ODEs). We observe that the 28-layer Transformer architecture of FreeFlow can be characterized as an Euler discretization scheme for an ODE along the depth axis, where the layer index serves as the discrete time step. Therefore, we distill the number of layers of the FreeFlow model, following the same derivation logic as FreeFlow, and propose SLT (Single-Layer Transformer), which uses a single shared DiT block to approximate the depth-wise feature evolution of the 28-layer teacher. During training, it matches the teacher's intermediate features at several depth patches, fuses those patch-level representations, and simultaneously aligns the teacher's final velocity prediction. Through distillation training, we compress the 28 independent Transformer Blocks of the teacher model DiT-XL/2 into a single Transformer Block, reducing the parameter count from 675M to 4.3M. Furthermore, leveraging its minimal parameters and rapid sampling speed, SLT can screen more candidate points in the noise space within the same timeframe, thereby selecting higher-quality initial points for the teacher model FreeFlow and ultimately enhancing the quality of generated images. Experimental results demonstrate that within a time budget comparable to two random samplings of the teacher model, our method performs over 100 noise screenings and produces a high-quality sample through the teacher model using the selected points. Quality fluctuations caused by low-quality initial noise under a limited number of FreeFlow sampling calls are effectively avoided, substantially improving the stability and average generation quality of one-step generation.

</details>


### [21] [Compress to Focus: Efficient Coordinate Compression for Policy Optimization in Multi-Turn GUI Agents](https://arxiv.org/abs/2601.11631)
*Yurun Song,Jiong Yin,Rongjunchen Zhang,Ian G. Harris*

Main category: cs.CV

TL;DR: CCPO框架通过坐标感知空间压缩和多轮交互学习，在保持GUI智能体性能的同时实现高达55%的token压缩和3.8倍训练加速。


<details>
  <summary>Details</summary>
Motivation: 多轮GUI智能体在任务执行过程中面临严重的上下文膨胀问题，现有方法要么通过截断牺牲长期上下文，要么通过token剪枝损害空间结构完整性。

Method: 提出坐标压缩策略优化框架，包含坐标感知空间压缩机制，通过多轮交互聚合坐标信息来捕捉目标相关区域，并逐步缩小历史注意力范围；同时设计基于距离的优势函数提供细粒度学习信号。

Result: 在四个基准测试中达到最先进性能，实现高达55%的token压缩和3.8倍的训练加速。

Conclusion: CCPO框架有效解决了多轮GUI智能体的上下文膨胀问题，通过视觉压缩与策略优化的耦合实现了高效的任务完成。

Abstract: Multi-turn GUI agents enable complex task completion through sequential decision-making, but suffer from severe context inflation as interaction history accumulates. Existing strategies either sacrifice long-term context via truncation or compromise spatial structure through token pruning. In this paper, we propose Coordinate Compression Policy Optimization (CCPO), an efficient policy optimization framework that couples visual compression with policy optimization for multi-turn GUI agents. CCPO introduces Coordinate-Aware Spatial Compression (CASC), which aggregates coordinates from multiple rollouts to capture target-relevant regions and progressively narrow historical attention around key visual areas. From interactions across rollouts, CASC adaptively constructs attention boundaries that concentrate computation on the most informative regions of the scene. We further design a Distance-Based Advantage that provides fine-grained learning signals based on distance rather than binary correctness, improving both grounding accuracy and compression quality. Extensive experiments demonstrate that CCPO achieves SOTA performance across four benchmarks with up to 55% token compression and 3.8$\times$ training speedup.

</details>


### [22] [KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering](https://arxiv.org/abs/2601.11632)
*Zhiyang Li,Ao Ke,Yukun Cao,Xike Xie*

Main category: cs.CV

TL;DR: KG-ViP是一个统一框架，通过融合场景图和常识图来解决MLLMs在VQA中的知识幻觉和细粒度视觉感知不足问题，显著提升VQA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉问答中存在双重限制：知识幻觉和细粒度视觉感知不足。现有方法通常孤立处理场景图和常识图，忽视了它们的协同潜力。

Method: 提出KG-ViP统一框架，采用新颖的检索-融合管道，利用查询作为语义桥梁逐步整合场景图和常识图，合成统一的结构化上下文以促进可靠的多模态推理。

Result: 在FVQA 2.0+和MVQA基准测试上的广泛实验表明，KG-ViP显著优于现有的VQA方法。

Conclusion: 通过融合场景图和常识图的互补优势，KG-ViP有效解决了MLLMs在VQA中的知识幻觉和细粒度视觉感知问题，为多模态推理提供了可靠的结构化上下文。

Abstract: Multi-modal Large Language Models (MLLMs) for Visual Question Answering (VQA) often suffer from dual limitations: knowledge hallucination and insufficient fine-grained visual perception. Crucially, we identify that commonsense graphs and scene graphs provide precisely complementary solutions to these respective deficiencies by providing rich external knowledge and capturing fine-grained visual details. However, prior works typically treat them in isolation, overlooking their synergistic potential. To bridge this gap, we propose KG-ViP, a unified framework that empowers MLLMs by fusing scene graphs and commonsense graphs. The core of the KG-ViP framework is a novel retrieval-and-fusion pipeline that utilizes the query as a semantic bridge to progressively integrate both graphs, synthesizing a unified structured context that facilitates reliable multi-modal reasoning. Extensive experiments on FVQA 2.0+ and MVQA benchmarks demonstrate that KG-ViP significantly outperforms existing VQA methods.

</details>


### [23] [Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos](https://arxiv.org/abs/2601.11635)
*Anil Egin,Andrea Tangherloni,Antitza Dantcheva*

Main category: cs.CV

TL;DR: Anon-NET：基于扩散模型的统一人脸视频匿名化框架，通过属性引导和运动感知表情迁移实现身份混淆，同时保留年龄、性别、种族、姿态和表情等属性


<details>
  <summary>Details</summary>
Motivation: 在保护隐私的同时，允许视频在表情识别、人员跟踪、动作识别等下游计算机视觉任务中进行分析，需要一种既能有效去身份化又能保留原始视频重要属性的解决方案

Method: 提出Anon-NET统一框架：1）使用基于扩散的生成模型进行人脸修复，通过高级属性识别和运动感知表情迁移引导；2）通过视频驱动动画对去身份化人脸进行动画化，接受去身份化人脸和原始视频作为输入

Result: 在VoxCeleb2、CelebV-HQ和HDTF等包含多样化面部动态的数据集上进行广泛实验，证明Anon-NET在混淆身份的同时保持了视觉真实性和时间一致性

Conclusion: Anon-NET是一个有效的人脸视频匿名化框架，能够在保护隐私的同时保留重要的视觉属性，代码将公开发布

Abstract: Face video anonymization is aimed at privacy preservation while allowing for the analysis of videos in a number of computer vision downstream tasks such as expression recognition, people tracking, and action recognition. We propose here a novel unified framework referred to as Anon-NET, streamlined to de-identify facial videos, while preserving age, gender, race, pose, and expression of the original video. Specifically, we inpaint faces by a diffusion-based generative model guided by high-level attribute recognition and motion-aware expression transfer. We then animate deidentified faces by video-driven animation, which accepts the de-identified face and the original video as input. Extensive experiments on the datasets VoxCeleb2, CelebV-HQ, and HDTF, which include diverse facial dynamics, demonstrate the effectiveness of AnonNET in obfuscating identity while retaining visual realism and temporal consistency. The code of AnonNet will be publicly released.

</details>


### [24] [Confident Learning for Object Detection under Model Constraints](https://arxiv.org/abs/2601.11640)
*Yingda Yu,Jiaqi Xuan,Shuhui Shi,Xuanyu Teng,Shuyang Xu,Guanchao Tong*

Main category: cs.CV

TL;DR: 提出MDDC框架，通过数据质量优化提升边缘设备杂草检测性能，在固定轻量检测器下实现5-25%的mAP提升


<details>
  <summary>Details</summary>
Motivation: 边缘设备杂草检测面临模型容量、计算资源和实时推理延迟的严格约束，无法通过模型缩放或集成来提升性能，需要数据中心的解决方案

Method: 提出模型驱动数据校正框架，通过自动化错误分析将检测失败分为四类，采用结构化训练-修复-再训练流程，配合版本控制数据管理

Result: 在多个杂草检测数据集上，使用固定轻量检测器实现5-25%的mAP@0.5提升，证明数据质量优化能有效缓解固定模型容量下的性能瓶颈

Conclusion: 系统化的数据质量优化是提升边缘设备杂草检测性能的有效途径，在固定模型约束下通过数据校正实现显著性能改进

Abstract: Agricultural weed detection on edge devices is subject to strict constraints on model capacity, computational resources, and real-time inference latency, which prevent performance improvements through model scaling or ensembling. This paper proposes Model-Driven Data Correction (MDDC), a data-centric framework that enhances detection performance by iteratively diagnosing and correcting data quality deficiencies. An automated error analysis procedure categorizes detection failures into four types: false negatives, false positives, class confusion, and localization errors. These error patterns are systematically addressed through a structured train-fix-retrain pipeline with version-controlled data management. Experimental results on multiple weed detection datasets demonstrate consistent improvements of 5-25 percent in mAP at 0.5 using a fixed lightweight detector (YOLOv8n), indicating that systematic data quality optimization can effectively alleviate performance bottlenecks under fixed model capacity constraints.

</details>


### [25] [Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers](https://arxiv.org/abs/2601.11641)
*Yuxi Liu,Yipeng Hu,Zekun Zhang,Kunze Jiang,Kun Yuan*

Main category: cs.CV

TL;DR: MOD-DiT提出了一种无需采样的动态注意力框架，通过两阶段过程准确建模视频生成中的注意力模式，解决了传统稀疏注意力方法的计算复杂度和质量下降问题。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在视频生成中面临自注意力机制的二次复杂度问题，现有稀疏注意力方法要么依赖过于简化的静态模式，要么需要计算昂贵的采样操作来实现动态稀疏性，导致模式预测不准确和生成质量下降。

Method: 提出混合分布DiT（MOD-DiT），采用两阶段过程：1）利用早期去噪步骤的先验信息，通过分布式混合方法建模高效的线性近似模型，预测特定去噪区间的掩码模式；2）在线块掩码策略动态应用预测的掩码，同时保持历史稀疏信息，无需重复采样操作。

Result: 在多个基准测试和模型架构上实现了持续加速和质量提升，验证了MOD-DiT在高效高质量视频生成中的有效性，克服了传统稀疏注意力方法的计算限制。

Conclusion: MOD-DiT通过采样自由的动态注意力框架，准确建模演化中的注意力模式，为视频生成提供了既高效又高质量的解决方案，解决了现有稀疏注意力方法的局限性。

Abstract: While Diffusion Transformers (DiTs) have achieved notable progress in video generation, this long-sequence generation task remains constrained by the quadratic complexity inherent to self-attention mechanisms, creating significant barriers to practical deployment. Although sparse attention methods attempt to address this challenge, existing approaches either rely on oversimplified static patterns or require computationally expensive sampling operations to achieve dynamic sparsity, resulting in inaccurate pattern predictions and degraded generation quality. To overcome these limitations, we propose a \underline{\textbf{M}}ixtrue-\underline{\textbf{O}}f-\underline{\textbf{D}}istribution \textbf{DiT} (\textbf{MOD-DiT}), a novel sampling-free dynamic attention framework that accurately models evolving attention patterns through a two-stage process. First, MOD-DiT leverages prior information from early denoising steps and adopts a {distributed mixing approach} to model an efficient linear approximation model, which is then used to predict mask patterns for a specific denoising interval. Second, an online block masking strategy dynamically applies these predicted masks while maintaining historical sparsity information, eliminating the need for repetitive sampling operations. Extensive evaluations demonstrate consistent acceleration and quality improvements across multiple benchmarks and model architectures, validating MOD-DiT's effectiveness for efficient, high-quality video generation while overcoming the computational limitations of traditional sparse attention approaches.

</details>


### [26] [PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models](https://arxiv.org/abs/2601.11642)
*Abbas Alzubaidi,Ali Al-Bayaty*

Main category: cs.CV

TL;DR: 提出基于物理的合成模拟框架(PSSF)生成可控膝关节X光片，用于骨关节炎评估，解决真实数据获取的隐私和资源限制问题。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎是全球主要致残原因，目前主要依赖主观的Kellgren-Lawrence分级评估。AI和影像组学需要大量标注良好的X光图像数据集，但由于隐私、治理和资源限制，这些数据往往难以获取。

Method: 开发基于物理的合成模拟框架(PSSF)，从参数化解剖模型生成前后位膝关节X光片。创建180名受试者(260个膝盖)的虚拟队列，每个膝盖在三种协议下成像(参考、低剂量、几何偏移)。自动定位内侧关节区域，使用IBSI标准进行预处理和特征提取。采用逻辑回归、随机森林和梯度提升三种机器学习模型进行二元(类似KL分级"0" vs. "2")和三分类(0-2)预测。

Result: 在IBSI协议内、跨协议和多协议场景下评估模型鲁棒性。通过类内相关系数评估特征在不同采集条件下的稳定性。

Conclusion: PSSF框架能够生成可控的合成X光片，避免了患者隐私和机构限制问题，为膝关节骨关节炎的定量评估提供了新的数据生成方法。

Abstract: Knee osteoarthritis (OA) is a major cause of disability worldwide and is still largely assessed using subjective radiographic grading, most commonly the Kellgren-Lawrence (KL) scale. Artificial intelligence (AI) and radiomics offer quantitative tools for OA assessment but depend on large, well-annotated image datasets, mainly X-ray scans, that are often difficult to obtain because of privacy, governance and resourcing constraints. In this research, we introduce a physics-based synthetic simulation framework (PSSF) to fully generate controllable X-ray scans without patients' involvement and violating their privacy and institutional constraints. This PSSF is a 2D X-ray projection simulator of anteroposterior knee radiographs from a parametric anatomical model of the distal femur and proximal tibia. Using PSSF, we create a virtual cohort of 180 subjects (260 knees), each is imaged under three protocols (reference, low-dose, and geometry-shift). Medial joint regions are automatically localized, preprocessed, and processed with the Image Biomarker Standardisation Initiative (IBSI). Practically, three machine learning (ML) models are utilized, logistic regression, random forest, and gradient boosting, to train binary (KL-like "0" vs. "2") and three-class (0-2) prediction radiographic images. Robustness is assessed within IBSI protocol, cross-protocol, and multi-protocol scenarios. Finally, features stability is then evaluated using intraclass correlation coefficients across acquisition changes.

</details>


### [27] [Predicting When to Trust Vision-Language Models for Spatial Reasoning](https://arxiv.org/abs/2601.11644)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

TL;DR: 提出基于视觉的置信度估计框架，通过独立几何验证来预测何时信任VLM的空间预测，相比基于文本的自评估方法有显著改进


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在多模态任务中表现出色，但在空间推理方面存在系统性失败（准确率仅49%-54%）。为确保在机器人和自主系统中的安全部署，需要预测何时信任VLM的空间预测，而不是盲目接受所有输出

Method: 提出基于视觉的置信度估计框架，通过独立几何验证使用物体检测来验证VLM预测。融合四个信号：VLM声明与坐标的几何对齐、重叠引起的空间模糊性、检测质量、VLM内部不确定性，使用梯度提升进行融合

Result: 在BLIP-2上达到0.674 AUROC（比文本基线提升34.0%），在CLIP上达到0.583 AUROC（提升16.1%）。在60%目标准确率下，覆盖率达到61.9%（基线27.6%，提升2.2倍）。特征分析显示视觉信号贡献87.4%重要性，VLM置信度仅12.7%

Conclusion: 外部几何验证优于自评估方法，能够可靠地进行场景图构建，通过置信度剪枝将精度从52.1%提升到78.3%，同时保留68.2%的边。该框架实现了选择性预测，提高了VLM空间推理的可靠性

Abstract: Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks, yet exhibit systematic spatial reasoning failures, achieving only 49% (CLIP) to 54% (BLIP-2) accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, we need to predict when to trust VLM spatial predictions rather than accepting all outputs. We propose a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches relying on self-assessment, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. We achieve 0.674 AUROC on BLIP-2 (34.0% improvement over text-based baselines) and 0.583 AUROC on CLIP (16.1% improvement), generalizing across generative and classification architectures. Our framework enables selective prediction: at 60% target accuracy, we achieve 61.9% coverage versus 27.6% baseline (2.2x improvement) on BLIP-2. Feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence, validating that external geometric verification outperforms self-assessment. We demonstrate reliable scene graph construction where confidence-based pruning improves precision from 52.1% to 78.3% while retaining 68.2% of edges.

</details>


### [28] [IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation](https://arxiv.org/abs/2601.11645)
*Ujjwal Jain,Oshin Misra,Roshni Chakraborty,Mahua Bhattacharya*

Main category: cs.CV

TL;DR: 提出IMSAHLO框架，通过多尺度注意力机制和混合损失优化，解决荧光显微镜神经元分割中细胞密度不均、形态复杂和类别不平衡等挑战。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜神经元分割面临密集与稀疏细胞共存、复杂重叠形态和严重类别不平衡等挑战，传统深度学习模型难以保持精细拓扑细节和准确边界划分。

Method: 提出IMSAHLO框架，包含多尺度密集块(MSDBs)捕获不同感受野特征，分层注意力(HA)机制聚焦显著形态特征，以及结合Tversky损失、Focal损失、拓扑感知中心线Dice损失和轮廓加权边界损失的混合损失函数。

Result: 在公开FNC数据集上，模型在密集和稀疏细胞情况下均优于现有方法，达到81.4%精确率、82.7%宏F1分数、83.3%微F1分数和99.5%平衡准确率。

Conclusion: 该工作为可泛化的分割模型奠定了基础，适用于广泛的生物医学成像模态，推动AI辅助分析向高通量神经生物学流程发展。

Abstract: Accurate segmentation of neuronal cells in fluorescence microscopy is a fundamental task for quantitative analysis in computational neuroscience. However, it is significantly impeded by challenges such as the coexistence of densely packed and sparsely distributed cells, complex overlapping morphologies, and severe class imbalance. Conventional deep learning models often fail to preserve fine topological details or accurately delineate boundaries under these conditions. To address these limitations, we propose a novel deep learning framework, IMSAHLO (Integrating Multi-Scale Attention and Hybrid Loss Optimization), for robust and adaptive neuronal segmentation. The core of our model features Multi-Scale Dense Blocks (MSDBs) to capture features at various receptive fields, effectively handling variations in cell density, and a Hierarchical Attention (HA) mechanism that adaptively focuses on salient morphological features to preserve Region of Interest (ROI) boundary details. Furthermore, we introduce a novel hybrid loss function synergistically combining Tversky and Focal loss to combat class imbalance, alongside a topology-aware Centerline Dice (clDice) loss and a Contour-Weighted Boundary loss to ensure topological continuity and precise separation of adjacent cells. Large-scale experiments on the public Fluorescent Neuronal Cells (FNC) dataset demonstrate that our framework outperforms state-of-the-art architectures, achieving precision of 81.4%, macro F1 score of 82.7%, micro F1 score of 83.3%, and balanced accuracy of 99.5% on difficult dense and sparse cases. Ablation studies validate the synergistic benefits of multi-scale attention and hybrid loss terms. This work establishes a foundation for generalizable segmentation models applicable to a wide range of biomedical imaging modalities, pushing AI-assisted analysis toward high-throughput neurobiological pipelines.

</details>


### [29] [Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification](https://arxiv.org/abs/2601.11651)
*Miriam Doh,Aditya Gulati,Corina Canali,Nuria Oliver*

Main category: cs.CV

TL;DR: 研究发现文本到图像生成AI和性别分类算法中存在系统性"算法外貌主义"偏见，即基于外貌的偏好性对待，揭示了生成模型将面部吸引力与积极属性关联，以及性别分类算法中的显著性别偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是调查文本到图像生成AI和下游性别分类任务中存在的"算法外貌主义"问题，即基于物理外貌的系统性偏好对待。这种偏见反映了社会构建的偏见而非基于证据的关联，可能加剧现有不平等。

Method: 研究方法包括使用Stable Diffusion 2.1和3.5 Medium生成26,400张合成人脸，分析生成AI模型如何系统性地将面部吸引力与积极属性关联。同时评估三种性别分类算法在不同属性输入人脸上的表现，检测性别偏见。

Result: 研究发现三个关键危害：(1)T2I模型中系统编码了吸引力-积极属性关联；(2)性别分类系统中存在性别差异，女性面孔（特别是带有负面属性的）误分类率显著高于男性；(3)新模型通过年龄同质化、性别化暴露模式和地理简化加剧了审美约束。

Conclusion: 研究结论表明算法外貌主义是跨AI视觉系统运作的系统性基础设施，通过表征和识别两方面加剧现有不平等。这些收敛模式揭示了生成AI和分类算法中嵌入的社会偏见，需要系统性干预来解决这些偏见。

Abstract: This paper examines algorithmic lookism-the systematic preferential treatment based on physical appearance-in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, we demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, we find significant gender bias in three gender classification algorithms depending on the attributes of the input faces. Our findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women's faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men's; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition.
  Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems-not from empirical truths or the authors' views.

</details>


### [30] [PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation](https://arxiv.org/abs/2601.11654)
*Kaustubh Shivshankar Shejole,Gaurav Mishra*

Main category: cs.CV

TL;DR: 提出基于像素段相似性指数(PSSI)和最大生成树(MaxST)的交互式图分割方法，通过谐波均值结合像素强度和空间平滑特征，在GrabCut和Images250数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有交互式图分割方法存在计算成本高、对用户交互敏感、前景背景颜色分布相似时性能下降等问题。图分割性能的关键影响因素是图中边权重的相似性度量。

Method: 提出像素段相似性指数(PSSI)，利用谐波均值结合像素强度和空间平滑特征；使用MeanShift进行低层分割捕获颜色、纹理和形状；基于像素段构建图，用PSSI确定边权重；采用最大生成树(MaxST)进行分割，捕获强连接的局部邻域。

Result: 在GrabCut和Images250数据集上的实验表明，该方法在分割质量（Jaccard指数、F1分数）、执行时间和平均误差方面均优于AMOE、OneCut、SSNCut等当前图基交互分割方法。

Conclusion: 提出的PSSI-MaxST方法通过结合颜色相似性、平滑性、纹理、形状和强局部连通性，有效解决了现有交互式图分割方法的局限性，实现了更优的分割性能。

Abstract: Interactive graph-based segmentation methods partition an image into foreground and background regions with the aid of user inputs. However, existing approaches often suffer from high computational costs, sensitivity to user interactions, and degraded performance when the foreground and background share similar color distributions. A key factor influencing segmentation performance is the similarity measure used for assigning edge weights in the graph. To address these challenges, we propose a novel Pixel Segment Similarity Index (PSSI), which leverages the harmonic mean of inter-channel similarities by incorporating both pixel intensity and spatial smoothness features. The harmonic mean effectively penalizes dissimilarities in any individual channel, enhancing robustness. The computational complexity of PSSI is $\mathcal{O}(B)$, where $B$ denotes the number of histogram bins. Our segmentation framework begins with low-level segmentation using MeanShift, which effectively captures color, texture, and segment shape. Based on the resulting pixel segments, we construct a pixel-segment graph with edge weights determined by PSSI. For partitioning, we employ the Maximum Spanning Tree (MaxST), which captures strongly connected local neighborhoods beneficial for precise segmentation. The integration of the proposed PSSI, MeanShift, and MaxST allows our method to jointly capture color similarity, smoothness, texture, shape, and strong local connectivity. Experimental evaluations on the GrabCut and Images250 datasets demonstrate that our method consistently outperforms current graph-based interactive segmentation methods such as AMOE, OneCut, and SSNCut in terms of segmentation quality, as measured by Jaccard Index (IoU), $F_1$ score, execution time and Mean Error (ME). Code is publicly available at: https://github.com/KaustubhShejole/PSSI-MaxST.

</details>


### [31] [UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM](https://arxiv.org/abs/2601.11665)
*Amir Farzin Nikkhah,Dong Chen,Bradford Campbell,Somayeh Asadi,Arsalan Heydarian*

Main category: cs.CV

TL;DR: 这篇综述论文系统分析了无人机在AEC+FM领域基础设施检测中的应用，涵盖数据采集、建模、缺陷检测和决策支持，提出了融合多模态数据的框架，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 无人机正在改变建筑、工程、施工和设施管理领域的基础设施检测方式，但现有方法在实时处理、多模态数据融合和泛化能力方面仍存在挑战，需要系统性的框架来整合先进技术并提高检测的准确性和可靠性。

Method: 通过综合分析150多项研究，提出一个集成RGB图像、LiDAR和热传感的多模态数据融合工作流程框架，结合基于Transformer的架构，并采用动态路径规划适应复杂环境，形成分步指导方案。

Result: 无人机已在结构健康监测、灾害响应、城市基础设施管理、能源效率评估和文化遗产保护等领域证明价值，使用YOLO、Faster R-CNN等机器学习模型实现异常检测，路径优化和热集成等技术显著提升了检测能力。

Conclusion: 尽管无人机检测技术取得显著进展，但仍面临实时处理、多模态融合和泛化性等挑战。未来研究方向包括轻量级AI模型、自适应飞行规划、合成数据集和更丰富的模态融合，以进一步优化现代基础设施检测流程。

Abstract: Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections.

</details>


### [32] [MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models](https://arxiv.org/abs/2601.11666)
*Muhammad Imran,Chi Lee,Yugyung Lee*

Main category: cs.CV

TL;DR: MATEX框架通过多尺度注意力、文本引导空间先验和层一致性分析，提升医学视觉语言模型的可解释性，在胸部X光数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型解释方法存在空间不精确、缺乏解剖学基础、注意力粒度有限等问题，需要更忠实、可解释的模型解释框架来增强放射学AI应用的信任度和透明度。

Method: MATEX框架结合多层注意力展开、文本引导空间先验和层一致性分析，生成精确、稳定且具有临床意义的梯度归因图，通过解剖学信息增强空间推理能力。

Result: 在MS-CXR数据集上评估，MATEX在空间精度和与专家标注发现的对齐度方面均优于最先进的M2IB方法。

Conclusion: MATEX框架通过解决现有方法的局限性，能够提供更忠实、可解释的模型解释，具有增强放射学AI应用信任度和透明度的潜力。

Abstract: We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.

</details>


### [33] [Generating metamers of human scene understanding](https://arxiv.org/abs/2601.11675)
*Ritik Raina,Abe Leite,Alexandros Graikos,Seoyoung Ahn,Dimitris Samaras,Gregory J. Zelinsky*

Main category: cs.CV

TL;DR: MetamerGen是一个潜在扩散模型，通过结合周边视觉获得的场景要点信息和注视点获得的高分辨率信息，生成与人类场景理解对齐的图像元匹配物。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过结合周边低分辨率"要点"信息和注视点高分辨率信息来理解场景。研究者希望开发一种工具，能够生成与人类潜在场景表征对齐的图像，从而更好地理解人类场景理解机制。

Method: 提出MetamerGen——一种潜在扩散模型，采用双流表示方法：使用DINOv2令牌融合注视区域的详细特征和周边降级特征（捕捉场景上下文）。通过行为实验（相同-不同判断任务）评估生成图像与人类潜在场景表征的感知对齐程度。

Result: MetamerGen能够生成与人类场景理解对齐的图像元匹配物。当生成场景基于观看者自身的注视区域时，高层次语义对齐最能预测元匹配性。概念验证分析揭示了多个视觉处理层次上影响人类判断的具体特征。

Conclusion: MetamerGen是理解场景理解的强大工具，能够生成与人类潜在场景表征对齐的图像元匹配物，为研究人类视觉场景理解机制提供了新方法。

Abstract: Human vision combines low-resolution "gist" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. "foveated") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a "same" or "different" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.

</details>


### [34] [Conformal Point and the Calibrated Conic](https://arxiv.org/abs/2601.11679)
*Richard Hartley*

Main category: cs.CV

TL;DR: 论文探讨了共形点和校准圆锥的概念及其相互关系，这些概念有助于图像几何可视化，并提供了计算图像中角度和方向的直观方法。


<details>
  <summary>Details</summary>
Motivation: 开发直观的几何可视化工具和计算方法，以简化图像中角度和方向等几何属性的计算，提高图像几何分析的直观性和效率。

Method: 引入共形点和校准圆锥的概念，分析它们之间的数学关系，并利用这些概念构建图像几何的可视化框架。

Result: 建立了共形点与校准圆锥之间的明确关系，开发了基于这些概念的图像几何可视化方法，能够直观地计算图像中的角度和方向。

Conclusion: 共形点和校准圆锥为图像几何分析提供了有效的可视化工具和计算方法，简化了几何属性的计算过程，增强了图像几何理解的直观性。

Abstract: This gives some information about the conformal point and the calibrating conic, and their relationship one to the other. These concepts are useful for visualizing image geometry, and lead to intuitive ways to compute geometry, such as angles and directions in an image.

</details>


### [35] [SemAlign: Language Guided Semi-supervised Domain Generalization](https://arxiv.org/abs/2601.11724)
*Muditha Fernando,Kajhanan Kailainathan,Krishnakanth Nagaratnam,Isuranga Udaravi Bandara Senavirathne,Ranga Rodrigo*

Main category: cs.CV

TL;DR: 提出了一种新的半监督域泛化方法，通过将模型中间特征与视觉语言模型的语义丰富特征空间对齐来提升性能，同时采用图像级增强和输出级正则化策略提高数据利用率和防止过拟合。


<details>
  <summary>Details</summary>
Motivation: 现有SSDG方法过度关注伪标签准确性而忽视了训练过程中的最大数据利用，这限制了性能提升潜力。需要一种既能提高伪标签质量又能充分利用数据的方法来改善域泛化能力。

Method: 1) 将模型中间特征与视觉语言模型(VLM)的语义丰富且泛化的特征空间对齐，以促进域不变性；2) 采用有效的图像级增强策略提高数据利用率；3) 使用输出级正则化策略最小化过拟合。

Result: 在四个基准测试上与现有SSDG基线方法相比，该方法在定性和定量上都达到了最先进(SOTA)的结果。

Conclusion: 通过将模型特征与VLM特征空间对齐，并结合数据增强和正则化策略，可以有效解决SSDG问题，实现更好的域泛化性能，超越了现有方法对伪标签准确性的过度关注。

Abstract: Semi-supervised Domain Generalization (SSDG) addresses the challenge of generalizing to unseen target domains with limited labeled data. Existing SSDG methods highlight the importance of achieving high pseudo-labeling (PL) accuracy and preventing model overfitting as the main challenges in SSDG. In this light, we show that the SSDG literature's excessive focus on PL accuracy, without consideration for maximum data utilization during training, limits potential performance improvements. We propose a novel approach to the SSDG problem by aligning the intermediate features of our model with the semantically rich and generalized feature space of a Vision Language Model (VLM) in a way that promotes domain-invariance. The above approach is enhanced with effective image-level augmentation and output-level regularization strategies to improve data utilization and minimize overfitting. Extensive experimentation across four benchmarks against existing SSDG baselines suggests that our method achieves SOTA results both qualitatively and quantitatively. The code will be made publicly available.

</details>


### [36] [SpaRRTa: A Synthetic Benchmark for Evaluating Spatial Intelligence in Visual Foundation Models](https://arxiv.org/abs/2601.11729)
*Turhan Can Kargin,Wojciech Jasiński,Adam Pardyl,Bartosz Zieliński,Marcin Przewięźlikowski*

Main category: cs.CV

TL;DR: 论文提出了SpaRRTa基准测试，用于评估视觉基础模型的空间关系识别能力，发现现有模型在空间推理方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型（如DINO和CLIP）在语义理解方面表现出色，但空间推理能力有限，限制了它们在具身系统中的应用。虽然近期研究尝试将3D任务（如深度估计）融入VFM训练，但模型在不同空间任务上的表现不一致，引发了对这些模型是否真正具备空间意识还是过度拟合特定3D目标的疑问。

Method: 提出了空间关系识别任务（SpaRRTa）基准测试，通过生成任意数量的逼真图像（包含多样化场景和完全可控的对象排列）以及可自由访问的空间标注，评估VFM识别图像中物体相对位置的能力。该基准不同于传统3D目标（如表面法线估计）关注精确度量预测，而是探究支撑更高级人类空间理解的基本能力。

Result: 评估了一系列最先进的视觉基础模型，揭示了它们在空间推理能力方面的显著差异。通过分析，提供了对现代VFM中支持或阻碍空间意识机制的见解。

Conclusion: SpaRRTa基准测试有望成为指导未来空间感知视觉模型开发的有用工具。研究表明现有VFM在空间关系识别方面存在局限性，需要进一步改进以增强空间推理能力。

Abstract: Visual Foundation Models (VFMs), such as DINO and CLIP, excel in semantic understanding of images but exhibit limited spatial reasoning capabilities, which limits their applicability to embodied systems. As a result, recent work incorporates some 3D tasks (such as depth estimation) into VFM training. However, VFM performance remains inconsistent across other spatial tasks, raising the question of whether these models truly have spatial awareness or overfit to specific 3D objectives. To address this question, we introduce the Spatial Relation Recognition Task (SpaRRTa) benchmark, which evaluates the ability of VFMs to identify relative positions of objects in the image. Unlike traditional 3D objectives that focus on precise metric prediction (e.g., surface normal estimation), SpaRRTa probes a fundamental capability underpinning more advanced forms of human-like spatial understanding. SpaRRTa generates an arbitrary number of photorealistic images with diverse scenes and fully controllable object arrangements, along with freely accessible spatial annotations. Evaluating a range of state-of-the-art VFMs, we reveal significant disparities between their spatial reasoning abilities. Through our analysis, we provide insights into the mechanisms that support or hinder spatial awareness in modern VFMs. We hope that SpaRRTa will serve as a useful tool for guiding the development of future spatially aware visual models.

</details>


### [37] [From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce](https://arxiv.org/abs/2601.11769)
*Cheng Lyu,Jingyue Zhang,Ryan Maunu,Mengwei Li,Vinny DeGenova,Yuanli Pei*

Main category: cs.CV

TL;DR: 提出一种解耦分类的视觉搜索架构，使用无分类区域建议和统一嵌入进行相似性检索，并引入LLM-as-a-Judge框架进行零样本评估，在电商家居平台实现部署和效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有电商视觉搜索系统通常将目标检测与基于分类学的分类耦合，依赖有噪声的目录数据进行评估，限制了系统的鲁棒性和可扩展性，特别是在风格驱动的领域，用户意图主观且开放。

Method: 1. 提出分类学解耦架构：使用无分类区域建议生成候选区域，通过统一嵌入进行相似性检索，实现更灵活通用的视觉搜索；2. 引入LLM-as-a-Judge框架：以零样本方式评估查询-结果对的细微视觉相似性和类别相关性，摆脱对人工标注或有噪声目录数据的依赖。

Result: 在全球家居电商平台大规模部署，系统提升了检索质量，带来了可测量的客户参与度提升，离线评估指标与实际业务结果强相关。

Conclusion: 提出的分类学解耦架构和LLM-as-a-Judge评估框架有效解决了现有电商视觉搜索系统的局限性，实现了更灵活、鲁棒的视觉搜索系统，在实际部署中验证了其有效性。

Abstract: Visual search is critical for e-commerce, especially in style-driven domains where user intent is subjective and open-ended. Existing industrial systems typically couple object detection with taxonomy-based classification and rely on catalog data for evaluation, which is prone to noise that limits robustness and scalability. We propose a taxonomy-decoupled architecture that uses classification-free region proposals and unified embeddings for similarity retrieval, enabling a more flexible and generalizable visual search. To overcome the evaluation bottleneck, we propose an LLM-as-a-Judge framework that assesses nuanced visual similarity and category relevance for query-result pairs in a zero-shot manner, removing dependence on human annotations or noise-prone catalog data. Deployed at scale on a global home goods platform, our system improves retrieval quality and yields a measurable uplift in customer engagement, while our offline evaluation metrics strongly correlate with real-world outcomes.

</details>


### [38] [Cross-Domain Object Detection Using Unsupervised Image Translation](https://arxiv.org/abs/2601.11779)
*Vinicius F. Arruda,Rodrigo F. Berriel,Thiago M. Paixão,Claudine Badue,Alberto F. De Souza,Nicu Sebe,Thiago Oliveira-Santos*

Main category: cs.CV

TL;DR: 提出一种通过生成目标域人工数据集来训练目标检测器的方法，使用CycleGAN和AdaIN模型进行无监督图像翻译，无需目标域标注数据，在自动驾驶场景中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前无监督域自适应目标检测方法虽然通过中间特征对齐取得了不错效果，但实现复杂且难以解释，性能与使用目标域数据训练的上界仍有差距，需要更简单有效的方法。

Method: 使用两种无监督图像翻译模型（CycleGAN和AdaIN-based模型），仅利用源域标注数据和目标域非标注数据，生成目标域的人工数据集来训练目标检测器。

Result: 在自动驾驶真实场景中，该方法在大多数情况下超越了当前最先进方法，显著提升了性能，进一步缩小了与使用目标域数据训练的上界之间的差距。

Conclusion: 提出的方法不仅复杂度更低、更易于解释，而且效果更好，为无监督域自适应目标检测提供了一种简单有效的解决方案，在自动驾驶等实际应用中具有重要价值。

Abstract: Unsupervised domain adaptation for object detection addresses the adaption of detectors trained in a source domain to work accurately in an unseen target domain. Recently, methods approaching the alignment of the intermediate features proven to be promising, achieving state-of-the-art results. However, these methods are laborious to implement and hard to interpret. Although promising, there is still room for improvements to close the performance gap toward the upper-bound (when training with the target data). In this work, we propose a method to generate an artificial dataset in the target domain to train an object detector. We employed two unsupervised image translators (CycleGAN and an AdaIN-based model) using only annotated data from the source domain and non-annotated data from the target domain. Our key contributions are the proposal of a less complex yet more effective method that also has an improved interpretability. Results on real-world scenarios for autonomous driving show significant improvements, outperforming state-of-the-art methods in most cases, further closing the gap toward the upper-bound.

</details>


### [39] [RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection](https://arxiv.org/abs/2601.11898)
*Yilmaz Korkmaz,Vishal M. Patel*

Main category: cs.CV

TL;DR: RemoteVAR：一种基于视觉自回归模型的变化检测框架，通过多分辨率特征融合和交叉注意力机制，在遥感变化检测任务中超越了基于扩散和Transformer的基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉自回归模型在图像生成方面表现出色，但由于可控性弱、密集预测性能不佳和曝光偏差等问题，在像素级判别任务中的应用有限。本研究旨在解决这些限制，将自回归模型应用于遥感变化检测任务。

Method: 提出RemoteVAR框架：1）通过交叉注意力机制将自回归预测条件化于多分辨率融合的双时相特征；2）采用专门为变化图预测设计的自回归训练策略。

Result: 在标准变化检测基准测试上的广泛实验表明，RemoteVAR相比基于扩散和Transformer的基线方法，取得了持续且显著的改进，为遥感变化检测建立了具有竞争力的自回归替代方案。

Conclusion: RemoteVAR成功解决了视觉自回归模型在像素级判别任务中的局限性，通过创新的特征融合和训练策略，在遥感变化检测任务中实现了优越性能，为自回归模型在密集预测任务中的应用开辟了新途径。

Abstract: Remote sensing change detection aims to localize and characterize scene changes between two time points and is central to applications such as environmental monitoring and disaster assessment. Meanwhile, visual autoregressive models (VARs) have recently shown impressive image generation capability, but their adoption for pixel-level discriminative tasks remains limited due to weak controllability, suboptimal dense prediction performance and exposure bias. We introduce RemoteVAR, a new VAR-based change detection framework that addresses these limitations by conditioning autoregressive prediction on multi-resolution fused bi-temporal features via cross-attention, and by employing an autoregressive training strategy designed specifically for change map prediction. Extensive experiments on standard change detection benchmarks show that RemoteVAR delivers consistent and significant improvements over strong diffusion-based and transformer-based baselines, establishing a competitive autoregressive alternative for remote sensing change detection. Code will be available \href{https://github.com/yilmazkorkmaz1/RemoteVAR}{\underline{here}}.

</details>


### [40] [Towards Airborne Object Detection: A Deep Learning Analysis](https://arxiv.org/abs/2601.11907)
*Prosenjit Chatterjee,ANK Zaman*

Main category: cs.CV

TL;DR: 基于EfficientNetB4的双任务模型，同时进行空中目标分类和威胁等级预测，在自建AODTA数据集上取得96%分类准确率和90%威胁预测准确率


<details>
  <summary>Details</summary>
Motivation: 空中平台（商用飞机、无人机、UAV）快速增多，需要实时自动化威胁评估系统。现有方法依赖人工监控，可扩展性有限且效率低下

Method: 采用EfficientNetB4构建双任务模型，同时执行空中目标分类和威胁等级预测。为解决数据稀缺问题，聚合多个公开源构建AODTA数据集。在AVD数据集和AODTA数据集上进行基准测试，并与ResNet-50基线对比

Result: EfficientNetB4模型在目标分类上达到96%准确率，威胁等级预测达到90%准确率，显著优于ResNet-50基线。模型在AVD和AODTA数据集上均表现良好

Conclusion: 提出的双任务EfficientNetB4模型在自动威胁评估方面表现出色，适用于监视、国防和空域管理应用。虽然标题提及检测，但研究专注于使用预定位图像进行分类和威胁推断

Abstract: The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.

</details>


### [41] [Effects of the retina-inspired light intensity encoding on color discrimination performance](https://arxiv.org/abs/2601.11909)
*Io Yamada,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 研究比较了中心/周边Retinex模型中不同光强编码函数（对数函数 vs Naka-Rushton函数）对颜色恒常性性能的影响，发现N-R函数结合双对立色平面表示提供最佳颜色辨别性能。


<details>
  <summary>Details</summary>
Motivation: 颜色是物体识别等视觉功能的重要信息来源，但受光照颜色影响很大。颜色恒常性（CC）是视觉系统的重要特性，能够独立于光照颜色感知目标颜色。研究旨在探索光强编码函数对中心/周边Retinex模型颜色恒常性性能的影响。

Method: 使用两种光强编码函数：原始C/S Retinex模型的对数函数和视网膜光感受器响应模型Naka-Rushton函数。采用颜色可变LED以不同光照颜色照射视觉目标，评估各模型计算的颜色信息在不同光照下对目标颜色的辨别能力。颜色信息使用HSV色彩空间和基于经典对立色理论的色平面表示。

Result: 结果显示，Naka-Rushton函数与双对立色平面表示的组合提供了最优的颜色辨别性能。

Conclusion: Naka-Rushton函数作为光强编码函数，结合双对立色平面表示，能够显著提升中心/周边Retinex模型的颜色恒常性性能，为使用颜色信息的视觉系统提供了更好的颜色辨别能力。

Abstract: Color is an important source of information for visual functions such as object recognition, but it is greatly affected by the color of illumination. The ability to perceive the color of a visual target independent of illumination color is called color constancy (CC), and is an important feature for vision systems that use color information. In this study, we investigated the effects of the light intensity encoding function on the performance of CC of the center/surround (C/S) retinex model, which is a well-known model inspired by CC of the visual nervous system. The functions used to encode light intensity are the logarithmic function used in the original C/S retinex model and the Naka-Rushton (N-R) function, which is a model of retinal photoreceptor response. Color-variable LEDs were used to illuminate visual targets with various lighting colors, and color information computed by each model was used to evaluate the degree to which the color of visual targets illuminated with different lighting colors could be discriminated. Color information was represented using the HSV color space and a color plane based on the classical opponent color theory. The results showed that the combination of the N-R function and the double opponent color plane representation provided superior discrimination performance.

</details>


### [42] [A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection](https://arxiv.org/abs/2601.11910)
*Guiying Zhu,Bowen Yang,Yin Zhuang,Tong Zhang,Guanqun Wang,Zhihao Che,He Chen,Lianlin Li*

Main category: cs.CV

TL;DR: 提出无需训练的GW-VLM方法，通过多尺度视觉语言搜索和上下文概念提示，利用预训练VLM和LLM实现开放词汇目标检测，在自然和遥感数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法通常忽视基于预训练基础模型建立通用对象认知理解的必要性。虽然大规模预训练模型展现出零样本能力，但缺乏系统性的通用理解范式。

Method: 提出GW-VLM框架：1）多尺度视觉语言搜索（MS-VLS）利用VLM进行类无关检测结果的多尺度视觉语言软对齐生成片段；2）上下文概念提示（CCP）基于MS-VLS形成概念流，使LLM理解片段用于开放词汇检测。

Result: 在COCO val、Pascal VOC、DIOR和NWPU-10等自然和遥感数据集上进行实验，GW-VLM无需任何训练步骤即可达到最先进的开放词汇目标检测性能。

Conclusion: GW-VLM通过创新的训练无关方法，有效利用预训练VLM和LLM的协同作用，为开放词汇目标检测提供了通用理解范式，在多种数据集上验证了其优越性。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of "guess what". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.

</details>


### [43] [From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection](https://arxiv.org/abs/2601.11915)
*Chi Wang,Xinjue Hu,Boyu Wang,Ziwen He,Zhangjie Fu*

Main category: cs.CV

TL;DR: 提出一种通过低秩子空间干预消除人脸伪造检测中虚假相关性的方法，仅需0.43M可训练参数，在多个基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 人脸伪造检测中的泛化问题源于虚假相关性因素（伪造无关信息）通过"后门路径"影响标签预测，导致有偏学习。现有方法需要识别具体虚假相关性并针对性解决，但虚假相关性源于不可观测的混杂因素，难以逐一识别和处理。

Method: 提出表示空间干预范式：将实例级虚假相关性统一建模为低秩子空间并进行干预。通过正交低秩投影将虚假相关特征分解到低秩子空间，从原始表示中移除该子空间，训练其正交补空间来捕获伪造相关特征。低秩投影移除有效消除虚假相关性因素。

Result: 仅使用0.43M可训练参数，在多个基准测试中达到最先进性能，表现出优秀的鲁棒性和泛化能力。

Conclusion: 通过将虚假相关性统一建模为低秩子空间并进行干预，有效解决了人脸伪造检测中的泛化问题，避免了逐一识别具体虚假相关性的不切实际性，实现了高效且泛化能力强的伪造检测。

Abstract: The generalization problem remains a critical challenge in face forgery detection. Some researches have discovered that ``a backdoor path" in the representations from forgery-irrelevant information to labels induces biased learning, thereby hindering the generalization. In this paper, these forgery-irrelevant information are collectively termed spurious correlations factors. Previous methods predominantly focused on identifying concrete, specific spurious correlation and designing corresponding solutions to address them. However, spurious correlations arise from unobservable confounding factors, making it impractical to identify and address each one individually. To address this, we propose an intervention paradigm for representation space. Instead of tracking and blocking various instance-level spurious correlation one by one, we uniformly model them as a low-rank subspace and intervene in them. Specifically, we decompose spurious correlation features into a low-rank subspace via orthogonal low-rank projection, subsequently removing this subspace from the original representation and training its orthogonal complement to capture forgery-related features. This low-rank projection removal effectively eliminates spurious correlation factors, ensuring that classification decision is based on authentic forgery cues. With only 0.43M trainable parameters, our method achieves state-of-the-art performance across several benchmarks, demonstrating excellent robustness and generalization.

</details>


### [44] [SupScene: Learning Overlap-Aware Global Descriptor for Unconstrained SfM](https://arxiv.org/abs/2601.11930)
*Xulei Shi,Maoyu Wang,Yuning Peng,Guanbo Wang,Xin Wang,Qi Chen,Pengjie Tao*

Main category: cs.CV

TL;DR: SupScene提出了一种用于SfM图像检索的新型全局描述符学习方法，通过子图训练策略和DiVLAD聚合器，专注于寻找具有相似几何特征的重叠图像对而非语义相似性。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的图像检索方法通常关注批量二元分类（重叠vs非重叠），但未能充分捕捉SfM中几何匹配性的细微差别。传统方法更注重语义相似性，而非几何性质相似的重叠图像对，这限制了SfM中图像匹配的效率。

Method: 1. 采用基于子图的训练策略，超越同等重要的孤立图像对，利用真实几何重叠关系及其不同权重，通过软监督对比损失提供细粒度监督。2. 提出DiVLAD聚合器，利用ViT最后一层的多头部注意力图。3. 设计可学习的门控机制，自适应地结合语义显著线索与视觉特征，生成更具区分性的全局描述符。

Result: 在GL3D数据集上的广泛实验表明，该方法实现了最先进的性能，显著优于NetVLAD，同时仅引入可忽略的额外可训练参数。此外，所提出的训练策略在不同聚合技术中都带来了一致的性能提升。

Conclusion: SupScene通过创新的训练策略和聚合器设计，成功解决了SfM中图像检索的特定需求，专注于几何匹配性而非语义相似性，为大规模无约束SfM提供了更有效的图像检索解决方案。

Abstract: Image retrieval is a critical step for alleviating the quadratic complexity of image matching in unconstrained Structure-from-Motion (SfM). However, in this context, image retrieval typically focuses more on the image pairs of geometric matchability than on those of semantic similarity, a nuance that most existing deep learning-based methods guided by batched binaries (overlapping vs. non-overlapping pairs) fail to capture. In this paper, we introduce SupScene, a novel solution that learns global descriptors tailored for finding overlapping image pairs of similar geometric nature for SfM. First, to better underline co-visible regions, we employ a subgraph-based training strategy that moves beyond equally important isolated pairs, leveraging ground-truth geometric overlapping relationships with various weights to provide fine-grained supervision via a soft supervised contrastive loss. Second, we introduce DiVLAD, a DINO-inspired VLAD aggregator that leverages the inherent multi-head attention maps from the last block of ViT. And then, a learnable gating mechanism is designed to adaptively utilize these semantically salient cues with visual features, enabling a more discriminative global descriptor. Extensive experiments on the GL3D dataset demonstrate that our method achieves state-of-the-art performance, significantly outperforming NetVLAD while introducing a negligible number of additional trainable parameters. Furthermore, we show that the proposed training strategy brings consistent gains across different aggregation techniques. Code and models are available at https://anonymous.4open.science/r/SupScene-5B73.

</details>


### [45] [Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition](https://arxiv.org/abs/2601.11931)
*Zhengxian Wu,Chuanrui Zhang,Shenao Jiang,Hangrui Xu,Zirui Liao,Luyuan Zhang,Huaqiu Li,Peng Jiao,Haoqian Wang*

Main category: cs.CV

TL;DR: LMGait框架使用语言引导和运动感知进行步态识别，通过设计步态相关语言提示来捕捉关键运动特征，解决现有方法过度拟合静态噪声的问题


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法通常依赖复杂架构直接从图像提取特征，并通过池化操作获得序列级表示。这种设计容易过度拟合静态噪声（如衣物），同时无法有效捕捉动态运动区域

Method: 提出语言引导和运动感知的步态识别框架LMGait，利用设计的步态相关语言提示来捕捉步态序列中的关键运动特征

Result: 从摘要中无法获取具体实验结果，但该方法旨在解决现有方法的局限性

Conclusion: LMGait框架通过语言引导和运动感知的方法，有望改善步态识别中对动态运动特征的捕捉能力，减少对静态噪声的过度拟合

Abstract: Gait recognition is emerging as a promising technology and an innovative field within computer vision. However, existing methods typically rely on complex architectures to directly extract features from images and apply pooling operations to obtain sequence-level representations. Such designs often lead to overfitting on static noise (e.g., clothing), while failing to effectively capture dynamic motion regions.To address the above challenges, we present a Language guided and Motion-aware gait recognition framework, named LMGait.In particular, we utilize designed gait-related language cues to capture key motion features in gait sequences.

</details>


### [46] [Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal](https://arxiv.org/abs/2601.11952)
*Haonan An,Guang Hua,Wei Du,Hangcheng Cao,Yihang Tao,Guowen Xu,Susanto Rahardja,Yuguang Fang*

Main category: cs.CV

TL;DR: 提出Decoder Gradient Shields (DGS)防御机制，保护无盒模型水印的解码器免受基于梯度泄露查询的攻击。


<details>
  <summary>Details</summary>
Motivation: 现有无盒模型水印研究主要关注编码器的鲁棒性，而解码器被忽视，导致水印容易受到攻击。本文识别了一种针对解码器的攻击，攻击者利用查询响应获取反向传播梯度来训练水印移除器。

Method: 提出Decoder Gradient Shields (DGS)防御机制家族，包括输出层DGS-O、输入层DGS-I和层间DGS-L。DGS-O有闭式解，所有DGS都有可证明的性能。通过重新定向和重新缩放来自水印通道梯度泄露查询的梯度，防止水印移除器达到训练收敛。

Result: 在去雨和图像生成任务中，使用最先进的无盒水印技术进行实验，DGS在所有设置下实现了100%的防御成功率，同时保持解码器输出的图像质量。

Conclusion: DGS机制有效保护无盒模型水印的解码器免受基于梯度泄露的攻击，填补了现有水印保护研究中对解码器安全性的空白。

Abstract: Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.

</details>


### [47] [Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms](https://arxiv.org/abs/2601.11970)
*S. M. Khalid Bin Zahid,Md. Rakibul Hasan Nishat,Abdul Hasib,Md. Rakibul Hasan,Md. Ashiqussalehin,Md. Sahadat Hossen Sajib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 提出了一种用于树莓派5边缘平台的实时多模态视觉框架，集成了目标检测、人脸识别和情感检测，通过自适应调度机制将计算负载降低65%。


<details>
  <summary>Details</summary>
Motivation: 现有智能监控系统通常独立处理感知任务（如目标检测、人脸识别、情感分析），缺乏统一的、自适应的运行时调度器来根据上下文触发动态分配计算资源，这限制了它们在低功耗边缘设备上的整体理解能力和效率。

Method: 开发了一个实时多模态视觉框架，将目标检测（YOLOv8n）、所有者特定人脸识别（基于FaceNet的自定义嵌入系统）和情感检测（DeepFace的CNN）集成到统一流水线中。核心是自适应调度机制，通过选择性激活模块来减少计算负载。

Result: 目标检测模块平均精度（AP）达到0.861，人脸识别准确率为88%，情感检测对特定情绪的AUC高达0.97，系统以5.6帧/秒的速度运行，计算负载相比连续处理降低了65%。

Conclusion: 上下文感知调度是实现复杂多模态AI在成本效益边缘硬件上运行的关键，使智能感知更加可访问且保护隐私。

Abstract: Intelligent surveillance systems often handle perceptual tasks such as object detection, facial recognition, and emotion analysis independently, but they lack a unified, adaptive runtime scheduler that dynamically allocates computational resources based on contextual triggers. This limits their holistic understanding and efficiency on low-power edge devices. To address this, we present a real-time multi-modal vision framework that integrates object detection, owner-specific face recognition, and emotion detection into a unified pipeline deployed on a Raspberry Pi 5 edge platform. The core of our system is an adaptive scheduling mechanism that reduces computational load by 65\% compared to continuous processing by selectively activating modules such as, YOLOv8n for object detection, a custom FaceNet-based embedding system for facial recognition, and DeepFace's CNN for emotion classification. Experimental results demonstrate the system's efficacy, with the object detection module achieving an Average Precision (AP) of 0.861, facial recognition attaining 88\% accuracy, and emotion detection showing strong discriminatory power (AUC up to 0.97 for specific emotions), while operating at 5.6 frames per second. Our work demonstrates that context-aware scheduling is the key to unlocking complex multi-modal AI on cost-effective edge hardware, making intelligent perception more accessible and privacy-preserving.

</details>


### [48] [AVIR: Adaptive Visual In-Document Retrieval for Efficient Multi-Page Document Question Answering](https://arxiv.org/abs/2601.11976)
*Zongmin Li,Yachuan Li,Lei Kang,Dimosthenis Karatzas,Wenkang Ma*

Main category: cs.CV

TL;DR: AVIR框架通过自适应视觉文档内检索，显著减少多页文档视觉问答所需的页面数量，在保持高性能的同时大幅降低计算成本


<details>
  <summary>Details</summary>
Motivation: 多页文档视觉问答面临两个主要挑战：长文档消耗大量计算资源，同时削弱大型视觉语言模型中注意力机制的有效性。现有方法在处理长文档时效率低下且成本高昂。

Method: 提出自适应视觉文档内检索(AVIR)框架：1) 使用轻量级检索模型对每页进行问题相关性评分；2) 根据评分分布进行页面聚类，自适应选择相关内容；3) 对聚类页面进行Top-K筛选保持上下文紧凑；4) 对短文档使用相关性概率阈值选择页面；5) 仅将选中的页面输入冻结的大型视觉语言模型生成答案，无需微调。

Result: 在MP-DocVQA数据集上，AVIR将问答所需的平均页面数量减少70%，同时达到84.58%的ANLS分数，超越先前方法且计算成本显著降低。在SlideVQA和DUDE基准测试中也验证了有效性。

Conclusion: AVIR框架通过自适应检索机制有效解决了多页文档视觉问答中的计算效率和注意力机制问题，在保持高性能的同时大幅降低了计算需求，为长文档处理提供了高效解决方案。

Abstract: Multi-page Document Visual Question Answering (MP-DocVQA) remains challenging because long documents not only strain computational resources but also reduce the effectiveness of the attention mechanism in large vision-language models (LVLMs). We tackle these issues with an Adaptive Visual In-document Retrieval (AVIR) framework. A lightweight retrieval model first scores each page for question relevance. Pages are then clustered according to the score distribution to adaptively select relevant content. The clustered pages are screened again by Top-K to keep the context compact. However, for short documents, clustering reliability decreases, so we use a relevance probability threshold to select pages. The selected pages alone are fed to a frozen LVLM for answer generation, eliminating the need for model fine-tuning. The proposed AVIR framework reduces the average page count required for question answering by 70%, while achieving an ANLS of 84.58% on the MP-DocVQA dataset-surpassing previous methods with significantly lower computational cost. The effectiveness of the proposed AVIR is also verified on the SlideVQA and DUDE benchmarks. The code is available at https://github.com/Li-yachuan/AVIR.

</details>


### [49] [Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection](https://arxiv.org/abs/2601.11981)
*Jian Lang,Rongpei Hong,Ting Zhong,Yong Wang,Fan Zhou*

Main category: cs.CV

TL;DR: RADAR：首个支持测试时自适应检测未见新闻视频的假新闻视频检测框架，通过检索引导的适应范式解决新兴事件和未见主题的检测问题。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻视频检测方法通常假设训练和测试阶段新闻主题分布一致，无法检测与新兴事件和未见主题相关的假新闻视频。需要开发能够适应未见新闻视频的测试时自适应框架。

Method: 提出RADAR框架，采用检索引导的适应范式：1）基于熵选择的检索机制，为目标域提供稳定（低熵）、相关的参考视频；2）稳定锚点引导的对齐模块，通过分布级匹配将不稳定实例表示与源域对齐；3）目标域感知的自训练范式，生成由稳定参考增强的信息性伪标签。

Result: 大量实验表明，RADAR在测试时假新闻视频检测方面实现了卓越性能，能够对未见假新闻视频主题进行强大的实时适应。

Conclusion: RADAR是首个支持测试时自适应检测未见新闻视频的框架，通过创新的检索引导适应范式有效解决了新兴事件和未见主题的假新闻视频检测挑战。

Abstract: Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.

</details>


### [50] [An AI-IoT Based Smart Wheelchair with Gesture-Controlled Mobility, Deep Learning-Based Obstacle Detection, Multi-Sensor Health Monitoring, and Emergency Alert System](https://arxiv.org/abs/2601.11983)
*Md. Asiful Islam,Abdul Hasib,Tousif Mahmud Emon,Khandaker Tabin Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 基于AI-IoT的智能轮椅系统，集成手势控制、实时物体检测和健康监测，提供低成本、多模态的辅助解决方案


<details>
  <summary>Details</summary>
Motivation: 传统轮椅缺乏动态功能，现有智能轮椅成本高、功能单一且健康监测集成不足，需要为残障人士和老年人提供先进、个性化且负担得起的辅助技术

Method: 提出综合AI-IoT智能轮椅系统：1) 基于手套的手势控制实现免手导航；2) YOLOv8实时物体检测配合听觉反馈避障；3) 超声波传感器实现即时碰撞避免；4) 持续监测心率、血氧、心电图、体温等生命体征，上传至ThingSpeak平台并触发邮件警报

Result: 手势控制成功率95.5%，超声波障碍检测准确率94%，YOLOv8物体检测精度91.5%、召回率90.2%、F1分数90.8%。系统基于模块化低成本架构，提供实用、可扩展的解决方案

Conclusion: 这种集成多模态方法弥合了创新研究与实际部署之间的差距，显著增强用户自主性、安全性和独立性，为辅助技术提供了实用、可扩展且经济实惠的解决方案

Abstract: The growing number of differently-abled and elderly individuals demands affordable, intelligent wheelchairs that combine safe navigation with health monitoring. Traditional wheelchairs lack dynamic features, and many smart alternatives remain costly, single-modality, and limited in health integration. Motivated by the pressing demand for advanced, personalized, and affordable assistive technologies, we propose a comprehensive AI-IoT based smart wheelchair system that incorporates glove-based gesture control for hands-free navigation, real-time object detection using YOLOv8 with auditory feedback for obstacle avoidance, and ultrasonic for immediate collision avoidance. Vital signs (heart rate, SpO$_2$, ECG, temperature) are continuously monitored, uploaded to ThingSpeak, and trigger email alerts for critical conditions. Built on a modular and low-cost architecture, the gesture control achieved a 95.5\% success rate, ultrasonic obstacle detection reached 94\% accuracy, and YOLOv8-based object detection delivered 91.5\% Precision, 90.2\% Recall, and a 90.8\% F1-score. This integrated, multi-modal approach offers a practical, scalable, and affordable solution, significantly enhancing user autonomy, safety, and independence by bridging the gap between innovative research and real-world deployment.

</details>


### [51] [SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture](https://arxiv.org/abs/2601.12015)
*Pavan Kumar Yata,Pediredla Pradeep,Goli Himanish,Swathi M*

Main category: cs.CV

TL;DR: 提出DeepSegFusion混合深度学习模型，用于SAR图像中的溢油分割，显著降低误报率并提高边界精度


<details>
  <summary>Details</summary>
Motivation: 传统阈值方法在卫星图像溢油检测中因风滑、船迹等相似现象导致高误报率，需要更精确的检测方法

Method: 结合SegNet和DeepLabV3+的混合深度学习模型，集成基于注意力的特征融合机制，提升边界精度和上下文理解

Result: 在SAR溢油数据集上达到94.85%准确率、0.5685 IoU和0.9330 ROC-AUC，误检率比基线模型降低64.4%，减少三倍以上误检

Conclusion: DeepSegFusion在各种海洋条件下表现稳定，可用于近实时溢油监测，显著优于传统方法和单一基线模型

Abstract: Detection of oil spills from satellite images is essential for both environmental surveillance and maritime safety. Traditional threshold-based methods frequently encounter performance degradation due to very high false alarm rates caused by look-alike phenomena such as wind slicks and ship wakes. Here, a hybrid deep learning model, DeepSegFusion, is presented for oil spill segmentation in Synthetic Aperture Radar (SAR) images. The model uses SegNet and DeepLabV3+ integrated with an attention-based feature fusion mechanism to achieve better boundary precision as well as improved contextual understanding. Results obtained on SAR oil spill datasets, including ALOS PALSAR imagery, confirm that the proposed DeepSegFusion model achieves an accuracy of 94.85%, an Intersection over Union (IoU) of 0.5685, and a ROC-AUC score of 0.9330. The proposed method delivers more than three times fewer false detections compared to individual baseline models and traditional non-segmentation methods, achieving a reduction of 64.4%. These results indicate that DeepSegFusion is a stable model under various marine conditions and can therefore be used in near real-time oil spill monitoring scenarios.

</details>


### [52] [DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering](https://arxiv.org/abs/2601.12020)
*Guillermo Figueroa-Araneda,Iris Diana Jimenez,Florian Hofherr,Manny Ko,Hector Andrade-Loarca,Daniel Cremers*

Main category: cs.CV

TL;DR: DIAMOND-SSS：一种数据高效的框架，用于从极稀疏监督（少至10张图像）实现高保真半透明重建，通过扩散模型生成新视角和重光照，减少真实采集需求达90%


<details>
  <summary>Details</summary>
Motivation: 解决神经渲染中半透明材质（如蜡、玉石、大理石、皮肤）建模的挑战，这些材质需要复杂的次表面散射光传输，传统方法需要密集的多视角多光照数据集（通常超过100个视角和112个OLAT），数据采集成本高昂

Method: 1. 微调扩散模型用于新视角合成和重光照，基于估计的几何条件，在不到7%的数据集上训练；2. 引入光照无关的几何先验：多视角轮廓一致性损失和多视角深度一致性损失，以稳定稀疏或合成监督下的重建；3. 使用高斯渲染进行可重光照的渲染

Result: DIAMOND-SSS在所有稀疏度下都达到了最先进的质量，能够生成逼真的增强数据替代高达95%的缺失采集，相比SSS-3DGS减少了90%的真实采集需求

Conclusion: DIAMOND-SSS框架显著降低了半透明材质重建的数据需求，通过扩散模型生成和几何先验实现了从极稀疏监督（少至10张图像）的高质量可重光照重建，为数据高效的神经渲染提供了有效解决方案

Abstract: Subsurface scattering (SSS) gives translucent materials -- such as wax, jade, marble, and skin -- their characteristic soft shadows, color bleeding, and diffuse glow. Modeling these effects in neural rendering remains challenging due to complex light transport and the need for densely captured multi-view, multi-light datasets (often more than 100 views and 112 OLATs).
  We present DIAMOND-SSS, a data-efficient framework for high-fidelity translucent reconstruction from extremely sparse supervision -- even as few as ten images. We fine-tune diffusion models for novel-view synthesis and relighting, conditioned on estimated geometry and trained on less than 7 percent of the dataset, producing photorealistic augmentations that can replace up to 95 percent of missing captures. To stabilize reconstruction under sparse or synthetic supervision, we introduce illumination-independent geometric priors: a multi-view silhouette consistency loss and a multi-view depth consistency loss.
  Across all sparsity regimes, DIAMOND-SSS achieves state-of-the-art quality in relightable Gaussian rendering, reducing real capture requirements by up to 90 percent compared to SSS-3DGS.

</details>


### [53] [\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions](https://arxiv.org/abs/2601.12049)
*Chenchen Zhao,Muxi Chen,Qiang Xu*

Main category: cs.CV

TL;DR: FocaLogic：一种基于逻辑表示的可解释性框架，用于解释和量化视觉模型决策，通过识别关键视觉区域并转化为逻辑表达式，提供系统化、可扩展的定量分析。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模型可解释性方法存在两大局限：要么依赖白盒模型访问权限，要么缺乏足够的定量严谨性。在高风险应用中，模型可解释性至关重要，需要克服这些限制。

Method: 提出FocaLogic框架，这是一种模型无关的方法。它识别对模型预测有决定性影响的最小可解释视觉区域子集（称为"视觉焦点"），并将这些视觉焦点转化为精确紧凑的逻辑表达式。同时提出一套定量评估指标，包括焦点精度、召回率和分歧度。

Result: 实证分析表明FocaLogic能够揭示关键洞察：训练引起的注意力集中、通过泛化提高焦点准确性，以及在偏见和对抗攻击下的异常焦点。该框架提供了系统化、可扩展的定量解决方案。

Conclusion: FocaLogic为解释视觉模型提供了一个系统化、可扩展且定量的解决方案，通过逻辑表示实现透明结构化解释，并能够客观评估模型在不同场景下的行为。

Abstract: Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.

</details>


### [54] [A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models](https://arxiv.org/abs/2601.12051)
*Weixin Ye,Wei Wang,Yahui Liu,Yue Song,Bin Ren,Wei Bi,Rita Cucchiara,Nicu Sebe*

Main category: cs.CV

TL;DR: 提出MJP框架，通过随机打乱token顺序并使用可学习的未知位置嵌入来掩盖位置信息，增强Transformer在联邦学习中的安全性和性能


<details>
  <summary>Details</summary>
Motivation: 联邦学习中Transformer面临梯度攻击威胁，研究发现位置嵌入的梯度包含足够信息可用于重构输入数据，需要解决这一安全隐患

Method: 提出Masked Jigsaw Puzzle框架：1) 随机打乱token顺序破坏token顺序；2) 使用可学习的未知位置嵌入掩盖打乱token的位置信息，破坏局部空间信息编码

Result: MJP不仅能提高模型对梯度攻击的鲁棒性，还能提升在图像分类和文本情感分析等任务上的性能，是适用于视觉和语言任务的统一框架

Conclusion: MJP通过破坏位置嵌入中的局部空间信息，使模型学习更少依赖局部空间信息的特征表示，有效平衡了安全性和性能需求

Abstract: In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via https://github.com/ywxsuperstar/transformerattack

</details>


### [55] [Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation](https://arxiv.org/abs/2601.12052)
*Zaiyan Zhang,Jie Li,Shaowei Shi,Qiangqiang Yuan*

Main category: cs.CV

TL;DR: TDP-CR是一个任务驱动的多模态云去除框架，通过可学习的退化提示编码云层厚度和空间不确定性，结合SAR数据自适应修复光学遥感图像，同时进行云去除和土地覆盖分割，在参数效率和性能上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有云去除方法主要优化低层保真度，容易过度平滑纹理和边界，导致视觉上合理的修复与语义实用性之间存在不匹配。光学遥感图像受云遮挡限制，需要既能有效去除云层又能保持分析就绪数据（ARD）语义信息的方法。

Method: 提出TDP-CR框架，核心是提示引导融合（PGF）机制，使用可学习的退化提示编码云层厚度和空间不确定性。通过结合全局通道上下文和局部提示条件空间偏置，自适应地仅在光学数据损坏处融合SAR信息。采用参数高效的两阶段训练策略，解耦重建和语义表示学习。

Result: 在LuojiaSET-OSFCR数据集上，TDP-CR在PSNR上超过最先进基线0.18 dB，仅使用15%的参数；在多任务竞争者中mIoU持续提升1.4%，有效提供分析就绪数据。

Conclusion: TDP-CR通过任务驱动的多模态框架成功解决了云去除中视觉保真度与语义实用性之间的不匹配问题，提出的PGF机制和两阶段训练策略在参数效率和性能上均有显著优势，为遥感图像分析提供了有效的分析就绪数据解决方案。

Abstract: Optical remote sensing imagery is indispensable for Earth observation, yet persistent cloud occlusion limits its downstream utility. Most cloud removal (CR) methods are optimized for low-level fidelity and can over-smooth textures and boundaries that are critical for analysis-ready data (ARD), leading to a mismatch between visually plausible restoration and semantic utility. To bridge this gap, we propose TDP-CR, a task-driven multimodal framework that jointly performs cloud removal and land-cover segmentation. Central to our approach is a Prompt-Guided Fusion (PGF) mechanism, which utilizes a learnable degradation prompt to encode cloud thickness and spatial uncertainty. By combining global channel context with local prompt-conditioned spatial bias, PGF adaptively integrates Synthetic Aperture Radar (SAR) information only where optical data is corrupted. We further introduce a parameter-efficient two-phase training strategy that decouples reconstruction and semantic representation learning. Experiments on the LuojiaSET-OSFCR dataset demonstrate the superiority of our framework: TDP-CR surpasses heavy state-of-the-art baselines by 0.18 dB in PSNR while using only 15\% of the parameters, and achieves a 1.4\% improvement in mIoU consistently against multi-task competitors, effectively delivering analysis-ready data.

</details>


### [56] [Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation](https://arxiv.org/abs/2601.12066)
*Zijie Lou,Xiangwei Feng,Jiaxin Wang,Xiaochao Qu,Luoqi Liu,Ting Liu*

Main category: cs.CV

TL;DR: 提出基于随机桥模型的视频对象移除方法，将任务重新定义为视频到视频的转换，利用源视频作为结构先验，通过自适应掩码调制平衡背景保真度和生成灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频对象移除方法从高斯噪声开始生成，丢弃了原始视频丰富的结构和上下文先验，导致对象擦除不完整或生成内容与场景物理逻辑冲突。

Method: 将视频对象移除重新定义为通过随机桥模型实现的视频到视频转换任务，建立从源视频（含对象）到目标视频（对象移除）的直接随机路径；提出自适应掩码调制策略，根据掩码特征动态调节输入嵌入，平衡背景保真度和生成灵活性。

Result: 大量实验表明，该方法在视觉质量和时间一致性方面显著优于现有方法。

Conclusion: 通过桥式建模框架和自适应掩码调制，能够有效利用输入视频的结构先验，实现精确的对象移除，同时确保填充区域与周围环境逻辑一致。

Abstract: Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency.

</details>


### [57] [CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation](https://arxiv.org/abs/2601.12076)
*H. Jiang,Y. Sun,Z. Dong,T. Liu,Y. Gu*

Main category: cs.CV

TL;DR: 本文针对遥感视频指代对象分割（RS-RVOS）问题，构建了首个大规模基准数据集RS-RVOS Bench，并提出了基于记忆质量控制的在线分割框架MQC-SAM，通过初始记忆校准和动态质量评估解决目标显著性弱、视觉信息截断等问题。


<details>
  <summary>Details</summary>
Motivation: RS-RVOS面临目标显著性弱、动态场景中视觉信息截断严重等挑战，难以在分割过程中保持判别性目标表示。该领域进展受限于缺乏大规模专用基准数据集，现有模型存在初始记忆构建偏差影响复杂场景中的实例定位，以及无差别记忆积累导致遮挡或误分类噪声编码和持续错误传播等问题。

Method: 提出双贡献：1）构建RS-RVOS Bench基准数据集，包含111个视频序列、约25,000帧和213,000个时序指代标注，采用严格的因果感知标注策略；2）提出记忆质量感知的在线指代分割框架MQC-SAM，包含时间运动一致性模块进行初始记忆校准，利用短期运动轨迹先验校正结构偏差并建立准确记忆锚定，以及解耦注意力记忆集成机制配合动态质量评估，选择性更新高置信度语义特征并过滤不可靠信息。

Result: 在RS-RVOS Bench上的大量实验表明，MQC-SAM实现了最先进的性能。

Conclusion: 本文通过构建首个大规模RS-RVOS基准数据集和提出记忆质量控制的在线分割框架，有效解决了遥感视频指代对象分割中的关键挑战，包括初始记忆偏差、错误传播等问题，为领域研究提供了重要数据和方法基础。

Abstract: Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.

</details>


### [58] [Toward Real-World High-Precision Image Matting and Segmentation](https://arxiv.org/abs/2601.12080)
*Haipeng Zhou,Zhaohu Xing,Hongqiu Wang,Jun Ma,Ping Li,Lei Zhu*

Main category: cs.CV

TL;DR: FCLM模型通过深度感知蒸馏、域不变学习和面向对象解码器，解决高精度场景解析中的前景一致性学习问题，在图像抠图和二分分割任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有高精度场景解析方法主要关注显著单前景对象，交互式方法类别不可知限制了跨类别泛化，高质量标注稀缺导致依赖不和谐的合成数据，对真实场景泛化能力差。

Method: 提出前景一致性学习模型FCLM：1) 深度感知蒸馏策略，转移深度相关知识以改善前景表示；2) 将合成数据处理视为域适应问题，提出域不变学习策略专注于前景学习；3) 面向对象解码器，可接收视觉和语言提示来预测参考目标。

Result: 实验结果表明，该方法在定量和定性评估上均优于最先进的方法。

Conclusion: FCLM通过深度感知蒸馏、域不变学习和面向对象解码器，有效解决了高精度场景解析中的前景一致性学习问题，提升了跨类别泛化和真实场景适应性。

Abstract: High-precision scene parsing tasks, including image matting and dichotomous segmentation, aim to accurately predict masks with extremely fine details (such as hair). Most existing methods focus on salient, single foreground objects. While interactive methods allow for target adjustment, their class-agnostic design restricts generalization across different categories. Furthermore, the scarcity of high-quality annotation has led to a reliance on inharmonious synthetic data, resulting in poor generalization to real-world scenarios. To this end, we propose a Foreground Consistent Learning model, dubbed as FCLM, to address the aforementioned issues. Specifically, we first introduce a Depth-Aware Distillation strategy where we transfer the depth-related knowledge for better foreground representation. Considering the data dilemma, we term the processing of synthetic data as domain adaptation problem where we propose a domain-invariant learning strategy to focus on foreground learning. To support interactive prediction, we contribute an Object-Oriented Decoder that can receive both visual and language prompts to predict the referring target. Experimental results show that our method quantitatively and qualitatively outperforms SOTA methods.

</details>


### [59] [Conditional Random Fields for Interactive Refinement of Histopathological Predictions](https://arxiv.org/abs/2601.12082)
*Tiffanie Godelaine,Maxime Zanella,Karim El Khoury,Saïd Mahmoudi,Benoît Macq,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 提出HistoCRF框架，通过条件随机场（CRF）改进组织病理学图像分析中视觉语言模型（VLM）的零样本预测，无需额外训练，利用标注信息提升分类准确性。


<details>
  <summary>Details</summary>
Motivation: 组织病理学图像分析对癌症检测和分期具有重要临床价值。虽然视觉语言模型（VLMs）在零样本预测中表现良好但仍不完美，需要改进预测准确性。

Method: 提出HistoCRF框架，将条件随机场（CRF）适配于组织病理学应用，设计新颖的成对势函数以促进标签多样性并利用专家标注。考虑三种实验设置：无标注、有专家标注、以及迭代式人机协同标注。

Result: 在五个涵盖不同器官和疾病的patch级分类数据集上，相比零样本预测，平均准确率提升：无标注时16.0%，仅100个标注时27.5%。人机协同标注进一步达到32.6%的增益。

Conclusion: HistoCRF能有效改进组织病理学VLM的零样本预测，无需额外训练，通过CRF框架和标注信息显著提升分类性能，人机协同方法效果更佳。

Abstract: Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.

</details>


### [60] [CARLA-Round: A Multi-Factor Simulation Dataset for Roundabout Trajectory Prediction](https://arxiv.org/abs/2601.12119)
*Xiaotong Zhou,Zhenhui Yuan,Yi Han,Tianhua Xu,Laurence T. Yang*

Main category: cs.CV

TL;DR: CARLA-Round是一个系统设计的仿真数据集，用于环岛场景的车辆轨迹预测，通过控制天气条件和交通密度创建25个结构化场景，量化了不同因素对预测性能的影响。


<details>
  <summary>Details</summary>
Motivation: 环岛场景的车辆轨迹预测对减少交通事故至关重要，但由于其圆形几何结构、连续的汇入和让行交互以及缺乏交通信号而极具挑战性。现有数据集稀缺，真实世界数据收集存在观测不完整和混杂因素难以分离的问题。

Method: 使用CARLA仿真平台系统设计数据集，结构化控制天气条件（5种类型）和交通密度水平（服务水平A-E级），创建25个可控场景。每个场景包含真实的驾驶行为混合，并提供现有数据集缺乏的显式标注。

Result: 验证实验使用标准基线模型（LSTM、GCN、GRU+GCN）显示：交通密度对预测难度具有主导性的单调效应，而天气条件呈现非线性影响。最佳模型在真实世界rounD数据集上达到0.312m ADE，实现了有效的仿真到真实迁移。

Conclusion: CARLA-Round数据集通过结构化设计实现了对环岛轨迹预测中不同因素影响的精确量化，解决了真实世界数据中混杂因素难以分离的问题，为环岛场景的轨迹预测研究提供了有价值的基准数据集。

Abstract: Accurate trajectory prediction of vehicles at roundabouts is critical for reducing traffic accidents, yet it remains highly challenging due to their circular road geometry, continuous merging and yielding interactions, and absence of traffic signals. Developing accurate prediction algorithms relies on reliable, multimodal, and realistic datasets; however, such datasets for roundabout scenarios are scarce, as real-world data collection is often limited by incomplete observations and entangled factors that are difficult to isolate. We present CARLA-Round, a systematically designed simulation dataset for roundabout trajectory prediction. The dataset varies weather conditions (five types) and traffic density levels (spanning Level-of-Service A-E) in a structured manner, resulting in 25 controlled scenarios. Each scenario incorporates realistic mixtures of driving behaviors and provides explicit annotations that are largely absent from existing datasets. Unlike randomly sampled simulation data, this structured design enables precise analysis of how different conditions influence trajectory prediction performance. Validation experiments using standard baselines (LSTM, GCN, GRU+GCN) reveal traffic density dominates prediction difficulty with strong monotonic effects, while weather shows non-linear impacts. The best model achieves 0.312m ADE on real-world rounD dataset, demonstrating effective sim-to-real transfer. This systematic approach quantifies factor impacts impossible to isolate in confounded real-world datasets. Our CARLA-Round dataset is available at https://github.com/Rebecca689/CARLA-Round.

</details>


### [61] [Segment and Matte Anything in a Unified Model](https://arxiv.org/abs/2601.12147)
*Zezhong Fan,Xiaohan Li,Topojoy Biswas,Kaushiki Nag,Kannan Achan*

Main category: cs.CV

TL;DR: SAMA是一个轻量级扩展的SAM模型，能够在统一框架中同时实现高质量的交互式图像分割和抠图，通过MVLE编码器和Local-Adapter提升边界细节，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM在零样本泛化和灵活提示方面表现出色，但其掩码预测精度在实际应用中仍显不足。现有细化模块难以在统一框架中实现高精度对象分割，且交互式图像抠图在SAM背景下尚未探索。研究表明分割与抠图之间存在强相关性，这为统一模型提供了可行性。

Method: 提出SAMA作为SAM的轻量级扩展，包含：1) Multi-View Localization Encoder (MVLE)从局部视图捕获详细特征；2) Localization Adapter (Local-Adapter)通过恢复细微边界细节来细化掩码输出；3) 为每个任务集成两个预测头，同时生成分割和抠图掩码。模型在公开数据集上训练。

Result: SAMA在多个分割和抠图基准测试中达到了最先进的性能，展示了其在广泛下游任务中的适应性和有效性。模型仅需少量额外参数即可实现高质量的分割和抠图结果。

Conclusion: SAMA成功地将分割和抠图任务统一到一个轻量级框架中，通过MVLE和Local-Adapter有效提升了边界细节恢复能力，为实际应用提供了高精度的分割和抠图解决方案。

Abstract: Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.

</details>


### [62] [Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models](https://arxiv.org/abs/2601.12150)
*Mengxuan Hu,Zihan Guan,John Kang,Sheng Li,Zhongliang Zhou*

Main category: cs.CV

TL;DR: 提出一种空间和时间高效的推理策略，通过空间感知的邻近块稀疏化注意力机制，并利用全局注意力分数过滤非信息性token，从而在保持甚至提升下游性能的同时，显著减少高分辨率全切片图像推理时的GPU内存和运行时间。


<details>
  <summary>Details</summary>
Motivation: 当前病理学基础模型通常受限于特定输入尺寸（如224×224），在处理跨越数千分辨率级别的全切片图像时效率低下。简单放大输入会导致GPU内存消耗过高，而降低采样会改变微米每像素分辨率并模糊关键形态细节。

Method: 提出空间和时间高效的推理策略：1）使用空间感知的邻近块稀疏化注意力机制；2）通过全局注意力分数过滤非信息性token。该设计在保持高分辨率推理的同时，显著减少GPU内存和运行时间。

Result: 实验结果显示，该方法在ROI分类任务上实现了高达7.67%的性能提升，在分割任务上获得兼容的结果。能够在相同GPU预算下实现更高分辨率的推理。

Conclusion: 该方法有效解决了病理学基础模型在处理全切片图像时的效率瓶颈，通过注意力稀疏化和token过滤策略，在保持甚至提升下游任务性能的同时，显著优化了计算资源使用。

Abstract: Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.

</details>


### [63] [VIRTUE: Versatile Video Retrieval Through Unified Embeddings](https://arxiv.org/abs/2601.12193)
*Shaunak Halbe,Bhagyashree Puranik,Jayakrishnan Unnikrishnan,Kushan Thakkar,Vimal Bhat,Toufiq Parag*

Main category: cs.CV

TL;DR: VIRTUE是一个基于多模态大语言模型的通用视频检索框架，集成语料库和时刻级检索能力，支持组合多模态查询，通过对比对齐和LoRA高效训练，在零样本视频检索、时刻检索和组合视频检索任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索系统存在局限性：专用架构虽然检索性能强，但无法处理组合多模态查询；而基于MLLM的方法支持丰富多模态搜索，但检索性能远低于专用系统。需要开发一个既能处理组合多模态查询，又能达到专用系统检索性能的通用视频检索框架。

Method: 使用共享MLLM主干生成视觉和文本嵌入，通过对比对齐促进高效的基于嵌入的候选搜索。采用低秩适应（LoRA）在70万对视觉-文本数据样本上进行高效训练。通过重排序进一步提升检索性能，无需额外训练即可适应零样本时刻检索。

Result: 在零样本视频检索任务上超越其他MLLM方法；零样本时刻检索达到竞争性结果；零样本组合视频检索达到最先进水平。通过重排序后，性能大幅超越现有MLLM检索系统，与在更大规模数据上训练的专用模型性能相当。

Conclusion: VIRTUE展示了MLLM在视频检索中的巨大潜力，通过单一架构实现了语料库检索、时刻定位和组合多模态查询的集成，在保持高效训练的同时达到了与专用系统相当的检索性能，为通用视频检索系统提供了有前景的解决方案。

Abstract: Modern video retrieval systems are expected to handle diverse tasks ranging from corpus-level retrieval and fine-grained moment localization to flexible multimodal querying. Specialized architectures achieve strong retrieval performance by training modality-specific encoders on massive datasets, but they lack the ability to process composed multimodal queries. In contrast, multimodal LLM (MLLM)-based methods support rich multimodal search but their retrieval performance remains well below that of specialized systems. We present VIRTUE, an MLLM-based versatile video retrieval framework that integrates corpus and moment-level retrieval capabilities while accommodating composed multimodal queries within a single architecture. We use contrastive alignment of visual and textual embeddings generated using a shared MLLM backbone to facilitate efficient embedding-based candidate search. Our embedding model, trained efficiently using low-rank adaptation (LoRA) on 700K paired visual-text data samples, surpasses other MLLM-based methods on zero-shot video retrieval tasks. Additionally, we demonstrate that the same model can be adapted without further training to achieve competitive results on zero-shot moment retrieval, and state of the art results for zero-shot composed video retrieval. With additional training for reranking candidates identified in the embedding-based search, our model substantially outperforms existing MLLM-based retrieval systems and achieves retrieval performance comparable to state of the art specialized models which are trained on orders of magnitude larger data.

</details>


### [64] [Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion](https://arxiv.org/abs/2601.12224)
*Meng Wei,Kun Yuan,Shi Li,Yue Zhou,Long Bai,Nassir Navab,Hongliang Ren,Hong Joo Lee,Tom Vercauteren,Nicolas Padoy*

Main category: cs.CV

TL;DR: SurgRef：一种基于运动引导的框架，通过跟踪手术器械的运动轨迹而非静态外观，实现自然语言描述对手术器械的精准分割，解决了遮挡、模糊和术语不熟悉等问题。


<details>
  <summary>Details</summary>
Motivation: 当前手术场景中的指代分割任务（根据自然语言描述定位手术器械）存在不足，现有方法依赖静态视觉特征和预定义器械名称，难以泛化到不同手术场景，特别是在遮挡、模糊或使用非标准术语时表现不佳。

Method: 提出SurgRef框架，核心思想是利用器械的运动轨迹而非外观特征进行语言接地。通过分析工具在时间维度上的移动和交互模式，实现对自由形式语言表达的理解和器械分割。同时构建了Ref-IMotion数据集，包含多机构手术视频、密集时空掩码和以运动为中心的语言描述。

Result: SurgRef在多种手术过程中实现了最先进的准确性和泛化能力，为鲁棒的语言驱动手术视频分割设立了新的基准。即使在器械被遮挡、描述模糊或使用不熟悉术语的情况下，仍能准确分割目标器械。

Conclusion: 通过将语言表达与器械运动模式而非静态视觉特征相结合，SurgRef框架显著提升了手术场景中语言驱动交互的鲁棒性和泛化能力，为智能手术室和自主手术机器人辅助系统的发展提供了重要技术基础。

Abstract: Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.

</details>


### [65] [DiffusionQC: Artifact Detection in Histopathology via Diffusion Model](https://arxiv.org/abs/2601.12233)
*Zhenzhen Wang,Zhongliang Zhou,Zhuoyu Wen,Jeong Hwan Kook,John B Wojcik,John Kang*

Main category: cs.CV

TL;DR: 提出DiffusionQC方法，仅需干净图像训练即可检测组织病理学图像中的伪影，无需像素级标注或预定义伪影类型


<details>
  <summary>Details</summary>
Motivation: 数字病理学图像常包含制备和数字化过程中引入的伪影，影响下游分析可靠性。传统监督方法需要大量标注数据且难以泛化到新伪影类型，资源消耗大且通用性差

Method: 基于扩散模型将伪影检测为干净图像中的异常值，仅需干净图像训练集。引入对比学习模块显式扩大伪影与干净图像分布差异，形成增强版本

Result: 实验结果显示性能优于现有最优方法，具有跨染色泛化能力，且所需数据和标注显著减少

Conclusion: DiffusionQC为数字病理学伪影检测提供了一种高效、泛化性强的无监督方法，仅需干净图像即可训练，解决了传统监督方法的标注负担和泛化限制问题

Abstract: Digital pathology plays a vital role across modern medicine, offering critical insights for disease diagnosis, prognosis, and treatment. However, histopathology images often contain artifacts introduced during slide preparation and digitization. Detecting and excluding them is essential to ensure reliable downstream analysis. Traditional supervised models typically require large annotated datasets, which is resource-intensive and not generalizable to novel artifact types. To address this, we propose DiffusionQC, which detects artifacts as outliers among clean images using a diffusion model. It requires only a set of clean images for training rather than pixel-level artifact annotations and predefined artifact types. Furthermore, we introduce a contrastive learning module to explicitly enlarge the distribution separation between artifact and clean images, yielding an enhanced version of our method. Empirical results demonstrate superior performance to state-of-the-art and offer cross-stain generalization capacity, with significantly less data and annotations.

</details>


### [66] [CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training](https://arxiv.org/abs/2601.12282)
*Pralaypati Ta,Sriram Venkatesaperumal,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: CytoCLIP：基于预训练CLIP框架的视觉-语言模型，用于学习大脑细胞构筑的联合视觉-文本表示，实现大脑区域自动识别


<details>
  <summary>Details</summary>
Motivation: 大脑不同区域的功能与其独特的细胞构筑密切相关，但手动在脑组织切片中描绘这些区域耗时且需要专业知识，需要自动化方法减少专家工作量

Method: 提出CytoCLIP套件，包含两种模型变体：1) 使用低分辨率全区域图像训练以理解区域整体细胞构筑模式；2) 使用高分辨率图像块训练以获得细胞级详细表示。训练数据来自不同孕周胎儿大脑的NISSL染色组织切片，包含86个区域（低分辨率）和384个区域（高分辨率）

Result: CytoCLIP在区域分类和跨模态检索任务中优于现有方法，全区域分类F1分数达0.87，高分辨率图像块分类F1分数达0.91，展示了良好的细胞构筑理解和泛化能力

Conclusion: CytoCLIP通过视觉-语言模型有效学习大脑细胞构筑的联合表示，为大脑区域自动识别提供了高效解决方案，减少了专家工作量并提高了分析效率

Abstract: The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, which is defined by the spatial arrangement and morphology of the cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.

</details>


### [67] [SDiT: Semantic Region-Adaptive for Diffusion Transformers](https://arxiv.org/abs/2601.12283)
*Bowen Lin,Fanjiang Ye,Yihua Liu,Zhenghui Guo,Boyuan Zhang,Weijian Zheng,Yufan Xu,Tiancheng Xing,Yuke Wang,Chengming Zhang*

Main category: cs.CV

TL;DR: SDiT：一种无需训练的语义区域自适应扩散Transformer，通过语义感知聚类、复杂度驱动区域调度和边界感知细化，在保持感知和语义质量的同时实现高达3.0倍加速


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer在文本到图像合成中达到最先进性能，但由于去噪过程的迭代性和全局注意力的二次计算成本，计算开销仍然很高。研究发现去噪动态在空间上不均匀：背景区域快速收敛，而边缘和纹理区域演化更活跃。

Method: 提出SDiT框架：1）通过快速Quickshift分割进行语义感知聚类；2）复杂度驱动区域调度，选择性更新信息丰富的区域；3）边界感知细化以保持空间连贯性。该框架无需模型重新训练或架构修改。

Result: SDiT在保持与全注意力推理几乎相同的感知和语义质量的同时，实现了高达3.0倍的加速。

Conclusion: 通过利用去噪动态的空间不均匀性，SDiT提供了一种高效且无需训练的加速方法，为扩散Transformer的实际应用提供了有前景的解决方案。

Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.

</details>


### [68] [LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines](https://arxiv.org/abs/2601.12285)
*Safa C. Medin,Gengyan Li,Ziqian Bai,Ruofei Du,Leonhard Helminger,Yinda Zhang,Stephan J. Garbin,Philip L. Davidson,Gregory W. Wornell,Thabo Beeler,Abhimitra Meka*

Main category: cs.CV

TL;DR: 提出一种基于参数化人脸模型锚定辐射场的新型3D人脸化身表示方法，实现可控的复杂面部特征体积渲染，支持在线流式传输并在传统图形平台上使用经典网格和着色器渲染。


<details>
  <summary>Details</summary>
Motivation: 现有3D人脸化身渲染方法通常需要复杂的定制工程和集成，难以在传统图形平台上高效部署。需要一种既能实现逼真渲染，又能在标准图形硬件上高效运行的表示方法。

Method: 基于参数化人脸模型锚定辐射场，学习3D空间中的辐射流形，提取显式分层网格以及外观和变形纹理。通过简单的线性混合和alpha合成在静态网格上控制动画。

Result: 实现了对复杂面部特征（头发、皮肤、眼睛）的可控体积渲染，生成的化身可以高效在线流式传输，并在传统图形平台上使用经典网格和着色器渲染，无需定制工程。

Conclusion: 该方法提供了一种高效、可控且易于部署的3D人脸化身表示方案，将先进的辐射场技术与传统图形渲染管线相结合，实现了逼真渲染与高效部署的平衡。

Abstract: We introduce a novel representation for efficient classical rendering of photorealistic 3D face avatars. Leveraging recent advances in radiance fields anchored to parametric face models, our approach achieves controllable volumetric rendering of complex facial features, including hair, skin, and eyes. At enrollment time, we learn a set of radiance manifolds in 3D space to extract an explicit layered mesh, along with appearance and warp textures. During deployment, this allows us to control and animate the face through simple linear blending and alpha compositing of textures over a static mesh. This explicit representation also enables the generated avatar to be efficiently streamed online and then rendered using classical mesh and shader-based rendering on legacy graphics platforms, eliminating the need for any custom engineering or integration.

</details>


### [69] [Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations](https://arxiv.org/abs/2601.12303)
*Shizhan Gong,Xiaofan Zhang,Qi Dou*

Main category: cs.CV

TL;DR: PCBM-ReD是一种后处理概念瓶颈模型，通过表示分解将可解释性注入预训练黑盒模型，自动提取视觉概念并用多模态大语言模型标注，在保持高性能的同时提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在图像识别中表现出色，但其不透明性阻碍了在关键领域的部署。现有基于概念的解释方法存在概念相关性不可靠、概念定义非视觉化或劳动密集、模型或数据无关假设等局限性，需要一种能平衡性能和可解释性的解决方案。

Method: PCBM-ReD通过三个步骤实现：1)从预训练编码器中自动提取视觉概念；2)使用多模态大语言模型基于视觉可识别性和任务相关性标注和筛选概念；3)通过重建引导的优化选择独立概念子集。利用CLIP的视觉-文本对齐，将图像表示分解为概念嵌入的线性组合，适配概念瓶颈模型框架。

Result: 在11个图像分类任务上的广泛实验表明，PCBM-ReD实现了最先进的准确率，缩小了与端到端模型的性能差距，并展现出更好的可解释性。

Conclusion: PCBM-ReD成功地将可解释性注入预训练黑盒模型，通过自动化的概念提取和筛选流程，在保持高性能的同时提供了人类可理解的概念解释，为关键领域部署深度学习模型提供了可行的解决方案。

Abstract: Deep learning has achieved remarkable success in image recognition, yet their inherent opacity poses challenges for deployment in critical domains. Concept-based interpretations aim to address this by explaining model reasoning through human-understandable concepts. However, existing post-hoc methods and ante-hoc concept bottleneck models (CBMs), suffer from limitations such as unreliable concept relevance, non-visual or labor-intensive concept definitions, and model or data-agnostic assumptions. This paper introduces Post-hoc Concept Bottleneck Model via Representation Decomposition (PCBM-ReD), a novel pipeline that retrofits interpretability onto pretrained opaque models. PCBM-ReD automatically extracts visual concepts from a pre-trained encoder, employs multimodal large language models (MLLMs) to label and filter concepts based on visual identifiability and task relevance, and selects an independent subset via reconstruction-guided optimization. Leveraging CLIP's visual-text alignment, it decomposes image representations into linear combination of concept embeddings to fit into the CBMs abstraction. Extensive experiments across 11 image classification tasks show PCBM-ReD achieves state-of-the-art accuracy, narrows the performance gap with end-to-end models, and exhibits better interpretability.

</details>


### [70] [A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models](https://arxiv.org/abs/2601.12304)
*Wutao Chen,Huaqin Zou,Chen Wan,Lifeng Huang*

Main category: cs.CV

TL;DR: 提出2S-GDA：一种两阶段全局多样性攻击框架，通过文本和视觉双重扰动增强对抗样本的多样性和攻击成功率


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言预训练模型对抗攻击方法存在扰动多样性有限和多阶段流程不稳定的问题，特别是在黑盒场景下攻击效果受限

Method: 采用两阶段全局多样性攻击框架：1) 文本扰动阶段通过候选文本扩展和全局感知替换实现全局多样性；2) 视觉扰动阶段使用多尺度调整和块状旋转增强视觉多样性

Result: 在VLP模型上实验表明，2S-GDA相比现有方法显著提升攻击成功率，黑盒设置下最高提升11.17%，且框架模块化易于与现有方法结合

Conclusion: 2S-GDA通过增强扰动多样性有效提升对抗攻击的转移性，为黑盒场景下的多模态对抗攻击提供了有效的解决方案

Abstract: Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The proposed method first introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17\% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.

</details>


### [71] [CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding](https://arxiv.org/abs/2601.12312)
*Yongjun Jeon,Jongmin Shin,Kanggil Park,Seonmin Park,Soyoung Lim,Jung Yong Kim,Jinsoo Rhu,Jongman Kim,Gyu-Seong Choi,Namkee Oh,Kyu-Hwan Jung*

Main category: cs.CV

TL;DR: 提出CurConMix+框架，结合课程引导对比学习与多分辨率时序Transformer，用于手术动作三元组识别，并在新数据集LLS48上验证性能


<details>
  <summary>Details</summary>
Motivation: 手术动作三元组识别对工作流分析和技能评估很重要，但面临类别不平衡、视觉变化细微、语义相互依赖等挑战，现有方法未能联合解决这些问题

Method: 基于CurConMix空间表示框架，采用课程引导对比学习策略，结合结构化难例采样和特征级混合；其时序扩展CurConMix+集成多分辨率时序Transformer，自适应融合多尺度时序特征并动态平衡时空线索

Result: 在CholecT45和LLS48数据集上，CurConMix+在动作三元组识别方面优于现有方法，并展现出强大的跨层级泛化能力，其细粒度特征可有效迁移到更高层级的阶段和步骤识别任务

Conclusion: 该框架和数据集为层次感知、可复现、可解释的手术工作流理解提供了统一基础，代码和数据集将在GitHub公开以促进可复现性和进一步研究

Abstract: Surgical action triplet recognition aims to understand fine-grained surgical behaviors by modeling the interactions among instruments, actions, and anatomical targets. Despite its clinical importance for workflow analysis and skill assessment, progress has been hindered by severe class imbalance, subtle visual variations, and the semantic interdependence among triplet components. Existing approaches often address only a subset of these challenges rather than tackling them jointly, which limits their ability to form a holistic understanding. This study builds upon CurConMix, a spatial representation framework. At its core, a curriculum-guided contrastive learning strategy learns discriminative and progressively correlated features, further enhanced by structured hard-pair sampling and feature-level mixup. Its temporal extension, CurConMix+, integrates a Multi-Resolution Temporal Transformer (MRTT) that achieves robust, context-aware understanding by adaptively fusing multi-scale temporal features and dynamically balancing spatio-temporal cues. Furthermore, we introduce LLS48, a new, hierarchically annotated benchmark for complex laparoscopic left lateral sectionectomy, providing step-, task-, and action-level annotations. Extensive experiments on CholecT45 and LLS48 demonstrate that CurConMix+ not only outperforms state-of-the-art approaches in triplet recognition, but also exhibits strong cross-level generalization, as its fine-grained features effectively transfer to higher-level phase and step recognition tasks. Together, the framework and dataset provide a unified foundation for hierarchy-aware, reproducible, and interpretable surgical workflow understanding. The code and dataset will be publicly released on GitHub to facilitate reproducibility and further research.

</details>


### [72] [S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection](https://arxiv.org/abs/2601.12313)
*Xiangyu Hu,Yicheng Hong,Hongchuang Zheng,Wenjun Zeng,Bingyao Liu*

Main category: cs.CV

TL;DR: S²F-Net：一种基于频谱差异的跨模型合成图像检测框架，通过可学习频率注意力模块增强判别性频带，在17类生成模型上实现90.49%的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展对具有强泛化能力的检测方案提出了迫切需求。现有检测方法通常过度拟合特定源模型，在面对未见过的生成架构时性能显著下降。

Method: 提出跨模型检测框架S²F-Net，核心在于探索和利用真实与合成纹理之间的固有频谱差异。引入可学习频率注意力模块，通过协同空间纹理分析和频谱依赖关系，自适应加权和增强判别性频带。

Result: 在包含17类生成模型的AIGCDetectBenchmark上，S²F-Net达到90.49%的检测准确率，在跨域检测场景中显著优于各种现有基线方法。

Conclusion: 通过关注上采样操作在频域留下的独特指纹，从根本层面提升模型泛化性能，为解决生成模型检测的泛化问题提供了有效方案。

Abstract: The rapid development of generative models has imposed an urgent demand for detection schemes with strong generalization capabilities. However, existing detection methods generally suffer from overfitting to specific source models, leading to significant performance degradation when confronted with unseen generative architectures. To address these challenges, this paper proposes a cross-model detection framework called S 2 F-Net, whose core lies in exploring and leveraging the inherent spectral discrepancies between real and synthetic textures. Considering that upsampling operations leave unique and distinguishable frequency fingerprints in both texture-poor and texture-rich regions, we focus our research on the detection of frequency-domain artifacts, aiming to fundamentally improve the generalization performance of the model. Specifically, we introduce a learnable frequency attention module that adaptively weights and enhances discriminative frequency bands by synergizing spatial texture analysis and spectral dependencies.On the AIGCDetectBenchmark, which includes 17 categories of generative models, S 2 F-Net achieves a detection accuracy of 90.49%, significantly outperforming various existing baseline methods in cross-domain detection scenarios.

</details>


### [73] [GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer](https://arxiv.org/abs/2601.12316)
*Xinyuan Zhao,Xianrui Chen,Ahmad Chaddad*

Main category: cs.CV

TL;DR: 提出了一种语义调制多尺度Transformer用于3D视线估计，通过原型库调节CLIP全局特征，融合多尺度特征，使用MoE增强条件容量，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视线估计方法在处理复杂场景变化（如光照、头部姿态、背景等）时存在局限性，需要更强大的语义理解和多尺度特征融合能力来提升估计精度。

Method: 1. 使用可学习的原型库（光照、头部姿态、背景、方向）调节CLIP全局特征；2. 在统一注意力空间中融合原型增强的全局向量、CLIP补丁token和高分辨率CNN token；3. 用路由/共享的混合专家（MoE）替换多个FFN块以增加条件容量。

Result: 在MPIIFaceGaze、EYEDIAP、Gaze360和ETH-XGaze数据集上分别达到2.49°、3.22°、10.16°和1.44°的角误差，相比先前结果相对提升最高达64%，创下新的SOTA。

Conclusion: 通过语义调制、多尺度融合和MoE架构的协同作用，显著提升了3D视线估计的精度和鲁棒性，消融实验证实了原型调节、跨尺度融合和MoE的有效性。

Abstract: We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github. com/AIPMLab/Gazeformer.

</details>


### [74] [EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation](https://arxiv.org/abs/2601.12326)
*Jing Zhang,Bingjie Fan*

Main category: cs.CV

TL;DR: EmoKGEdit：基于多模态情感关联知识图谱的无训练图像情感编辑框架，通过解耦情感与内容表示实现精确且结构保持的情感编辑


<details>
  <summary>Details</summary>
Motivation: 现有图像情感编辑方法难以从潜在内容表示中解耦情感线索，导致情感表达弱且视觉结构扭曲，需要开发能精确保持结构的情感编辑方法

Method: 构建多模态情感关联知识图谱（MSA-KG）来解耦对象、场景、属性、视觉线索和情感之间的复杂关系；设计解耦结构-情感编辑模块，在潜在空间中明确分离情感属性和布局特征

Result: EmoKGEdit在情感保真度和内容保持方面表现优异，超越了现有最先进方法，实现了精确且结构保持的图像情感编辑

Conclusion: 通过知识图谱驱动的解耦方法，EmoKGEdit有效解决了图像情感编辑中的情感-内容纠缠问题，为精确且结构保持的情感编辑提供了新范式

Abstract: Existing image emotion editing methods struggle to disentangle emotional cues from latent content representations, often yielding weak emotional expression and distorted visual structures. To bridge this gap, we propose EmoKGEdit, a novel training-free framework for precise and structure-preserving image emotion editing. Specifically, we construct a Multimodal Sentiment Association Knowledge Graph (MSA-KG) to disentangle the intricate relationships among objects, scenes, attributes, visual clues and emotion. MSA-KG explicitly encode the causal chain among object-attribute-emotion, and as external knowledge to support chain of thought reasoning, guiding the multimodal large model to infer plausible emotion-related visual cues and generate coherent instructions. In addition, based on MSA-KG, we design a disentangled structure-emotion editing module that explicitly separates emotional attributes from layout features within the latent space, which ensures that the target emotion is effectively injected while strictly maintaining visual spatial coherence. Extensive experiments demonstrate that EmoKGEdit achieves excellent performance in both emotion fidelity and content preservation, and outperforms the state-of-the-art methods.

</details>


### [75] [FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching](https://arxiv.org/abs/2601.12329)
*Mithlesh Singla,Seema Kumari,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 提出FlowIID，一种基于流匹配的轻量级本征图像分解方法，在保持性能的同时显著减少参数量，适合资源受限和实时应用


<details>
  <summary>Details</summary>
Motivation: 现有本征图像分解模型虽然效果好但参数量大，难以与其他模型结合在实际应用中部署，需要参数高效且性能良好的解决方案

Method: 提出FlowIID架构，基于潜在流匹配，结合VAE引导的潜在空间和流匹配模块，实现稳定的反照率和着色分解

Result: FlowIID不仅参数高效，还能单步推理产生结果，在多个基准测试中取得与现有模型相当甚至更优的性能

Conclusion: FlowIID是一种紧凑且高效的本征图像分解方法，特别适合资源受限和实时视觉应用部署

Abstract: Intrinsic Image Decomposition (IID) separates an image into albedo and shading components. It is a core step in many real-world applications, such as relighting and material editing. Existing IID models achieve good results, but often use a large number of parameters. This makes them costly to combine with other models in real-world settings. To address this problem, we propose a flow matching-based solution. For this, we design a novel architecture, FlowIID, based on latent flow matching. FlowIID combines a VAE-guided latent space with a flow matching module, enabling a stable decomposition of albedo and shading. FlowIID is not only parameter-efficient, but also produces results in a single inference step. Despite its compact design, FlowIID delivers competitive and superior results compared to existing models across various benchmarks. This makes it well-suited for deployment in resource-constrained and real-time vision applications.

</details>


### [76] [SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence](https://arxiv.org/abs/2601.12357)
*Hailing Jin,Huiying Li*

Main category: cs.CV

TL;DR: SimpleMatch：一个简单有效的语义对应框架，通过轻量级上采样解码器和多尺度监督损失，在低分辨率下实现高性能，同时减少51%的训练内存使用。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练大模型的语义对应方法依赖高分辨率输入以获得最佳性能，导致计算开销大。主要问题在于深度下采样操作会导致相邻关键点特征不可逆地融合，当语义不同的关键点落入同一降采样感受野时（如16x16块），这一问题尤为严重。

Method: 提出SimpleMatch框架：1）轻量级上采样解码器，将深层特征逐步上采样到1/4分辨率以恢复空间细节；2）多尺度监督损失，确保上采样特征在不同空间尺度上保持判别性特征；3）稀疏匹配和基于窗口的定位，优化训练内存使用。

Result: 在252x252分辨率（比当前SOTA方法小3.3倍）下，SimpleMatch在SPair-71k基准测试上达到84.1% PCK@0.1的优异性能，同时训练内存使用减少51%。

Conclusion: SimpleMatch为语义对应研究提供了一个实用且高效的基准框架，能够在低分辨率下实现强大性能，解决了当前方法对高分辨率输入的依赖问题。

Abstract: Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, a limitation of these approaches is their dependence on high-resolution input images to achieve optimal performance, which results in considerable computational overhead. In this work, we address a fundamental limitation in current methods: the irreversible fusion of adjacent keypoint features caused by deep downsampling operations. This issue is triggered when semantically distinct keypoints fall within the same downsampled receptive field (e.g., 16x16 patches). To address this issue, we present SimpleMatch, a simple yet effective framework for semantic correspondence that delivers strong performance even at low resolutions. We propose a lightweight upsample decoder that progressively recovers spatial detail by upsampling deep features to 1/4 resolution, and a multi-scale supervised loss that ensures the upsampled features retain discriminative features across different spatial scales. In addition, we introduce sparse matching and window-based localization to optimize training memory usage and reduce it by 51%. At a resolution of 252x252 (3.3x smaller than current SOTA methods), SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. We believe this framework provides a practical and efficient baseline for future research in semantic correspondence. Code is available at: https://github.com/hailong23-jin/SimpleMatch.

</details>


### [77] [DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data](https://arxiv.org/abs/2601.12366)
*Jiafei Zhang,Songliang Cao,Binghui Xu,Yanan Li,Weiwei Jia,Tingting Wu,Hao Lu,Weijuan Hu,Zhiguo Han*

Main category: cs.CV

TL;DR: DepthCropSeg++是一个用于作物分割的基础模型，能够在开放田间环境下分割不同作物物种，在多个挑战性场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前作物分割模型大多因像素级标注成本高昂而只能从有限数据中学习，通常仅在特定作物类型或受控环境下表现良好。需要开发能够跨物种、跨场景泛化的作物分割基础模型。

Method: 1) 扩展跨物种跨场景作物分割数据集（28,406张图像，30+物种，15种环境条件）；2) 基于ViT-Adapter架构，增强动态上采样以提升细节感知；3) 采用两阶段自训练流水线进行模型训练。

Result: 在综合测试集上达到93.11% mIoU，显著优于监督基线（+0.36%）和通用视觉基础模型如SAM（+48.57%）。在夜间环境（86.90% mIoU）、高密度冠层（90.09% mIoU）和未见作物品种（90.09% mIoU）等挑战性场景中表现优异。

Conclusion: DepthCropSeg++代表了作物分割的新技术水平，展示了基础模型在农业视觉任务中的潜力，能够有效处理开放田间环境下的作物分割问题。

Abstract: DepthCropSeg++: a foundation model for crop segmentation, capable of segmenting different crop species under open in-field environment. Crop segmentation is a fundamental task for modern agriculture, which closely relates to many downstream tasks such as plant phenotyping, density estimation, and weed control. In the era of foundation models, a number of generic large language and vision models have been developed. These models have demonstrated remarkable real world generalization due to significant model capacity and largescale datasets. However, current crop segmentation models mostly learn from limited data due to expensive pixel-level labelling cost, often performing well only under specific crop types or controlled environment. In this work, we follow the vein of our previous work DepthCropSeg, an almost unsupervised approach to crop segmentation, to scale up a cross-species and crossscene crop segmentation dataset, with 28,406 images across 30+ species and 15 environmental conditions. We also build upon a state-of-the-art semantic segmentation architecture ViT-Adapter architecture, enhance it with dynamic upsampling for improved detail awareness, and train the model with a two-stage selftraining pipeline. To systematically validate model performance, we conduct comprehensive experiments to justify the effectiveness and generalization capabilities across multiple crop datasets. Results demonstrate that DepthCropSeg++ achieves 93.11% mIoU on a comprehensive testing set, outperforming both supervised baselines and general-purpose vision foundation models like Segmentation Anything Model (SAM) by significant margins (+0.36% and +48.57% respectively). The model particularly excels in challenging scenarios including night-time environment (86.90% mIoU), high-density canopies (90.09% mIoU), and unseen crop varieties (90.09% mIoU), indicating a new state of the art for crop segmentation.

</details>


### [78] [Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12379)
*Jiahui Sheng,Yidan Shi,Shu Xiang,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 提出基于分数生成模型(ScoreAD)的高光谱异常检测方法，利用数据分布的时变梯度场(分数)来区分背景和异常光谱


<details>
  <summary>Details</summary>
Motivation: 高光谱图像中的光谱由少数因素(如化学成分、光照)决定，满足流形假设。背景光谱位于低维流形上，而异常光谱因独特光谱特征被视为不遵循背景流形的离群点

Method: 基于分数生成模型(SGM)学习数据分布的梯度场(分数)。首先在整个高光谱图像的光谱集上训练SGM，测试时每个光谱通过扰动核处理，将扰动后的光谱输入训练好的SGM获取估计分数，利用背景和异常光谱在流形分布上的差异进行检测

Result: 在四个高光谱数据集上的实验证明了该方法的有效性

Conclusion: ScoreAD方法利用分数生成模型捕捉高光谱数据的流形结构，成功实现了基于流形假设的异常检测

Abstract: Hyperspectral images (HSIs) are a type of image that contains abundant spectral information. As a type of real-world data, the high-dimensional spectra in hyperspectral images are actually determined by only a few factors, such as chemical composition and illumination. Thus, spectra in hyperspectral images are highly likely to satisfy the manifold hypothesis. Based on the hyperspectral manifold hypothesis, we propose a novel hyperspectral anomaly detection method (named ScoreAD) that leverages the time-dependent gradient field of the data distribution (i.e., the score), as learned by a score-based generative model (SGM). Our method first trains the SGM on the entire set of spectra from the hyperspectral image. At test time, each spectrum is passed through a perturbation kernel, and the resulting perturbed spectrum is fed into the trained SGM to obtain the estimated score. The manifold hypothesis of HSIs posits that background spectra reside on one or more low-dimensional manifolds. Conversely, anomalous spectra, owing to their unique spectral signatures, are considered outliers that do not conform to the background manifold. Based on this fundamental discrepancy in their manifold distributions, we leverage a generative SGM to achieve hyperspectral anomaly detection. Experiments on the four hyperspectral datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/jiahuisheng/ScoreAD.

</details>


### [79] [A Hierarchical Benchmark of Foundation Models for Dermatology](https://arxiv.org/abs/2601.12382)
*Furkan Yuceyalcin,Abdurrahim Yilmaz,Burak Temelkuran*

Main category: cs.CV

TL;DR: 该研究评估了10种基础模型在皮肤病变分层分类中的表现，发现通用医学影像模型在高层次筛查中表现优异，而皮肤病专用模型在细粒度亚型区分方面更优，揭示了模型能力的"粒度差距"。


<details>
  <summary>Details</summary>
Motivation: 当前皮肤病学基准通常将复杂的诊断分类简化为扁平化的二元分类任务（如区分黑色素瘤与良性痣），这种过度简化掩盖了模型执行细粒度鉴别诊断的能力，而这对临床工作流程整合至关重要。

Method: 使用DERM12345数据集（包含40个病变亚类），计算10种基础模型（涵盖通用计算机视觉、通用医学影像和皮肤病专用领域）的冻结嵌入，并训练轻量级适配器模型，采用五折交叉验证。引入分层评估框架，在四个临床粒度级别评估性能：40个亚类、15个主类、2个和4个超类以及二元恶性分类。

Result: 结果揭示了模型能力的"粒度差距"：MedImageInsights在二元恶性检测中表现最佳（加权F1分数97.52%），但在细粒度40类亚型分类中下降至65.50%。相反，MedSigLip（69.79%）和皮肤病专用模型（Derm Foundation和MONET）在细粒度40类亚型区分方面表现出色，但在更广泛的分类任务中整体性能低于MedImageInsights。

Conclusion: 虽然通用医学基础模型在高层次筛查中非常有效，但诊断支持系统所需的细粒度区分需要专门的建模策略。研究强调了根据临床需求选择适当模型的重要性，并建议未来工作应开发能够同时处理多层次诊断任务的基础模型。

Abstract: Foundation models have transformed medical image analysis by providing robust feature representations that reduce the need for large-scale task-specific training. However, current benchmarks in dermatology often reduce the complex diagnostic taxonomy to flat, binary classification tasks, such as distinguishing melanoma from benign nevi. This oversimplification obscures a model's ability to perform fine-grained differential diagnoses, which is critical for clinical workflow integration. This study evaluates the utility of embeddings derived from ten foundation models, spanning general computer vision, general medical imaging, and dermatology-specific domains, for hierarchical skin lesion classification. Using the DERM12345 dataset, which comprises 40 lesion subclasses, we calculated frozen embeddings and trained lightweight adapter models using a five-fold cross-validation. We introduce a hierarchical evaluation framework that assesses performance across four levels of clinical granularity: 40 Subclasses, 15 Main Classes, 2 and 4 Superclasses, and Binary Malignancy. Our results reveal a "granularity gap" in model capabilities: MedImageInsights achieved the strongest overall performance (97.52% weighted F1-Score on Binary Malignancy detection) but declined to 65.50% on fine-grained 40-class subtype classification. Conversely, MedSigLip (69.79%) and dermatology-specific models (Derm Foundation and MONET) excelled at fine-grained 40-class subtype discrimination while achieving lower overall performance than MedImageInsights on broader classification tasks. Our findings suggest that while general medical foundation models are highly effective for high-level screening, specialized modeling strategies are necessary for the granular distinctions required in diagnostic support systems.

</details>


### [80] [Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation](https://arxiv.org/abs/2601.12391)
*Dasith de Silva Edirimuni,Ajmal Saeed Mian*

Main category: cs.CV

TL;DR: 提出CPVQ-VAE方法，通过类别分区码本和类感知更新机制，直接从扩散模型生成的潜在特征解码为点云对象，无需外部数据库检索，实现纯点云场景生成。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景生成方法大多只能生成物体边界框参数，较新的扩散方法虽能生成类别标签和潜在特征，但现有自编码器无法有效解码这些特征为与目标类别一致的正确点云对象。对于包含多样化、多类别物体的复杂场景，基于扩散的潜在特征无法被当前自编码器正确解码。

Method: 1. 提出类别分区向量量化变分自编码器(CPVQ-VAE)，采用创新的类别分区码本，其中码向量按类别标记；2. 为解决码本坍缩问题，提出类感知运行平均更新机制，在每个分区内重新初始化死码向量；3. 推理时，由专门为场景生成设计的潜在空间流匹配模型(LFMM)生成物体特征和类别标签，CPVQ-VAE通过类感知逆查找将生成的潜在特征映射到码本条目，解码为类别特定的点云形状。

Result: 实验表明该方法能可靠地恢复合理的点云场景，在复杂客厅场景上，Chamfer误差和Point2Mesh误差分别降低了70.4%和72.3%。

Conclusion: CPVQ-VAE方法通过类别分区码本和类感知更新机制，成功解决了扩散模型潜在特征解码为类别一致点云对象的问题，实现了不依赖外部对象数据库的纯点云生成，显著提升了复杂场景生成的准确性和质量。

Abstract: Most 3D scene generation methods are limited to only generating object bounding box parameters while newer diffusion methods also generate class labels and latent features. Using object size or latent feature, they then retrieve objects from a predefined database. For complex scenes of varied, multi-categorical objects, diffusion-based latents cannot be effectively decoded by current autoencoders into the correct point cloud objects which agree with target classes. We introduce a Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE) that is trained to effectively decode object latent features, by employing a pioneering $\textit{class-partitioned codebook}$ where codevectors are labeled by class. To address the problem of $\textit{codebook collapse}$, we propose a $\textit{class-aware}$ running average update which reinitializes dead codevectors within each partition. During inference, object features and class labels, both generated by a Latent-space Flow Matching Model (LFMM) designed specifically for scene generation, are consumed by the CPVQ-VAE. The CPVQ-VAE's class-aware inverse look-up then maps generated latents to codebook entries that are decoded to class-specific point cloud shapes. Thereby, we achieve pure point cloud generation without relying on an external objects database for retrieval. Extensive experiments reveal that our method reliably recovers plausible point cloud scenes, with up to 70.4% and 72.3% reduction in Chamfer and Point2Mesh errors on complex living room scenes.

</details>


### [81] [HOT-POT: Optimal Transport for Sparse Stereo Matching](https://arxiv.org/abs/2601.12423)
*Antonin Clerc,Michael Quellmalz,Moritz Piening,Philipp Flotho,Gregor Kornhardt,Gabriele Steidl*

Main category: cs.CV

TL;DR: 该论文提出了一种基于最优传输理论的非监督稀疏特征匹配方法，通过相机几何的线约束来解决立体视觉中的匹配问题，特别适用于面部标志点匹配等应用。


<details>
  <summary>Details</summary>
Motivation: 立体视觉在图像间面临遮挡、运动和相机畸变等挑战，特别是在使用稀疏特征（如面部标志点）进行立体匹配时，由于参数敏感性导致问题更加复杂。需要克服这种不适定性并实现非监督稀疏匹配。

Method: 从最优传输视角考虑相机几何的线约束，将相机投影点建模为（半）线，提出使用经典极线距离和3D射线距离来量化匹配质量。将这些距离作为（部分）最优传输问题的成本函数，得到可高效求解的分配问题。进一步将方法扩展到非监督对象匹配，将其表述为分层最优传输问题。

Result: 开发出的算法能够高效进行特征和对象匹配，数值实验证明了其有效性。特别关注面部分析应用，旨在匹配不同的标志点标注规范。

Conclusion: 该方法通过最优传输理论框架，利用相机几何约束解决了稀疏特征匹配的挑战，为面部分析等应用提供了一种有效的非监督匹配解决方案。

Abstract: Stereo vision between images faces a range of challenges, including occlusions, motion, and camera distortions, across applications in autonomous driving, robotics, and face analysis. Due to parameter sensitivity, further complications arise for stereo matching with sparse features, such as facial landmarks. To overcome this ill-posedness and enable unsupervised sparse matching, we consider line constraints of the camera geometry from an optimal transport (OT) viewpoint. Formulating camera-projected points as (half)lines, we propose the use of the classical epipolar distance as well as a 3D ray distance to quantify matching quality. Employing these distances as a cost function of a (partial) OT problem, we arrive at efficiently solvable assignment problems. Moreover, we extend our approach to unsupervised object matching by formulating it as a hierarchical OT problem. The resulting algorithms allow for efficient feature and object matching, as demonstrated in our numerical experiments. Here, we focus on applications in facial analysis, where we aim to match distinct landmarking conventions.

</details>


### [82] [SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition](https://arxiv.org/abs/2601.12432)
*Shunyu Huang,Yunjiao Zhou,Jianfei Yang*

Main category: cs.CV

TL;DR: SkeFi提出了一种新颖的跨模态知识转移框架，利用数据丰富的RGB模态来增强无线传感器（LiDAR和mmWave）的骨架估计和动作识别性能，解决了黑暗环境和隐私限制下的动作识别问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于RGB摄像头的骨架动作识别方法在黑暗环境下性能下降且存在隐私问题，限制了在智能家居和医院等场景的应用。无线传感器（LiDAR和mmWave）作为非侵入式替代方案面临两个主要挑战：1）无线传感器模态数据不足难以训练准确的骨架估计模型；2）无线传感器提取的骨架关键点噪声更大，影响后续动作识别。

Method: 提出SkeFi框架，采用跨模态知识转移方法从数据丰富的RGB模态获取知识。核心包括：1）增强的时间相关性自适应图卷积（TC-AGC）结合帧交互增强，处理缺失或不连续帧的噪声；2）双重时间卷积增强多尺度时间建模；3）将TC-AGC与时间建模集成用于跨模态转移，从噪声无线传感器中提取准确姿态和动作。

Result: 实验表明SkeFi在mmWave和LiDAR传感器上实现了最先进的性能，验证了该框架在无线传感器模态上提取准确姿态和动作的有效性。

Conclusion: SkeFi通过创新的跨模态知识转移方法成功解决了无线传感器骨架动作识别的数据不足和噪声问题，为黑暗环境和隐私敏感场景提供了可行的非侵入式解决方案，在mmWave和LiDAR传感器上表现出优越性能。

Abstract: Skeleton-based action recognition leverages human pose keypoints to categorize human actions, which shows superior generalization and interoperability compared to regular end-to-end action recognition. Existing solutions use RGB cameras to annotate skeletal keypoints, but their performance declines in dark environments and raises privacy concerns, limiting their use in smart homes and hospitals. This paper explores non-invasive wireless sensors, i.e., LiDAR and mmWave, to mitigate these challenges as a feasible alternative. Two problems are addressed: (1) insufficient data on wireless sensor modality to train an accurate skeleton estimation model, and (2) skeletal keypoints derived from wireless sensors are noisier than RGB, causing great difficulties for subsequent action recognition models. Our work, SkeFi, overcomes these gaps through a novel cross-modal knowledge transfer method acquired from the data-rich RGB modality. We propose the enhanced Temporal Correlation Adaptive Graph Convolution (TC-AGC) with frame interactive enhancement to overcome the noise from missing or inconsecutive frames. Additionally, our research underscores the effectiveness of enhancing multiscale temporal modeling through dual temporal convolution. By integrating TC-AGC with temporal modeling for cross-modal transfer, our framework can extract accurate poses and actions from noisy wireless sensors. Experiments demonstrate that SkeFi realizes state-of-the-art performances on mmWave and LiDAR. The code is available at https://github.com/Huang0035/Skefi.

</details>


### [83] [Adversarial Defense in Vision-Language Models: An Overview](https://arxiv.org/abs/2601.12443)
*Xiaowei Fu,Lei Zhang*

Main category: cs.CV

TL;DR: 本文综述了视觉语言模型（VLMs）对抗性防御的三大范式：训练时防御、测试时自适应防御和免训练防御，分析了各类方法的优缺点及当前挑战。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（如CLIP）的广泛应用，其对抗性攻击脆弱性引发了安全担忧。这些攻击可能损害跨模态任务中的模型性能和系统安全，因此需要系统性地研究防御策略。

Method: 本文采用文献综述方法，系统梳理了三种主要防御范式：1）训练时防御（通过对抗性微调增强鲁棒性）；2）测试时自适应防御（在推理时更新参数处理对抗样本）；3）免训练防御（通过修改输入或特征嵌入来缓解攻击影响）。

Result: 综述总结了各类防御方法的最新进展：训练时防御有效但计算成本高且泛化能力有限；测试时自适应防御灵活但增加复杂性和计算开销；免训练防御无需修改模型但效果可能受限。同时指出了当前防御策略的局限性。

Conclusion: 尽管已有多种防御策略，但增强视觉语言模型的鲁棒性仍面临挑战。未来需要更高效、通用且实用的防御方法，以应对日益复杂的对抗性攻击威胁。

Abstract: The widespread use of Vision Language Models (VLMs, e.g. CLIP) has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks. These attacks could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve the robustness to adversarial examples. While effective, this approach requires substantial computational resources and may not generalize across all adversarial attacks. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings, which enforces input perturbations to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.

</details>


### [84] [Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild](https://arxiv.org/abs/2601.12464)
*Yanrui Lu,Danyang Chen,Haowen Xiao,Jiarui Zhu,Fukang Ge,Binqian Zou,Jiali Guan,Jiayin Liang,Yuting Wang,Ziqian Guan,Xiangcheng Bao,Jinhao Bi,Lin Gu,Jun He,Yingying Zhu*

Main category: cs.CV

TL;DR: 该研究创建了一个大规模、多来源的电子显微镜多细胞器实例分割基准数据集，包含超过10万张2D EM图像，涵盖多种细胞类型和五个细胞器类别，以解决现有基准数据集无法捕捉真实世界EM数据异质性和大空间上下文的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于小型、精选数据集的基准无法捕捉真实世界EM数据固有的异质性和大空间上下文，这给基于局部补丁的方法带来了根本性限制，需要开发更全面的基准来评估和改进细胞器实例分割方法。

Method: 开发了一个大规模、多来源的多细胞器实例分割基准数据集，包含超过10万张2D EM图像，涵盖多种细胞类型和五个细胞器类别。使用设计的连通性感知标签传播算法（3D LPA）生成数据集标注，并经过专家精修。进一步对包括U-Net、SAM变体和Mask2Former在内的多个最先进模型进行了基准测试。

Result: 基准测试结果显示当前模型存在多个局限性：在异质EM数据上泛化能力不足，对具有全局、分布形态的细胞器（如内质网）表现较差。这些发现突显了局部上下文模型与在真实世界变异性存在下建模长程结构连续性挑战之间的根本性不匹配。

Conclusion: 需要开发能够处理长程结构连续性和真实世界变异性的新模型架构，以解决电子显微镜中细胞器实例分割的根本挑战。该基准数据集和标注工具将公开发布，以推动该领域的发展。

Abstract: Accurate instance-level segmentation of organelles in electron microscopy (EM) is critical for quantitative analysis of subcellular morphology and inter-organelle interactions. However, current benchmarks, based on small, curated datasets, fail to capture the inherent heterogeneity and large spatial context of in-the-wild EM data, imposing fundamental limitations on current patch-based methods. To address these limitations, we developed a large-scale, multi-source benchmark for multi-organelle instance segmentation, comprising over 100,000 2D EM images across variety cell types and five organelle classes that capture real-world variability. Dataset annotations were generated by our designed connectivity-aware Label Propagation Algorithm (3D LPA) with expert refinement. We further benchmarked several state-of-the-art models, including U-Net, SAM variants, and Mask2Former. Our results show several limitations: current models struggle to generalize across heterogeneous EM data and perform poorly on organelles with global, distributed morphologies (e.g., Endoplasmic Reticulum). These findings underscore the fundamental mismatch between local-context models and the challenge of modeling long-range structural continuity in the presence of real-world variability. The benchmark dataset and labeling tool will be publicly released soon.

</details>


### [85] [NeuralFur: Animal Fur Reconstruction From Multi-View Images](https://arxiv.org/abs/2601.12481)
*Vanessa Sklyarova,Berna Kabadayi,Anastasios Yiannakidis,Giorgio Becherini,Michael J. Black,Justus Thies*

Main category: cs.CV

TL;DR: 首个基于多视角图像重建动物毛发三维模型的方法，利用视觉语言模型指导毛发长度和方向，实现多种动物毛发的高保真重建


<details>
  <summary>Details</summary>
Motivation: 从图像重建逼真动物毛发几何面临挑战：毛发细节精细、自遮挡、视角依赖外观，且缺乏可用于学习不同动物毛发先验的数据集

Method: 1) 使用传统多视角立体技术重建粗糙表面几何；2) 利用视觉语言模型检索身体各部位毛发长度结构信息；3) 构建无毛几何并在其上生长毛发；4) 使用几何和光度损失监督重建；5) 利用VLM指导毛发生长方向和重力向量关系

Result: 展示了在多种不同毛发类型动物上的泛化能力，实现了高保真三维毛发重建

Conclusion: 提出了一种利用视觉语言模型指导多视角输入三维重建的新范式，能够跨多种动物毛发类型实现高质量毛发建模

Abstract: Reconstructing realistic animal fur geometry from images is a challenging task due to the fine-scale details, self-occlusion, and view-dependent appearance of fur. In contrast to human hairstyle reconstruction, there are also no datasets that can be leveraged to learn a fur prior for different animals. In this work, we present a first multi-view-based method for high-fidelity 3D fur modeling of animals using a strand-based representation, leveraging the general knowledge of a vision language model. Given multi-view RGB images, we first reconstruct a coarse surface geometry using traditional multi-view stereo techniques. We then use a vision language model (VLM) system to retrieve information about the realistic length structure of the fur for each part of the body. We use this knowledge to construct the animal's furless geometry and grow strands atop it. The fur reconstruction is supervised with both geometric and photometric losses computed from multi-view images. To mitigate orientation ambiguities stemming from the Gabor filters that are applied to the input images, we additionally utilize the VLM to guide the strands' growth direction and their relation to the gravity vector that we incorporate as a loss. With this new schema of using a VLM to guide 3D reconstruction from multi-view inputs, we show generalization across a variety of animals with different fur types. For additional results and code, please refer to https://neuralfur.is.tue.mpg.de.

</details>


### [86] [Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation](https://arxiv.org/abs/2601.12493)
*Mehrdad Noori,Gustavo Adolfo Vargas Hakim,David Osowiechi,Fereshteh Shakeri,Ali Bahri,Moslem Yazdanpanah,Sahar Dastani,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 该论文提出了Histopath-C基准测试和LATTE方法，用于评估和提升医学视觉语言模型在组织病理学图像中的鲁棒性，通过模拟真实世界分布偏移和低秩适应策略来改善模型性能。


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型在组织病理学等医学影像领域表现出色，但组织病理学图像存在染色、污染、模糊和噪声等严重领域偏移，这些偏移会显著降低模型的下游性能。需要开发能够应对这些真实世界分布偏移的鲁棒性评估方法和适应策略。

Method: 1. 提出Histopath-C基准测试，包含模拟数字组织病理学中真实分布偏移的合成损坏；2. 开发动态框架，可将损坏应用于任何可用数据集并实时评估测试时适应机制；3. 提出LATTE方法，一种利用多个文本模板的转导低秩适应策略，减轻组织病理学视觉语言模型对多样化文本输入的敏感性。

Result: LATTE方法在多个组织病理学数据集上超越了为自然图像设计的最先进测试时适应方法，证明了所提出设计在组织病理学图像中鲁棒适应的有效性。

Conclusion: 该研究为组织病理学视觉语言模型的鲁棒性评估提供了新基准，提出的LATTE方法能够有效应对真实世界分布偏移，提升模型在组织病理学图像中的适应能力和性能。

Abstract: Medical Vision-language models (VLMs) have shown remarkable performances in various medical imaging domains such as histo\-pathology by leveraging pre-trained, contrastive models that exploit visual and textual information. However, histopathology images may exhibit severe domain shifts, such as staining, contamination, blurring, and noise, which may severely degrade the VLM's downstream performance. In this work, we introduce Histopath-C, a new benchmark with realistic synthetic corruptions designed to mimic real-world distribution shifts observed in digital histopathology. Our framework dynamically applies corruptions to any available dataset and evaluates Test-Time Adaptation (TTA) mechanisms on the fly. We then propose LATTE, a transductive, low-rank adaptation strategy that exploits multiple text templates, mitigating the sensitivity of histopathology VLMs to diverse text inputs. Our approach outperforms state-of-the-art TTA methods originally designed for natural images across a breadth of histopathology datasets, demonstrating the effectiveness of our proposed design for robust adaptation in histopathology images. Code and data are available at https://github.com/Mehrdad-Noori/Histopath-C.

</details>


### [87] [Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods](https://arxiv.org/abs/2601.12500)
*Yaowu Fan,Jia Wan,Tao Han,Andy J. Ma,Antoni B. Chan*

Main category: cs.CV

TL;DR: 提出基于移动无人机的大规模密集人群计数与跟踪解决方案，包括新数据集MovingDroneCrowd++和两个新方法：GD3A用于视频级人群计数，DVTrack用于行人跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖固定摄像头数据集，空间覆盖有限，无法满足大规模密集人群分析需求。移动无人机能提供更灵活的视角和更广的覆盖范围，但现有方法在此类数据上表现不佳。

Method: 1) 提出MovingDroneCrowd++数据集，包含移动无人机在不同高度、角度和光照条件下捕获的密集人群视频；2) 提出GD3A方法，通过最优传输和自适应dustbin分数建立像素级行人描述符对应关系，将全局密度图分解为共享、流入和流出分量；3) 提出DVTrack方法，通过描述符投票机制将描述符级匹配转换为实例级关联。

Result: 实验结果表明，所提方法在密集人群和复杂运动条件下显著优于现有方法，计数误差降低47.4%，跟踪性能提升39.2%。

Conclusion: 移动无人机为大规模密集人群分析提供了灵活解决方案，所提GD3A和DVTrack方法在移动无人机捕获的复杂场景中表现出色，为密集人群计数和跟踪提供了有效框架。

Abstract: Counting and tracking dense crowds in large-scale scenes is highly challenging, yet existing methods mainly rely on datasets captured by fixed cameras, which provide limited spatial coverage and are inadequate for large-scale dense crowd analysis. To address this limitation, we propose a flexible solution using moving drones to capture videos and perform video-level crowd counting and tracking of unique pedestrians across entire scenes. We introduce MovingDroneCrowd++, the largest video-level dataset for dense crowd counting and tracking captured by moving drones, covering diverse and complex conditions with varying flight altitudes, camera angles, and illumination. Existing methods fail to achieve satisfactory performance on this dataset. To this end, we propose GD3A (Global Density Map Decomposition via Descriptor Association), a density map-based video individual counting method that avoids explicit localization. GD3A establishes pixel-level correspondences between pedestrian descriptors across consecutive frames via optimal transport with an adaptive dustbin score, enabling the decomposition of global density maps into shared, inflow, and outflow components. Building on this framework, we further introduce DVTrack, which converts descriptor-level matching into instance-level associations through a descriptor voting mechanism for pedestrian tracking. Experimental results show that our methods significantly outperform existing approaches under dense crowds and complex motion, reducing counting error by 47.4 percent and improving tracking performance by 39.2 percent.

</details>


### [88] [Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images](https://arxiv.org/abs/2601.12512)
*Mohd Usama,Belal Ahmad,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 提出基于CycleGAN的无监督医学图像域适应方法，解决不同MRI扫描仪间的域偏移问题，无需配对数据即可实现双向域映射


<details>
  <summary>Details</summary>
Motivation: 不同扫描仪或机构获取的MRI图像存在域偏移（硬件、协议、采集参数差异），导致在源域训练的深度学习模型在目标域性能下降

Method: 基于CycleGAN的模型，利用循环一致性学习源域和目标域间的双向映射，结合内容和差异损失保持图像解剖结构完整性

Result: 在多个MRI数据集上的实验表明，该方法能有效实现无标签数据的双向域适应，提高模型性能并减少域相关变异性

Conclusion: 该方法为改善医疗诊断准确性提供了有前景的途径，有助于实现更精确、一致的医学图像分析

Abstract: Magnetic Resonance Imaging (MRI) scans acquired from different scanners or institutions often suffer from domain shifts owing to variations in hardware, protocols, and acquisition parameters. This discrepancy degrades the performance of deep learning models trained on source domain data when applied to target domain images. In this study, we propose a Cycle-GAN-based model for unsupervised medical-image domain adaptation. Leveraging CycleGANs, our model learns bidirectional mappings between the source and target domains without paired training data, preserving the anatomical content of the images. By leveraging Cycle-GAN capabilities with content and disparity loss for adaptation tasks, we ensured image-domain adaptation while maintaining image integrity. Several experiments on MRI datasets demonstrated the efficacy of our model in bidirectional domain adaptation without labelled data. Furthermore, research offers promising avenues for improving the diagnostic accuracy of healthcare. The statistical results confirm that our approach improves model performance and reduces domain-related variability, thus contributing to more precise and consistent medical image analysis.

</details>


### [89] [Deep Feature Deformation Weights](https://arxiv.org/abs/2601.12527)
*Richard Liu,Itai Lang,Rana Hanocka*

Main category: cs.CV

TL;DR: 提出一种融合数据驱动语义先验与传统精确控制的网格变形方法，通过深度特征邻近性实现平滑语义变形权重，支持实时计算和高分辨率网格处理。


<details>
  <summary>Details</summary>
Motivation: 传统基于手柄的网格变形方法需要用户预先知道手柄的理想分布，且手柄到变形行为的映射不直观、非语义；而现代数据驱动方法虽然能获得语义编辑，但速度慢且不精确。需要一种融合两者优势的方法。

Method: 使用深度特征邻近性生成平滑语义变形权重，无需额外正则化；提出重心特征蒸馏管道，利用形状渲染的视觉信号最小化蒸馏成本；通过特征空间约束和局部性加权保留传统方法特性；支持语义对称性自动检测和保持。

Result: 方法能在1分钟内为高分辨率网格计算权重（传统和神经方法可能需要数小时），在消费级机器上实时处理百万面网格变形，实现语义部件协同变形和对称保持。

Conclusion: 该方法成功融合了数据驱动的语义先验与传统框架的精确控制和速度，通过深度特征邻近性实现了简单有效的语义变形权重计算，为实时高分辨率网格变形提供了实用解决方案。

Abstract: Handle-based mesh deformation has been a long-standing paradigm in computer graphics, enabling intuitive shape edits from sparse controls. Classic techniques offer precise and rapid deformation control. However, they solve an optimization problem with constraints defined by control handle placement, requiring a user to know apriori the ideal distribution of handles on the shape to accomplish the desired edit. The mapping from handle set to deformation behavior is often unintuitive and, importantly, non-semantic. Modern data-driven methods, on the other hand, leverage a data prior to obtain semantic edits, but are slow and imprecise. We propose a technique that fuses the semantic prior of data with the precise control and speed of traditional frameworks. Our approach is surprisingly simple yet effective: deep feature proximity makes for smooth and semantic deformation weights, with no need for additional regularization. The weights can be computed in real-time for any surface point, whereas prior methods require optimization for new handles. Moreover, the semantic prior from deep features enables co-deformation of semantic parts. We introduce an improved feature distillation pipeline, barycentric feature distillation, which efficiently uses the visual signal from shape renders to minimize distillation cost. This allows our weights to be computed for high resolution meshes in under a minute, in contrast to potentially hours for both classical and neural methods. We preserve and extend properties of classical methods through feature space constraints and locality weighting. Our field representation allows for automatic detection of semantic symmetries, which we use to produce symmetry-preserving deformations. We show a proof-of-concept application which can produce deformations for meshes up to 1 million faces in real-time on a consumer-grade machine.

</details>


### [90] [XRefine: Attention-Guided Keypoint Match Refinement](https://arxiv.org/abs/2601.12530)
*Jan Fabian Schmid,Annika Hagemann*

Main category: cs.CV

TL;DR: XRefine：一种与检测器无关的亚像素关键点细化方法，仅使用以匹配关键点为中心的图像块，通过跨注意力架构预测细化坐标，可推广到多视角特征跟踪


<details>
  <summary>Details</summary>
Motivation: 稀疏关键点匹配对3D视觉任务至关重要，但当前关键点检测器常产生空间不准确的匹配。现有细化方法通常通过对齐匹配关键点位置来缓解此问题，但它们通常是检测器特定的，需要为每个关键点检测器重新训练

Method: 提出XRefine方法，这是一种与检测器无关的亚像素关键点细化方法，仅使用以匹配关键点为中心的图像块。基于跨注意力的架构学习预测细化关键点坐标，不依赖检测器内部表示。该方法可扩展到处理多视角特征跟踪

Result: 在MegaDepth、KITTI和ScanNet上的实验表明，该方法一致提高了几何估计精度，相比现有细化方法实现了更优性能，同时保持了运行时效率

Conclusion: XRefine是一种有效的与检测器无关的关键点细化方法，能够提高匹配精度并推广到不同检测器，在多个数据集上验证了其有效性

Abstract: Sparse keypoint matching is crucial for 3D vision tasks, yet current keypoint detectors often produce spatially inaccurate matches. Existing refinement methods mitigate this issue through alignment of matched keypoint locations, but they are typically detector-specific, requiring retraining for each keypoint detector. We introduce XRefine, a novel, detector-agnostic approach for sub-pixel keypoint refinement that operates solely on image patches centered at matched keypoints. Our cross-attention-based architecture learns to predict refined keypoint coordinates without relying on internal detector representations, enabling generalization across detectors. Furthermore, XRefine can be extended to handle multi-view feature tracks. Experiments on MegaDepth, KITTI, and ScanNet demonstrate that the approach consistently improves geometric estimation accuracy, achieving superior performance compared to existing refinement methods while maintaining runtime efficiency. Our code and trained models can be found at https://github.com/boschresearch/xrefine.

</details>


### [91] [BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images](https://arxiv.org/abs/2601.12533)
*Md. Ahanaf Arif Khan,Ariful Islam,Sangeeta Biswas,Md. Iqbal Aziz Khan,Subrata Pramanik,Sanjoy Kumar Chakrabarty,Bimal Kumar Pramanik*

Main category: cs.CV

TL;DR: 作者创建了BirdsEye-RU数据集，包含2,978张图像和8,000多个标注的人脸，专门用于检测高空图像中的小尺寸和远距离人脸，数据集包含无人机和智能手机拍摄的高空图像。


<details>
  <summary>Details</summary>
Motivation: 高空图像中的人脸检测面临极端尺度变化和环境杂波的重大挑战，现有数据集难以有效解决这些问题。

Method: 创建了BirdsEye-RU数据集，这是一个包含2,978张图像的综合集合，标注了超过8,000个人脸，专门设计用于捕捉不同环境中的小尺寸和远距离人脸，包含无人机和高空智能手机拍摄的图像。

Result: 成功构建了一个专门针对高空人脸检测的数据集，包含多样化的环境场景，数据集已公开可用，可通过Kaggle平台访问。

Conclusion: BirdsEye-RU数据集为解决高空图像中小尺寸人脸检测的挑战提供了有价值的资源，有助于推动该领域的研究发展。

Abstract: Detecting faces in overhead images remains a significant challenge due to extreme scale variations and environmental clutter. To address this, we created the BirdsEye-RU dataset, a comprehensive collection of 2,978 images containing over eight thousand annotated faces. This dataset is specifically designed to capture small and distant faces across diverse environments, containing both drone images and smartphone-captured images from high altitude. We present a detailed description of the BirdsEye-RU dataset in this paper. We made our dataset freely available to the public, and it can be accessed at https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru.

</details>


### [92] [Encoding Emotion Through Self-Supervised Eye Movement Reconstruction](https://arxiv.org/abs/2601.12534)
*Marcus Ma,Jordan Prescott,Emily Zhou,Tiantian Feng,Kleanthis Avramidis,Gabor Mihaly Toth,Shrikanth Narayanan*

Main category: cs.CV

TL;DR: 提出基于自监督眼动重建的新模型，利用低分辨率视频预测情感表达，在Holocaust幸存者访谈数据上验证了模型对情感预测的有效性


<details>
  <summary>Details</summary>
Motivation: 现有眼动-情感关系研究多依赖高分辨率眼动追踪设备，限制了研究范围和实际应用。本研究旨在探索如何从自然、低分辨率视频中利用眼动预测情感表达的多模态标记

Method: 1) 使用USC Shoah Foundation视觉历史档案中的Holocaust幸存者访谈视频；2) 受语言模型预训练启发，开发自监督眼动重建模型，有效利用未标记视频；3) 使用模型编码器嵌入微调两个下游任务：眼动与语音情感方向估计对齐，眼动预测三种瞬时情感行为（笑、哭/抽泣、叹气）

Result: 新模型能有效预测情感结果，观察到预训练性能与情感处理性能之间存在正相关关系，两个实验均验证了这一点

Conclusion: 自监督眼动重建是编码眼动所携带情感信号的有效方法，为从低分辨率视频中提取情感信息提供了新途径

Abstract: The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation's Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model's encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry.

</details>


### [93] [PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception](https://arxiv.org/abs/2601.12551)
*Tong Wu*

Main category: cs.CV

TL;DR: PISE是一个基于物理信息的深度鬼成像框架，用于低带宽边缘感知，通过结合伴随算子初始化和语义指导，在5%采样率下将分类准确率提升2.57%，方差降低9倍。


<details>
  <summary>Details</summary>
Motivation: 边缘计算场景中需要低带宽感知，传统鬼成像方法在低采样率下性能受限，需要结合物理先验和深度学习来提高边缘感知的准确性和稳定性。

Method: 提出PISE框架，结合伴随算子初始化（利用物理模型先验）和语义指导（利用深度学习语义信息），在低采样率下优化鬼成像重建和分类性能。

Result: 在5%采样率下，PISE将分类准确率提升2.57%，方差降低9倍，显著提高了低带宽边缘感知的准确性和稳定性。

Conclusion: PISE通过融合物理模型先验和深度学习语义信息，有效解决了低采样率鬼成像的边缘感知问题，为低带宽边缘计算提供了高效解决方案。

Abstract: We propose PISE, a physics-informed deep ghost imaging framework for low-bandwidth edge perception. By combining adjoint operator initialization with semantic guidance, PISE improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.

</details>


### [94] [Camera Pose Revisited](https://arxiv.org/abs/2601.12567)
*Władysław Skarbek,Michał Salomonowicz,Michał Król*

Main category: cs.CV

TL;DR: 提出PnP-ProCay78算法解决平面透视n点问题，结合二次重建误差公式、Cayley旋转参数化和最小二乘优化，通过确定性起始点选择避免搜索，在RGB和热成像相机上验证性能接近最优SQPnP。


<details>
  <summary>Details</summary>
Motivation: 解决相机标定和多传感器系统中的核心问题——相机相对于观察场景的位置和姿态估计，特别关注标定物体姿态的初始估计。现有PnP求解器在几何透明性和计算效率方面存在不足。

Method: 提出PnP-ProCay78算法：1) 结合经典二次重建误差公式与Cayley旋转参数化；2) 采用最小二乘优化；3) 关键创新是通过分析两个规范向量的重建误差进行确定性起始点选择，避免昂贵的解空间搜索；4) 创建混合成本函数，将投影误差最小化与解析消除平移的重建误差替代项相结合。

Result: 实验验证使用高分辨率RGB相机和低分辨率热成像相机的集成RGB-IR设置。结果表明：1) 投影精度与最优SQPnP几乎相同，略高于IPPE；2) 算法结构显著更简单；3) Cayley空间中的优化轨迹分析提供了收敛过程的直观理解；4) 混合成本函数兼具几何透明性和计算效率。

Conclusion: PnP-ProCay78算法在保持与最优方法相当精度的同时，提供了更简单的算法结构和几何透明性。Cayley参数化使收敛过程更直观，具有教学价值。该算法为平面PnP问题提供了高效且易于理解的解决方案。

Abstract: Estimating the position and orientation of a camera with respect to an observed scene is one of the central problems in computer vision, particularly in the context of camera calibration and multi-sensor systems. This paper addresses the planar Perspective--$n$--Point problem, with special emphasis on the initial estimation of the pose of a calibration object. As a solution, we propose the \texttt{PnP-ProCay78} algorithm, which combines the classical quadratic formulation of the reconstruction error with a Cayley parameterization of rotations and least-squares optimization. The key component of the method is a deterministic selection of starting points based on an analysis of the reconstruction error for two canonical vectors, allowing costly solution-space search procedures to be avoided. Experimental validation is performed using data acquired also from high-resolution RGB cameras and very low-resolution thermal cameras in an integrated RGB--IR setup. The results demonstrate that the proposed algorithm achieves practically the same projection accuracy as optimal \texttt{SQPnP} and slightly higher than \texttt{IPPE}, both prominent \texttt{PnP-OpenCV} procedures. However, \texttt{PnP-ProCay78} maintains a significantly simpler algorithmic structure. Moreover, the analysis of optimization trajectories in Cayley space provides an intuitive insight into the convergence process, making the method attractive also from a didactic perspective. Unlike existing PnP solvers, the proposed \texttt{PnP-ProCay78} algorithm combines projection error minimization with an analytically eliminated reconstruction-error surrogate for translation, yielding a hybrid cost formulation that is both geometrically transparent and computationally efficient.

</details>


### [95] [From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2](https://arxiv.org/abs/2601.12636)
*Satyaki Roy Chowdhury,Aswathnarayan Radhakrishnan,Hsiao Jou Hsu,Hari Subramoni,Joachim Moortgat*

Main category: cs.CV

TL;DR: 论文分析了基于Swin-Transformer的U-Net模型(Swin-BathyUNet)在Sentinel-2卫星测深(SDB)中的应用，通过特征重要性分析、注意力机制研究和跨区域验证，揭示了模型推断深度的机制并提供了实用部署指南。


<details>
  <summary>Details</summary>
Motivation: Sentinel-2卫星测深(SDB)在不同站点间的稳健部署仍具挑战性，需要深入理解深度学习模型如何推断水深以及何时其预测是可信的，以提升跨区域应用的可靠性。

Method: 采用Swin-Transformer U-Net架构；进行波段重要性分析（leave-one-band out）；开发回归任务的基于消融的类激活映射(A-CAM-R)并进行可靠性验证；进行注意力机制消融研究；实施跨区域推理实验（在一个站点训练，在另一个站点测试）。

Result: 波段重要性排序与浅水光学理论一致；A-CAM-R验证显示仅保留前p%显著像素会导致RMSE单调大幅增加，表明解释定位在模型依赖的证据上；解码器条件化跨注意力机制有效提升了对眩光/泡沫的鲁棒性；跨区域推理显示误差随深度近线性增加，双峰深度分布加剧中/深水区误差。

Conclusion: 为稳健的SDB部署提供实用指导：保持宽感受野，保护绿/蓝通道的辐射测量保真度，预过滤近岸高亮度高方差区域，结合轻量目标站点微调和深度感知校准以实现跨区域迁移。

Abstract: Deploying Sentinel-2 satellite derived bathymetry (SDB) robustly across sites remains challenging. We analyze a Swin-Transformer based U-Net model (Swin-BathyUNet) to understand how it infers depth and when its predictions are trustworthy. A leave-one-band out study ranks spectral importance to the different bands consistent with shallow water optics. We adapt ablation-based CAM to regression (A-CAM-R) and validate the reliability via a performance retention test: keeping only the top-p% salient pixels while neutralizing the rest causes large, monotonic RMSE increase, indicating explanations localize on evidence the model relies on. Attention ablations show decoder conditioned cross attention on skips is an effective upgrade, improving robustness to glint/foam. Cross-region inference (train on one site, test on another) reveals depth-dependent degradation: MAE rises nearly linearly with depth, and bimodal depth distributions exacerbate mid/deep errors. Practical guidance follows: maintain wide receptive fields, preserve radiometric fidelity in green/blue channels, pre-filter bright high variance near shore, and pair light target site fine tuning with depth aware calibration to transfer across regions.

</details>


### [96] [Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT](https://arxiv.org/abs/2601.12638)
*Ninnart Fuengfusin,Keisuke Yoneda,Naoki Suganuma*

Main category: cs.CV

TL;DR: 该论文提出了一种用于PointPillars的混合精度量化框架，通过敏感层搜索和异常值处理策略，在保持检测性能的同时实现实时加速。


<details>
  <summary>Details</summary>
Motivation: LIDAR 3D目标检测对自动驾驶至关重要，需要实时运行。模型量化可以加速推理，但直接应用量化会因LIDAR数据的宽数值分布和极端异常值导致性能下降。

Method: 1. 提出混合精度框架：通过后训练量化（PTQ）逐层量化到INT8并评估AP，识别敏感层；2. 将top-k敏感层保持为浮点（FP）；3. 贪婪搜索这些层的组合生成候选混合精度模型；4. 使用PTQ或量化感知训练（QAT）完成模型；5. 使用少量校准数据减少异常值影响。

Result: 1. PTQ流水线无需训练即可获得混合精度模型；2. QAT流水线达到与FP模型相当的性能；3. TensorRT部署下，延迟降低最多2.35倍，模型大小减少最多2.26倍。

Conclusion: 提出的混合精度量化框架有效解决了LIDAR数据量化中的数值分布和异常值问题，在保持检测精度的同时显著提升了推理速度，适用于自动驾驶实时3D目标检测。

Abstract: LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.

</details>


### [97] [Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images](https://arxiv.org/abs/2601.12664)
*Elisa Gonçalves Ribeiro,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 研究探索了在非独立同分布联邦学习场景下，针对癌症组织病理学任务的超参数优化策略及其跨数据集泛化能力


<details>
  <summary>Details</summary>
Motivation: 深度学习在癌症组织病理学训练中存在隐私约束问题，联邦学习虽然能保持数据本地化，但其性能在非独立同分布客户端数据集下高度依赖超参数选择，需要研究超参数优化策略的跨数据集泛化能力

Method: 采用集中式贝叶斯超参数优化，将数据集特定最优配置迁移到非独立同分布联邦学习设置，并引入简单的跨数据集聚合启发式方法，通过平均学习率、考虑模态优化器和批量大小来组合配置

Result: 组合配置实现了具有竞争力的分类性能，表明该策略在跨非独立同分布联邦学习场景中有效

Conclusion: 提出的简单跨数据集聚合启发式方法能够为癌症组织病理学的非独立同分布联邦学习提供有效的超参数配置，平衡了隐私保护与模型性能的需求

Abstract: Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.

</details>


### [98] [Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface](https://arxiv.org/abs/2601.12666)
*Zonglin Li,Jieji Ren,Shuangfan Zhou,Heng Guo,Jinnuo Zhang,Jiang Zhou,Boxin Shi,Zhanyu Ma,Guoying Gu*

Main category: cs.CV

TL;DR: 提出一种基于神经隐式表示的单次彩色光度立体视觉框架，用于近光和复杂反射条件下的表面重建，并通过紧凑光学触觉传感器验证


<details>
  <summary>Details</summary>
Motivation: 传统彩色光度立体视觉假设理想远距离照明和朗伯反射，限制了在更实际的近光条件和非朗伯表面场景中的应用。现有方法对这些实际条件探索不足，需要克服这些限制以实现更实用的单次表面重建。

Method: 提出一个框架，利用神经隐式表示对深度和BRDF进行建模，基于单色性假设（均匀色度和同质材料），缓解彩色光度立体视觉固有的不适定性。同时设计了紧凑的光学触觉传感器来验证方法。

Result: 在合成和真实世界数据集上的实验表明，该方法能够实现准确且鲁棒的表面重建，特别是在近光条件和复杂反射表面情况下表现优异。

Conclusion: 该方法成功扩展了彩色光度立体视觉的应用范围，使其能够处理更实际的近光条件和复杂反射表面，通过神经隐式表示和单色性假设实现了从单张图像进行详细表面重建。

Abstract: Color photometric stereo enables single-shot surface reconstruction, extending conventional photometric stereo that requires multiple images of a static scene under varying illumination to dynamic scenarios. However, most existing approaches assume ideal distant lighting and Lambertian reflectance, leaving more practical near-light conditions and non-Lambertian surfaces underexplored. To overcome this limitation, we propose a framework that leverages neural implicit representations for depth and BRDF modeling under the assumption of mono-chromaticity (uniform chromaticity and homogeneous material), which alleviates the inherent ill-posedness of color photometric stereo and allows for detailed surface recovery from just one image. Furthermore, we design a compact optical tactile sensor to validate our approach. Experiments on both synthetic and real-world datasets demonstrate that our method achieves accurate and robust surface reconstruction.

</details>


### [99] [Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement](https://arxiv.org/abs/2601.12682)
*Banglei Guan,Dongcai Tan,Jing Tao,Ang Su,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 该论文提出了一种针对高温结构变形测量的图像处理方法，通过多曝光图像融合和灰度平均算法来抑制热辐射和热霾干扰，提高数字图像相关法（DIC）的测量精度。


<details>
  <summary>Details</summary>
Motivation: 在高温结构变形测量中，热辐射引起的图像退化和热霾引入的随机误差限制了变形测量的精度和有效性。传统方法难以有效处理这些干扰因素，需要开发专门的图像处理技术来改善高温环境下的DIC测量性能。

Method: 1. 针对热辐射引起的图像退化：基于图像分层表示，将图像分解为正负通道进行并行处理，通过多曝光图像融合优化图像质量。
2. 针对热霾引入的高频随机误差：采用FSIM（特征相似度）作为目标函数指导模型参数迭代优化，应用灰度平均算法均衡异常灰度值以减少测量误差。

Result: 1. 多曝光图像融合算法有效抑制了复杂光照条件下的图像退化，将欠曝光图像的有效计算区域从26%提升至50%，过曝光图像从32%提升至40%，且不降低测量精度。
2. 结合灰度平均算法的图像恢复方法显著降低了静态热变形测量误差：ε_xx误差减少85.3%，ε_yy误差减少36.0%，γ_xy误差减少36.4%。

Conclusion: 提出的图像处理方法能有效抑制高温变形测量中热辐射和热霾的干扰，提高图像质量并降低变形测量误差，在热变形测量领域具有潜在应用价值。实验验证了该方法在改善DIC测量性能方面的有效性。

Abstract: In the deformation measurement of high-temperature structures, image degradation caused by thermal radiation and random errors introduced by heat haze restrict the accuracy and effectiveness of deformation measurement. To suppress thermal radiation and heat haze using fusion-restoration image processing methods, thereby improving the accuracy and effectiveness of DIC in the measurement of high-temperature deformation. For image degradation caused by thermal radiation, based on the image layered representation, the image is decomposed into positive and negative channels for parallel processing, and then optimized for quality by multi-exposure image fusion. To counteract the high-frequency, random errors introduced by heat haze, we adopt the FSIM as the objective function to guide the iterative optimization of model parameters, and the grayscale average algorithm is applied to equalize anomalous gray values, thereby reducing measurement error. The proposed multi-exposure image fusion algorithm effectively suppresses image degradation caused by complex illumination conditions, boosting the effective computation area from 26% to 50% for under-exposed images and from 32% to 40% for over-exposed images without degrading measurement accuracy in the experiment. Meanwhile, the image restoration combined with the grayscale average algorithm reduces static thermal deformation measurement errors. The error in ε_xx is reduced by 85.3%, while the errors in ε_yy and γ_xy are reduced by 36.0% and 36.4%, respectively. We present image processing methods to suppress the interference of thermal radiation and heat haze in high-temperature deformation measurement using DIC. The experimental results verify that the proposed method can effectively improve image quality, reduce deformation measurement errors, and has potential application value in thermal deformation measurement.

</details>


### [100] [GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation](https://arxiv.org/abs/2601.12683)
*Liwei Liao,Ronggang Wang*

Main category: cs.CV

TL;DR: 提出GaussianTrimmer方法，通过虚拟相机和2D分割结果在基元级别修剪3D高斯分割的粗糙边界


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯分割方法基于高斯基元进行分割，但由于3D高斯尺度变化范围大，大尺寸高斯常跨越前景和背景，导致分割物体边界呈锯齿状

Method: 提出在线边界修剪方法GaussianTrimmer，包含两个核心步骤：1.生成均匀且覆盖良好的虚拟相机；2.基于虚拟相机上的2D分割结果在基元级别修剪高斯

Result: 大量定量和定性实验表明，该方法作为即插即用方法能够提高现有3D高斯分割方法的分割质量

Conclusion: GaussianTrimmer是一种高效且即插即用的后处理方法，能够为现有3D高斯分割方法修剪粗糙边界

Abstract: With the widespread application of 3D Gaussians in 3D scene representation, 3D scene segmentation methods based on 3D Gaussians have also gradually emerged. However, existing 3D Gaussian segmentation methods basically segment on the basis of Gaussian primitives. Due to the large variation range of the scale of 3D Gaussians, large-sized Gaussians that often span the foreground and background lead to jagged boundaries of segmented objects. To this end, we propose an online boundary trimming method, GaussianTrimmer, which is an efficient and plug-and-play post-processing method capable of trimming coarse boundaries for existing 3D Gaussian segmentation methods. Our method consists of two core steps: 1. Generating uniformly and well-covered virtual cameras; 2. Trimming Gaussian at the primitive level based on 2D segmentation results on virtual cameras. Extensive quantitative and qualitative experiments demonstrate that our method can improve the segmentation quality of existing 3D Gaussian segmentation methods as a plug-and-play method.

</details>


### [101] [Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation](https://arxiv.org/abs/2601.12697)
*Chao Yang,Deshui Miao,Chao Tian,Guoqing Zhu,Yameng Gu,Zhenyu He*

Main category: cs.CV

TL;DR: 提出IVGF框架，通过3D高斯重建解决传统2D红外-可见光图像融合方法视角固定、场景理解不全面的问题，实现多模态融合图像的直接渲染。


<details>
  <summary>Details</summary>
Motivation: 现有2D融合方法局限于固定相机视角，无法全面理解复杂场景，导致关键信息丢失。需要一种能够重建场景几何并实现多模态融合的新方法。

Method: 提出红外-可见光高斯融合(IVGF)框架：1) 从多模态2D输入重建场景几何；2) 设计跨模态调整(CMA)模块，通过调制高斯不透明度解决跨模态冲突；3) 引入融合损失指导CMA优化，保留各模态关键特征。

Result: 全面的定性和定量实验证明了该方法的有效性，能够生成保留红外和可见光关键特征的融合图像。

Conclusion: IVGF框架通过3D高斯重建和跨模态调整，解决了传统2D融合方法的局限性，实现了更全面的场景理解和更高质量的融合图像渲染。

Abstract: Infrared-visible image fusion aims to integrate infrared and visible information into a single fused image. Existing 2D fusion methods focus on fusing images from fixed camera viewpoints, neglecting a comprehensive understanding of complex scenarios, which results in the loss of critical information about the scene. To address this limitation, we propose a novel Infrared-Visible Gaussian Fusion (IVGF) framework, which reconstructs scene geometry from multimodal 2D inputs and enables direct rendering of fused images. Specifically, we propose a cross-modal adjustment (CMA) module that modulates the opacity of Gaussians to solve the problem of cross-modal conflicts. Moreover, to preserve the distinctive features from both modalities, we introduce a fusion loss that guides the optimization of CMA, thus ensuring that the fused image retains the critical characteristics of each modality. Comprehensive qualitative and quantitative experiments demonstrate the effectiveness of the proposed method.

</details>


### [102] [P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2601.12714)
*Songlin Dong,Jiangyang Li,Chenhao Ding,Zhiheng Ma,Haoyu Luo,Yuhang He,Yihong Gong*

Main category: cs.CV

TL;DR: P2L-CA：一种参数高效的多标签类增量学习框架，通过提示到标签模块和连续适配器模块解决特征混淆和领域差异问题，无需内存缓冲区且参数量少。


<details>
  <summary>Details</summary>
Motivation: 现有多标签类增量学习方法存在计算成本高（全参数微调）、存储开销大（内存缓冲区）以及难以充分解决特征混淆和领域差异的问题。

Method: 提出P2L-CA框架，包含两个核心模块：1）P2L模块使用类别特定提示解耦多标签表示，并利用语言先验稳定语义-视觉对齐；2）CA模块使用轻量级适配器缓解预训练模型与下游任务间的领域差距，增强模型可塑性。

Result: 在MS-COCO和PASCAL VOC的标准和挑战性MLCIL设置上进行广泛实验，P2L-CA不仅显著超越现有最先进方法，还在CIL场景中表现出强大泛化能力，同时仅需极少可训练参数且无需内存缓冲区。

Conclusion: P2L-CA通过参数高效的设计有效解决了多标签类增量学习中的计算成本、存储开销和特征混淆问题，为实际应用提供了可行的解决方案。

Abstract: Multi-label Class-Incremental Learning aims to continuously recognize novel categories in complex scenes where multiple objects co-occur. However, existing approaches often incur high computational costs due to full-parameter fine-tuning and substantial storage overhead from memory buffers, or they struggle to address feature confusion and domain discrepancies adequately. To overcome these limitations, we introduce P2L-CA, a parameter-efficient framework that integrates a Prompt-to-Label module with a Continuous Adapter module. The P2L module leverages class-specific prompts to disentangle multi-label representations while incorporating linguistic priors to enforce stable semantic-visual alignment. Meanwhile, the CA module employs lightweight adapters to mitigate domain gaps between pre-trained models and downstream tasks, thereby enhancing model plasticity. Extensive experiments across standard and challenging MLCIL settings on MS-COCO and PASCAL VOC show that P2L-CA not only achieves substantial improvements over state-of-the-art methods but also demonstrates strong generalization in CIL scenarios, all while requiring minimal trainable parameters and eliminating the need for memory buffers.

</details>


### [103] [RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels](https://arxiv.org/abs/2601.12715)
*Chengzhou Li,Ping Guo,Guanchen Meng,Qi Jia,Jinyuan Liu,Zhu Liu,Xiaokang Liu,Yu Liu,Zhongxuan Luo,Xin Fan*

Main category: cs.CV

TL;DR: 提出RSOD教师-学生框架，通过可靠性评分和对象混合伪标签策略解决声纳图像标注数据有限的问题，在仅5%标注数据下达到与100%标注基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 声纳图像相比自然图像纹理细节少、噪声多，非专家难以区分类别差异，导致无法提供精确标注数据。因此，在标注数据极其有限的情况下设计有效的声纳图像目标检测方法尤为重要。

Method: 提出RSOD教师-学生框架：1) 通过评估教师模型在不同视图下预测的一致性计算可靠性评分；2) 引入对象混合伪标签方法解决声纳图像标注数据不足问题；3) 实施可靠性引导的自适应约束优化学生模型性能。

Result: 在UATD数据集上，仅使用5%标注数据的方法结果可与使用100%标注数据的基线算法相竞争。同时收集了新数据集为声纳领域研究提供更多有价值数据。

Conclusion: RSOD框架通过充分利用未标注数据，在标注数据极其有限的情况下仍能实现良好性能，为解决声纳图像目标检测中的标注数据稀缺问题提供了有效方案。

Abstract: Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.

</details>


### [104] [S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation](https://arxiv.org/abs/2601.12719)
*Lin Zhao,Yushu Wu,Aleksei Lebedev,Dishani Lahiri,Meng Dong,Arpit Sahni,Michael Vasilkovsky,Hao Chen,Ju Hu,Aliaksandr Siarohin,Sergey Tulyakov,Yanzhi Wang,Anil Kag,Yanyu Li*

Main category: cs.CV

TL;DR: S2DiT是一种用于移动设备的高效流式视频生成模型，通过新颖的注意力机制和动态规划搜索实现高质量实时生成


<details>
  <summary>Details</summary>
Motivation: 当前Diffusion Transformers在视频生成方面质量虽好但计算成本过高，无法在移动设备上实现实时或设备端生成

Method: 提出S2DiT模型，采用LinConv Hybrid Attention和Stride Self-Attention高效注意力机制，通过预算感知动态规划搜索设计sandwich结构，并使用2-in-1蒸馏框架将大模型能力迁移到紧凑模型

Result: S2DiT在质量上与最先进的服务器视频模型相当，同时在iPhone上实现超过10 FPS的流式生成

Conclusion: S2DiT成功解决了移动设备上高效高质量视频生成的挑战，为实时设备端视频生成提供了可行方案

Abstract: Diffusion Transformers (DiTs) have recently improved video generation quality. However, their heavy computational cost makes real-time or on-device generation infeasible. In this work, we introduce S2DiT, a Streaming Sandwich Diffusion Transformer designed for efficient, high-fidelity, and streaming video generation on mobile hardware. S2DiT generates more tokens but maintains efficiency with novel efficient attentions: a mixture of LinConv Hybrid Attention (LCHA) and Stride Self-Attention (SSA). Based on this, we uncover the sandwich design via a budget-aware dynamic programming search, achieving superior quality and efficiency. We further propose a 2-in-1 distillation framework that transfers the capacity of large teacher models (e.g., Wan 2.2-14B) to the compact few-step sandwich model. Together, S2DiT achieves quality on par with state-of-the-art server video models, while streaming at over 10 FPS on an iPhone.

</details>


### [105] [DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition](https://arxiv.org/abs/2601.12729)
*Hanyu Zhu,Zhihao Zhan,Yuhang Ming,Liang Li,Dibo Hou,Javier Civera,Wanzeng Kong*

Main category: cs.CV

TL;DR: DC-VLAQ：一种用于视觉地点识别的表示中心框架，通过残差引导的互补融合和向量化局部聚合查询，整合不同视觉基础模型的互补信息，提升在视角变化、光照变化和域偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉地点识别方法大多依赖单一视觉基础模型，忽略了不同模型提供的互补信息。然而，利用这些互补信息会改变token分布，挑战现有基于查询的全局聚合方案的稳定性。

Method: 提出DC-VLAQ框架：1）轻量级残差引导互补融合，以DINOv2特征空间为锚点，通过学习的残差校正注入CLIP的互补语义；2）向量化局部聚合查询，通过编码局部token对可学习查询的残差响应，实现稳定的全局聚合并保留细粒度判别线索。

Result: 在Pitts30k、Tokyo24/7、MSLS、Nordland、SPED和AmsterTime等标准VPR基准测试中，DC-VLAQ始终优于强基线，特别是在挑战性域偏移和长期外观变化下达到最先进性能。

Conclusion: DC-VLAQ通过有效融合不同视觉基础模型的互补信息并采用稳定的全局聚合方案，显著提升了视觉地点识别在复杂环境变化下的鲁棒性和判别能力。

Abstract: One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes.

</details>


### [106] [KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction](https://arxiv.org/abs/2601.12736)
*Qingtian Zhu,Xu Cao,Zhixiang Wang,Yinqiang Zheng,Takafumi Taketomi*

Main category: cs.CV

TL;DR: KaoLRM：利用大型重建模型（LRM）的先验知识，通过FLAME参数化模型和2D高斯泼溅技术实现单视角图像的人脸3D重建，显著提升视角一致性和重建精度


<details>
  <summary>Details</summary>
Motivation: 现有3D形变模型（3DMM）回归器在不同视角下表现不一致，对视角变化敏感，需要提升单视角人脸重建的鲁棒性和跨视角一致性

Method: 1. 利用预训练的LRM三维先验知识；2. 将LRM的三平面特征投影到FLAME参数空间恢复几何；3. 使用与FLAME网格紧密耦合的2D高斯基元建模外观；4. 在LRM渲染管线中集成FLAME-based 2D高斯泼溅

Result: 在受控和野外基准测试中，KaoLRM在重建精度和跨视角一致性方面优于现有方法，对自遮挡和多样视角具有鲁棒性，而现有方法仍对视角变化敏感

Conclusion: KaoLRM通过利用LRM的丰富先验知识并结合参数化3DMM与神经渲染，实现了准确、鲁棒且视角一致的单视角人脸重建，为3D人脸重建提供了新思路

Abstract: We propose KaoLRM to re-target the learned prior of the Large Reconstruction Model (LRM) for parametric 3D face reconstruction from single-view images. Parametric 3D Morphable Models (3DMMs) have been widely used for facial reconstruction due to their compact and interpretable parameterization, yet existing 3DMM regressors often exhibit poor consistency across varying viewpoints. To address this, we harness the pre-trained 3D prior of LRM and incorporate FLAME-based 2D Gaussian Splatting into LRM's rendering pipeline. Specifically, KaoLRM projects LRM's pre-trained triplane features into the FLAME parameter space to recover geometry, and models appearance via 2D Gaussian primitives that are tightly coupled to the FLAME mesh. The rich prior enables the FLAME regressor to be aware of the 3D structure, leading to accurate and robust reconstructions under self-occlusions and diverse viewpoints. Experiments on both controlled and in-the-wild benchmarks demonstrate that KaoLRM achieves superior reconstruction accuracy and cross-view consistency, while existing methods remain sensitive to viewpoint variations. The code is released at https://github.com/CyberAgentAILab/KaoLRM.

</details>


### [107] [SSPFormer: Self-Supervised Pretrained Transformer for MRI Images](https://arxiv.org/abs/2601.12747)
*Jingkai Li,Xiaoze Tian,Yuhang Shen,Jia Wang,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: SSPFormer：一种用于MRI图像的自监督预训练Transformer，通过逆频率投影掩码和频率加权FFT噪声增强解决医学图像领域适应和数据稀缺问题，在分割、超分辨率和去噪任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 预训练Transformer在自然图像处理中表现出色，但直接应用于MRI图像面临两个关键挑战：1）无法适应医学解剖结构的特异性；2）医学数据的隐私性和稀缺性带来的限制。

Method: 提出SSPFormer自监督预训练Transformer，采用两种核心策略：1）逆频率投影掩码，优先重建高频解剖区域以强制结构感知表示学习；2）频率加权FFT噪声增强，在傅里叶域注入生理真实的噪声以增强对MRI伪影的鲁棒性。

Result: 在分割、超分辨率和去噪任务上的广泛实验表明，SSPFormer实现了最先进的性能，充分验证了其捕获细粒度MRI图像保真度和适应临床应用需求的能力。

Conclusion: SSPFormer通过领域特定的自监督预训练策略，成功解决了医学图像领域适应和数据稀缺问题，能够学习领域不变和伪影鲁棒的特征，为临床MRI图像分析提供了有效的解决方案。

Abstract: The pre-trained transformer demonstrates remarkable generalization ability in natural image processing. However, directly transferring it to magnetic resonance images faces two key challenges: the inability to adapt to the specificity of medical anatomical structures and the limitations brought about by the privacy and scarcity of medical data. To address these issues, this paper proposes a Self-Supervised Pretrained Transformer (SSPFormer) for MRI images, which effectively learns domain-specific feature representations of medical images by leveraging unlabeled raw imaging data. To tackle the domain gap and data scarcity, we introduce inverse frequency projection masking, which prioritizes the reconstruction of high-frequency anatomical regions to enforce structure-aware representation learning. Simultaneously, to enhance robustness against real-world MRI artifacts, we employ frequency-weighted FFT noise enhancement that injects physiologically realistic noise into the Fourier domain. Together, these strategies enable the model to learn domain-invariant and artifact-robust features directly from raw scans. Through extensive experiments on segmentation, super-resolution, and denoising tasks, the proposed SSPFormer achieves state-of-the-art performance, fully verifying its ability to capture fine-grained MRI image fidelity and adapt to clinical application requirements.

</details>


### [108] [Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image](https://arxiv.org/abs/2601.12770)
*Shuling Zhao,Dan Xu*

Main category: cs.CV

TL;DR: 提出一种从单张图像重建3D可动画化头部虚拟形象的单次前馈框架，支持实时动画和360度渲染，通过高斯基元建模、3D GAN先验和UV空间特征融合实现高质量重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在大视角变化下容易失效，影响3D虚拟形象的真实感。需要解决单张图像重建3D可动画化头部虚拟形象的挑战，同时支持实时动画和全方位渲染。

Method: 1) 在参数化人脸模型的UV空间表面嵌入高斯基元进行3D头部建模；2) 利用预训练3D GAN提取全局全头部特征并提供多视角监督；3) 利用UV空间和人脸的对称性，将局部细粒度输入图像特征与全局全头部纹理融合。

Result: 实验证明该方法有效实现了高质量的3D全头部建模和实时动画，提升了3D说话虚拟形象的真实感，能够处理大视角变化并保持重建质量。

Conclusion: 该方法成功解决了单张图像重建3D可动画化头部虚拟形象的挑战，通过结合高斯基元建模、3D GAN先验和特征融合技术，实现了高质量、实时动画的全头部虚拟形象重建。

Abstract: Building 3D animatable head avatars from a single image is an important yet challenging problem. Existing methods generally collapse under large camera pose variations, compromising the realism of 3D avatars. In this work, we propose a new framework to tackle the novel setting of one-shot 3D full-head animatable avatar reconstruction in a single feed-forward pass, enabling real-time animation and simultaneous 360$^\circ$ rendering views. To facilitate efficient animation control, we model 3D head avatars with Gaussian primitives embedded on the surface of a parametric face model within the UV space. To obtain knowledge of full-head geometry and textures, we leverage rich 3D full-head priors within a pretrained 3D generative adversarial network (GAN) for global full-head feature extraction and multi-view supervision. To increase the fidelity of the 3D reconstruction of the input image, we take advantage of the symmetric nature of the UV space and human faces to fuse local fine-grained input image features with the global full-head textures. Extensive experiments demonstrate the effectiveness of our method, achieving high-quality 3D full-head modeling as well as real-time animation, thereby improving the realism of 3D talking avatars.

</details>


### [109] [Open Vocabulary Panoptic Segmentation With Retrieval Augmentation](https://arxiv.org/abs/2601.12779)
*Nafis Sadeq,Qingfeng Liu,Mostafa El-Khamy*

Main category: cs.CV

TL;DR: RetCLIP：一种检索增强的全景分割方法，通过构建掩码片段特征数据库，在推理时检索相似特征和类别标签，结合CLIP分数提升未见类别的分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统全景分割方法在特定数据集上训练后，对未见类别的泛化能力有限。开放词汇全景分割需要根据用户输入分割任意类别，但现有方法在未见类别上的性能不足。

Method: 提出RetCLIP方法：1）使用图文对数据构建掩码片段特征数据库；2）推理时，将输入图像的掩码片段特征作为查询键，从数据库中检索相似特征及相关类别标签；3）基于查询特征与检索特征的相似度分配分类分数；4）将检索分类分数与CLIP分数结合得到最终输出。

Result: 在COCO上训练，在ADE20k数据集上达到30.9 PQ、19.3 mAP、44.0 mIoU，相比基线方法（FC-CLIP）分别提升+4.5 PQ、+2.5 mAP、+10.0 mIoU的绝对改进。

Conclusion: RetCLIP通过检索增强机制有效提升了开放词汇全景分割在未见类别上的性能，证明了检索方法在零样本分割任务中的有效性。

Abstract: Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.

</details>


### [110] [SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification](https://arxiv.org/abs/2601.12791)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Hongyuan Shu,Junchu Zhao,Yanjun Huang,Yue Xiu,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: SKANet：一种基于双流架构的认知深度学习框架，通过选择性核与不对称卷积块动态调整感受野，结合SE机制自适应校准多模态特征，显著提升复杂电磁环境下GNSS复合干扰分类性能。


<details>
  <summary>Details</summary>
Motivation: 随着电磁环境日益复杂，GNSS面临越来越复杂的干扰威胁。现有深度学习方法能有效识别基本干扰，但对复合干扰分类困难，因为不同干扰源叠加且特征尺度冲突（瞬态突发信号需要微尺度特征，连续全局信号需要宏尺度特征）。单域方法性能受限，需要新的多模态自适应特征提取方案。

Method: 提出SKANet框架：1）双流架构同时处理时频图像（TFI）和功率谱密度（PSD）；2）多分支选择性核（SK）模块结合不对称卷积块（ACB），动态调整感受野，自适应捕获微尺度瞬态特征和宏尺度频谱趋势；3）融合阶段集成SE机制，自适应重新校准各模态异质特征的贡献度。

Result: 在405,000个样本的数据集上评估，SKANet总体准确率达到96.99%，在复合干扰分类方面表现出优越的鲁棒性，特别是在低干噪比（JNR）条件下性能突出。

Conclusion: SKANet通过动态感受野调整和多模态特征自适应融合，有效解决了复合干扰分类中特征尺度冲突的问题，为复杂电磁环境下的GNSS干扰识别提供了高效解决方案。

Abstract: As the electromagnetic environment becomes increasingly complex, Global Navigation Satellite Systems (GNSS) face growing threats from sophisticated jamming interference. Although Deep Learning (DL) effectively identifies basic interference, classifying compound interference remains difficult due to the superposition of diverse jamming sources. Existing single-domain approaches often suffer from performance degradation because transient burst signals and continuous global signals require conflicting feature extraction scales. We propose the Selective Kernel and Asymmetric convolution Network(SKANet), a cognitive deep learning framework built upon a dual-stream architecture that integrates Time-Frequency Images (TFIs) and Power Spectral Density (PSD). Distinct from conventional fusion methods that rely on static receptive fields, the proposed architecture incorporates a Multi-Branch Selective Kernel (SK) module combined with Asymmetric Convolution Blocks (ACBs). This mechanism enables the network to dynamically adjust its receptive fields, acting as an adaptive filter that simultaneously captures micro-scale transient features and macro-scale spectral trends within entangled compound signals. To complement this spatial-temporal adaptation, a Squeeze-and-Excitation (SE) mechanism is integrated at the fusion stage to adaptively recalibrate the contribution of heterogeneous features from each modality. Evaluations on a dataset of 405,000 samples demonstrate that SKANet achieves an overall accuracy of 96.99\%, exhibiting superior robustness for compound jamming classification, particularly under low Jamming-to-Noise Ratio (JNR) regimes.

</details>


### [111] [PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition](https://arxiv.org/abs/2601.12798)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Yue Xiu,Lu Chen,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: PhyG-MoE：一种基于物理引导的混合专家框架，通过动态调整模型容量来匹配信号复杂度，解决GNSS干扰识别中静态模型计算资源不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 当前GNSS干扰识别中的深度学习模型存在根本性限制：采用固定的计算拓扑结构，无论输入信号的物理熵如何变化。这种刚性导致严重的资源不匹配问题，简单信号和复杂饱和信号消耗相同的处理成本，在资源受限的认知接收器中效率低下。

Method: 提出PhyG-MoE（物理引导的混合专家）框架，采用基于频谱的门控机制，根据信号频谱特征纠缠程度进行路由。系统包含高容量的TransNeXt专家（用于处理复杂饱和场景）和轻量级专家（处理基础信号），实现模型容量与信号复杂度的动态对齐。

Result: 在21种干扰类别上的评估显示，PhyG-MoE达到97.58%的整体准确率。该框架显著降低了计算开销，同时保持性能不下降，解决了静态计算与动态电磁环境之间的内在冲突。

Conclusion: PhyG-MoE通过动态调整模型容量来匹配信号复杂度，为资源受限的认知接收器提供了可行的解决方案，有效解决了GNSS干扰识别中静态模型的计算资源不匹配问题。

Abstract: Complex electromagnetic interference increasingly compromises Global Navigation Satellite Systems (GNSS), threatening the reliability of Space-Air-Ground Integrated Networks (SAGIN). Although deep learning has advanced interference recognition, current static models suffer from a \textbf{fundamental limitation}: they impose a fixed computational topology regardless of the input's physical entropy. This rigidity leads to severe resource mismatch, where simple primitives consume the same processing cost as chaotic, saturated mixtures. To resolve this, this paper introduces PhyG-MoE (Physics-Guided Mixture-of-Experts), a framework designed to \textbf{dynamically align model capacity with signal complexity}. Unlike static architectures, the proposed system employs a spectrum-based gating mechanism that routes signals based on their spectral feature entanglement. A high-capacity TransNeXt expert is activated on-demand to disentangle complex features in saturated scenarios, while lightweight experts handle fundamental signals to minimize latency. Evaluations on 21 jamming categories demonstrate that PhyG-MoE achieves an overall accuracy of 97.58\%. By resolving the intrinsic conflict between static computing and dynamic electromagnetic environments, the proposed framework significantly reduces computational overhead without performance degradation, offering a viable solution for resource-constrained cognitive receivers.

</details>


### [112] [Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data](https://arxiv.org/abs/2601.12809)
*Takaki Yamamoto,Chihiro Noguchi,Toshihiro Tanizawa*

Main category: cs.CV

TL;DR: 该研究使用可控的1D图像-文本测试平台探究CLIP风格模型中左右关系理解的涌现机制，发现标签多样性是泛化的主要驱动力，并通过注意力分解揭示了位置与词元嵌入的交互如何打破左右对称性。


<details>
  <summary>Details</summary>
Motivation: 空间理解是视觉语言模型的关键挑战，但尚不清楚这种理解是否真正获得以及通过何种机制获得。研究旨在探究Transformer-based视觉和文本编码器在CLIP风格对比目标训练下，左右关系理解如何涌现。

Method: 使用轻量级Transformer-based视觉和文本编码器端到端训练，处理单物体和双物体场景的配对描述。通过系统变化标签和布局多样性评估泛化能力，并进行注意力分解分析位置嵌入和词元嵌入的交互作用。

Result: 对比训练能够学习左右关系，标签多样性（而非布局多样性）是泛化的主要驱动力。注意力分解显示位置嵌入和词元嵌入的交互诱导了水平注意力梯度，打破了编码器的左右对称性；消除这一贡献会显著降低左右辨别能力。

Conclusion: 研究提供了CLIP风格模型何时以及如何获得关系能力的机制性洞察，揭示了标签多样性在空间关系学习中的关键作用和位置-词元交互在打破对称性中的机制作用。

Abstract: Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.

</details>


### [113] [CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting](https://arxiv.org/abs/2601.12814)
*Yu-Jen Tseng,Chia-Hao Kao,Jing-Zhong Chen,Alessandro Gnutti,Shao-Yuan Lo,Yen-Yu Lin,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 首个统一框架，用于3D高斯泼溅的率失真优化压缩与分割，通过轻量级隐式神经表示超先验和压缩引导的分割学习，在保持高质量渲染的同时显著降低传输成本。


<details>
  <summary>Details</summary>
Motivation: 虽然3D高斯泼溅在实时渲染和语义场景理解方面都有效，但先前工作大多独立处理这些任务，缺乏联合考虑。本研究旨在将语义学习整合到压缩流程中，支持解码器端的场景编辑和操作等应用，超越传统的场景重建和视图合成。

Method: 1) 采用轻量级隐式神经表示超先验，高效编码颜色和语义属性，避免昂贵的基于网格的超先验；2) 开发压缩引导的分割学习，包括量化感知训练以增强特征可分性，以及质量感知加权机制以抑制不可靠的高斯基元。

Result: 在LERF和3D-OVS数据集上的大量实验表明，该方法显著降低了传输成本，同时保持了高渲染质量和强大的分割性能。

Conclusion: 提出了首个统一的率失真优化3D高斯泼溅压缩与分割框架，通过集成语义学习和轻量级超先验，实现了高效的编码和高质量的解码器端应用，为3D场景的压缩和语义理解提供了新方向。

Abstract: We present the first unified framework for rate-distortion-optimized compression and segmentation of 3D Gaussian Splatting (3DGS). While 3DGS has proven effective for both real-time rendering and semantic scene understanding, prior works have largely treated these tasks independently, leaving their joint consideration unexplored. Inspired by recent advances in rate-distortion-optimized 3DGS compression, this work integrates semantic learning into the compression pipeline to support decoder-side applications--such as scene editing and manipulation--that extend beyond traditional scene reconstruction and view synthesis. Our scheme features a lightweight implicit neural representation-based hyperprior, enabling efficient entropy coding of both color and semantic attributes while avoiding costly grid-based hyperprior as seen in many prior works. To facilitate compression and segmentation, we further develop compression-guided segmentation learning, consisting of quantization-aware training to enhance feature separability and a quality-aware weighting mechanism to suppress unreliable Gaussian primitives. Extensive experiments on the LERF and 3D-OVS datasets demonstrate that our approach significantly reduces transmission cost while preserving high rendering quality and strong segmentation performance.

</details>


### [114] [TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement](https://arxiv.org/abs/2601.12823)
*Belal Shaheen,Minh-Hieu Nguyen,Bach-Thuan Bui,Shubham,Tim Wu,Michael Fairley,Matthew David Zane,Michael Wu,James Tompkin*

Main category: cs.CV

TL;DR: TreeDGS：基于3D高斯泼溅的航拍图像重建方法，用于从稀疏航拍图像中精确测量树木胸径（DBH），在10个样地的评估中达到4.79cm RMSE，优于激光雷达基线（7.91cm RMSE）。


<details>
  <summary>Details</summary>
Motivation: 航拍遥感虽能高效进行大范围勘测，但在复杂自然场景中难以实现精确的直接物体级测量。尽管NeRF和3D高斯泼溅等学习辐射场表示提升了重建保真度和几何密度，但航拍测量树木胸径（DBH）仍具挑战性：树干在航拍扫描中距离远、图像观测稀疏，传统重建方法难以充分约束胸高处的树干几何。

Method: 提出TreeDGS方法：1）使用SfM-MVS进行初始化并优化3D高斯泼溅作为连续、可密集化的场景表示；2）通过RaDe-GS的深度感知累积不透明度积分从高斯场提取密集点集，并为每个样本分配多视角不透明度可靠性分数；3）从隔离的树干点使用不透明度加权实心圆拟合估计DBH。

Result: 在10个具有实地测量DBH的样地上评估，TreeDGS达到4.79cm RMSE（约相当于该地面采样距离下的2.6像素），优于最先进的激光雷达基线（7.91cm RMSE），表明基于泼溅的密集化几何能够实现准确、低成本的航拍DBH测量。

Conclusion: TreeDGS证明了3D高斯泼溅作为连续、可密集化场景表示的潜力，能够从稀疏航拍图像中重建足够精确的树干几何以进行胸径测量，为低成本、大范围的森林资源监测提供了新方法。

Abstract: Aerial remote sensing enables efficient large-area surveying, but accurate direct object-level measurement remains difficult in complex natural scenes. Recent advancements in 3D vision, particularly learned radiance-field representations such as NeRF and 3D Gaussian Splatting, have begun to raise the ceiling on reconstruction fidelity and densifiable geometry from posed imagery. Nevertheless, direct aerial measurement of important natural attributes such as tree diameter at breast height (DBH) remains challenging. Trunks in aerial forest scans are distant and sparsely observed in image views: at typical operating altitudes, stems may span only a few pixels. With these constraints, conventional reconstruction methods leave breast-height trunk geometry weakly constrained. We present TreeDGS, an aerial image reconstruction method that leverages 3D Gaussian Splatting as a continuous, densifiable scene representation for trunk measurement. After SfM-MVS initialization and Gaussian optimization, we extract a dense point set from the Gaussian field using RaDe-GS's depth-aware cumulative-opacity integration and associate each sample with a multi-view opacity reliability score. We then estimate DBH from trunk-isolated points using opacity-weighted solid-circle fitting. Evaluated on 10 plots with field-measured DBH, TreeDGS reaches 4.79,cm RMSE (about 2.6 pixels at this GSD) and outperforms a state-of-the-art LiDAR baseline (7.91,cm RMSE), demonstrating that densified splat-based geometry can enable accurate, low-cost aerial DBH measurement.

</details>


### [115] [Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation](https://arxiv.org/abs/2601.12876)
*Zhenxuan Lu,Zhihua Xu,Zhijing Yang,Feng Gao,Yongyi Lu,Keze Wang,Tianshui Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种名为THFEM的新框架，将音频驱动说话头生成模型与语音保留面部表情操纵技术相结合，通过相邻帧学习策略提高生成帧的连续性和质量，从而在改变面部表情时更好地保持口型同步。


<details>
  <summary>Details</summary>
Motivation: 现有的语音保留面部表情操纵技术在处理口型同步方面存在困难，因为面部表情和嘴部形状之间存在复杂的相互作用。音频驱动说话头生成模型在合成精确口型运动方面具有优势，但直接应用于多帧生成会损害图像真实性和表情保真度。

Method: 提出THFEM框架，整合AD-THG模型和SPFEM技术。开发相邻帧学习策略，微调AD-THG模型以预测连续帧序列，使模型能够利用相邻帧信息，显著提高测试时的图像质量。

Result: 实验评估表明，该框架在表情操纵过程中有效保持了嘴部形状，证明了将AD-THG与SPFEM集成的显著优势，改善了口型同步和图像质量。

Conclusion: 通过整合音频驱动说话头生成模型和相邻帧学习策略，THFEM框架成功解决了语音保留面部表情操纵中的口型同步问题，为表情操纵提供了更高质量的解决方案。

Abstract: Speech-Preserving Facial Expression Manipulation (SPFEM) is an innovative technique aimed at altering facial expressions in images and videos while retaining the original mouth movements. Despite advancements, SPFEM still struggles with accurate lip synchronization due to the complex interplay between facial expressions and mouth shapes. Capitalizing on the advanced capabilities of audio-driven talking head generation (AD-THG) models in synthesizing precise lip movements, our research introduces a novel integration of these models with SPFEM. We present a new framework, Talking Head Facial Expression Manipulation (THFEM), which utilizes AD-THG models to generate frames with accurately synchronized lip movements from audio inputs and SPFEM-altered images. However, increasing the number of frames generated by AD-THG models tends to compromise the realism and expression fidelity of the images. To counter this, we develop an adjacent frame learning strategy that finetunes AD-THG models to predict sequences of consecutive frames. This strategy enables the models to incorporate information from neighboring frames, significantly improving image quality during testing. Our extensive experimental evaluations demonstrate that this framework effectively preserves mouth shapes during expression manipulations, highlighting the substantial benefits of integrating AD-THG with SPFEM.

</details>


### [116] [Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning](https://arxiv.org/abs/2601.12889)
*Nazibul Basar Ayon,Abdul Hasib,Md. Faishal Ahmed,Md. Sadiqur Rahman,Kamrul Islam,T. M. Mehrab Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 提出集成深度学习框架，结合VGG16、ResNet50和InceptionV3，通过优化加权平均实现牛结节性皮肤病和口蹄疫的同时检测，准确率达98.2%，解决症状重叠的诊断难题。


<details>
  <summary>Details</summary>
Motivation: 牛结节性皮肤病和口蹄疫是高度传染性病毒疾病，造成重大经济损失。视觉诊断因症状重叠（包括相互之间以及与良性状况如昆虫叮咬或化学烧伤）而复杂化，阻碍及时控制措施。

Method: 使用来自印度、巴西和美国18个农场的10,516张专家标注图像数据集，提出集成深度学习框架，整合VGG16、ResNet50和InceptionV3三种架构，采用优化加权平均策略进行多疾病检测。

Result: 模型达到最先进的98.2%准确率，宏平均精确率98.2%、召回率98.1%、F1分数98.1%、AUC-ROC 99.5%，有效解决症状重叠的多疾病检测挑战。

Conclusion: 该集成深度学习框架能够实现早期、精确、自动化的牛结节性皮肤病和口蹄疫诊断，有潜力改善疾病管理，支持全球农业可持续性，并设计用于未来在资源有限环境中的部署。

Abstract: Lumpy Skin Disease (LSD) and Foot-and-Mouth Disease (FMD) are highly contagious viral diseases affecting cattle, causing significant economic losses and welfare challenges. Their visual diagnosis is complicated by significant symptom overlap with each other and with benign conditions like insect bites or chemical burns, hindering timely control measures. Leveraging a comprehensive dataset of 10,516 expert-annotated images from 18 farms across India, Brazil, and the USA, this study presents a novel Ensemble Deep Learning framework integrating VGG16, ResNet50, and InceptionV3 with optimized weighted averaging for simultaneous LSD and FMD detection. The model achieves a state-of-the-art accuracy of 98.2\%, with macro-averaged precision of 98.2\%, recall of 98.1\%, F1-score of 98.1\%, and an AUC-ROC of 99.5\%. This approach uniquely addresses the critical challenge of symptom overlap in multi-disease detection, enabling early, precise, and automated diagnosis. This tool has the potential to enhance disease management, support global agricultural sustainability, and is designed for future deployment in resource-limited settings.

</details>


### [117] [Membership Inference Test: Auditing Training Data in Object Classification Models](https://arxiv.org/abs/2601.12929)
*Gonzalo Mancera,Daniel DeAlcala,Aythami Morales,Ruben Tolosana,Julian Fierrez*

Main category: cs.CV

TL;DR: 该研究分析了成员推理测试（MINT）在物体识别领域的性能，提出了专门针对MINT模型的架构，通过实验在三个公共数据库上验证了架构有效性，实现了70%-80%的精度。


<details>
  <summary>Details</summary>
Motivation: 研究动机是分析成员推理测试在物体识别领域的性能，解决如何确定给定数据是否在训练阶段被使用的问题。针对物体识别领域的复杂性，需要开发专门优化的MINT架构来提高性能和效率。

Method: 方法包括：1）提出专门针对物体识别领域的MINT模型架构；2）利用卷积层捕捉和建模训练过程中的激活模式；3）构建包含物体检测模型、嵌入提取器和MINT模块的实验系统；4）在三个公共数据库（总计超过174K图像）上进行实验；5）分析不同检测模块层深度对MINT性能的影响。

Result: 实验结果：1）能够识别用于测试和训练的数据；2）精度达到70%-80%，具体取决于输入MINT模块的检测模块层深度；3）分析了影响MINT模块性能的因素；4）深入探讨了训练过程透明化的贡献因素。

Conclusion: 结论：提出的专门针对物体识别领域的MINT架构能够有效识别训练数据使用情况，精度可达70%-80%。研究为理解MINT性能影响因素和实现更透明的训练过程提供了重要见解。

Abstract: In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.

</details>


### [118] [QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning](https://arxiv.org/abs/2601.12936)
*Tianran Ouyang,Xingping Dong,Jing Zhang,Mang Ye,Jun Chen,Bo Du*

Main category: cs.CV

TL;DR: QASA是一种质量引导的K自适应槽注意力方法，通过解耦槽选择与重建、引入无监督槽质量度量、设计质量引导槽选择方案，解决了现有K自适应方法中槽绑定质量差和优化目标冲突的问题。


<details>
  <summary>Details</summary>
Motivation: 现有K自适应槽注意力方法存在两个主要问题：1) 没有显式约束槽绑定质量，导致低质量槽引起特征归属模糊；2) 在重建目标中添加槽数量惩罚会创建相互冲突的优化目标（减少活跃槽数量 vs 保持重建保真度），导致性能显著落后于K固定基线方法。

Method: 提出质量引导的K自适应槽注意力(QASA)：1) 将槽选择与重建解耦，消除两个目标间的相互约束；2) 提出无监督的槽质量度量来评估每个槽的质量，为细粒度槽-对象绑定提供原则性信号；3) 基于此度量设计质量引导槽选择方案，动态选择高质量槽子集，输入到新设计的门控解码器进行训练重建；4) 推理时通过槽注意力上的令牌级竞争获得K自适应结果。

Result: QASA在真实和合成数据集上显著优于现有K自适应方法。在真实世界数据集上，QASA甚至超越了K固定方法。

Conclusion: QASA通过质量引导的槽选择机制有效解决了K自适应槽注意力中的关键挑战，在保持重建质量的同时实现动态槽数量调整，在真实数据集上超越了传统K固定方法，为无监督对象中心学习提供了更灵活的解决方案。

Abstract: Slot Attention, an approach that binds different objects in a scene to a set of "slots", has become a leading method in unsupervised object-centric learning. Most methods assume a fixed slot count K, and to better accommodate the dynamic nature of object cardinality, a few works have explored K-adaptive variants. However, existing K-adaptive methods still suffer from two limitations. First, they do not explicitly constrain slot-binding quality, so low-quality slots lead to ambiguous feature attribution. Second, adding a slot-count penalty to the reconstruction objective creates conflicting optimization goals between reducing the number of active slots and maintaining reconstruction fidelity. As a result, they still lag significantly behind strong K-fixed baselines. To address these challenges, we propose Quality-Guided K-Adaptive Slot Attention (QASA). First, we decouple slot selection from reconstruction, eliminating the mutual constraints between the two objectives. Then, we propose an unsupervised Slot-Quality metric to assess per-slot quality, providing a principled signal for fine-grained slot--object binding. Based on this metric, we design a Quality-Guided Slot Selection scheme that dynamically selects a subset of high-quality slots and feeds them into our newly designed gated decoder for reconstruction during training. At inference, token-wise competition on slot attention yields a K-adaptive outcome. Experiments show that QASA substantially outperforms existing K-adaptive methods on both real and synthetic datasets. Moreover, on real-world datasets QASA surpasses K-fixed methods.

</details>


### [119] [GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation](https://arxiv.org/abs/2601.12948)
*Riccardo Catalini,Davide Di Nucci,Guido Borghi,Davide Davoli,Lorenzo Garattoni,Giampiero Francesca,Yuki Kawana,Roberto Vezzani*

Main category: cs.CV

TL;DR: GazeD是一种从单张RGB图像联合估计3D注视方向和人体姿态的新方法，利用扩散模型处理不确定性，生成多个合理的3D注视和姿态假设，在三个基准数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理3D注视估计和人体姿态估计，忽略了二者之间的密切关系。同时，从单张RGB图像进行3D注视估计存在固有的不确定性，需要能够处理多假设的方法。

Method: 提出GazeD方法：1) 利用扩散模型处理不确定性，基于输入图像提取的2D上下文信息生成多个合理的3D注视和姿态假设；2) 将去噪过程条件化于2D姿态、主体周围环境和场景上下文；3) 引入新颖的3D注视表示方法，将其作为距离眼睛固定距离的额外身体关节点；4) 联合去噪注视和姿态，利用二者之间的相关性。

Result: 在三个基准数据集上的评估表明，GazeD在3D注视估计方面达到了最先进的性能，甚至超过了依赖时间信息的方法。该方法能够从单张RGB图像生成多个合理的3D注视和姿态假设。

Conclusion: GazeD成功展示了扩散模型在联合3D注视和姿态估计任务中的有效性，通过将注视表示为额外身体关节并利用扩散模型处理不确定性，实现了从单张RGB图像的高性能多假设生成。

Abstract: We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at https://aimagelab.ing.unimore.it/go/gazed.

</details>


### [120] [StyMam: A Mamba-Based Generator for Artistic Style Transfer](https://arxiv.org/abs/2601.12954)
*Zhou Hong,Rongsheng Hu,Yicheng Di,Xiaolong Xu,Ning Dong,Yihua Shao,Run Ling,Yun Wang,Juqin Wang,Zhanjie Zhang,Ao Ma*

Main category: cs.CV

TL;DR: 本文提出了一种基于Mamba的生成器StyMam，用于解决图像风格迁移中存在的伪影、不和谐模式、内容结构保持不足和推理速度慢的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像风格迁移方法主要基于GAN或稳定扩散(SD)。GAN方法使用CNN或Transformer难以同时捕捉局部和全局依赖关系，导致伪影和不和谐模式；SD方法减少了这些问题但往往无法保持内容结构且推理速度慢。需要一种能同时解决这些问题的方案。

Method: 提出基于Mamba的生成器StyMam，包含两个核心模块：1) 残差双路径条带扫描机制，用于高效捕捉局部纹理特征；2) 通道重加权空间注意力模块，用于建模全局依赖关系。

Result: 广泛的定性和定量实验表明，所提方法在质量和速度上都优于现有最先进算法，能生成高质量的风格化图像而不引入伪影和不和谐模式。

Conclusion: 通过重新审视GAN架构并引入Mamba-based生成器，成功解决了图像风格迁移中的关键问题，在保持内容结构的同时实现了高质量、高效率的风格迁移。

Abstract: Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.

</details>


### [121] [Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation](https://arxiv.org/abs/2601.12964)
*John Waithaka,Gustave Bwirayesu,Moise Busogi*

Main category: cs.CV

TL;DR: 提出了一种空间亲和性组件，可将高分辨率遥感图像融入自监督预训练，以增强中分辨率图像的表示学习和下游分割性能


<details>
  <summary>Details</summary>
Motivation: 当前遥感自监督预训练主要使用中分辨率图像数据集，但随着高分辨率数据集的发布，需要研究如何利用高分辨率数据来增强中分辨率图像的表示学习和下游任务性能

Method: 设计了一个空间亲和性组件，可集成到现有的自监督学习框架中，利用高分辨率图像来学习更好的中分辨率图像表示

Result: 在两个自监督学习框架上测试表明，该方法优于仅使用高分辨率或中分辨率图像单独预训练的模型

Conclusion: 通过空间亲和性组件将高分辨率数据融入自监督预训练，能够有效提升中分辨率图像的表示质量和下游分割任务的性能

Abstract: Self-supervised pretraining in remote sensing is mostly done using mid-spatial resolution (MR) image datasets due to their high availability. Given the release of high-resolution (HR) datasets, we ask how HR datasets can be included in self-supervised pretraining to enhance MR image representation learning and downstream segmentation performance on MR tasks. We design a spatial affinity component that can be added to existing self-supervised learning frameworks and that uses HR imagery to learn better representations of MR imagery. We test the spatial affinity component on two self-supervised learning frameworks and show that it outperforms models pretrained on HR or MR images alone.

</details>


### [122] [From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models](https://arxiv.org/abs/2601.13166)
*Pedro M. Gordaliza,Jaume Banus,Benoît Gérin,Maxence Wynen,Nataliia Molchanova,Jonas Richiardi,Meritxell Bach Cuadra*

Main category: cs.CV

TL;DR: 该论文介绍了在MICCAI 2025的SSL3D和FOMO25挑战赛中排名第一的解决方案，该方案使用U-Net CNN架构结合解剖学先验和神经影像领域知识，相比基于transformer的方法训练速度快1-2个数量级且模型小10倍。


<details>
  <summary>Details</summary>
Motivation: 开发用于医学图像分析的基础模型对于克服放射学任务的独特挑战至关重要。SSL3D和FOMO25是首个针对3D脑MRI的此类挑战赛。

Method: 采用U-Net CNN架构，结合利用解剖学先验和神经影像领域知识的策略。模型训练速度比基于transformer的方法快1-2个数量级，模型大小小10倍。

Result: 在MICCAI 2025的SSL3D和FOMO25挑战赛的两个赛道中均排名第一。模型已开源在GitHub上。

Conclusion: U-Net CNN架构结合领域知识的方法在3D脑MRI分析任务中表现出色，在效率和性能上都优于基于transformer的方法，为医学图像分析基础模型开发提供了有效方案。

Abstract: Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.

</details>


### [123] [Think3D: Thinking with Space for Spatial Reasoning](https://arxiv.org/abs/2601.13029)
*Zaibin Zhang,Yuhan Wu,Lianjie Jia,Yifan Wang,Zhongbo Zhang,Yijiang Li,Binghao Ran,Fuxi Zhang,Zhuohan Sun,Zhenfei Yin,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: Think3D框架通过3D重建模型和交互式空间操作，使视觉大模型具备3D空间推理能力，无需额外训练即可显著提升空间推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉大模型本质上是2D感知器，缺乏真正的3D空间推理能力，而理解物理世界需要空间智能（几何、透视和空间关系理解）。

Method: 利用3D重建模型从图像/视频恢复点云和相机位姿，通过相机操作和自我/全局视角切换实现交互式3D思维链，小模型使用强化学习策略选择信息丰富的视点和操作。

Result: Think3D显著提升了GPT-4.1和Gemini 2.5 Pro等先进模型的空间推理性能：BLINK Multi-view和MindCube平均提升+7.8%，VSI-Bench提升+4.7%。小模型通过RL策略将工具使用收益从+0.7%提升到+6.8%。

Conclusion: 无需训练的、工具增强的空间探索是实现多模态智能体更灵活、类人3D推理的可行路径，建立了多模态智能的新维度。

Abstract: Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.

</details>


### [124] [GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure](https://arxiv.org/abs/2601.13052)
*Antoine Carreaud,Shanci Li,Malo De Lacour,Digre Frinde,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

TL;DR: GridNet-HD是一个用于电力基础设施3D语义分割的多模态数据集，结合高密度LiDAR和高分辨率倾斜影像，包含7,694张图像和25亿个点，标注为11个类别，提供基准模型和代码。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏同时提供高密度LiDAR、高分辨率倾斜影像和3D语义标注的公开电力线路资产数据集，限制了多模态融合方法的研究和应用。

Method: 构建包含7,694张图像和2.5亿个点的多模态数据集，标注11个语义类别，提供预定义的数据划分和mIoU评估指标，建立单模态（仅LiDAR、仅图像）和多模态融合的基准模型。

Result: 在GridNet-HD数据集上，多模态融合模型比最佳单模态基准模型提升了+5.55 mIoU，证明了几何信息和外观信息的互补性。

Conclusion: GridNet-HD填补了电力基础设施多模态3D语义分割数据集的空白，展示了多模态融合在电力线路资产识别中的优势，数据集、基准模型和代码已公开。

Abstract: This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: https://huggingface.co/collections/heig-vd-geo/gridnet-hd.

</details>


### [125] [MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic](https://arxiv.org/abs/2601.13331)
*Wei Wang,Quoc-Toan Ly,Chong Yu,Jun Bai*

Main category: cs.CV

TL;DR: MultiST是一个统一的多模态空间转录组学框架，通过交叉注意力融合空间拓扑、基因表达和组织形态学特征，以解决现有方法在整合组织形态与分子谱方面的不足，获得更清晰的空间域边界。


<details>
  <summary>Details</summary>
Motivation: 现有空间转录组学方法缺乏有效的组织形态学与分子谱整合，通常采用浅层融合策略或完全忽略组织图像，这限制了它们解析模糊空间域边界的能力。

Method: MultiST采用基于交叉注意力的融合策略，联合建模空间拓扑、基因表达和组织形态学。使用基于图的基因编码器结合对抗对齐学习鲁棒的空间表示，同时整合颜色归一化的组织学特征来捕获分子-形态学依赖关系并细化域边界。

Result: 在涵盖两个器官（人脑皮层和乳腺癌组织）的13个不同ST数据集上评估，MultiST产生的空间域边界比现有方法更清晰、更连贯，导致更稳定的伪时间轨迹和更具生物学可解释性的细胞-细胞相互作用模式。

Conclusion: MultiST通过有效的多模态融合成功解决了空间转录组学中形态学与分子谱整合的挑战，提供了更精确的空间域识别和生物学洞见，框架和源代码已开源。

Abstract: Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at https://github.com/LabJunBMI/MultiST.git.

</details>


### [126] [PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain](https://arxiv.org/abs/2601.13128)
*Sung Ju Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: PhaseMark：一种基于VAE潜在频率域相位调制的单次优化免费水印框架，比基于优化的方法快数千倍，同时保持卓越的抗攻击能力


<details>
  <summary>Details</summary>
Motivation: 潜在扩散模型（LDMs）生成超逼真图像的普及需要鲁棒的水印技术，但现有的后处理方法由于迭代优化或反演过程而速度极慢

Method: PhaseMark是一种单次、无需优化的框架，直接在VAE潜在频率域调制相位，分析了四种调制变体，揭示了性能与质量之间的权衡

Result: PhaseMark比基于优化的技术快数千倍，同时实现了最先进的抗攻击能力（包括再生攻击），且不降低图像质量

Conclusion: PhaseMark展示了一种新范式，通过利用内在潜在属性实现高效、鲁棒的水印技术

Abstract: The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.

</details>


### [127] [GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning](https://arxiv.org/abs/2601.13132)
*Kim Yu-Ji,Dahye Lee,Kim Jun-Seong,GeonU Kim,Nam Hyeon-Woo,Yongjin Kwon,Yu-Chiang Frank Wang,Jaesung Choe,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: GaussExplorer：基于3D高斯溅射的具身探索与推理框架，通过视觉语言模型实现复杂语言查询驱动的3D场景探索


<details>
  <summary>Details</summary>
Motivation: 现有语言嵌入3D高斯溅射方法只能处理简单文本查询，无法处理复杂组合语言查询；基于对象中心RGB-D结构化记忆的方法受限于预定义视角。需要一种能够处理复杂查询并支持自由视角探索的方法。

Method: 在3D高斯溅射基础上引入视觉语言模型，首先识别与查询问题最相关的预捕获图像，然后将其调整到新视角以更好地捕捉视觉信息供VLM推理。

Result: 在多个基准测试中优于现有方法，证明了VLM推理与3DGS集成在具身任务中的有效性。

Conclusion: GaussExplorer成功整合了VLM推理与3DGS，实现了复杂语言查询驱动的3D场景探索，为具身智能提供了新解决方案。

Abstract: We present GaussExplorer, a framework for embodied exploration and reasoning built on 3D Gaussian Splatting (3DGS). While prior approaches to language-embedded 3DGS have made meaningful progress in aligning simple text queries with Gaussian embeddings, they are generally optimized for relatively simple queries and struggle to interpret more complex, compositional language queries. Alternative studies based on object-centric RGB-D structured memories provide spatial grounding but are constrained by pre-fixed viewpoints. To address these issues, GaussExplorer introduces Vision-Language Models (VLMs) on top of 3DGS to enable question-driven exploration and reasoning within 3D scenes. We first identify pre-captured images that are most correlated with the query question, and subsequently adjust them into novel viewpoints to more accurately capture visual information for better reasoning by VLMs. Experiments show that ours outperforms existing methods on several benchmarks, demonstrating the effectiveness of integrating VLM-based reasoning with 3DGS for embodied tasks.

</details>


### [128] [CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks](https://arxiv.org/abs/2601.13133)
*Mingshuang Luo,Ruibing Hou,Bo Chao,Hong Chang,Zimo Liu,Yaowei Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: CLASP是一个用于人体中心视觉任务的无监督预训练框架，利用CLIP生成多级语义伪标签，通过提示控制专家混合模块动态适应不同下游任务，在多个人体中心基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着大规模无标签人体图像数据集的涌现，需要一种通用的无监督预训练模型来支持多样化的人体中心下游任务。现有方法缺乏对多级语义信息的有效利用，且难以适应不同任务对语义粒度的不同需求。

Method: 1. 利用CLIP生成低层（身体部位）和高层（属性）语义伪标签；2. 将这些多级语义线索整合到学习的视觉表示中；3. 引入提示控制专家混合模块，根据任务特定提示动态调整特征提取；4. 采用多任务预训练策略，由CLIP衍生的部位和属性级伪标签指导表示学习过程。

Result: 在多个基准测试上的广泛实验表明，CLASP持续优于现有的无监督预训练方法，推动了人体中心视觉分析领域的发展。

Conclusion: CLASP通过整合CLIP生成的多级语义伪标签和动态适应的专家混合模块，为人体中心视觉任务提供了一个强大且通用的无监督预训练框架，能够有效支持多样化的下游应用。

Abstract: Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.

</details>


### [129] [TVWorld: Foundations for Remote-Control TV Agents](https://arxiv.org/abs/2601.13142)
*Zhantao Ma,Quanfeng Lu,Shuai Zhong,Dahai Yu,Ping Luo,Michael K. Ng*

Main category: cs.CV

TL;DR: 该论文提出了TVWorld基准和TVTheseus模型，用于评估和改进大视觉语言模型在电视遥控导航任务中的能力，解决了现有模型在拓扑感知和长时程导航方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型主要关注点选交互，而日常电视使用中常见的遥控交互能力尚未得到充分探索。需要建立一个可重复、免部署的评估基准来系统评估模型在电视导航任务中的能力。

Method: 1) 提出TVWorld离线图结构抽象，模拟真实电视导航环境；2) 构建两个互补基准：TVWorld-N用于拓扑感知导航，TVWorld-G用于焦点感知定位；3) 提出拓扑感知训练框架，将拓扑意识注入大视觉语言模型；4) 开发TVTheseus专门用于电视导航的基础模型。

Result: TVTheseus在TVWorld-N基准上达到68.3%的成功率，超越了Gemini 3 Flash等强闭源基线模型，建立了最先进的性能。分析揭示了现有智能体在基于焦点的长时程电视导航中拓扑意识不足的关键限制。

Conclusion: 该研究填补了电视遥控交互评估的空白，提出的拓扑感知训练框架有效提升了模型在复杂电视导航任务中的性能，为开发有效的电视使用智能体提供了有价值的见解。

Abstract: Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \textbf{TVWorld-N} for topology-aware navigation and \textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.

</details>


### [130] [ICo3D: An Interactive Conversational 3D Virtual Human](https://arxiv.org/abs/2601.13148)
*Richard Shaw,Youngkyoon Jang,Athanasios Papaioannou,Arthur Moreau,Helisa Dhamo,Zhensong Zhang,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: ICo3D是一种生成交互式、对话式、逼真3D虚拟人的方法，通过多视角采集创建可动画的3D面部和动态3D身体模型，使用高斯图元渲染，结合LLM实现对话能力，音频驱动面部动画实现精确同步。


<details>
  <summary>Details</summary>
Motivation: 开发一个完全集成的虚拟化身体验，支持在沉浸式环境中进行口头和书面形式的交互，适用于游戏、虚拟助手和个性化教育等多个领域。

Method: 基于多视角采集创建可动画的3D面部模型和动态3D身体模型，两者均使用高斯图元渲染。合并两个模型形成逼真的虚拟人化身。采用LLM赋予对话能力，使用音频语音作为驱动信号来动画面部模型。改进了动态高斯模型：SWinGS++用于身体重建，HeadGaS++用于面部重建，并提供无伪影的面部和身体模型合并方案。

Result: 提出了ICo3D系统，能够生成交互式、对话式、逼真的3D虚拟人化身，支持实时用户交互。展示了完整系统的演示，包括多个实时与3D化身对话的使用案例。

Conclusion: ICo3D提供了一个完全集成的虚拟化身体验，支持沉浸式环境中的口头和书面交互，在游戏、虚拟助手、个性化教育等领域具有广泛应用前景。

Abstract: This work presents Interactive Conversational 3D Virtual Human (ICo3D), a method for generating an interactive, conversational, and photorealistic 3D human avatar. Based on multi-view captures of a subject, we create an animatable 3D face model and a dynamic 3D body model, both rendered by splatting Gaussian primitives. Once merged together, they represent a lifelike virtual human avatar suitable for real-time user interactions. We equip our avatar with an LLM for conversational ability. During conversation, the audio speech of the avatar is used as a driving signal to animate the face model, enabling precise synchronization. We describe improvements to our dynamic Gaussian models that enhance photorealism: SWinGS++ for body reconstruction and HeadGaS++ for face reconstruction, and provide as well a solution to merge the separate face and body models without artifacts. We also present a demo of the complete system, showcasing several use cases of real-time conversation with the 3D avatar. Our approach offers a fully integrated virtual avatar experience, supporting both oral and written form interactions in immersive environments. ICo3D is applicable to a wide range of fields, including gaming, virtual assistance, and personalized education, among others. Project page: https://ico3d.github.io/

</details>


### [131] [GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction](https://arxiv.org/abs/2601.13207)
*Jinnao Li,Zijian Chen,Tingzhu Chen,Changbo Wang*

Main category: cs.CV

TL;DR: 提出了GTPred基准，用于评估多模态大语言模型在地理时间预测任务上的性能，包含370张全球分布、跨越120年的图像，通过联合评估年份和分层位置序列匹配来测试模型能力。


<details>
  <summary>Details</summary>
Motivation: 现有地理定位基准大多忽略了图像中的时间信息，而时间信息可以进一步约束位置推断。为了填补这一空白，需要建立一个同时考虑地理和时间信息的基准来评估多模态大语言模型的能力。

Method: 构建了GTPred基准数据集，包含370张全球分布、跨越120年的图像。评估方法包括：1) 联合考虑年份和分层位置序列匹配；2) 使用精心标注的真实推理过程评估中间推理链。在8个专有和7个开源MLLMs上进行了实验。

Result: 实验表明，尽管当前模型具有较强的视觉感知能力，但在世界知识和地理时间推理方面仍存在局限。结果同时显示，纳入时间信息能显著提升位置推断性能。

Conclusion: 提出了首个地理时间预测基准GTPred，揭示了当前多模态大语言模型在地理时间推理方面的局限性，并证明了时间信息对地理定位任务的重要性，为未来研究提供了新的评估方向。

Abstract: Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.

</details>


### [132] [Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2601.13707)
*Yujin Jo,Sangyoon Bae,Taesup Kim*

Main category: cs.CV

TL;DR: ACG是一种单次前向计算的注意力空间对比引导方法，通过构建视觉-语言和纯语言注意力路径来减少大视觉语言模型中的幻觉，同时通过正交化校正消除近似偏差，在保持高质量的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型中的幻觉问题主要源于语言先验对视觉证据的支配，导致物体误识别和视觉不一致的描述。现有方法通常需要多次前向计算，计算成本高。需要一种既能有效缓解幻觉又能保持计算效率的方法。

Method: 提出注意力空间对比引导（ACG），在单次前向计算中构建视觉-语言和纯语言注意力路径，通过对比这两种路径来引导生成。进一步应用正交化校正，消除与纯语言路径对齐的分量，选择性增强视觉贡献。

Result: 在CHAIR和POPE基准测试中，ACG实现了最先进的忠实度和字幕质量，同时显著降低计算成本。与需要多次前向计算的对比解码方法相比，延迟降低高达2倍。

Conclusion: ACG为幻觉缓解提供了一种原理性且高效的替代方案，通过单次前向计算的注意力空间对比引导，有效减少语言先验的过度依赖，增强视觉基础性，同时保持计算效率。

Abstract: Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes.

</details>


### [133] [HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection](https://arxiv.org/abs/2601.13751)
*Daniel Kyselica,Jonáš Herec,Oliver Kutis,Rado Pitoňák*

Main category: cs.CV

TL;DR: 本文提出了一种用于小卫星的机载洪水检测系统HiT（History Injection Transformer），通过历史注入机制在保持检测精度的同时，将数据存储需求减少99%以上，实现了43 FPS的实时处理性能。


<details>
  <summary>Details</summary>
Motivation: 自然灾害监测需要处理多时相卫星数据，但小卫星存在严格的内存和计算限制。洪水检测作为灾害管理的关键应用，需要能够在机载环境下实时运行的解决方案，减少对地面处理基础设施的依赖。

Method: 提出了HiT（History Injection Transformer）机制，在Transformer模型中维护历史观测上下文，同时将数据存储减少到原始图像大小的不到1%。该方法基于Prithvi-tiny基础模型构建，在STTORM-CD洪水数据集上进行测试验证。

Result: HiT机制在保持与双时相基线相当的检测精度的同时，将数据存储需求减少了99%以上。HiT-Prithvi模型在Jetson Orin Nano（纳米卫星代表性硬件）上实现了43 FPS的处理速度，满足实时监测需求。

Conclusion: 该工作为基于卫星的自然灾害连续监测建立了实用框架，支持实时灾害评估，减少对地面处理基础设施的依赖。模型架构和检查点已开源，促进进一步研究和应用。

Abstract: Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection

</details>


### [134] [ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments](https://arxiv.org/abs/2601.13218)
*Igor Vozniak,Philipp Mueller,Nils Lipp,Janis Sprenger,Konstantin Poddubnyy,Davit Hovhannisyan,Christian Mueller,Andreas Bulling,Philipp Slusallek*

Main category: cs.CV

TL;DR: 提出StreetCrossingVR数据集和oSIM指标，用于评估基于对象的视觉注意力模型，并开发了SUMGraph模型在多个指标上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 人类视觉注意力具有基于对象的特性，但现有计算模型对此关注不足，主要原因是缺乏合适的数据集和评估指标。特别是在街道过街导航等复杂场景中，收集真实世界数据存在伦理和安全挑战。

Method: 1) 创建StreetCrossingVR数据集：包含120名参与者在VR环境中的空间街道过街导航数据，提供准确注视数据、完整物体状态空间表示、全景分割、深度信息和车辆关键点等丰富标注；2) 提出oSIM（基于对象相似度）作为新的评估指标；3) 开发SUMGraph模型：基于Mamba U-Net架构，将关键场景对象（车辆）编码为图表示。

Result: 1) 数据集成功解决了在真实环境中收集可比数据的伦理和安全挑战；2) 实验表明，明确优化基于对象的注意力不仅能提高oSIM性能，还能改善模型在常见指标上的表现；3) SUMGraph模型在多个最先进的视觉注意力预测方法中取得了进一步的性能提升。

Conclusion: 该研究填补了基于对象视觉注意力评估的数据集和指标空白，提出的StreetCrossingVR数据集、oSIM指标和SUMGraph模型为这一领域提供了重要工具，所有资源将公开释放以促进相关研究。

Abstract: The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.

</details>


### [135] [Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations](https://arxiv.org/abs/2601.13225)
*Tim Lachmann,Alexandra Israelsson,Christina Tornberg,Teimuraz Saghinadze,Michal Balazia,Philipp Müller,Petri Laukka*

Main category: cs.CV

TL;DR: 提出BLEMORE数据集，用于多模态混合情感识别，包含情感相对显著度信息，填补了现有数据集的空白


<details>
  <summary>Details</summary>
Motivation: 人类通常同时体验多种情感混合，而非单一情感，但现有视频情感识别方法大多只能识别单一情感，缺乏包含情感相对显著度标注的混合情感数据集

Method: 构建包含3000多个视频片段的多模态数据集，来自58名演员表演6种基本情感和10种不同混合情感，每种混合有3种显著度配置(50/50、70/30、30/70)；评估了最先进的视频分类方法在两个任务上的表现：情感存在预测和情感显著度预测

Result: 单模态分类器在验证集上达到29%的存在准确率和13%的显著度准确率；多模态方法有明显改进，ImageBind + WavLM达到35%存在准确率，HiCMAE达到18%显著度准确率；在测试集上，最佳模型达到33%存在准确率(VideoMAEv2 + HuBERT)和18%显著度准确率(HiCMAE)

Conclusion: BLEMORE数据集为推进考虑混合情感表达复杂性和重要性的情感识别系统研究提供了宝贵资源

Abstract: Humans often experience not just a single basic emotion at a time, but rather a blend of several emotions with varying salience. Despite the importance of such blended emotions, most video-based emotion recognition approaches are designed to recognize single emotions only. The few approaches that have attempted to recognize blended emotions typically cannot assess the relative salience of the emotions within a blend. This limitation largely stems from the lack of datasets containing a substantial number of blended emotion samples annotated with relative salience. To address this shortcoming, we introduce BLEMORE, a novel dataset for multimodal (video, audio) blended emotion recognition that includes information on the relative salience of each emotion within a blend. BLEMORE comprises over 3,000 clips from 58 actors, performing 6 basic emotions and 10 distinct blends, where each blend has 3 different salience configurations (50/50, 70/30, and 30/70). Using this dataset, we conduct extensive evaluations of state-of-the-art video classification approaches on two blended emotion prediction tasks: (1) predicting the presence of emotions in a given sample, and (2) predicting the relative salience of emotions in a blend. Our results show that unimodal classifiers achieve up to 29% presence accuracy and 13% salience accuracy on the validation set, while multimodal methods yield clear improvements, with ImageBind + WavLM reaching 35% presence accuracy and HiCMAE 18% salience accuracy. On the held-out test set, the best models achieve 33% presence accuracy (VideoMAEv2 + HuBERT) and 18% salience accuracy (HiCMAE). In sum, the BLEMORE dataset provides a valuable resource to advancing research on emotion recognition systems that account for the complexity and significance of blended emotion expressions.

</details>


### [136] [Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders](https://arxiv.org/abs/2601.13798)
*Kai Wittenmayer,Sukrut Rao,Amin Parchami-Araghi,Bernt Schiele,Jonas Fischer*

Main category: cs.CV

TL;DR: Insight是一个语言对齐的概念基础模型，通过分层稀疏自编码器提取多粒度可解释概念，提供空间定位的概念解释，在分类和分割任务上性能接近不透明基础模型。


<details>
  <summary>Details</summary>
Motivation: 语言对齐的视觉基础模型在下游任务中表现优异，但其学习到的表征不透明，难以解释决策过程。现有方法虽然能将表征分解为可解释概念，但缺乏空间定位能力且仅限于图像分类任务。

Method: 使用分层稀疏自编码器和具有强语义表征的基础模型自动提取多粒度概念；通过分析概念的局部共现依赖关系定义概念关系；利用这些关系改进概念命名并获得更丰富的解释。

Result: 在基准数据上，Insight在分类和分割任务上提供了与不透明基础模型竞争的性能，同时提供细粒度、高质量的概念解释。

Conclusion: Insight成功构建了一个语言对齐的概念基础模型，能够提供空间定位的细粒度概念解释，在保持性能的同时显著提升了模型的可解释性。

Abstract: Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight.

</details>


### [137] [Discriminant Learning-based Colorspace for Blade Segmentation](https://arxiv.org/abs/2601.13816)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出CSDA算法，通过多维非线性判别分析优化色彩表示，提升图像分割精度


<details>
  <summary>Details</summary>
Motivation: 现有图像分割算法常忽视色彩表示这一关键预处理步骤，次优的色彩表示会阻碍准确分割

Method: 提出Colorspace Discriminant Analysis (CSDA)算法，将线性判别分析扩展到深度学习框架中，通过最大化多维有符号类间可分性并最小化类内变异性来定制色彩表示；引入三种替代损失函数实现端到端优化

Result: 在风力涡轮机叶片数据上的实验显示显著精度提升，证明了定制化预处理在领域特定分割中的重要性

Conclusion: CSDA通过优化色彩表示显著改善分割性能，强调了预处理在图像分割中的关键作用

Abstract: Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.

</details>


### [138] [A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models](https://arxiv.org/abs/2601.13238)
*Chengyin Hu,Xiang Chen,Zhe Jia,Weiwen Shi,Fengyu Zhang,Jiujiang Guo,Yiwei Wei*

Main category: cs.CV

TL;DR: 该论文提出了首个利用真实天气条件攻击视觉语言模型的对抗框架，通过两阶段参数化扰动模型分析雨天气候对VLM决策的影响，揭示了物理合理的天气扰动能导致显著的语义错位。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型主要在标准视觉条件下训练，对真实天气条件（特别是雨天）的鲁棒性以及跨模态语义对齐的稳定性研究不足。需要评估VLM在现实天气扰动下的安全性和可靠性风险。

Method: 提出两阶段参数化扰动框架：第一阶段通过低维全局调制弱化原始语义决策边界；第二阶段显式建模多尺度雨滴外观和降雨引起的照明变化，优化不可微的天气空间以诱导稳定的语义偏移。该框架在非像素参数空间中生成物理基础且可解释的扰动。

Result: 实验表明，即使物理合理且高度约束的天气扰动也能在主流VLM中引起显著的语义错位，证实了现实部署中的潜在安全风险。消融研究进一步确认照明建模和多尺度雨滴结构是语义偏移的关键驱动因素。

Conclusion: 该研究首次系统分析了雨天条件对VLM语义对齐的影响，提出的对抗框架揭示了现实天气扰动对多模态模型安全性的威胁，强调了在真实世界部署中考虑环境鲁棒性的重要性。

Abstract: Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.

</details>


### [139] [Deep Learning for Semantic Segmentation of 3D Ultrasound Data](https://arxiv.org/abs/2601.13263)
*Chenyu Liu,Marco Cecotti,Harikrishnan Vijayakumar,Patrick Robinson,James Barson,Mihai Caleap*

Main category: cs.CV

TL;DR: 该论文提出了一种基于Calyo Pulse固态3D超声传感器的学习型3D语义分割框架，用于恶劣环境下的自动驾驶感知系统。


<details>
  <summary>Details</summary>
Motivation: 开发成本效益高且可靠的感知系统是自动驾驶车辆的核心挑战。当前主流的LiDAR和摄像头系统在成本、鲁棒性和恶劣条件下的性能之间存在权衡，需要寻找补充感知模态。

Method: 引入基于Calyo Pulse模块化固态3D超声传感器系统的学习框架，采用3D U-Net架构在空间超声数据上进行训练，实现体素级语义分割。

Result: Calyo Pulse传感器展示了稳健的分割性能，通过更大数据集、精细化地面真值和加权损失函数有进一步提升潜力。

Conclusion: 3D超声传感作为一种有前景的补充模态，能够增强自动驾驶系统的可靠性，特别是在恶劣和杂乱环境中。

Abstract: Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.

</details>


### [140] [Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams](https://arxiv.org/abs/2601.13299)
*Ethan Seefried,Prahitha Movva,Naga Harshita Marupaka,Tilak Kasturi,Tirthankar Ghosal*

Main category: cs.CV

TL;DR: Enginuity：首个开放、大规模、多领域工程图数据集，包含全面的结构标注，用于自动化图表解析


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在科学发现工作流程中存在根本性障碍，无法充分理解和操作工程图中的视觉结构知识。工程图解释、技术图纸分析和视觉推理对于假设生成、实验设计和科学发现至关重要，但缺乏合适的标注数据集限制了多模态大语言模型在这些任务中的应用。

Method: 创建开放、大规模、多领域的工程图数据集，包含全面的结构标注，捕捉层次化组件关系、连接关系和语义元素。该数据集设计用于支持多模态大语言模型处理工程图解析任务。

Result: 提出的Enginuity数据集将能够支持关键下游任务，包括结构化图表解析、跨模态信息检索和AI辅助工程仿真。该数据集将首次为多领域工程图提供大规模的结构化标注。

Conclusion: Enginuity数据集将变革科学发现领域的人工智能，使AI系统能够理解和操作工程图中嵌入的视觉结构知识，打破当前阻碍AI完全参与科学工作流程的根本障碍，在图表解释、技术图纸分析和视觉推理方面实现突破。

Abstract: We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.

</details>


### [141] [CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning](https://arxiv.org/abs/2601.13304)
*Wenxin Ma,Chenlong Wang,Ruisheng Yuan,Hao Chen,Nanru Dai,S. Kevin Zhou,Yijun Yang,Alan Yuille,Jieneng Chen*

Main category: cs.CV

TL;DR: 该论文提出了CausalSpatial基准测试，用于评估多模态大语言模型在因果空间推理方面的能力，发现模型表现远低于人类，并提出了Causal Object World模型（COW）框架来改进这一问题。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过观察静态场景预测后续动态结果（如物体移动是否会导致碰撞），这种因果空间推理能力是当前多模态大语言模型所缺乏的。模型主要局限于静态空间感知，难以回答3D场景中的"如果...会怎样"问题。

Method: 1. 创建CausalSpatial诊断基准，包含碰撞、兼容性、遮挡和轨迹四个任务；2. 分析模型失败原因，发现模型过度依赖文本链式推理而偏离视觉证据；3. 提出Causal Object World模型（COW）框架，通过生成假设动态的视频来外部化模拟过程，提供明确的因果视觉线索。

Result: 人类在基准测试中得分84%，而GPT-5仅得54%，存在显著差距。分析表明模型会产生流畅但空间无根据的幻觉。COW框架通过视觉模拟使模型能够将推理建立在物理现实而非语言先验之上。

Conclusion: 当前多模态大语言模型在因果空间推理方面存在根本性缺陷，过度依赖文本推理导致空间无根据的幻觉。COW框架通过外部化视觉模拟过程，为模型提供明确的因果视觉线索，是解决这一问题的有效途径。数据集和代码已公开。

Abstract: Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer "what-if" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: https://github.com/CausalSpatial/CausalSpatial

</details>


### [142] [TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation](https://arxiv.org/abs/2601.13935)
*Anoushkrit Goel,Simroop Singh,Ankita Joshi,Ranjeet Ranjan Jha,Chirag Ahuja,Aditya Nigam,Arnav Bhavsar*

Main category: cs.CV

TL;DR: TrackletGPT：一种基于GPT框架的白质纤维束分割方法，通过引入轨迹片段（tracklets）重新引入序列信息，在跨数据集实验中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 白质纤维束分割对于研究大脑结构连接性、神经系统疾病和神经外科手术至关重要。该任务具有挑战性，因为纤维束在不同个体和条件下存在差异，但在半球和个体间具有相似的三维结构。

Method: 提出TrackletGPT，一种类似语言的GPT框架，使用轨迹片段（tracklets）在标记中重新引入序列信息。该方法能够无缝泛化到不同数据集，完全自动化，并编码细粒度的子流线片段（tracklets），在纤维束成像分割中扩展和优化GPT模型。

Result: TrackletGPT在TractoInferno和HCP数据集上的平均DICE、Overlap和Overreach分数优于最先进方法，即使在跨数据集实验中也是如此。

Conclusion: TrackletGPT通过引入轨迹片段和GPT框架，有效解决了白质纤维束分割中的挑战，在跨数据集泛化性和分割精度方面表现出色。

Abstract: White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.

</details>


### [143] [Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments](https://arxiv.org/abs/2601.13364)
*Zhenan Liu,Yaodong Cui,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 提出了一种在粉尘环境中生成可控多级粉尘浓度的方法，开发了4D毫米波雷达数据集，并建立了基于阈值的噪声过滤框架和基于规则的分类管道，用于粉尘环境下的可靠行人检测。


<details>
  <summary>Details</summary>
Motivation: 地下矿井、道路隧道或倒塌建筑物等恶劣封闭环境中存在严重的粉尘污染和电磁约束，这些条件会显著影响毫米波雷达的传播特性和感知功能，需要开发能够在粉尘环境中可靠工作的感知系统。

Method: 1) 开发了在高度杂乱环境中生成可控多级粉尘浓度的方法；2) 创建了包含相机和LiDAR的4D毫米波雷达数据集；3) 建立了基于关键雷达参数（RCS、速度、方位角、仰角）的阈值噪声过滤框架；4) 设计了基于规则的聚类级分类管道，利用雷达语义特征（速度、RCS、体积分布）进行行人检测。

Result: 实验结果表明，该集成方法在粉尘环境中显著增强了杂波抑制、检测鲁棒性和系统整体弹性，能够实现可靠、实时的行人检测，无需大量领域特定训练。

Conclusion: 该方法为恶劣粉尘环境中的毫米波传播研究提供了可重复的实验平台，通过数据级过滤和语义级分类的集成策略，有效解决了粉尘颗粒和反射表面对感知功能的联合影响，提升了在严重电磁约束条件下的感知系统性能。

Abstract: This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.

</details>


### [144] [Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains](https://arxiv.org/abs/2601.13975)
*Marco Piccolo,Qiwei Han,Astrid van Toor,Joachim Vanneste*

Main category: cs.CV

TL;DR: 该研究为北极和大西洋海洋生态系统入侵物种监测建立了基础检测层，通过统一信息管道标准化异构数据集，发现场景结构因素比视觉退化对跨域性能影响更大，并验证了在低成本边缘硬件上的可行性。


<details>
  <summary>Details</summary>
Motivation: 海洋生物多样性监测需要在复杂水下环境中实现可扩展性和可靠性，以支持保护和入侵物种管理。现有检测方案存在明显的部署差距，当转移到新地点时性能急剧下降。该研究旨在为多年入侵物种监测计划建立基础检测层。

Method: 开发统一信息管道，将异构数据集标准化为可比信息流；在受控跨域协议下评估固定的部署相关检测器；分析结构因素（场景组成、物体密度、上下文冗余）和视觉退化因素对性能的影响；在低成本边缘硬件上基准测试推理性能。

Result: 发现结构因素（场景组成、物体密度、上下文冗余）比视觉退化（如浑浊度）更能解释跨域性能损失；稀疏场景引发特征性的"上下文崩溃"故障模式；运行时优化使低成本边缘硬件能够实现实际采样率，满足远程监测需求。

Conclusion: 研究结果将重点从图像增强转向结构感知可靠性，为一致的海洋生态系统评估提供了民主化工具，建立了可扩展的海洋生物多样性监测基础检测层。

Abstract: Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic "Context Collapse" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.

</details>


### [145] [Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations](https://arxiv.org/abs/2601.13371)
*Junyi Zhang,Yiming Wang,Yunhong Lu,Qichao Wang,Wenzhe Qian,Xiaoyin Xu,David Gu,Min Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于球形几何表示的文本到3D人脸生成方法，通过将几何信号锚定到均匀球面坐标来简化底层几何结构，结合条件扩散模型实现高质量几何和纹理生成。


<details>
  <summary>Details</summary>
Motivation: 文本到3D人脸生成的核心挑战在于实现高质量的几何结构。现有模型难以处理3D空间中顶点分布的任意性和复杂性，导致连接性不佳和几何质量低下。需要一种能简化底层几何结构的方法。

Method: 提出球形几何表示，将几何信号锚定到均匀球面坐标，确保规则的点分布，从而稳健地重建网格连接性。该规范球面可无缝展开为2D映射，与强大的2D生成模型形成完美协同。在此基础上构建球形几何扩散，这是一个基于2D映射的条件扩散框架，通过联合建模几何和纹理实现多样化可控生成。

Result: 该方法在文本到3D生成、人脸重建和基于文本的3D编辑等广泛任务中表现出色。大量实验表明，该方法在几何质量、文本保真度和推理效率方面显著优于现有方法。

Conclusion: 通过将几何约束到简单的拓扑球面流形上，提出了一种有效的文本到3D人脸生成方法。球形几何表示简化了底层结构，而球形几何扩散框架则实现了高质量、多样化和可控的生成，为3D人脸生成提供了新的解决方案。

Abstract: A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.

</details>


### [146] [A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions](https://arxiv.org/abs/2601.13373)
*Zhenan Liu,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 提出一种完全模型驱动的4D毫米波雷达感知框架，用于恶劣工业/地下环境中实时嵌入式边缘计算的人体检测，在粉尘/烟雾等能见度退化条件下保持稳定性能。


<details>
  <summary>Details</summary>
Motivation: 工业/地下环境中的粉尘、烟雾、受限几何结构和金属结构严重制约光学和LiDAR感知，而4D毫米波雷达对此类条件具有强鲁棒性，但对其稀疏各向异性点云的处理方法理解有限，需要可靠的人体检测方案。

Method: 采用完全模型驱动的4D雷达感知框架，集成领域感知多阈值滤波、自运动补偿时间累积、KD树欧几里得聚类与多普勒感知细化、基于规则的3D分类器，仅使用雷达作为感知模态。

Result: 在粉尘填充的封闭拖车和真实地下采矿隧道中评估，在相机和LiDAR因严重能见度退化而失效的场景下，雷达检测器保持稳定的行人识别能力。

Conclusion: 提出的模型驱动方法为恶劣工业/地下环境中的安全关键应用提供了鲁棒、可解释且计算高效的感知解决方案。

Abstract: Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.

</details>


### [147] [Federated Balanced Learning](https://arxiv.org/abs/2601.14042)
*Jiaze Li,Haoran Xu,Wanyi Wu,Changwei Wang,Shuaiguang Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Youyang Qu,Longxiang Gao,Xudong Yang,Lumin Xing*

Main category: cs.CV

TL;DR: 提出Federated Balanced Learning (FBL)框架，通过客户端样本平衡解决非独立同分布联邦学习中的客户端漂移问题，利用边缘生成模型进行知识填充和采样，并设计了知识对齐和丢弃策略。


<details>
  <summary>Details</summary>
Motivation: 在非独立同分布联邦学习中，全局模型会出现客户端漂移问题，严重影响最终性能。现有方法多基于损失函数或梯度修正已偏离的全局模型，忽视了客户端样本的影响。

Method: 提出Federated Balanced Learning (FBL)框架：1) 在客户端侧通过边缘生成模型实现知识填充和知识采样，在固定数据样本限制下实现样本平衡；2) 设计知识对齐策略弥合合成数据与真实数据的差距；3) 设计知识丢弃策略进行正则化；4) 扩展到真实复杂场景，允许不同客户端采用不同方法。

Result: 大量实验表明，该方法优于现有最先进的基线方法。

Conclusion: 通过重新思考客户端侧的作用，提出从源头预防客户端漂移的FBL框架，通过客户端样本平衡、知识对齐和丢弃策略，在非独立同分布联邦学习中取得了优异性能。

Abstract: Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.

</details>


### [148] [Practical Insights into Semi-Supervised Object Detection Approaches](https://arxiv.org/abs/2601.13380)
*Chaoxin Wang,Bharaneeshwar Balasubramaniyam,Anurag Sangem,Nicolais Guevara,Doina Caragea*

Main category: cs.CV

TL;DR: 对三种先进半监督目标检测方法（MixPL、Semi-DETR、Consistent-Teacher）在少样本场景下的综合性能比较研究


<details>
  <summary>Details</summary>
Motivation: 研究数据稀缺场景下的学习问题，特别是半监督目标检测（SSOD）方法在有限标注图像下的性能表现，理解不同方法在不同标注数据量下的性能变化

Method: 使用MS-COCO和Pascal VOC两个标准目标检测基准数据集，以及自定义的Beetle数据集，对三种先进SSOD方法（MixPL、Semi-DETR、Consistent-Teacher）进行系统性实验比较，分析标注图像数量对性能的影响

Result: 研究揭示了不同方法在准确率、模型大小和延迟之间的权衡关系，为低数据场景下的方法选择提供了见解

Conclusion: 通过系统性比较三种先进SSOD方法在不同数据集和标注数据量下的表现，为数据稀缺场景下的目标检测方法选择提供了实证依据和指导

Abstract: Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.

</details>


### [149] [Organ-Aware Attention Improves CT Triage and Classification](https://arxiv.org/abs/2601.13385)
*Lavsen Dahal,Yubraj Bhandari,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CV

TL;DR: ORACLE-CT：一种用于CT影像分类的器官感知模型，通过器官掩码注意力和器官标量融合技术，在胸部和腹部CT分类任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 医疗影像（特别是CT）数量激增，急需有效的分类和分诊系统以改善患者护理并减轻放射科医生负担。现有视觉语言模型在处理3D解剖结构、协议变化和噪声报告监督方面存在困难。

Method: 提出ORACLE-CT模型，包含两个核心组件：1) 器官掩码注意力（Organ-Masked Attention）- 基于器官掩码的受限注意力机制，提供空间证据；2) 器官标量融合（Organ-Scalar Fusion）- 轻量级融合归一化体积和平均HU值线索。模型在CT-RATE和RADCHEST-CT数据集上进行评估。

Result: 在胸部CT设置中，ORACLE-CT在CT-RATE上达到AUROC 0.86；在腹部CT设置中（MERLIN数据集，30个发现），监督基线超过复现的零样本VLM基线，添加掩码注意力和标量融合后性能进一步提升至AUROC 0.85。

Conclusion: ORACLE-CT在统一的评估协议下，在胸部和腹部CT分类任务中实现了最先进的监督分类性能，为医学影像分诊提供了有效的解决方案。

Abstract: There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.

</details>


### [150] [Leveraging Transformer Decoder for Automotive Radar Object Detection](https://arxiv.org/abs/2601.13386)
*Changxu Zhang,Zhaoze Wang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

TL;DR: 提出基于Transformer的3D雷达目标检测架构，使用新型Transformer解码器作为预测头，直接从雷达特征回归3D边界框和类别分数。


<details>
  <summary>Details</summary>
Motivation: 传统雷达目标检测方法依赖密集候选框生成和启发式后处理（如NMS调优），存在计算开销大和性能受限的问题。需要更高效的端到端检测框架来建模雷达数据中的长程时空关联。

Method: 1) 使用Transformer解码器作为预测头，将检测建模为集合预测问题，通过可学习对象查询和位置编码直接回归3D边界框和类别分数；2) 提出金字塔令牌融合(PTF)模块，将多尺度雷达特征金字塔转换为统一的尺度感知令牌序列；3) 消除密集候选框生成和NMS后处理。

Result: 在RADDet数据集上评估，相比最先进的纯雷达基线方法取得了显著改进。

Conclusion: 提出的Transformer架构通过端到端集合预测方法有效解决了3D雷达目标检测问题，简化了检测流程并提升了性能。

Abstract: In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.

</details>


### [151] [Deep Image Prior with L0 Gradient Regularizer for Image Smoothing](https://arxiv.org/abs/2601.13400)
*Nhat Thanh Tran,Kevin Bui,Jack Xin*

Main category: cs.CV

TL;DR: DIP-ℓ₀：一种无需训练数据的图像平滑方法，结合深度图像先验与ℓ₀梯度正则化，在边缘保持和JPEG伪影去除方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统图像平滑方法依赖局部窗口统计或优化问题求解，而基于深度学习的最新方法需要精心构建的训练数据集。由于为图像平滑构建合适的训练数据集具有挑战性，作者提出了一种无需训练数据的深度图像先验框架。

Method: 提出DIP-ℓ₀框架，将深度图像先验与ℓ₀梯度正则化相结合。为最小化包含非凸、非光滑ℓ₀"范数"的损失函数，开发了交替方向乘子法（ADMM）算法，并利用现成的ℓ₀梯度最小化求解器。

Result: 数值实验表明，DIP-ℓ₀在边缘保持图像平滑和JPEG伪影去除方面优于许多现有图像平滑算法。

Conclusion: DIP-ℓ₀框架成功实现了无需训练数据的高质量图像平滑，通过结合深度图像先验和ℓ₀梯度正则化，在保持重要结构特征的同时有效去除细节和纹理。

Abstract: Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\ell_0$, a deep image prior framework that incorporates the $\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\ell_0$ ``norm", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.

</details>


### [152] [Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting](https://arxiv.org/abs/2601.14208)
*Nitin Kulkarni,Akhil Devarashetti,Charlie Cluss,Livio Forte,Dan Buckmaster,Philip Schneider,Chunming Qiao,Alina Vereshchaka*

Main category: cs.CV

TL;DR: 提出端到端管道，使用三相机系统捕获车辆底盘视频并生成交互式3D模型，通过改进的SfM方法解决广角镜头畸变和低视差问题，实现实时渲染的逼真底盘检测


<details>
  <summary>Details</summary>
Motivation: 传统车辆底盘检查需要检查员蹲下或爬行到车下，工作强度大且存在安全隐患；在线买家很少能看到底盘照片，影响购买信心

Method: 使用三相机系统同步捕获底盘视频，提出针对相机系统的SfM管道，集成精确相机标定、同步视频流和几何先验，采用约束匹配策略结合DISK特征提取器和LightGlue匹配器生成高质量稀疏点云，通过高斯溅射生成实时渲染的逼真3D模型

Result: 系统能够生成交互式3D底盘模型，支持旋转、缩放和切片操作，可在数秒内检测锈蚀、泄漏或撞击损伤，实验和消融研究表明设计选择对实现最先进质量至关重要

Conclusion: 提出的端到端管道通过创新的SfM方法解决了广角镜头畸变和低视差场景的挑战，生成的交互式3D模型显著提高了工作场所安全和买家信心，为车辆底盘检查提供了高效解决方案

Abstract: Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.

</details>


### [153] [Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics](https://arxiv.org/abs/2601.13401)
*Peter A. Massih,Eric Cosatto*

Main category: cs.CV

TL;DR: 该论文针对当前视觉语言模型在定量空间推理上的失败，提出了SQuID基准数据集和QVLM架构，通过代码生成方式保持像素级精度，显著提升了卫星图像定量推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在定量空间推理任务上表现不佳，主要原因是其架构破坏了像素级信息。视觉编码器通过补丁嵌入压缩图像，减少了空间索引能力，丢失了精确计数和测量所需的像素级跟踪能力。这限制了模型在需要精确空间量化的应用（如卫星图像分析）中的表现。

Method: 论文提出两个核心贡献：1) SQuID数据集：包含2000个卫星图像问答对，涵盖数值范围和分类答案，分为三个难度层级，通过人类标注和学习的变异性自动生成注释；2) QVLM架构：采用代码生成方法，将语言理解与视觉分析解耦。QVLM不将图像编码为嵌入，而是生成可执行代码，首先调用分割模型获取像素级掩码，然后直接在这些掩码上操作，在整个推理过程中保持空间索引。

Result: 实验结果显示，使用GPT-5作为编码器的QVLM在SQuID数据集上达到42.0%的准确率，而传统VLM（仅使用图像-问题对提示）的准确率为28.1%。这表明在定量空间推理任务上，架构解耦能够显著提升准确性。

Conclusion: 对于定量空间推理任务，通过架构解耦（将语言理解与视觉分析分离）并保持像素级精度的代码生成方法，能够比传统视觉语言模型获得更好的准确性。QVLM的成功表明，在处理需要精确空间量化的任务时，避免像素级信息丢失是关键设计原则。

Abstract: Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.

</details>


### [154] [Using deep learning for predicting cleansing quality of colon capsule endoscopy images](https://arxiv.org/abs/2601.13412)
*Puneet Sharma,Kristian Dalsbø Hindberg,Benedicte Schelde-Olesen,Ulrik Deding,Esmaeil S. Nadimi,Jan-Matthias Braun*

Main category: cs.CV

TL;DR: 该研究应用深度学习预测结肠胶囊内镜图像清洁质量，使用ResNet-18模型和结构化剪枝技术，在保持88%准确率的同时实现79%稀疏度，并评估了多种可解释性方法。


<details>
  <summary>Details</summary>
Motivation: 结肠胶囊内镜图像清洁质量评估对临床诊断至关重要，但现有方法存在效率问题。研究旨在开发高效准确的深度学习模型，同时确保模型可解释性以满足临床应用需求。

Method: 使用500张由14名临床医生标注的CCE图像（Leighton-Rex量表：差、一般、好、优秀），采用ResNet-18模型进行分类。应用分层K折交叉验证确保稳健性，采用结构化剪枝技术优化模型。使用Grad-CAM、Grad-CAM++、Eigen-CAM、Ablation-CAM和Random-CAM进行可解释性分析，并用ROAD方法进行一致性评估。最后采用自适应温度缩放变体对剪枝模型进行外部数据集校准。

Result: 剪枝模型在保持88%交叉验证准确率的同时实现了79%的稀疏度，相比未剪枝模型的84%准确率有所提升。研究展示了剪枝在提高效率的同时不损害性能的有效性，并揭示了CCE图像清洁质量评估的挑战以及ROAD方法在特定任务中的局限性。

Conclusion: 结构化剪枝技术能显著提高深度学习模型在CCE图像清洁质量预测中的效率，同时保持高准确性。模型可解释性对临床应用至关重要，但需要针对特定任务优化评估方法。自适应温度缩放有助于模型在外部数据集上的校准应用。

Abstract: In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.

</details>


### [155] [Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study](https://arxiv.org/abs/2601.13416)
*A. Nieto Juscafresa,Á. Mazcuñán Herreros,J. Sullivan*

Main category: cs.CV

TL;DR: 扩散模型作为通用特征编码器的潜力研究：在浮游生物监测任务中，冻结的扩散模型特征与监督基线竞争，并在分布偏移下保持强鲁棒性


<details>
  <summary>Details</summary>
Motivation: 扩散模型已成为图像合成的最先进生成方法，但其作为通用特征编码器的潜力尚未充分探索。虽然扩散模型在无标签条件下训练用于去噪和生成，但它们可以被解释为能够捕获低层和高层结构的自监督学习器。

Method: 使用冻结的扩散模型主干作为特征编码器，通过探测不同层和去噪时间步的中间特征，为每个层-时间步对训练线性分类器。在真实世界的浮游生物监测场景中，使用受控且可比较的训练设置，与已建立的监督和自监督基线进行对比评估。

Result: 冻结扩散特征与监督基线竞争，并在平衡和自然长尾设置中优于其他自监督方法。在时间和地理分布偏移的浮游生物数据集上进行分布外评估显示，冻结扩散特征在显著分布偏移下仍保持强准确性和Macro F1分数。

Conclusion: 扩散模型不仅是强大的生成模型，还可以作为有效的通用特征编码器，在细粒度识别任务中表现出色，特别是在面对现实世界数据分布变化时具有强鲁棒性。

Abstract: Diffusion models have emerged as state-of-the-art generative methods for image synthesis, yet their potential as general-purpose feature encoders remains underexplored. Trained for denoising and generation without labels, they can be interpreted as self-supervised learners that capture both low- and high-level structure. We show that a frozen diffusion backbone enables strong fine-grained recognition by probing intermediate denoising features across layers and timesteps and training a linear classifier for each pair. We evaluate this in a real-world plankton-monitoring setting with practical impact, using controlled and comparable training setups against established supervised and self-supervised baselines. Frozen diffusion features are competitive with supervised baselines and outperform other self-supervised methods in both balanced and naturally long-tailed settings. Out-of-distribution evaluations on temporally and geographically shifted plankton datasets further show that frozen diffusion features maintain strong accuracy and Macro F1 under substantial distribution shift.

</details>


### [156] [SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement](https://arxiv.org/abs/2601.13417)
*Yujian Xiong,Xuanzhao Dong,Wenhui Zhu,Xin Li,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: SGW-GAN：首个将切片Gromov Wasserstein（SGW）融入视网膜图像增强的框架，通过随机投影近似GW距离，在提升图像质量的同时保持临床相关的类内几何结构，改善下游疾病分级任务。


<details>
  <summary>Details</summary>
Motivation: 现有基于GAN和扩散模型的视网膜图像增强方法虽然提升了感知质量，但会扭曲类内几何结构：临床相关样本变得分散，疾病类别边界模糊，从而损害下游分级或病变检测任务。Gromov Wasserstein（GW）距离通过内部成对距离对齐分布，能自然保持类内结构，但计算成本过高限制了实际应用。

Method: 提出SGW-GAN框架，首次将切片Gromov Wasserstein（SGW）融入视网膜图像增强。SGW通过随机投影近似GW距离，保留关系保真度同时大幅降低计算成本。该方法用于无配对医学图像增强，在提升视觉质量的同时保持临床相关的几何结构。

Result: 在公开数据集上的实验表明：SGW-GAN能生成视觉上令人信服的增强图像；在糖尿病视网膜病变分级任务上表现优异；在疾病标签上报告了最低的GW差异，证明了其在无配对医学图像增强中的效率和临床保真度。

Conclusion: SGW-GAN通过将切片Gromov Wasserstein距离融入视网膜图像增强，成功解决了现有方法扭曲类内几何结构的问题，在保持计算效率的同时实现了临床相关的结构保真，为无配对医学图像增强提供了高效且临床可信的解决方案。

Abstract: Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.

</details>


### [157] [Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation](https://arxiv.org/abs/2601.13440)
*Mohit Kakda,Mirudula Shri Muthukumaran,Uttapreksha Patel,Lawrence Swaminathan Xavier Prince*

Main category: cs.CV

TL;DR: 该论文对基于视觉语言模型（VLMs）的异常检测方法进行了全面分析，重点研究了CLIP等模型在零样本和少样本异常分类与分割中的应用，系统评估了不同架构范式、特征提取机制和提示工程策略。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（特别是CLIP）通过图像和文本的对齐表示学习，为异常检测提供了无需大量标注数据和缺陷样本的新范式。传统方法需要任务特定训练和缺陷示例，而VLMs能够通过自然语言描述正常和异常状态来实现零样本/少样本检测，这激发了对其在工业质量控制中应用潜力的系统研究。

Method: 系统研究了三种关键架构范式：1) 基于滑动窗口的密集特征提取（WinCLIP）；2) 具有可学习投影的多阶段特征对齐（AprilLab框架）；3) 组合提示集成策略。分析维度包括特征提取机制、文本-视觉对齐策略、提示工程技术、零样本与少样本权衡、计算效率和跨域泛化能力。在MVTec AD和VisA等基准数据集上进行严格实验。

Result: 通过基准测试比较了分类准确率、分割精度和推理效率。研究揭示了VLMs在异常检测中成功的原因和机制，为方法选择提供了实用见解，并识别了当前限制。结果表明VLMs在零样本/少样本异常检测方面具有显著优势，特别是在跨域泛化方面表现突出。

Conclusion: 该研究建立了对VLM在异常检测中应用的基础理解，为工业质量控制中的方法选择提供了指导，并指出了未来研究方向。VLMs通过自然语言描述实现异常检测的能力消除了传统方法对任务特定训练和缺陷示例的依赖，为实际应用提供了有前景的解决方案。

Abstract: Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.

</details>


### [158] [Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging](https://arxiv.org/abs/2601.13498)
*Nimrod Kruger,Nicholas Owen Ralph,Gregory Cohen,Paul Hurley*

Main category: cs.CV

TL;DR: 提出将事件相机数据映射到对数强度和强度导数估计，并嵌入动态线性系统模型，实现基于事件数据的逆滤波和维纳解卷积


<details>
  <summary>Details</summary>
Motivation: 事件视觉传感器（神经形态相机）输出稀疏、异步的ON/OFF事件，具有微秒级传感、高动态范围和低数据带宽优势。然而，这种非线性事件表示难以与大多数计算成像和光学系统设计所依赖的线性前向模型集成

Method: 提出基于物理的处理流程：1）将事件流映射到每像素对数强度和强度导数估计；2）将这些测量嵌入具有时变点扩散函数的动态线性系统模型；3）使用已知（或参数化）动态传递函数，通过频域维纳解卷积直接从事件数据进行逆滤波

Result: 在模拟中验证了调制离焦下单点和重叠点源的处理效果，并在真实事件数据（可调焦望远镜观测星场）上展示了源定位和可分离性

Conclusion: 该框架为动态光学系统中的事件传感和基于模型的计算成像提供了实用的桥梁，使事件数据能够直接用于逆滤波和图像重建

Abstract: Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.

</details>


### [159] [DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities](https://arxiv.org/abs/2601.13502)
*Nhi Kieu,Kien Nguyen,Arnold Wiliem,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: DIS2：针对遥感多模态学习中模态缺失问题的新范式，通过DLKD协同解耦学习与知识蒸馏，结合类特定特征学习和多分辨率混合融合，实现主动引导的缺失特征补偿。


<details>
  <summary>Details</summary>
Motivation: 遥感多模态学习面临模态缺失的严重挑战，且遥感数据具有高度异构性和尺度变化大的特点。传统跨域有效的方法（如解耦学习和知识蒸馏）在遥感领域失效：解耦学习依赖模态间显著特征重叠，而遥感数据异构性强；知识蒸馏成为不适定的模仿任务，学生模型无法聚焦必要的补偿知识，语义鸿沟未解决。

Method: 提出DIS2方法，基于三个核心支柱：1）原则性缺失信息补偿；2）类特定模态贡献；3）多分辨率特征重要性。核心创新是DLKD（解耦学习与知识蒸馏协同），明确捕获补偿特征，与可用模态特征融合以近似全模态的理想融合表示。CFLM（类特定特征学习模块）自适应学习每个目标的判别性证据。DLKD和CFLM由分层混合融合结构支持，利用跨分辨率特征增强预测。

Result: 大量实验验证所提方法在多个基准测试中显著优于最先进方法。

Conclusion: DIS2代表了从模态共享特征依赖和无目标模仿向主动引导缺失特征补偿的范式转变，有效解决了遥感多模态学习中的模态缺失挑战，通过DLKD协同、类特定学习和多分辨率融合实现了显著性能提升。

Abstract: The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.

</details>


### [160] [GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models](https://arxiv.org/abs/2601.13524)
*Yang Yu,Yunze Deng,Yige Zhang,Yanjie Xiao,Youkun Ou,Wenhao Hu,Mingchao Li,Bin Feng,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

TL;DR: GO-MLVTON是首个多层虚拟试穿方法，通过服装遮挡学习和基于StableDiffusion的服装变形拟合模块，解决多层服装试穿中的遮挡关系和变形问题，并提出了MLG数据集和LACD评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的虚拟试穿方法主要关注单层或多件服装试穿，忽略了多层虚拟试穿（ML-VTON）这一重要任务。多层试穿需要将多层服装穿到人体上，并实现真实的变形和层次关系，生成视觉上合理的结果。主要挑战在于准确建模内外层服装之间的遮挡关系，以减少冗余内层服装特征的干扰。

Method: 提出GO-MLVTON方法，包含两个核心模块：1）服装遮挡学习模块，用于学习内外层服装之间的遮挡关系；2）基于StableDiffusion的服装变形与拟合模块，用于将服装变形并贴合到人体上。此外还构建了MLG数据集用于该任务，并提出了新的评估指标LACD。

Result: 大量实验表明GO-MLVTON达到了最先进的性能。该方法能够生成高质量的多层试穿结果，有效处理多层服装之间的遮挡关系和变形问题。

Conclusion: GO-MLVTON是首个解决多层虚拟试穿问题的方法，通过创新的遮挡学习和基于扩散模型的服装变形技术，成功实现了高质量的多层服装试穿效果，为这一领域提供了新的解决方案和评估标准。

Abstract: Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.

</details>


### [161] [DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis](https://arxiv.org/abs/2601.13551)
*Feng Ding,Wenhui Yi,Xinan He,Mengyao Xiao,Jianfeng Xu,Jianqiang Du*

Main category: cs.CV

TL;DR: DiffFace-Edit是一个包含200多万张AI生成伪造图像的数据集，专注于面部细粒度区域编辑，并首次研究了拼接攻击对检测器的真实影响


<details>
  <summary>Details</summary>
Motivation: 现有AI生成人脸数据集缺乏细粒度区域编辑样本，且无人研究真实与伪造样本间拼接攻击对检测器的影响（检测器规避样本）

Method: 创建DiffFace-Edit数据集，包含8个面部区域（如眼睛、鼻子）的编辑，支持单区域和多区域编辑组合，并进行跨域评估结合IMDL方法

Result: 数据集包含超过200万张AI生成伪造图像，提供丰富的编辑组合，并首次分析了检测器规避样本对检测模型的影响

Conclusion: DiffFace-Edit填补了细粒度区域编辑数据集的空白，为研究拼接攻击对检测器的影响提供了重要资源，数据集将开源发布

Abstract: Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit.

</details>


### [162] [Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation](https://arxiv.org/abs/2601.13565)
*Yu Qin,Shimeng Fan,Fan Yang,Zixuan Xue,Zijie Mai,Wenrui Chen,Kailun Yang,Zhiyong Li*

Main category: cs.CV

TL;DR: FiCoP提出从噪声易扰的全局匹配转向空间约束的块级对应，通过补丁-补丁相关矩阵作为结构先验来缩小匹配范围，显著提升开放词汇6D物体姿态估计的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇6D物体姿态估计方法依赖无约束的全局匹配策略，在开放世界场景中，将锚点特征与整个查询图像空间匹配会引入过度歧义，目标特征容易与背景干扰物混淆，导致姿态估计性能下降。

Method: 1) 物体中心解耦预处理：隔离语义目标与环境噪声；2) 跨视角全局感知模块：融合双视图特征，通过显式上下文推理建立结构共识；3) 补丁相关预测器：生成精确的块级关联图，作为空间滤波器实现细粒度、抗噪声匹配。

Result: 在REAL275和Toyota-Light数据集上的实验表明，FiCoP相比最先进方法分别提升平均召回率8.0%和6.1%，在复杂无约束开放世界环境中展现出鲁棒且泛化的感知能力。

Conclusion: FiCoP通过从全局匹配转向空间约束的块级对应，有效解决了开放词汇6D姿态估计中的背景干扰问题，为机器人在复杂开放世界环境中的操作提供了更可靠的感知基础。

Abstract: Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP.

</details>


### [163] [ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch](https://arxiv.org/abs/2601.13606)
*Zheng Liu,Honglin Lin,Chonghan Qin,Xiaoyang Wang,Xin Gao,Yu Li,Mengzhang Cai,Yun Zhu,Zhanping Zhong,Qizhi Pei,Zhuoshi Pan,Xiaoran Shang,Bin Cui,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: ChartVerse框架通过量化图表复杂度和答案优先的QA合成方法，解决了开源视觉语言模型在图表推理任务中高质量训练数据缺乏的问题。


<details>
  <summary>Details</summary>
Motivation: 当前开源视觉语言模型在图表推理能力发展上受到高质量训练数据缺乏的严重制约。现有数据集存在双重挑战：合成图表过于简单重复，而相关QA对存在幻觉问题且缺乏复杂任务所需的推理深度。

Method: 提出ChartVerse框架：1) 引入Rollout Posterior Entropy(RPE)量化图表复杂度，基于RPE开发复杂度感知的图表编码器，通过可执行程序自主合成多样化的高复杂度图表；2) 采用真实锚定的逆向QA合成方法，采用答案优先范式：直接从源代码提取确定性答案，基于这些锚点生成问题，并执行严格的一致性验证；3) 基于模型失败率筛选样本并提炼高质量思维链推理，使用Qwen3-VL-30B-A3B-Thinking作为教师模型，构建ChartVerse-SFT-600K和ChartVerse-RL-40K数据集。

Result: ChartVerse-8B模型实现了最先进的性能，显著超越了其教师模型Qwen3-VL-30B-A3B-Thinking，并与更强的Qwen3-VL-32B-Thinking模型相媲美。

Conclusion: ChartVerse框架通过创新的图表复杂度量化和答案优先的QA合成方法，有效解决了图表推理任务中高质量训练数据缺乏的问题，为开源视觉语言模型的图表推理能力发展提供了可行的解决方案。

Abstract: Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.

</details>


### [164] [CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models](https://arxiv.org/abs/2601.13622)
*Donghee Lee,Rui Cai,Zhe Zhao*

Main category: cs.CV

TL;DR: CARPE：一种模型无关的框架，通过视觉集成层和上下文感知集成策略，让大型视觉语言模型在图像表示和语言模型推理之间自适应选择，提升视觉中心任务的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（LVLMs）在通用任务上表现良好，但在图像分类等视觉中心任务上仍表现不佳，甚至不如其基础视觉编码器（如CLIP）。需要解决LVLMs在视觉任务上的性能瓶颈。

Method: 提出CARPE框架：1）引入视觉集成层，使模型能够捕捉图像表示的不同方面；2）采用上下文感知集成策略，让模型自适应地决定何时优先使用图像表示，何时依赖语言模型的推理能力。

Result: CARPE在图像分类基准测试中显著提升性能，同时在多种视觉语言基准测试中也取得改进。该框架能够有效集成到大多数开源LVLMs中，具有良好的架构适应性。

Conclusion: CARPE通过自适应地权衡视觉和文本模态，解决了LVLMs在视觉中心任务上的性能不足问题，为提升LVLMs的视觉能力提供了一种有效且可扩展的解决方案。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.

</details>


### [165] [Scaling Test-time Inference for Visual Grounding](https://arxiv.org/abs/2601.13633)
*Guanqi Zhan,Changye Li,Zhijian Liu,Yao Lu,Yi Wu,Song Han,Ligeng Zhu*

Main category: cs.CV

TL;DR: EGM方法通过扩展测试时计算（生成更多token）来提升小型视觉语言模型的视觉定位能力，使其在保持部署友好性的同时达到或超越大型模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的视觉定位模型通常规模庞大，部署困难且推理缓慢。研究发现小型和大型VLM的主要差异在于语言模型大小而非视觉编码器，小型模型因语言理解能力不足而在定位任务中表现较差。

Method: 提出EGM（高效视觉定位语言模型）方法，通过扩展测试时计算（增加生成token数量）来弥补小型模型的语言理解能力差距。该方法部署友好，因为每个token的生成成本远低于直接运行大型模型。

Result: 在RefCOCO基准测试中，EGM-Qwen3-VL-8B达到91.4 IoU，平均延迟737ms（比Qwen3-VL-235B快5.9倍），而后者需要4320ms达到90.5 IoU。在新建立的非模态定位任务中，该方法也能显著提升小型模型性能，达到或超越大型模型水平。

Conclusion: EGM方法通过扩展测试时计算有效提升了小型视觉语言模型的视觉定位能力，在保持部署效率和推理速度的同时实现了与大型模型相当甚至更优的性能，显著提高了视觉定位的效率。

Abstract: Visual grounding is an essential capability of Visual Language Models (VLMs) to understand the real physical world. Previous state-of-the-art grounding visual language models usually have large model sizes, making them heavy for deployment and slow for inference. However, we notice that the sizes of visual encoders are nearly the same for small and large VLMs and the major difference is the sizes of the language models. Small VLMs fall behind larger VLMs in grounding because of the difference in language understanding capability rather than visual information handling. To mitigate the gap, we introduce 'Efficient visual Grounding language Models' (EGM): a method to scale the test-time computation (#generated tokens). Scaling the test-time computation of a small model is deployment-friendly, and yields better end-to-end latency as the cost of each token is much cheaper compared to directly running a large model. On the RefCOCO benchmark, our EGM-Qwen3-VL-8B demonstrates 91.4 IoU with an average of 737ms (5.9x faster) latency while Qwen3-VL-235B demands 4,320ms to achieve 90.5 IoU. To validate our approach's generality, we further set up a new amodal grounding setting that requires the model to predict both the visible and occluded parts of the objects. Experiments show our method can consistently and significantly improve the vanilla grounding and amodal grounding capabilities of small models to be on par with or outperform the larger models, thereby improving the efficiency for visual grounding.

</details>


### [166] [Face-Voice Association with Inductive Bias for Maximum Class Separation](https://arxiv.org/abs/2601.13651)
*Marta Moscati,Oleksandr Kats,Mubashir Noman,Muhammad Zaigham Zaheer,Yufang Hou,Markus Schedl,Shah Nawaz*

Main category: cs.CV

TL;DR: 该论文提出了一种在人脸-语音关联任务中应用最大类别分离作为归纳偏置的方法，首次将这一分类技术引入多模态学习领域，并在两个任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 人脸-语音关联研究通常通过损失函数使同一人的面部和语音嵌入接近而不同人的分离。分类领域的最新进展表明，通过施加最大类别分离作为归纳偏置可以增强嵌入的判别能力，但这一技术从未在人脸-语音关联领域应用过，本研究旨在填补这一空白。

Method: 开发了一种人脸-语音关联方法，将不同说话者的多模态表示之间的最大类别分离作为归纳偏置。该方法结合了类间正交性损失，通过量化实验验证了其有效性。

Result: 该方法在人脸-语音关联的两个任务制定上都达到了最先进的性能。消融研究表明，当归纳偏置与类间正交性损失结合时效果最佳。

Conclusion: 这是首次在多模态学习中应用并证明了最大类别分离作为归纳偏置的有效性，为建立新范式铺平了道路。

Abstract: Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm.

</details>


### [167] [VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement](https://arxiv.org/abs/2601.13664)
*Tiancheng Fang,Bowen Pan,Lingxi Chen,Jiangjing Lyu,Chengfei Lyu,Chaoyue Niu,Fan Wu*

Main category: cs.CV

TL;DR: VIAFormer是一个用于多视图条件体素细化的体素-图像对齐Transformer模型，通过校准的多视图图像指导修复不完整噪声体素


<details>
  <summary>Details</summary>
Motivation: 解决使用多视图图像指导修复不完整噪声体素的问题，为体素方法在大模型大数据浪潮中提供实用可靠的桥梁

Method: 采用协同设计：提供2D图像标记显式3D空间基础的图像索引、学习直接体素细化轨迹的校正流目标、实现鲁棒跨模态融合的混合流Transformer

Result: 在纠正从强大视觉基础模型获得的体素形状的严重合成损坏和真实伪影方面建立了新的最先进水平

Conclusion: VIAFormer为实际3D创作流程提供了实用可靠的桥梁，为体素方法在大模型大数据浪潮中蓬勃发展铺平了道路

Abstract: We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.

</details>


### [168] [Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging](https://arxiv.org/abs/2601.13677)
*Carsten T. Lüth,Jeremias Traub,Kim-Celine Kahl,Till J. Bungert,Lukas Klein,Lars Krämer,Paul F. Jäger,Klaus Maier-Hein,Fabian Isensee*

Main category: cs.CV

TL;DR: ClaSP PE是一种用于3D生物医学图像分割的主动学习方法，通过类分层查询和功率噪声调度解决类别不平衡和早期选择冗余问题，在多个数据集上显著优于改进的随机基线。


<details>
  <summary>Details</summary>
Motivation: 3D生物医学图像分割的专家标注成本高昂，现有主动学习方法无法在3D数据上稳定超越改进的随机采样基线，需要一种可靠且高效的解决方案。

Method: 提出Class-stratified Scheduled Power Predictive Entropy (ClaSP PE)查询策略，结合类分层查询确保对少数类结构的覆盖，以及采用对数尺度功率噪声和衰减调度来增强早期AL阶段的查询多样性并促进后期利用。

Result: 在nnActive基准测试的24个实验设置中，ClaSP PE是唯一在分割质量和标注效率方面均显著优于改进随机基线的方法，且在四个未见数据集上无需手动调整即可稳健泛化。

Conclusion: ClaSP PE证明了主动学习方法可以在3D分割任务中稳定超越随机基线，提供了一种实用且高效的标注解决方案，开源实现和部署指南使其易于实际应用。

Abstract: Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive.

</details>


### [169] [Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation](https://arxiv.org/abs/2601.13683)
*Boyuan Cao,Xingbo Yao,Chenhui Wang,Jiaxin Ye,Yujie Wei,Hongming Shan*

Main category: cs.CV

TL;DR: DyDiLA是一种新型线性注意力机制，通过动态投影模块、动态测量核和令牌差分算子解决线性扩散变换器中注意力权重过度平滑问题，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiTs)在高质量图像生成方面表现出色，但自注意力的二次计算成本成为主要可扩展性瓶颈。线性注意力机制虽然降低了计算成本，但线性扩散变换器(LiTs)通常以牺牲生成性能为代价，产生过度平滑的注意力权重，限制了表达能力。

Method: 提出动态差分线性注意力(DyDiLA)，包含三个关键设计：1) 动态投影模块，通过学习动态分配的知识促进令牌表示的解耦；2) 动态测量核，通过为令牌处理动态分配核函数提供更好的相似性度量，捕捉细粒度语义差异；3) 令牌差分算子，通过计算令牌与其动态测量核产生的信息冗余之间的差异，实现更稳健的查询到键检索。基于DyDiLA构建了改进的线性扩散变换器DyDi-LiT。

Result: 大量实验表明，DyDi-LiT在多个指标上持续优于当前最先进模型，显示出强大的实际潜力。

Conclusion: DyDiLA通过解决线性注意力中的过度平滑问题，显著提升了线性扩散变换器的生成质量，在保持计算效率的同时实现了更好的性能表现。

Abstract: Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.

</details>


### [170] [Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles](https://arxiv.org/abs/2601.13705)
*Maria Lymperaiou,Vasileios Karampinis,Giorgos Filandrianos,Angelos Vlachos,Chrysoula Zerva,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 该论文是一篇关于视觉谜题在大型视觉语言模型推理能力评估中的综述研究，将视觉谜题作为诊断工具来评估LVLMs的推理能力，并系统分析了现有基准测试的分类和模型局限性。


<details>
  <summary>Details</summary>
Motivation: 视觉谜题长期以来作为人类认知的紧凑探测工具，能够以最小的先验知识依赖来隔离抽象、规则发现和系统推理。利用这些特性，视觉谜题最近成为评估大型视觉语言模型推理能力的强大诊断工具，为开放式多模态基准测试提供了可控、可验证的替代方案。

Method: 通过统一的抽象框架来理解视觉谜题，并根据目标推理机制（归纳、类比、算法、演绎和几何/空间推理）组织现有基准测试，从而将谜题设计与解决所需的认知操作联系起来。综合这些类别的实证证据，分析当前模型的局限性。

Result: 识别出当前模型的一致局限性：脆弱的泛化能力、感知与推理之间的紧密纠缠、流畅解释与忠实执行之间的持续差距。通过将视觉谜题视为诊断工具而非任务格式，阐明了LVLM推理的现状。

Conclusion: 该综述为未来基准测试和推理感知多模态系统的关键方向提供了框架，强调视觉谜题作为诊断工具在评估和改进大型视觉语言模型推理能力方面的重要价值。

Abstract: Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems.

</details>


### [171] [PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval](https://arxiv.org/abs/2601.13797)
*Gabriele Serussi,David Vainshtein,Jonathan Kouchly,Dotan Di Castro,Chaim Baskin*

Main category: cs.CV

TL;DR: PREGEN：一种无需微调视觉语言模型的高效组合视频检索框架，通过提取VLM隐藏状态并训练轻量编码器实现语义丰富的紧凑嵌入，显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 当前组合视频检索方法未能充分利用现代视觉语言模型，要么使用过时架构，要么需要计算昂贵的微调和缓慢的标题生成。需要一种更高效、更强大的框架来克服这些限制。

Method: PREGEN采用冻结的预训练VLM与轻量编码模型配对。将查询视频和修改文本输入VLM，提取每层最后一个token的隐藏状态，然后在这些池化表示上训练简单编码器，生成语义丰富且紧凑的检索嵌入。

Result: PREGEN显著推进了组合视频检索的技术水平，在标准基准测试中超越所有先前方法，Recall@1分别提升+27.23和+69.59。方法在不同VLM骨干上表现出鲁棒性，对更复杂的文本修改具有强大的零样本泛化能力。

Conclusion: PREGEN是一种高效且强大的组合视频检索框架，无需微调VLM即可充分利用其语义能力，在性能和泛化方面均取得显著改进，为组合视频检索提供了新的解决方案。

Abstract: Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities.

</details>


### [172] [DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes](https://arxiv.org/abs/2601.13839)
*Aisha Al-Mohannadi,Ayisha Firoz,Yin Yang,Muhammad Imran,Ferda Ofli*

Main category: cs.CV

TL;DR: DisasterVQA是一个专门为灾害响应设计的视觉问答基准数据集，包含1,395张真实灾害图像和4,405个专家标注的问答对，用于评估视觉语言模型在灾害场景下的感知和推理能力。


<details>
  <summary>Details</summary>
Motivation: 社交媒体图像在灾害期间提供低延迟的态势信息，但现有通用视觉问答模型在灾害响应这种复杂、安全关键的推理任务中的适用性尚不明确。需要专门针对灾害场景的基准来指导开发更鲁棒、操作性强的视觉语言模型。

Method: 基于FEMA ESF和OCHA MIRA等人道主义框架，构建了包含洪水、野火、地震等多种灾害类型的真实图像数据集。设计了二元、多项选择和开放式问题，涵盖态势感知和操作决策任务。对7个最先进的视觉语言模型进行了基准测试。

Result: 模型在二元问题上表现良好，但在细粒度定量推理、物体计数和上下文敏感解释方面存在困难，特别是在代表性不足的灾害场景中。性能在不同问题类型、灾害类别、区域和人道主义任务之间存在显著差异。

Conclusion: DisasterVQA提供了一个具有挑战性和实用性的基准，能够指导开发更适合灾害响应的鲁棒视觉语言模型。数据集已公开可用，填补了灾害响应领域专门评估工具的空白。

Abstract: Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.

</details>


### [173] [OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting](https://arxiv.org/abs/2601.13871)
*Michail Spanakis,Iason Oikonomidis,Antonis Argyros*

Main category: cs.CV

TL;DR: OCCAM是首个无需训练、无需额外信息的类无关目标计数方法，可处理图像中任意多类目标计数，基于SAM2和自定义FINCH算法实现。


<details>
  <summary>Details</summary>
Motivation: 现有类无关目标计数方法通常假设每张图像只有一个目标类别，依赖大规模深度学习模型训练，并需要额外信息（如视觉示例或文本提示）。需要开发无需训练、无需补充信息且能处理多类目标计数的方法。

Method: 利用Segment Anything Model 2 (SAM2)基础模型和自定义阈值版本的First Integer Neighbor Clustering Hierarchy (FINCH)算法，无需训练即可实现多类目标计数。

Result: 在FSC-147和CARPK基准数据集上取得有竞争力的性能，提出了合成多类数据集和更合适的F1评分评估指标。

Conclusion: OCCAM是首个无需训练、无需额外信息的类无关目标计数方法，能有效处理多类目标计数问题，为实际应用提供了更实用的解决方案。

Abstract: Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter.

</details>


### [174] [OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3](https://arxiv.org/abs/2601.13895)
*Xu Zhang,Danyang Li,Yingjie Xia,Xiaohang Dong,Hualong Yu,Jianye Wang,Qicheng Li*

Main category: cs.CV

TL;DR: 提出OmniOVCD框架，利用SAM 3的解耦输出头，通过SFID策略融合语义、实例和存在性输出构建地物掩码，再分解为实例掩码进行变化检测，在四个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有免训练的开放词汇变化检测方法多依赖CLIP识别类别，并需要额外模型提取特征，导致特征匹配问题和系统不稳定。SAM 3的推出为OVCD任务提供了新可能，其集成分割和识别能力于单一可提示模型中。

Method: 提出OmniOVCD框架，利用SAM 3的解耦输出头，设计协同融合到实例解耦策略。SFID首先融合SAM 3的语义、实例和存在性输出来构建地物覆盖掩码，然后将其分解为单独的实例掩码进行变化比较。该设计保持了类别识别的高精度和跨图像的实例级一致性。

Result: 在四个公开基准测试（LEVIR-CD、WHU-CD、S2Looking和SECOND）上实现了最先进的性能，分别获得了67.2、66.5、24.5和27.1的IoU分数（类别平均），超越了所有先前方法。

Conclusion: OmniOVCD通过利用SAM 3的解耦能力，提出SFID策略有效解决了开放词汇变化检测中的特征匹配和稳定性问题，在多个基准测试中展现了优越性能，为遥感变化检测提供了新的解决方案。

Abstract: Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.

</details>


### [175] [Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging](https://arxiv.org/abs/2601.13899)
*Masoumeh Javanbakhat,Piotr Komorowski,Dilyara Bareeva,Wei-Chang Lai,Wojciech Samek,Christoph Lippert*

Main category: cs.CV

TL;DR: 提出可解释的深度统计测试框架，为深度双样本测试提供样本级和特征级解释，揭示哪些样本和特征驱动组间差异


<details>
  <summary>Details</summary>
Motivation: 深度双样本测试虽然检测能力强但缺乏可解释性，现有解释方法依赖类别标签，不适用于无标签的统计测试场景，限制了在生物医学分析中的实际应用

Method: 提出可解释的深度统计测试框架，通过样本级和特征级解释增强深度双样本测试，识别驱动统计显著差异的个体样本和输入特征

Result: 方法能突出显示对检测到的组间差异贡献最大的图像区域和个体样本，提供空间和实例层面的洞察，应用于生物医学成像数据时能识别有影响力的样本和与疾病相关变异相关的解剖学意义区域

Conclusion: 该工作桥接了统计推断和可解释AI，实现了医学成像中可解释、无标签的群体分析

Abstract: Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.

</details>


### [176] [Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning](https://arxiv.org/abs/2601.13942)
*Hongbo Bai,Yujin Zhou,Yile Wu,Chi-Min Chan,Pengcheng Wen,Kunhao Pan,Sirui Han,Yike Guo*

Main category: cs.CV

TL;DR: GoG框架通过选择性注视机制和双阶段训练策略，解决了大型多模态模型在处理知识密集型视觉查询时的局限性，实现了从被动感知到主动视觉规划的转变。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型在视觉理解方面取得了显著成功，但在处理涉及长尾实体或动态信息的知识密集型查询时，由于静态参数化知识的限制而表现不佳。现有的搜索增强方法存在视觉冗余和噪声问题，且缺乏深度迭代反思，限制了其在复杂视觉查询上的有效性。

Method: 提出了Glance-or-Gaze（GoG）框架，包含选择性注视机制（动态选择全局上下文或高价值区域），以及双阶段训练策略：通过监督微调进行反射性GoG行为对齐，以及复杂度自适应强化学习来增强处理复杂查询的能力。

Result: 在六个基准测试中展示了最先进的性能。消融研究证实选择性注视机制和复杂度自适应强化学习对于有效的视觉搜索都是必不可少的。

Conclusion: GoG框架通过从被动感知转向主动视觉规划，有效解决了大型多模态模型在处理知识密集型视觉查询时的局限性，为复杂视觉搜索任务提供了新的解决方案。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon.

</details>


### [177] [VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content](https://arxiv.org/abs/2601.13951)
*Shengyi Wu,Yan Hong,Shengyao Chen,Zheng Wang,Xianbing Sun,Jiahui Zhan,Jun Lan,Jianfu Zhang*

Main category: cs.CV

TL;DR: 提出VTONGuard大规模基准数据集，包含超过775,000张真实和合成试穿图像，用于评估虚拟试穿内容的真实性检测方法。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在虚拟试穿(VTON)领域的快速发展，AI生成的试穿内容越来越逼真，引发了关于真实性和负责任使用的迫切担忧。需要建立基准数据集来促进检测方法的发展。

Method: 1) 构建VTONGuard数据集，包含超过775,000张真实和合成试穿图像，涵盖姿势、背景、服装风格等多种真实场景；2) 在统一训练和测试协议下系统评估多种检测范式；3) 设计多任务框架，集成辅助分割以增强边界感知特征学习。

Result: 1) 揭示了各种检测方法的优缺点；2) 突出了跨范式泛化的持续挑战；3) 提出的多任务框架在VTONGuard上实现了最佳整体性能。

Conclusion: VTONGuard基准数据集能够实现公平比较，促进更鲁棒的检测模型发展，推动VTON技术在实际应用中的安全和负责任部署。

Abstract: With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.

</details>


### [178] [DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging](https://arxiv.org/abs/2601.13954)
*Adrien Meyer,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: DExTeR是基于Transformer的点到框回归器，专为医学影像设计，通过类引导可变形注意力、CLICK-MoE专家混合和多点训练策略，在点标注下实现高精度目标检测。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的解剖标志检测对诊断和介入指导至关重要，但传统目标检测模型依赖昂贵的边界框标注。弱半监督目标检测使用点标注可减少标注成本，但医学影像存在解剖重叠、尺寸多变和结构模糊等挑战，影响边界框推断准确性。

Method: 基于Point-DETR构建DExTeR，将单点标注编码为对象查询；引入类引导可变形注意力，利用点坐标和类别标签指导注意力采样；提出CLICK-MoE（类别、实例和通用知识混合专家）解耦类别和实例表示；采用多点训练策略提升对标注变化的鲁棒性。

Result: 在三个不同医学领域数据集（内窥镜、胸部X光和内镜超声）上达到最先进性能，显著降低标注成本的同时保持高检测精度。

Conclusion: DExTeR通过专门设计的Transformer架构有效解决了医学影像中点标注到边界框推断的挑战，为减少医学影像标注成本同时保持高检测精度提供了有效解决方案。

Abstract: Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.

</details>


### [179] [STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames](https://arxiv.org/abs/2601.13974)
*Shih-Yao Lin*

Main category: cs.CV

TL;DR: STEC是一种用于评估视频帧采样质量的无参考指标，通过联合建模空间信息强度、时间分散性和非冗余性来衡量采样帧的信息覆盖度。


<details>
  <summary>Details</summary>
Motivation: 现有视频帧采样评估指标主要关注感知质量或重建保真度，缺乏评估采样帧是否充分捕捉视频信息内容和代表性的方法，需要一种任务无关的诊断工具来分析有限预算下的帧采样行为。

Method: 提出时空熵覆盖率(STEC)，基于时空帧熵(STFE)测量每帧的空间信息（基于熵的结构复杂度），并通过时间覆盖度和冗余度评估采样帧，联合建模空间信息强度、时间分散性和非冗余性。

Result: 在MSR-VTT test-1k基准测试中，STEC能清晰区分随机、均匀和内容感知等常见采样策略，并揭示单个视频的鲁棒性模式，这些模式无法通过平均性能单独捕获。

Conclusion: STEC提供了一种轻量级、原则性的采样质量度量方法，作为通用评估工具具有实际价值，但强调其设计目的不是预测下游任务准确性，而是提供任务无关的诊断信号。

Abstract: Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content.
  We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality.
  Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding.
  We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.

</details>


### [180] [FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation](https://arxiv.org/abs/2601.13976)
*Jing Zuo,Lingzhou Mu,Fan Jiang,Chengcheng Ma,Mu Xu,Yonggang Qi*

Main category: cs.CV

TL;DR: FantasyVLN提出了一种统一的隐式推理框架，通过将想象的视觉标记编码到紧凑的潜在空间，在保持CoT推理优势的同时避免了显式标记开销，实现了推理感知的实时视觉语言导航。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法在视觉语言导航中存在两个关键缺陷：纯文本CoT缺乏空间基础且容易过拟合稀疏标注的推理步骤，而多模态CoT由于生成想象的视觉观察导致严重的标记膨胀，使得实时导航不切实际。

Method: 提出FantasyVLN统一隐式推理框架：1）使用预训练的视觉自回归器（VAR）将想象的视觉标记编码到紧凑潜在空间；2）在CoT推理训练中联合学习文本、视觉和多模态CoT模式；3）采用统一的多CoT策略；4）推理时直接进行指令到动作的映射，同时保持推理感知的表示。

Result: 在LH-VLN数据集上的广泛实验表明，该方法实现了推理感知的实时导航，提高了成功率和效率，同时相比显式CoT方法将推理延迟降低了一个数量级。

Conclusion: FantasyVLN框架在保持CoT推理优势的同时避免了显式标记开销，为视觉语言导航提供了一种既具有推理能力又实用的解决方案，平衡了推理深度和计算效率。

Abstract: Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.

</details>


### [181] [Equivariant Learning for Unsupervised Image Dehazing](https://arxiv.org/abs/2601.13986)
*Zhang Wen,Jiangwei Xie,Dongdong Chen*

Main category: cs.CV

TL;DR: 提出了一种新的无监督图像去雾框架EID，利用图像信号的对称性从原始有雾图像中恢复清晰图像，无需精心设计的先验或大量无雾地面真值。


<details>
  <summary>Details</summary>
Motivation: 当前图像去雾方法通常依赖精心设计的先验或大量无雾地面真值，这些在科学成像中获取成本高或不切实际，需要一种更实用的无监督方法。

Method: 提出EID框架，利用图像信号的对称性，通过强制雾一致性约束和系统性等变性来恢复清晰模式；同时提出对抗学习策略来建模未知的雾物理特性。

Result: 在两个科学图像去雾基准（细胞显微镜和医学内窥镜）以及自然图像去雾实验中，EID显著优于现有最先进方法。

Conclusion: 通过将等变学习与雾物理建模相结合，EID有望在科学成像中实现更通用和有效的雾去除，代码和数据集将公开发布。

Abstract: Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published.

</details>


### [182] [Human detectors are surprisingly powerful reward models](https://arxiv.org/abs/2601.14037)
*Kumar Ashutosh,XuDong Wang,Xi Yin,Kristen Grauman,Adam Polyak,Ishan Misra,Rohit Girdhar*

Main category: cs.CV

TL;DR: 提出HuDA奖励模型，通过结合人体检测置信度和时序提示对齐分数来量化生成视频中人体动作质量，无需额外训练即可显著提升复杂人体动作生成效果


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在视觉保真度和时序一致性方面已取得显著进展，但在处理复杂非刚性运动（特别是人体动态动作如运动、舞蹈等）时仍存在困难，常出现肢体缺失/多余、姿态扭曲或物理上不可信的动作

Method: 提出HuDA奖励模型，整合人体检测置信度（评估外观质量）和时序提示对齐分数（捕捉运动真实性），使用现成模型无需额外训练；采用Group Reward Policy Optimization (GRPO)后训练方法优化视频模型

Result: HuDA在评估人体动作质量方面优于使用人工标注数据微调的专用模型；通过GRPO后训练显著提升视频生成质量，特别是在复杂人体动作生成上，以73%胜率超越Wan 2.1等SOTA模型；HuDA还能改善动物视频和人物-物体交互的生成质量

Conclusion: HuDA作为一个简单但有效的奖励模型，能够准确量化生成视频中人体动作质量，通过GRPO后训练可显著提升视频生成模型的性能，不仅适用于人体动作，还能泛化到其他复杂运动场景

Abstract: Video generation models have recently achieved impressive visual fidelity and temporal coherence. Yet, they continue to struggle with complex, non-rigid motions, especially when synthesizing humans performing dynamic actions such as sports, dance, etc. Generated videos often exhibit missing or extra limbs, distorted poses, or physically implausible actions. In this work, we propose a remarkably simple reward model, HuDA, to quantify and improve the human motion in generated videos. HuDA integrates human detection confidence for appearance quality, and a temporal prompt alignment score to capture motion realism. We show this simple reward function that leverages off-the-shelf models without any additional training, outperforms specialized models finetuned with manually annotated data. Using HuDA for Group Reward Policy Optimization (GRPO) post-training of video models, we significantly enhance video generation, especially when generating complex human motions, outperforming state-of-the-art models like Wan 2.1, with win-rate of 73%. Finally, we demonstrate that HuDA improves generation quality beyond just humans, for instance, significantly improving generation of animal videos and human-object interactions.

</details>


### [183] [Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving](https://arxiv.org/abs/2601.14038)
*Alexandre Justo Miro,Ludvig af Klinteberg,Bogdan Timus,Aron Asefaw,Ajinkya Khoche,Thomas Gustafsson,Sina Sharif Mansouri,Masoud Daneshtalab*

Main category: cs.CV

TL;DR: 该论文首次发现并纠正了自动驾驶数据集中的3D框标注误差，通过离线估计方法使标注符合物理可行轨迹并与传感器数据保持时空一致性，显著提升了标注质量。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统依赖准确的3D框标注进行监督学习和性能评估。然而，在动态场景中，由于物体在不同时间戳被观测到，基于LiDAR等主动传感器的3D框标注容易引入系统性误差，这些误差在现有公开数据集中尚未被发现和纠正。

Method: 提出了一种新颖的离线估计方法，通过纠正标注使其遵循物理可行轨迹，并与传感器数据保持空间和时间一致性。该方法首次定义了该问题的评估指标，并在Argoverse 2、MAN TruckScenes和专有数据集上进行了验证。

Result: 方法将数据集中的框标注质量提升了超过17%。量化分析显示原始标注误差最大可达2.5米，高度动态物体受影响最严重。基准测试表明，这些误差的影响超过了最先进方法相对于先前方法的改进幅度。

Conclusion: 准确的3D框标注对于正确解释自动驾驶系统性能至关重要。该工作首次发现并纠正了公开数据集中的标注误差，为更可靠的自动驾驶系统评估提供了基础。代码已开源。

Abstract: Accurate ground truth annotations are critical to supervised learning and evaluating the performance of autonomous vehicle systems. These vehicles are typically equipped with active sensors, such as LiDAR, which scan the environment in predefined patterns. 3D box annotation based on data from such sensors is challenging in dynamic scenarios, where objects are observed at different timestamps, hence different positions. Without proper handling of this phenomenon, systematic errors are prone to being introduced in the box annotations. Our work is the first to discover such annotation errors in widely used, publicly available datasets. Through our novel offline estimation method, we correct the annotations so that they follow physically feasible trajectories and achieve spatial and temporal consistency with the sensor data. For the first time, we define metrics for this problem; and we evaluate our method on the Argoverse 2, MAN TruckScenes, and our proprietary datasets. Our approach increases the quality of box annotations by more than 17% in these datasets. Furthermore, we quantify the annotation errors in them and find that the original annotations are misplaced by up to 2.5 m, with highly dynamic objects being the most affected. Finally, we test the impact of the errors in benchmarking and find that the impact is larger than the improvements that state-of-the-art methods typically achieve with respect to the previous state-of-the-art methods; showing that accurate annotations are essential for correct interpretation of performance. Our code is available at https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes.

</details>


### [184] [Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation](https://arxiv.org/abs/2601.14039)
*Wesam Moustafa,Hossam Elsafty,Helen Schneider,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CV

TL;DR: 提出一个通用的弃权框架，通过选择性忽略噪声样本来增强医学图像分割的噪声鲁棒性


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中标签噪声问题严重，现有方法对此研究不足。弃权机制在分类任务中证明有效，但在分割领域潜力未经验证

Method: 提出通用模块化弃权框架，包含两个关键组件：引导弃权行为的知情正则化项和基于幂律的自适应调参算法。将该框架与三种不同损失函数集成，创建了GAC、SAC和ADS三种噪声鲁棒变体

Result: 在CaDIS和DSAD医学数据集上的实验表明，该方法在多种噪声水平下均显著优于非弃权基线，特别是在高噪声水平下表现突出

Conclusion: 通过选择性忽略损坏样本的弃权机制是构建更可靠分割模型的强大且可泛化策略，该框架具有通用性和模块化特点

Abstract: Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation.

</details>


### [185] [Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology](https://arxiv.org/abs/2601.14044)
*Kaiyu Wu,Pucheng Han,Hualong Zhang,Naigeng Wu,Keze Wang*

Main category: cs.CV

TL;DR: 该论文针对气象领域的视觉语言模型存在领域鸿沟和推理忠实度问题，提出了WeatherQA基准和LoCo-RFT方法，开发了首个具有逻辑忠实度的气象推理VLM Weather-R1


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在气象学应用中面临两个主要挑战：领域鸿沟和推理忠实度鸿沟。主流强化微调方法会导致自相矛盾推理，即模型的推理过程与其最终答案相矛盾，这在气象等高风险领域是不可接受的。

Method: 1. 构建WeatherQA，一个新颖的气象学多模态推理基准；2. 提出逻辑一致性强化微调方法，通过引入逻辑一致性奖励来解决自相矛盾推理问题；3. 开发Weather-R1，这是首个在气象领域具有逻辑忠实度的推理视觉语言模型。

Result: 实验表明，Weather-R1在WeatherQA基准上的性能比基线提高了9.8个百分点，优于监督微调和传统强化微调方法，甚至超越了原始的Qwen2.5-VL-32B模型。

Conclusion: 该研究提出的LoCo-RFT方法有效解决了气象领域视觉语言模型的推理一致性问题，Weather-R1模型在气象推理任务上表现出优越性能，为高风险领域的可靠AI应用提供了重要解决方案。

Abstract: While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1.

</details>


### [186] [Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model](https://arxiv.org/abs/2601.14052)
*Haoran Xu,Yanlin Liu,Zizhao Tong,Jiaze Li,Kexue Fu,Yuyang Zhang,Longxiang Gao,Shuaiguang Li,Xingyu Li,Yanran Xu,Changwei Wang*

Main category: cs.CV

TL;DR: 提出MM-OOD方法，利用多模态大语言模型进行零样本OOD检测，通过多轮对话增强异常检测能力，针对近OOD和远OOD任务采用不同策略。


<details>
  <summary>Details</summary>
Motivation: 现有零样本OOD检测方法过度依赖文本空间知识，忽视了图像空间检测的固有挑战。CLIP的出现推动了零样本OOD检测研究，但需要更有效的多模态方法来处理图像空间的异常检测问题。

Method: 提出MM-OOD管道：1) 对于近OOD任务，直接将ID图像和文本提示输入MLLMs识别潜在异常；2) 对于远OOD任务，采用sketch-generate-elaborate框架：先用文本提示勾画异常暴露，生成对应的视觉OOD样本，最后通过多模态提示进行详细阐述。

Result: 在Food-101等广泛使用的多模态数据集上取得显著改进，同时在ImageNet-1K上验证了方法的可扩展性。

Conclusion: MM-OOD方法通过利用MLLMs的多模态推理能力和多轮对话，有效提升了零样本OOD检测性能，特别是在处理图像空间异常检测挑战方面表现出优势。

Abstract: Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.

</details>


### [187] [POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion](https://arxiv.org/abs/2601.14056)
*Andrea Rigo,Luca Stornaiuolo,Weijie Wang,Mauro Martino,Bruno Lepri,Nicu Sebe*

Main category: cs.CV

TL;DR: POCI-Diff：基于扩散的文本到图像生成框架，通过3D布局控制和语义绑定实现一致的多对象场景合成与编辑


<details>
  <summary>Details</summary>
Motivation: 现有方法使用2D线索或迭代复制-变形-粘贴策略来改善空间一致性，但经常扭曲对象几何形状且无法在编辑过程中保持一致性。需要一种能够同时强制执行3D几何约束和实例级语义绑定的统一方法。

Method: 提出POCI-Diff框架：1）通过Blended Latent Diffusion将单个文本描述绑定到特定3D边界框，实现显式的每对象语义控制；2）采用无变形生成编辑管道，通过重新生成而非像素变形支持对象插入、移除和变换；3）使用IP-Adapter基于参考图像条件化扩散过程，在交互式3D编辑中保持对象身份和一致性。

Result: 实验结果表明，POCI-Diff生成与指定3D布局和编辑一致的高质量图像，在视觉保真度和布局一致性方面优于最先进方法，同时消除了变形引起的几何伪影。

Conclusion: POCI-Diff通过统一的扩散过程实现了3D几何约束和实例级语义绑定，为文本到图像生成提供了具有一致性和交互性的3D布局控制与编辑能力，解决了现有方法在几何保真度和编辑一致性方面的局限性。

Abstract: We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.

</details>


### [188] [VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences](https://arxiv.org/abs/2601.14066)
*Hendrik Möller,Hanna Schoen,Robert Graf,Matan Atad,Nathan Molinier,Anjany Sekuboyina,Bettina K. Budai,Fabian Bamberg,Steffen Ringhof,Christopher Schlett,Tobias Pischon,Thoralf Niendorf,Josua A. Decker,Marc-André Weber,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke*

Main category: cs.CV

TL;DR: VERIDAH算法通过多分类头结合加权椎体序列预测，能自动识别脊柱计数异常，在T2w和CT影像上显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 脊柱计数异常（如11或13个胸椎、4或6个腰椎）具有临床意义，但临床报告中常被忽视，现有深度学习方法缺乏自动识别异常的能力

Method: 提出VERIDAH算法，基于多分类头结合加权椎体序列预测，能处理任意视野图像并自动识别计数异常

Result: 在T2w TSE矢状位影像上正确标记所有椎体的比例从94.24%提升至98.30%，CT影像上从77.26%提升至99.18%；胸椎计数异常识别率T2w为87.80%、CT为96.30%，腰椎异常识别率T2w为94.48%、CT为97.22%

Conclusion: VERIDAH能有效自动识别脊柱计数异常，显著优于现有方法，具有临床应用价值，代码已开源

Abstract: The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing "Vertebra Identification with Anomaly Handling" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps.

</details>


### [189] [VENI: Variational Encoder for Natural Illumination](https://arxiv.org/abs/2601.14079)
*Paul Walker,James A. D. Gardner,Andreea Ardelean,William A. P. Smith,Bernhard Egger*

Main category: cs.CV

TL;DR: 提出一种旋转等变变分自编码器，用于在球面上建模自然光照，避免使用2D投影，通过新型VN-ViT编码器和旋转等变条件神经场解码器实现SO(2)-等变表示。


<details>
  <summary>Details</summary>
Motivation: 现有逆渲染方法要么忽略了光照环境的球面和旋转等变特性，要么未能提供良好行为的潜在空间。需要一种能够保持SO(2)-等变性的环境映射建模方法。

Method: 使用新型向量神经元视觉变换器(VN-ViT)作为编码器，旋转等变条件神经场作为解码器。在编码器中通过新型SO(2)-等变全连接层将等变性从SO(3)降至SO(2)，这是向量神经元的扩展。

Result: 提出的SO(2)-等变全连接层在SO(2)-等变模型中优于标准向量神经元。相比先前方法，该变分自编码器在潜在空间中实现更平滑的插值，并提供更良好行为的潜在空间。

Conclusion: 该方法成功建模了球面上的自然光照，保持了SO(2)-等变性，避免了2D投影，提供了更优的潜在空间表示，为逆渲染问题提供了更好的先验。

Abstract: Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.

</details>


### [190] [DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning](https://arxiv.org/abs/2601.14084)
*Abdurrahim Yilmaz,Ozan Erdem,Ece Gokyayla,Ayda Acar,Burc Bugra Dagtas,Dilara Ilhan Erdil,Gulsum Gencoglan,Burak Temelkuran*

Main category: cs.CV

TL;DR: DermaBench：基于DDI数据集的皮肤科视觉问答基准，包含656张临床图像、22个主要问题类型，约1.45万条专家标注，用于评估多模态模型在皮肤科的视觉理解和临床推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在皮肤科的评估主要局限于图像级分类任务（如病变识别），无法全面评估多模态模型的视觉理解、语言基础和临床推理能力。需要视觉问答基准来评估模型如何解释皮肤科图像、推理细粒度形态特征并生成有临床意义的描述。

Method: 基于多样化皮肤科图像（DDI）数据集构建DermaBench基准，包含656张来自570名不同患者的临床图像，涵盖Fitzpatrick皮肤类型I-VI。采用分层标注方案，由皮肤科专家对每张图像进行诊断、解剖部位、病变形态、分布、表面特征、颜色和图像质量等方面的标注，包含22个主要问题类型（单选、多选和开放式），生成约14,474条VQA风格标注。以仅元数据形式发布以遵守上游许可。

Result: 成功构建了DermaBench基准，包含656张临床图像、570名患者、覆盖所有Fitzpatrick皮肤类型，通过专家标注产生了约14,474条视觉问答标注，涵盖诊断、解剖部位、病变形态、分布、表面特征、颜色、图像质量等多个维度，并包含开放式叙述描述和总结。

Conclusion: DermaBench填补了皮肤科视觉问答基准的空白，能够全面评估多模态模型在皮肤科的视觉理解、语言基础和临床推理能力。该基准以元数据形式在哈佛Dataverse公开可用，为皮肤科AI研究提供了重要的评估工具。

Abstract: Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.

</details>


### [191] [Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition](https://arxiv.org/abs/2601.14101)
*Emily Kim,Allen Wu,Jessica Hodgins*

Main category: cs.CV

TL;DR: 该论文研究了课程学习在跨视角动作识别中的应用，通过结合合成航拍数据和真实地面数据，在不使用真实航拍数据训练的情况下，提高了模型对未见真实航拍数据的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有动作识别模型主要基于地面视角数据训练，难以泛化到航拍视角等不同领域。真实航拍数据获取困难，需要探索如何在不使用真实航拍数据的情况下，通过课程学习策略提高跨视角泛化能力。

Method: 提出两种课程学习策略：1）两阶段课程（直接微调）：先在合成航拍数据上训练，然后在真实地面数据上微调；2）渐进式课程（多阶段扩展）：通过多个阶段逐步扩展数据集后再微调。使用SlowFast（CNN）和MViTv2（Transformer）架构在REMAG数据集上评估。

Result: 结合两种域外数据集明显优于单一域训练。两种课程策略在保持top-1准确率（在3%范围内）的同时显著提升训练效率：两阶段微调使SlowFast减少37%迭代次数，MViTv2减少30%；渐进式方法进一步减少迭代次数（SlowFast 9%，MViTv2 30%）。

Conclusion: 课程学习在跨视角动作识别中能有效平衡性能与效率，通过合理的训练策略可以在不使用真实航拍数据的情况下实现良好的泛化能力，为数据稀缺场景下的跨域识别提供解决方案。

Abstract: Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training.
  We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures.
  Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.

</details>


### [192] [Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing](https://arxiv.org/abs/2601.14103)
*Xiaolu Liu,Yicong Li,Qiyuan He,Jiayin Zhu,Wei Ji,Angela Yao,Jianke Zhu*

Main category: cs.CV

TL;DR: Interp3D是一个无需训练的三维纹理变形框架，通过生成先验和渐进对齐策略实现几何保真和纹理连贯的平滑三维资产过渡。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么只处理几何形状忽略纹理，要么将2D插值策略扩展到3D导致语义模糊、结构错位和纹理模糊。需要同时保持几何一致性、纹理对齐和过渡过程的鲁棒性。

Method: 提出Interp3D训练免费框架，利用生成先验和渐进对齐原则：1）条件空间的语义对齐插值；2）SLAT引导的结构插值确保结构一致性；3）细粒度纹理融合传递外观细节。

Result: 构建了分级难度数据集Interp3DData进行评估，定量指标和人工研究均显示该方法在保真度、过渡平滑性和合理性方面显著优于先前方法。

Conclusion: Interp3D通过联合保持几何一致性和纹理对齐，实现了高质量的三维纹理变形，为动画、编辑和数字内容创作提供了实用解决方案。

Abstract: Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.

</details>


### [193] [PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning](https://arxiv.org/abs/2601.14111)
*Jiaying Wu,Can Gao,Jinglu Hu,Hui Li,Xiaofeng Cao,Jingcai Guo*

Main category: cs.CV

TL;DR: PMCE：一个概率性少样本学习框架，通过多粒度语义和字幕引导增强来改善原型估计，利用基础类知识库和BLIP字幕器提升少样本分类性能。


<details>
  <summary>Details</summary>
Motivation: 少样本学习中，从少量标记样本估计的原型往往存在偏差且泛化能力差。现有的语义方法主要应用于支持集侧，而查询表示保持不变。需要一种更全面的方法来利用多粒度语义信息改善原型估计。

Method: 1. 构建非参数知识库：存储基础类别的视觉统计信息和CLIP编码的类别名称嵌入。2. 元测试时检索：基于类别名称嵌入相似性为每个新类别检索最相关的基础类。3. 先验信息融合：将检索到的统计信息聚合为类别特定先验，通过MAP更新与支持集原型融合。4. 字幕引导增强：使用冻结的BLIP字幕器提供无标签实例级图像描述，通过轻量级增强器在基础类上训练，优化支持原型和查询特征，采用一致性正则化稳定噪声字幕。

Result: 在四个基准测试上，PMCE始终优于强基线方法。在MiniImageNet的1-shot设置中，比最强的语义竞争对手获得了高达7.71%的绝对增益提升。

Conclusion: PMCE通过结合多粒度语义信息和字幕引导增强，有效改善了少样本学习中的原型估计问题。该方法利用基础类知识库提供类别先验，并通过实例级字幕描述增强特征表示，在多个基准测试上取得了显著性能提升。

Abstract: Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D

</details>


### [194] [The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning](https://arxiv.org/abs/2601.14127)
*Renmiao Chen,Yida Lu,Shiyao Cui,Xuan Ouyang,Victor Shea-Jay Huang,Shumin Zhang,Chengwei Pan,Han Qiu,Minlie Huang*

Main category: cs.CV

TL;DR: MIR-SafetyBench是首个专注于多图像推理安全性的基准测试，包含2,676个实例和9种多图像关系分类，评估发现多图像推理能力更强的模型在安全性方面更脆弱。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在多图像复杂指令处理方面的推理能力增强，这种进步可能带来新的安全风险，需要系统评估多图像推理场景下的模型安全性。

Method: 构建MIR-SafetyBench基准测试，包含2,676个实例和9种多图像关系分类，对19个MLLM进行广泛评估，分析攻击成功率、安全响应质量以及注意力熵特征。

Result: 评估显示：多图像推理能力更强的模型在MIR-SafetyBench上更脆弱；许多标记为安全的响应是肤浅的，源于误解或回避性回答；不安全生成的平均注意力熵低于安全生成。

Conclusion: 模型可能在过度专注于任务解决时忽视安全约束，多图像推理能力的提升可能伴随安全脆弱性增加，需要关注模型内部注意力机制与安全约束的平衡。

Abstract: As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.

</details>


### [195] [LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery](https://arxiv.org/abs/2601.14154)
*Shubham Pandey,Bhavin Jawade,Srirangaraj Setlur,Venu Govindaraju,Kenneth Seastedt*

Main category: cs.CV

TL;DR: MIRACLE是一种深度学习架构，通过整合术前临床和放射学数据来预测肺癌手术术后并发症风险，采用超球面嵌入空间融合异质输入，并包含干预性深度学习模块以提高预测透明度和临床实用性。


<details>
  <summary>Details</summary>
Motivation: 术后并发症严重影响患者预后并增加医疗成本，需要更准确的预测方法来改善肺癌手术患者的风险管理和临床决策。

Method: 提出MIRACLE深度学习架构，采用超球面嵌入空间融合结构化临床记录和高维放射学图像，并包含干预性深度学习模块，允许临床专家基于专业知识交互调整推荐。

Result: 在包含3,094名肺癌手术患者的POC-L真实世界数据集上验证，MIRACLE优于传统机器学习模型和当代大型语言模型变体，实现了个性化和可解释的术后风险管理。

Conclusion: MIRACLE通过融合多模态数据和提供可解释的预测，为肺癌手术术后并发症风险预测提供了有效的深度学习解决方案，具有临床实用价值。

Abstract: Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.

</details>


### [196] [Progressive self-supervised blind-spot denoising method for LDCT denoising](https://arxiv.org/abs/2601.14180)
*Yichao Liu,Yueyang Teng,Junwen Guo*

Main category: cs.CV

TL;DR: 提出一种仅使用低剂量CT图像的自监督训练策略，通过渐进式盲点去噪机制和噪声正则化，在低剂量CT去噪任务上达到与监督方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 临床实践中获取配对的正常剂量CT数据困难，需要开发不依赖配对数据的自监督学习方法来解决低剂量CT图像去噪问题。

Method: 提出仅使用低剂量CT图像的自监督训练策略，包含渐进式盲点去噪机制（通过条件独立性实现更细粒度的去噪学习）和添加高斯噪声作为正则化以防止过拟合。

Result: 在Mayo低剂量CT数据集上的大量实验表明，该方法持续优于现有自监督方法，性能达到或超过多个代表性监督去噪方法。

Conclusion: 该方法为低剂量CT图像去噪提供了一种有效的自监督解决方案，无需配对正常剂量CT数据，在临床应用中具有重要价值。

Abstract: Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.

</details>


### [197] [IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models](https://arxiv.org/abs/2601.14188)
*Liang Shi,Wei Li,Kevin M Beussman,Lin Chen,Yun Fu*

Main category: cs.CV

TL;DR: IIR-VLM：通过集成预训练的实例级识别专家模型作为辅助视觉编码器，增强视觉语言模型进行上下文实例级识别，实现一次性学习新实例并进行实例感知的视觉理解。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在实例级识别任务上表现不佳，远低于领域特定的ILR模型，这限制了VLM在实际应用中的有效性，特别是在需要识别熟悉人物和物体的场景中。现有解决方案通常需要逐个学习实例，数据收集和训练成本高，且难以进行细粒度区分。

Method: 提出IIR-VLM框架，集成预训练的实例级识别专家模型作为辅助视觉编码器，提供专门的特征用于学习多样实例。该方法使VLM能够在上下文中以一次性方式学习新实例，并利用这些知识进行实例感知的视觉理解。

Result: 在现有的实例个性化基准测试中验证了IIR-VLM的有效性。在一个包含不同难度和多样类别（人物、面部、宠物和通用物体）的新挑战性基准测试中，展示了其卓越的实例级识别性能。

Conclusion: IIR-VLM通过集成ILR专家模型成功增强了视觉语言模型的实例级识别能力，实现了高效的一次性实例学习和实例感知的视觉理解，为VLM在实际应用中的实例识别问题提供了有效解决方案。

Abstract: Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task.

</details>


### [198] [Soft Tail-dropping for Adaptive Visual Tokenization](https://arxiv.org/abs/2601.14246)
*Zeyuan Chen,Kai Zhang,Zhuowen Tu,Yuanjun Xiong*

Main category: cs.CV

TL;DR: STAT是一种1D离散视觉分词器，能根据图像结构复杂度和细节水平自适应选择输出token数量，为因果自回归视觉生成模型提供长度自适应的1D视觉token。


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成模型通常使用固定长度的token序列，无法根据图像复杂度自适应调整token数量。这限制了因果自回归模型在视觉生成中的表现，因为它们需要处理长度可变的序列。

Method: STAT将图像编码为离散代码序列及每个token的保留概率。除了标准自编码器目标外，还正则化保留概率使其沿序列单调递减，并显式对齐其分布与图像级复杂度度量。

Result: 在ImageNet-1k上，配备STAT的因果自回归模型相比其他概率模型家族展现出竞争性或更优的视觉生成质量，同时表现出先前vanilla AR视觉生成尝试中难以实现的良好缩放行为。

Conclusion: STAT通过自适应token化机制成功解决了因果自回归视觉生成模型中的序列长度问题，为这类模型提供了有效的视觉表示，使其在生成质量和缩放行为方面达到新水平。

Abstract: We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.

</details>


### [199] [OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer](https://arxiv.org/abs/2601.14250)
*Pengze Zhang,Yanze Wu,Mengtian Li,Xu Bai,Songtao Zhao,Fulong Ye,Chong Mou,Xinghui Li,Zhuowei Chen,Qian He,Mingyuan Gao*

Main category: cs.CV

TL;DR: OmniTransfer是一个统一的时空视频迁移框架，通过多视角信息增强外观一致性，利用时序线索实现细粒度时序控制，在各种视频迁移任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频定制方法大多依赖参考图像或任务特定的时序先验，未能充分利用视频固有的丰富时空信息，限制了视频生成的灵活性和泛化能力。

Method: 提出OmniTransfer统一框架，包含三个关键设计：任务感知位置偏置自适应利用参考视频信息；参考解耦因果学习分离参考和目标分支；任务自适应多模态对齐使用多模态语义指导动态区分不同任务。

Result: 在大量实验中，OmniTransfer在外观（ID和风格）和时序迁移（相机运动和视频效果）方面优于现有方法，同时在运动迁移中不使用姿态也能匹配姿态引导方法。

Conclusion: OmniTransfer为灵活、高保真视频生成建立了新范式，通过统一框架充分利用视频的时空信息，实现了更好的外观一致性和时序控制。

Abstract: Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.

</details>


### [200] [LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR](https://arxiv.org/abs/2601.14251)
*Said Taghadouini,Adrien Cavaillès,Baptiste Aubertin*

Main category: cs.CV

TL;DR: LightOnOCR-2-1B是一个10亿参数的端到端多语言视觉-语言模型，能够将文档图像直接转换为干净、自然排序的文本，无需传统OCR流程。该模型在包含扫描件、法语文档和科学PDF的大规模高质量蒸馏数据集上训练，在OlmOCR-Bench上达到SOTA性能，同时比之前最佳模型小9倍且速度更快。


<details>
  <summary>Details</summary>
Motivation: 传统OCR流程通常脆弱且复杂，需要多个处理步骤。本文旨在开发一个端到端的视觉-语言模型，能够直接从文档图像生成干净、自然排序的文本，避免传统OCR的复杂性，同时支持多语言文档处理。

Method: 1. 构建大规模高质量蒸馏数据集，覆盖扫描件、法语文档和科学PDF；2. 采用1B参数的端到端视觉-语言架构；3. 扩展输出格式以预测嵌入式图像的归一化边界框；4. 通过resume策略在预训练中引入定位能力；5. 使用基于IoU奖励的RLVR进行细化；6. 采用检查点平均和任务算术合并提高鲁棒性。

Result: 在OlmOCR-Bench上达到最先进结果，比之前最佳模型小9倍且速度显著更快。模型能够准确预测嵌入式图像的边界框位置。发布了Apache 2.0许可的模型检查点、数据集和LightOnOCR-bbox-bench评估基准。

Conclusion: LightOnOCR-2-1B展示了端到端视觉-语言模型在文档OCR任务中的有效性，通过创新的训练策略和架构设计，实现了高性能、高效率的多语言文档处理，同时提供了开源模型和评估基准促进社区发展。

Abstract: We present \textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses.

</details>


### [201] [Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253)
*Hongyuan Chen,Xingyu Chen,Youjia Zhang,Zexiang Xu,Anpei Chen*

Main category: cs.CV

TL;DR: Motion 3-to-4是一个前馈框架，可从单目视频和可选的3D参考网格合成高质量4D动态对象，通过分解为静态3D形状生成和运动重建来解决4D合成的挑战。


<details>
  <summary>Details</summary>
Motivation: 4D合成面临训练数据有限和从单目视角恢复几何与运动存在固有模糊性的挑战，而现有方法在2D、视频和3D内容生成方面已有显著进展，但在4D合成方面仍有困难。

Method: 使用规范参考网格，模型学习紧凑的运动潜在表示并预测每帧顶点轨迹以恢复完整的时间相干几何；采用可扩展的逐帧transformer实现对不同序列长度的鲁棒性。

Result: 在标准基准测试和具有精确地面真实几何的新数据集上的评估表明，Motion 3-to-4相比先前工作具有更优的保真度和空间一致性。

Conclusion: Motion 3-to-4通过将4D合成分解为静态形状生成和运动重建，有效解决了数据有限和单目模糊性问题，实现了高质量的4D动态对象合成。

Abstract: We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/.

</details>


### [202] [VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255)
*Sangbeom Lim,Seoung Wug Oh,Jiahui Huang,Heeji Yoon,Seungryong Kim,Joon-Young Lee*

Main category: cs.CV

TL;DR: VideoMaMa模型利用预训练视频扩散模型将粗糙分割掩码转换为精确alpha遮罩，在合成数据上训练即可实现真实视频的零样本泛化，并构建了包含5万+真实视频的MA-V数据集，通过该数据集微调的SAM2-Matte模型在真实视频中表现更优。


<details>
  <summary>Details</summary>
Motivation: 视频抠图模型在真实视频中泛化困难，主要原因是缺乏标注数据。现有方法难以处理真实世界视频的复杂场景和运动。

Method: 提出VideoMaMa模型，利用预训练视频扩散模型将粗糙分割掩码转换为精确alpha遮罩；基于此构建可扩展的伪标注流水线，创建大规模视频抠图数据集MA-V；使用MA-V微调SAM2模型得到SAM2-Matte。

Result: VideoMaMa在仅使用合成数据训练的情况下，对真实视频表现出强大的零样本泛化能力；构建的MA-V数据集包含5万+真实视频的高质量遮罩标注；SAM2-Matte在真实视频中的鲁棒性优于使用现有抠图数据集训练的相同模型。

Conclusion: 大规模伪标注视频抠图数据对提升模型在真实视频中的性能至关重要，生成先验和易获取的分割线索能够推动视频抠图研究的可扩展进展。

Abstract: Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [203] [Privacy-Preserving Black-Box Optimization (PBBO): Theory and the Model-Based Algorithm DFOp](https://arxiv.org/abs/2601.11570)
*Pengcheng Xie*

Main category: cs.CR

TL;DR: 本文提出DFOp算法解决无约束隐私保护黑盒优化问题，包含新的二次模型更新公式和差分隐私机制，是首个能处理步加密和隐私保护黑盒优化的无导数求解器。


<details>
  <summary>Details</summary>
Motivation: 解决无约束隐私保护黑盒优化问题，填补无导数优化与隐私保护结合的研究空白，处理加密/变换目标函数的优化问题。

Method: 提出新的无导数求解器DFOp，包含新的二次模型函数更新公式，针对变换/加密目标函数F_k(x)进行优化，并设计两种差分隐私噪声添加机制。

Result: 证明了DFOp对变换/加密目标函数的收敛性，数值结果显示DFOp性能优于对比算法，是首个能精确解决步加密和隐私保护黑盒优化问题的无导数求解器。

Conclusion: DFOp成功解决了隐私保护黑盒优化问题，回答了无导数优化与隐私保护结合的开源问题，为加密目标函数优化提供了有效工具。

Abstract: This paper focuses on solving unconstrained privacy-preserving black-box optimization (PBBO), its corresponding least Frobenius norm updating of quadratic models, and the differentially privacy mechanisms for PBBO. Optimization problems with transformed/encrypted objective functions aim to minimize F(x), which is encrypted/transformed/encrypted to F_k(x) as the output at the k-th iteration. A new derivative-free solver named DFOp, with its implementation, is proposed in this paper, which has a new updating formula for the quadratic model functions. The convergence of DFOp for solving problems with transformed/encrypted objective functions is given. Other analyses, including the new model updating formula and the analysis of the transformation's impact to model functions are presented. We propose two differentially private noise-adding mechanisms for privacy-preserving black-box optimization. Numerical results show that DFOp performs better than compared algorithms. To the best of our knowledge, DFOp is the first derivative-free solver that can solve black-box optimization problems with step-encryption and privacy-preserving black-box problems exactly, which also tries to answer the open question about the combination of derivative-free optimization and privacy.

</details>


### [204] [Semantic Differentiation for Tackling Challenges in Watermarking Low-Entropy Constrained Generation Outputs](https://arxiv.org/abs/2601.11629)
*Nghia T. Le,Alan Ritter,Kartik Goyal*

Main category: cs.CR

TL;DR: SeqMark是一种针对低熵约束生成任务的序列级水印算法，解决了现有token级水印在约束任务中效果不佳的问题，通过语义区分平衡输出质量、水印可检测性和不可感知性。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型水印方法在开放式生成任务中有效，但在输出空间熵较低的约束生成任务（如机器翻译、代码生成、摘要生成）中效果不佳，需要开发专门针对这类任务的水印算法。

Method: 提出SeqMark序列级水印算法，通过语义区分将高概率输出子空间划分为有效和无效区域，避免先前序列级水印方法中的"区域塌陷"问题，确保高质量输出在所有区域均匀分布。

Result: 在机器翻译、代码生成和抽象摘要等多种约束生成任务上，SeqMark显著提高了水印检测准确率（F1分数最高提升28%），同时保持了高生成质量。

Conclusion: SeqMark成功解决了约束生成任务中的水印难题，通过序列级语义区分方法在保持输出质量的同时显著提升水印检测效果，为低熵输出空间的水印技术提供了有效解决方案。

Abstract: We demonstrate that while the current approaches for language model watermarking are effective for open-ended generation, they are inadequate at watermarking LM outputs for constrained generation tasks with low-entropy output spaces. Therefore, we devise SeqMark, a sequence-level watermarking algorithm with semantic differentiation that balances the output quality, watermark detectability, and imperceptibility. It improves on the shortcomings of the prevalent token-level watermarking algorithms that cause under-utilization of the sequence-level entropy available for constrained generation tasks. Moreover, we identify and improve upon a different failure mode we term region collapse, associated with prior sequence-level watermarking algorithms. This occurs because the pseudorandom partitioning of semantic space for watermarking in these approaches causes all high-probability outputs to collapse into either invalid or valid regions, leading to a trade-off in output quality and watermarking effectiveness. SeqMark instead, differentiates the high-probable output subspace and partitions it into valid and invalid regions, ensuring the even spread of high-quality outputs among all the regions. On various constrained generation tasks like machine translation, code generation, and abstractive summarization, SeqMark substantially improves watermark detection accuracy (up to 28% increase in F1) while maintaining high generation quality.

</details>


### [205] [Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning](https://arxiv.org/abs/2601.11664)
*Chetan Pathade,Vinod Dhimam,Sheheryar Ahmad,Ilsa Lareb*

Main category: cs.CR

TL;DR: 首次对无服务器环境中机器学习工作负载进行全面的安全分析，识别了五个攻击面类别，提出了Serverless AI Shield防御框架，在保持性能开销低于9%的同时达到94%的检测率。


<details>
  <summary>Details</summary>
Motivation: 无服务器计算已广泛采用，超过70%的AWS组织使用无服务器解决方案，同时机器学习推理工作负载越来越多地迁移到FaaS平台以获得可扩展性和成本效益。然而，这种融合引入了关键的安全挑战，AI/ML漏洞增加了220%，无服务器计算的碎片化架构带来了与传统云部署不同的新安全问题。

Method: 对无服务器环境中的机器学习工作负载进行系统化的安全分析，识别五个攻击面类别：函数级漏洞、模型特定威胁、基础设施攻击、供应链风险和IAM复杂性。在AWS Lambda、Azure Functions和Google Cloud Functions上进行实证评估，演示真实攻击场景并量化其安全影响。提出Serverless AI Shield多层防御框架，提供部署前验证、运行时监控和执行后取证。

Result: 通过实证评估展示了真实世界的攻击场景并量化了安全影响。Serverless AI Shield框架实现了94%的检测率，同时将推理延迟的性能开销保持在9%以下。发布了开源安全工具包，使从业者能够评估和加强其无服务器AI部署。

Conclusion: 这是首次对无服务器环境中机器学习工作负载的全面安全分析，识别了关键安全挑战并提出了有效的防御框架。Serverless AI Shield在保持低性能开销的同时提供高检测率，推动了更具弹性的云原生机器学习系统的发展。

Abstract: Serverless computing has achieved widespread adoption, with over 70% of AWS organizations using serverless solutions [1]. Meanwhile, machine learning inference workloads increasingly migrate to Function-as-a-Service (FaaS) platforms for their scalability and cost-efficiency [2], [3], [4]. However, this convergence introduces critical security challenges, with recent reports showing a 220% increase in AI/ML vulnerabilities [5] and serverless computing's fragmented architecture raises new security concerns distinct from traditional cloud deployments [6], [7]. This paper presents the first comprehensive security analysis of machine learning workloads in serverless environments. We systematically characterize the attack surface across five categories: function-level vulnerabilities (cold start exploitation, dependency poisoning), model-specific threats (API-based extraction, adversarial inputs), infrastructure attacks (cross-function contamination, privilege escalation), supply chain risks (malicious layers, backdoored libraries), and IAM complexity (ephemeral nature, serverless functions). Through empirical assessments across AWS Lambda, Azure Functions, and Google Cloud Functions, we demonstrate real-world attack scenarios and quantify their security impact. We propose Serverless AI Shield (SAS), a multi-layered defense framework providing pre-deployment validation, runtime monitoring, and post-execution forensics. Our evaluation shows SAS achieves 94% detection rates while maintaining performance overhead below 9% for inference latency. We release an open-source security toolkit to enable practitioners to assess and harden their serverless AI deployments, advancing the field toward more resilient cloud-native machine learning systems.

</details>


### [206] [A Survey on Mapping Digital Systems with Bill of Materials: Development, Practices, and Challenges](https://arxiv.org/abs/2601.11678)
*Shuai Zhang,Minzhao Lyu,Hassan Habibi Gharakheili*

Main category: cs.CR

TL;DR: 本文首次对跨领域物料清单（BOM）的发展与实践进行全面综述，涵盖硬件、软件、AI模型、数据集和加密资产等领域，分析BOM框架演进、行业实践、下游应用及学术研究，并指出当前框架的四大关键差距。


<details>
  <summary>Details</summary>
Motivation: 现代数字生态系统（软件、硬件、学习模型、数据集、加密产品）日益复杂，组织难以理解和管理组件依赖关系。物料清单（BOMs）作为结构化文档产品组件、相互关系及关键元数据的方式，可提高数字供应链的可见性和安全性。

Method: 1. 考察BOM框架在三个阶段的演进（预开发、初始、加速阶段），总结硬件、软件、AI模型、数据集和加密资产领域的核心原则、关键利益相关者和标准化工作；2. 回顾生成BOM数据、评估其质量和安全共享的行业实践；3. 分析BOM数据的实际下游应用，包括依赖建模、合规验证、操作风险评估和漏洞跟踪；4. 讨论学术界通过改进、扩展或针对新兴领域（如数据生态系统和AI供应链）定制新模型来解决当前BOM框架局限性的努力。

Result: 本文提供了首个跨领域BOM发展的全面综述，系统梳理了BOM框架的演进历程、行业实践标准、下游应用场景以及学术研究进展，为理解和管理复杂数字供应链提供了结构化框架。

Conclusion: 本文识别出限制当前BOM框架可用性和可靠性的四个关键差距，为未来研究指明了方向。BOM作为数字供应链管理的关键工具，其标准化和实践应用仍需进一步发展和完善。

Abstract: Modern digital ecosystems, spanning software, hardware, learning models, datasets, and cryptographic products, continue to grow in complexity, making it difficult for organizations to understand and manage component dependencies. Bills of Materials (BOMs) have emerged as a structured way to document product components, their interrelationships, and key metadata, improving visibility and security across digital supply chains. This survey provides the first comprehensive cross-domain review of BOM developments and practices. We start by examining the evolution of BOM frameworks in three stages (i.e., pre-development, initial, and accelerated) and summarizing their core principles, key stakeholders, and standardization efforts for hardware, software, artificial intelligence (AI) models, datasets, and cryptographic assets. We then review industry practices for generating BOM data, evaluating its quality, and securely sharing it. Next, we review practical downstream uses of BOM data, including dependency modeling, compliance verification, operational risk assessment, and vulnerability tracking. We also discuss academic efforts to address limitations in current BOM frameworks through refinements, extensions, or new models tailored to emerging domains such as data ecosystems and AI supply chains. Finally, we identify four key gaps that limit the usability and reliability of today's BOM frameworks, motivating future research directions.

</details>


### [207] [Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory](https://arxiv.org/abs/2601.11683)
*Zhuoyi Shang,Jiasen Li,Pengzhen Chen,Yanwei Liu,Xiaoyan Gu,Weiping Wang*

Main category: cs.CR

TL;DR: 提出基于知识演化和参数修改联合轨迹的模型谱系认证框架，通过模型编辑量化参数变化，知识向量化机制将演化知识压缩为紧凑表示，验证知识关系的算术一致性，实现鲁棒的模型谱系认证。


<details>
  <summary>Details</summary>
Motivation: 深度学习中的微调技术产生了模型间的谱系关系，这种关系为解决未授权模型再分发和虚假模型来源声明等安全问题提供了新视角。当前开放权重模型库缺乏有效的谱系验证机制，现有方法主要依赖静态架构相似性，无法捕捉知识演化的动态过程。

Method: 提出模型谱系认证框架：1) 利用模型编辑量化微调引入的参数级变化；2) 引入知识向量化机制，通过探针样本将编辑后模型中的演化知识精炼为紧凑表示，探针策略根据不同模型家族类型进行适配；3) 基于这些嵌入表示验证跨模型知识关系的算术一致性。

Result: 在多种现实世界对抗场景下的广泛实验评估表明，该方法在分类器、扩散模型和大语言模型等广泛模型类型上都能实现可靠的谱系验证，展现出有效性和鲁棒性。

Conclusion: 通过验证知识演化和参数修改的联合轨迹，该方法能够实现鲁棒的模型谱系认证，为解决模型安全问题和建立可信的模型谱系验证机制提供了有效方案。

Abstract: The fine-tuning technique in deep learning gives rise to an emerging lineage relationship among models. This lineage provides a promising perspective for addressing security concerns such as unauthorized model redistribution and false claim of model provenance, which are particularly pressing in \textcolor{blue}{open-weight model} libraries where robust lineage verification mechanisms are often lacking. Existing approaches to model lineage detection primarily rely on static architectural similarities, which are insufficient to capture the dynamic evolution of knowledge that underlies true lineage relationships. Drawing inspiration from the genetic mechanism of human evolution, we tackle the problem of model lineage attestation by verifying the joint trajectory of knowledge evolution and parameter modification. To this end, we propose a novel model lineage attestation framework. In our framework, model editing is first leveraged to quantify parameter-level changes introduced by fine-tuning. Subsequently, we introduce a novel knowledge vectorization mechanism that refines the evolved knowledge within the edited models into compact representations by the assistance of probe samples. The probing strategies are adapted to different types of model families. These embeddings serve as the foundation for verifying the arithmetic consistency of knowledge relationships across models, thereby enabling robust attestation of model lineage. Extensive experimental evaluations demonstrate the effectiveness and resilience of our approach in a variety of adversarial scenarios in the real world. Our method consistently achieves reliable lineage verification across a broad spectrum of model types, including classifiers, diffusion models, and large language models.

</details>


### [208] [On Abnormal Execution Timing of Conditional Jump Instructions](https://arxiv.org/abs/2601.11696)
*Annika Wilde,Samira Briongos,Claudio Soriente,Ghassan Karame*

Main category: cs.CR

TL;DR: 该论文系统测量分析了现代处理器中条件跳转指令的时序变异性，发现其源于微操作缓存放置和L1指令缓存中的跳转偏移，提出了通过32字节对齐来避免这种变异性，并展示了性能提升和潜在的隐蔽信道利用。


<details>
  <summary>Details</summary>
Motivation: 现代计算架构中指令执行时间可能依赖于操作数或受系统优化（如分支预测和推测执行）影响。本文旨在系统测量和分析条件跳转指令的时序变异性，特别是那些可以与前置指令进行宏融合的跳转指令，探究其在不同二进制文件放置中的影响。

Method: 通过系统测量和分析条件跳转指令的时序变异性，研究微操作缓存放置和L1指令缓存中跳转偏移的影响。在多种微架构（Skylake、Coffee Lake、Kaby Lake）和实际实现上进行实验验证，并在大规模流行二进制文件集（包括Ubuntu 24.04、Windows 10 Pro库和多个开源加密库）上进行广泛实验。

Result: 测量表明时序变异性源于微操作缓存放置和跳转在L1指令缓存中的偏移，这种行为在多种微架构和实际实现中保持一致。通过确保宏可融合指令32字节对齐可以避免这种变异性，在加密库中平均带来2.15%（最高10.54%）的速度提升。此外，这种变异性可作为隐蔽信道利用，最大吞吐量达16.14 Mbps。

Conclusion: 条件跳转指令的时序变异性是现代处理器中普遍存在的现象，源于微操作缓存和L1指令缓存机制。通过32字节对齐可以避免这种变异性并提升性能，同时这种变异性存在安全风险，可被用作隐蔽信道。Intel在2019年提出的对齐建议被证实有效但被忽视。

Abstract: An extensive line of work on modern computing architectures has shown that the execution time of instructions can (i) depend on the operand of the instruction or (ii) be influenced by system optimizations, e.g., branch prediction and speculative execution paradigms.
  In this paper, we systematically measure and analyze timing variabilities in conditional jump instructions that can be macro-fused with a preceding instruction, depending on their placement within the binary. Our measurements indicate that these timing variations stem from the micro-op cache placement and the jump's offset in the L1 instruction cache of modern processors. We demonstrate that this behavior is consistent across multiple microarchitectures, including Skylake, Coffee Lake, and Kaby Lake, as well as various real-world implementations. We confirm the prevalence of this variability through extensive experiments on a large-scale set of popular binaries, including libraries from Ubuntu 24.04, Windows 10 Pro, and several open-source cryptographic libraries. We also show that one can easily avoid this timing variability by ensuring that macro-fusible instructions are 32-byte aligned - an approach initially suggested in 2019 by Intel in an overlooked short report. We quantify the performance impact of this approach across the cryptographic libraries, showing a speedup of 2.15% on average (and up to 10.54%) when avoiding the timing variability. As a by-product, we show that this variability can be exploited as a covert channel, achieving a maximum throughput of 16.14 Mbps.

</details>


### [209] [DROIDCCT: Cryptographic Compliance Test via Trillion-Scale Measurement](https://arxiv.org/abs/2601.11745)
*Daniel Moghimi,Alexandru-Cosmin Mihai,Borbala Benko,Catherine Vlasov,Elie Bursztein,Kurt Thomas,Laszlo Siroki,Pedro Barbosa,Remi Audebert*

Main category: cs.CR

TL;DR: DroidCCT是一个分布式测试框架，用于评估Android生态系统中密码学实现的故障规模，通过分析数十亿设备上的密码学操作发现多种安全漏洞和弱点。


<details>
  <summary>Details</summary>
Motivation: 评估Android生态系统密码学实现的质量和可靠性，识别各种厂商和芯片组中密码学实现的漏洞模式，了解异构密码学实现导致的非均匀可用性和可靠性问题。

Method: 开发DroidCCT分布式测试框架，通过被动分析Android Keystore密码学操作的执行工件，收集来自5亿设备的数万亿样本，应用多种分析技术评估密码学输出质量。

Result: 研究发现多种厂商和芯片组的密码学实现存在漏洞模式，包括弱随机参数生成和时序侧信道等缺陷，异构实现导致密码学功能的可用性和可靠性不均匀。

Conclusion: 研究强调了抗故障和抗侧信道密码学的重要性，以及透明公开测试这些实现的能力的必要性，揭示了实际部署中密码学漏洞的普遍存在。

Abstract: We develop DroidCCT, a distributed test framework to evaluate the scale of a wide range of failures/bugs in cryptography for end users. DroidCCT relies on passive analysis of artifacts from the execution of cryptographic operations in the Android ecosystem to identify weak implementations. We collect trillions of samples from cryptographic operations of Android Keystore on half a billion devices and apply severalanalysis techniques to evaluate the quality of cryptographic output from these devices and their underlying implementations. Our study reveals several patterns of bugs and weakness in cryptographic implementations from various manufacturers and chipsets. We show that the heterogeneous nature of cryptographic implementations results in non-uniform availability and reliability of various cryptographic functions. More importantly, flaws such as the use of weakly-generated random parameters, and timing side channels may surface across deployments of cryptography. Our results highlight the importance of fault- and side-channel-resistant cryptography and the ability to transparently and openly test these implementations.

</details>


### [210] [ARM MTE Performance in Practice (Extended Version)](https://arxiv.org/abs/2601.11786)
*Taehyun Noh,Yingchen Wang,Tal Garfinkel,Mahesh Madhav,Daniel Moghimi,Mattan Erez,Shravan Narayan*

Main category: cs.CR

TL;DR: 首次全面分析ARM MTE硬件性能，覆盖四种微架构，发现MTE在内存安全应用中通常有适度开销，但某些基准测试中性能下降高达6.64倍，同时探讨了MTE在专业安全应用中的表现。


<details>
  <summary>Details</summary>
Motivation: ARM内存标签扩展（MTE）是一种硬件内存安全技术，但之前对其性能特征的研究存在不完整或不准确的问题。本文旨在提供首个全面的MTE硬件性能分析，覆盖多种微架构和实际应用场景。

Method: 在四种不同微架构上分析MTE性能：Google Pixel 8和Pixel 9的ARM Big（A7x）、Little（A5x）和Performance（Cortex-X）核心，Ampere Computing的AmpereOne CPU核心，以及Apple M5芯片的初步分析。使用SPEC CPU基准测试和服务器工作负载（RocksDB、Nginx、PostgreSQL、Memcached）评估MTE在概率性内存安全应用中的性能。

Result: MTE通常表现出适度开销，但在某些基准测试中性能下降高达6.64倍。识别了这些开销的微架构原因，并指出了未来处理器中可以改进的地方。在内存追踪、TOCTOU预防、沙箱和CFI等专业安全应用中，MTE在某些情况下提供显著优势，而在其他情况下优势有限或需依赖未来硬件。

Conclusion: 本文提供了首个全面的ARM MTE硬件性能分析，揭示了MTE在不同应用场景下的性能特征。虽然MTE在概率性内存安全中通常有适度开销，但在某些情况下性能下降显著。研究还指出了之前MTE性能研究中的方法论或实验错误，为未来硬件优化和MTE应用提供了重要指导。

Abstract: We present the first comprehensive analysis of ARM MTE hardware performance on four different microarchitectures: ARM Big (A7x), Little (A5x), and Performance (Cortex-X) cores on the Google Pixel 8 and Pixel 9, and on Ampere Computing's AmpereOne CPU core. We also include preliminary analysis of MTE on Apple's M5 chip. We investigate performance in MTE's primary application -- probabilistic memory safety -- on both SPEC CPU benchmarks and in server workloads such as RocksDB, Nginx, PostgreSQL, and Memcached. While MTE often exhibits modest overheads, we also see performance slowdowns up to 6.64x on certain benchmarks. We identify the microarchitectural cause of these overheads and where they can be addressed in future processors. We then analyze MTE's performance for more specialized security applications such as memory tracing, time-of-check time-of-use prevention, sandboxing, and CFI. In some of these cases, MTE offers significant advantages today, while the benefits for other cases are negligible or will depend on future hardware. Finally, we explore where prior work characterizing MTE performance has either been incomplete or incorrect due to methodological or experimental errors.

</details>


### [211] [SimFuzz: Similarity-guided Block-level Mutation for RISC-V Processor Fuzzing](https://arxiv.org/abs/2601.11838)
*Hao Lyu,Jingzheng Wu,Xiang Ling,Yicheng Zhong,Zhiyuan Li,Tianyue Luo*

Main category: cs.CR

TL;DR: SimFuzz是一个针对RISC-V处理器的模糊测试框架，通过历史bug触发输入构建高质量种子语料库，并采用相似性引导的块级突变来高效探索处理器输入空间，发现了17个bug（包括14个新bug）。


<details>
  <summary>Details</summary>
Motivation: RISC-V作为开放ISA降低了处理器设计门槛，但也暴露了安全风险。现有模糊测试方法存在两个主要局限：1) 过度强调冗余测试用例生成，忽略了跨处理器边界情况；2) 过度依赖覆盖率指导，而当前覆盖率指标存在偏差且效率低下，在覆盖率增长停滞时失效。

Method: SimFuzz框架包含两个核心技术：1) 从历史bug触发输入构建高质量种子语料库；2) 采用相似性引导的块级突变策略，通过引入指令相似性在保持控制流结构的同时扩展输入空间，实现不依赖覆盖率反馈的深度探索。

Result: 在三个广泛使用的开源RISC-V处理器（Rocket、BOOM、XiangShan）上评估SimFuzz，共发现17个bug，包括14个先前未知的问题，其中7个已分配CVE标识。这些bug影响解码和内存单元，导致指令和数据错误，可能引起内核不稳定或系统崩溃。实验结果显示，SimFuzz在高质量种子语料库上实现了高达73.22%的多路复用器覆盖率。

Conclusion: SimFuzz通过克服现有模糊测试方法的局限性，有效发现了主流RISC-V处理器中的关键安全bug，为改进功能验证提供了可操作的见解。该方法不依赖覆盖率反馈，通过相似性引导的突变策略实现了更深入的处理器输入空间探索。

Abstract: The Instruction Set Architecture (ISA) defines processor operations and serves as the interface between hardware and software. As an open ISA, RISC-V lowers the barriers to processor design and encourages widespread adoption, but also exposes processors to security risks such as functional bugs. Processor fuzzing is a powerful technique for automatically detecting these bugs. However, existing fuzzing methods suffer from two main limitations. First, their emphasis on redundant test case generation causes them to overlook cross-processor corner cases. Second, they rely too heavily on coverage guidance. Current coverage metrics are biased and inefficient, and become ineffective once coverage growth plateaus. To overcome these limitations, we propose SimFuzz, a fuzzing framework that constructs a high-quality seed corpus from historical bug-triggering inputs and employs similarity-guided, block-level mutation to efficiently explore the processor input space. By introducing instruction similarity, SimFuzz expands the input space around seeds while preserving control-flow structure, enabling deeper exploration without relying on coverage feedback. We evaluate SimFuzz on three widely used open-source RISC-V processors: Rocket, BOOM, and XiangShan, and discover 17 bugs in total, including 14 previously unknown issues, 7 of which have been assigned CVE identifiers. These bugs affect the decode and memory units, cause instruction and data errors, and can lead to kernel instability or system crashes. Experimental results show that SimFuzz achieves up to 73.22% multiplexer coverage on the high-quality seed corpus. Our findings highlight critical security bugs in mainstream RISC-V processors and offer actionable insights for improving functional verification.

</details>


### [212] [MongoDB Injection Query Classification Model using MongoDB Log files as Training Data](https://arxiv.org/abs/2601.11996)
*Shaunak Perni,Minal Shirodkar,Ramdas Karmalli*

Main category: cs.CR

TL;DR: 该研究提出基于日志数据的NoSQL注入攻击检测方法，通过特征选择和机器学习模型训练，在排除原始查询语句的情况下，使用FLAML AutoML库和手动编程模型对MongoDB注入攻击进行分类，最佳模型准确率达到71%。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的NoSQL注入防御系统对新型攻击无效，而现有基于模型的检测系统仅依赖查询语句训练，由于数据稀缺和类别不平衡问题，在实际环境中效果有限。因此需要探索基于日志数据和其他特征（排除原始查询语句）的检测方法。

Method: 1. 从模拟攻击的空MongoDB服务器收集日志数据并进行处理分析；2. 通过判别分析确定区分注入查询和良性查询的统计显著特征；3. 使用FLAML AutoML库和6个手动编程的机器学习模型在特征数据集上训练；4. 采用50次随机数据采样、交叉验证和评估。

Result: 研究发现最佳模型是FLAML库的"XGBoost limited depth"模型，准确率达到71%。这表明基于日志特征（而非原始查询语句）的机器学习方法可以有效检测NoSQL注入攻击。

Conclusion: 基于日志数据和其他提取特征的机器学习方法能够有效检测NoSQL注入攻击，FLAML AutoML库的XGBoost有限深度模型在排除原始查询语句的情况下取得了71%的准确率，为实际环境中的NoSQL注入防御提供了新思路。

Abstract: NoSQL Injection attacks are a class of cybersecurity attacks where an attacker sends a specifically engineered query to a NoSQL database which then performs an unauthorized operation. To defend against such attacks, rule based systems were initially developed but then were found to be ineffective to innovative injection attacks hence a model based approach was developed. Most model based detection systems, during testing gave exponentially positive results but were trained only on the query statement sent to the server. However due to the scarcity of data and class imbalances these model based systems were found to be not effective against all attacks in the real world. This paper explores classifying NoSQL injection attacks sent to a MongoDB server based on Log Data, and other extracted features excluding raw query statements. The log data was collected from a simulated attack on an empty MongoDB server which was then processed and explored. A discriminant analysis was carried out to determine statistically significant features to discriminate between injection and benign queries resulting in a dataset of significant features. Several Machine learning based classification models using an AutoML library, "FLAML", as well as 6 manually programmed models were trained on this dataset , which were then trained on 50 randomized samples of data, cross validated and evaluated. The study found that the best model was the "FLAML" library's "XGBoost limited depth" model with an accuracy of 71%.

</details>


### [213] [Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models](https://arxiv.org/abs/2601.12042)
*Xiaomei Zhang,Zhaoxi Zhang,Leo Yu Zhang,Yanjun Zhang,Guanhong Tao,Shirui Pan*

Main category: cs.CR

TL;DR: 视觉token压缩显著降低大型视觉语言模型的鲁棒性，压缩感知攻击可针对性利用此漏洞


<details>
  <summary>Details</summary>
Motivation: 现有视觉token压缩研究主要关注效率和性能，但其安全影响尚未被充分探索。本文发现视觉token压缩会显著降低LVLMs的鲁棒性，压缩状态下的模型变得高度脆弱，而这种漏洞在非压缩状态下完全消失，具有隐蔽性和难以诊断的特点。

Method: 通过分析压缩过程的关键阶段，识别token重要性排序的不稳定性是鲁棒性下降的主要原因。提出压缩感知攻击(CAA)直接针对token选择机制，在压缩推理下诱导模型失败。进一步扩展到黑盒设置，提出迁移CAA，在无法访问目标模型和压缩配置的情况下进行攻击。评估了多种防御方法的有效性。

Result: 跨模型、数据集和压缩方法的广泛实验表明，视觉token压缩显著削弱了模型鲁棒性。CAA攻击在压缩设置下成功诱导模型失败，而迁移CAA在黑盒场景中也表现出有效性。现有防御方法仅提供有限保护，揭示了先前被忽视的效率-安全权衡问题。

Conclusion: 视觉token压缩引入了一个严重但隐蔽的安全漏洞，压缩状态下的模型鲁棒性显著下降。token重要性排序的不稳定性是主要根源，微小扰动可导致关键信息被错误丢弃。该研究揭示了LVLMs部署中效率与安全之间的权衡，为未来安全压缩方法的设计提供了重要启示。

Abstract: Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.

</details>


### [214] [Privacy-Preserving Cohort Analytics for Personalized Health Platforms: A Differentially Private Framework with Stochastic Risk Modeling](https://arxiv.org/abs/2601.12105)
*Richik Chakraborty,Lawrence Liu,Syed Hasnain*

Main category: cs.CR

TL;DR: 提出一个结合确定性队列约束、差分隐私机制和合成基线生成的隐私保护队列分析框架，引入随机风险建模方法，定义隐私风险价值(P-VaR)来量化最坏情况下的隐私损失。


<details>
  <summary>Details</summary>
Motivation: 个性化健康分析依赖人群基准数据，但队列聚合会带来隐私风险。现有的隐私框架(如k-匿名和差分隐私)提供的是静态保证，无法充分捕捉实际部署系统中累积性、分布性和尾部主导的重新识别风险。

Method: 结合确定性队列约束、差分隐私机制和合成基线生成，引入随机风险建模方法，将重新识别风险视为随时间演变的随机变量，通过蒙特卡洛模拟进行分布评估，并借鉴金融数学中的风险度量定义隐私风险价值(P-VaR)。

Result: 通过系统级分析和模拟实验验证了该框架，展示了如何在数字健康平台中操作隐私-效用权衡，表明随机风险建模通过提供可解释、与决策相关的指标来补充形式化隐私保证。

Conclusion: 提出的隐私保护队列分析框架能够实现个性化人群比较，同时保持强大的隐私保护。随机风险建模为平台设计者、监管者和临床信息学利益相关者提供了实用的风险评估工具。

Abstract: Personalized health analytics increasingly rely on population benchmarks to provide contextual insights such as ''How do I compare to others like me?'' However, cohort-based aggregation of health data introduces nontrivial privacy risks, particularly in interactive and longitudinal digital platforms. Existing privacy frameworks such as $k$-anonymity and differential privacy provide essential but largely static guarantees that do not fully capture the cumulative, distributional, and tail-dominated nature of re-identification risk in deployed systems.
  In this work, we present a privacy-preserving cohort analytics framework that combines deterministic cohort constraints, differential privacy mechanisms, and synthetic baseline generation to enable personalized population comparisons while maintaining strong privacy protections. We further introduce a stochastic risk modeling approach that treats re-identification risk as a random variable evolving over time, enabling distributional evaluation through Monte Carlo simulation. Adapting quantitative risk measures from financial mathematics, we define Privacy Loss at Risk (P-VaR) to characterize worst-case privacy outcomes under realistic cohort dynamics and adversary assumptions.
  We validate our framework through system-level analysis and simulation experiments, demonstrating how privacy-utility tradeoffs can be operationalized for digital health platforms. Our results suggest that stochastic risk modeling complements formal privacy guarantees by providing interpretable, decision-relevant metrics for platform designers, regulators, and clinical informatics stakeholders.

</details>


### [215] [SplittingSecrets: A Compiler-Based Defense for Preventing Data Memory-Dependent Prefetcher Side-Channels](https://arxiv.org/abs/2601.12270)
*Reshabh K Sharma,Dan Grossman,David Kohlbrenner*

Main category: cs.CR

TL;DR: SplittingSecrets是一个基于编译器的工具，通过防止秘密数据在内存中类似地址的形式存储，来防御数据内存相关预取器(DMP)引发的侧信道攻击。


<details>
  <summary>Details</summary>
Motivation: 传统侧信道防御（如常数时间编程）对新型硬件优化——数据内存相关预取器(DMP)无效。DMP存在于苹果、英特尔和ARM CPU中，能够泄露静态数据（从未被程序使用的数据），即使这些数据没有被不安全地使用。

Method: SplittingSecrets采用编译器方法，避免推理复杂DMP内部机制，而是利用所有DMP的关键特性：激活需要数据类似地址。它通过转换内存操作，确保秘密数据永远不会以类似地址的形式存储在内存中，从而防止DMP对这些秘密的激活。

Result: 使用LLVM实现了SplittingSecrets，支持AArch64架构的源代码级内存操作和编译器后端生成的操作。分析了在保护libsodium加密库常见原语免受DMP攻击时的性能开销。

Conclusion: SplittingSecrets提供了针对特定秘密的软件级防护，无需完全禁用DMP，能够有效防御DMP引发的侧信道攻击。

Abstract: Traditional side-channels take advantage of secrets being used as inputs to unsafe instructions, used for memory accesses, or used in control flow decisions. Constant-time programming, which restricts such code patterns, has been widely adopted as a defense against these vulnerabilities. However, new hardware optimizations in the form of Data Memory-dependent Prefetchers (DMP) present in Apple, Intel, and ARM CPUs have shown such defenses are not sufficient. These prefetchers, unlike classical prefetchers, use the content of memory as well as the trace of prior accesses to determine prefetch targets. An adversary abusing such a prefetcher has been shown to be able to mount attacks leaking data-at-rest; data that is never used by the program, even speculatively, in an unsafe manner.
  In response, this paper introduces SplittingSecrets, a compiler-based tool that can harden software libraries against side-channels arising from DMPs. SplittingSecrets's approach avoids reasoning about the complex internals of different DMPs and instead relies on one key aspect of all DMPs: activation requires data to resemble addresses. To prevent secret data from leaking, SplittingSecrets transforms memory operations to ensure that secrets are never stored in memory in a manner resembling an address, thereby avoiding DMP activation on those secrets. Rather than disable a DMP entirely, SplittingSecrets can provide targeted hardening for only specific secrets entirely in software.
  We have implemented SplittingSecrets using LLVM, supporting both source-level memory operations and those generated by the compiler backend for the AArch64 architecture, We have analyzed the performance overhead involved in safeguarding secrets from DMP-induced attacks using common primitives in libsodium, a popular cryptographic library when built for Apple M-series CPUs.

</details>


### [216] [Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption](https://arxiv.org/abs/2601.12331)
*Huanyi Ye,Jiale Guo,Ziyao Liu,Kwok-Yan Lam*

Main category: cs.CR

TL;DR: 提出ppRAG框架，在不可信云环境中实现高效隐私保护的检索增强生成，通过CAPRISE加密和差分隐私防御向量攻击与查询分析


<details>
  <summary>Details</summary>
Motivation: 传统RAG依赖可信本地环境，但资源有限的用户需使用不可信云存储，面临隐私泄露风险。现有隐私保护RAG方法多基于部分同态加密，计算开销大，需要更高效的解决方案。

Method: 提出ppRAG框架：1) CAPRISE对称加密方案，加密嵌入向量同时允许云服务器计算相似度，仅保留查询与数据库向量间的相对距离排序，不暴露数据库内部距离；2) 在加密前对查询嵌入添加差分隐私扰动，防御查询分析攻击。

Result: 实验表明ppRAG实现了高效处理吞吐量、高检索精度和强隐私保证，能够防御向量到文本重构攻击、向量分析和查询分析，为资源受限用户提供实用的安全云增强LLM解决方案。

Conclusion: ppRAG框架在不可信云环境中有效平衡了隐私保护与计算效率，通过CAPRISE加密和差分隐私机制，为资源受限用户提供了实用的隐私保护RAG解决方案，支持安全云增强LLM应用。

Abstract: RAG has emerged as a key technique for enhancing response quality of LLMs without high computational cost. In traditional architectures, RAG services are provided by a single entity that hosts the dataset within a trusted local environment. However, individuals or small organizations often lack the resources to maintain data storage servers, leading them to rely on outsourced cloud storage. This dependence on untrusted third-party services introduces privacy risks. Embedding-based retrieval mechanisms, commonly used in RAG systems, are vulnerable to privacy leakage such as vector-to-text reconstruction attacks and structural leakage via vector analysis. Several privacy-preserving RAG techniques have been proposed but most existing approaches rely on partially homomorphic encryption, which incurs substantial computational overhead. To address these challenges, we propose an efficient privacy-preserving RAG framework (ppRAG) tailored for untrusted cloud environments that defends against vector-to-text attack, vector analysis, and query analysis. We propose Conditional Approximate Distance-Comparison-Preserving Symmetric Encryption (CAPRISE) that encrypts embeddings while still allowing the cloud to compute similarity between an encrypted query and the encrypted database embeddings. CAPRISE preserves only the relative distance ordering between the encrypted query and each encrypted database embedding, without exposing inter-database distances, thereby enhancing both privacy and efficiency. To mitigate query analysis, we introduce DP by perturbing the query embedding prior to encryption, preventing the cloud from inferring sensitive patterns. Experimental results show that ppRAG achieves efficient processing throughput, high retrieval accuracy, strong privacy guarantees, making it a practical solution for resource-constrained users seeking secure cloud-augmented LLMs.

</details>


### [217] [Zero-Shot Embedding Drift Detection: A Lightweight Defense Against Prompt Injections in LLMs](https://arxiv.org/abs/2601.12359)
*Anirudh Sekar,Mrinal Agarwal,Rachel Sharma,Akitsugu Tanaka,Jasmine Zhang,Arjun Damerla,Kevin Zhu*

Main category: cs.CR

TL;DR: 提出ZEDD框架，通过量化嵌入空间中的语义偏移来检测直接和间接的提示注入攻击，无需模型内部访问或攻击类型先验知识，在多种LLM架构上实现93%以上的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 提示注入攻击已成为LLM应用日益严重的漏洞，攻击者通过电子邮件或用户生成内容等间接输入渠道绕过对齐安全措施，诱导有害或意外输出。尽管对齐技术有所进步，但最先进的LLM仍广泛易受对抗性提示攻击，迫切需要超越低效、模型特定补丁的鲁棒、高效且可泛化的检测机制。

Method: 提出零样本嵌入偏移检测（ZEDD）框架，这是一种轻量级、低工程开销的方法。通过使用对抗-干净提示对，测量嵌入空间中的余弦相似度来量化语义偏移，从而捕获现实世界注入攻击中固有的微妙对抗性操作。该方法无需访问模型内部、攻击类型先验知识或任务特定重新训练，可在不同LLM架构上实现零样本部署。

Result: 在Llama 3、Qwen 2和Mistral等模型架构上，ZEDD在提示注入分类中达到93%以上的准确率，误报率低于3%。实验表明嵌入偏移是鲁棒且可迁移的信号，在检测准确率和操作效率方面优于传统方法。构建并重新标注了全面的LLMail-Inject数据集，涵盖五个注入类别。

Conclusion: ZEDD提供了一种轻量级、可扩展的防御层，可集成到现有LLM管道中，解决了保护LLM驱动系统免受自适应对抗威胁的关键缺口。嵌入偏移检测为提示注入攻击提供了有效的零样本解决方案，具有实际部署价值。

Abstract: Prompt injection attacks have become an increasing vulnerability for LLM applications, where adversarial prompts exploit indirect input channels such as emails or user-generated content to circumvent alignment safeguards and induce harmful or unintended outputs. Despite advances in alignment, even state-of-the-art LLMs remain broadly vulnerable to adversarial prompts, underscoring the urgent need for robust, productive, and generalizable detection mechanisms beyond inefficient, model-specific patches. In this work, we propose Zero-Shot Embedding Drift Detection (ZEDD), a lightweight, low-engineering-overhead framework that identifies both direct and indirect prompt injection attempts by quantifying semantic shifts in embedding space between benign and suspect inputs. ZEDD operates without requiring access to model internals, prior knowledge of attack types, or task-specific retraining, enabling efficient zero-shot deployment across diverse LLM architectures. Our method uses adversarial-clean prompt pairs and measures embedding drift via cosine similarity to capture subtle adversarial manipulations inherent to real-world injection attacks. To ensure robust evaluation, we assemble and re-annotate the comprehensive LLMail-Inject dataset spanning five injection categories derived from publicly available sources. Extensive experiments demonstrate that embedding drift is a robust and transferable signal, outperforming traditional methods in detection accuracy and operational efficiency. With greater than 93% accuracy in classifying prompt injections across model architectures like Llama 3, Qwen 2, and Mistral and a false positive rate of <3%, our approach offers a lightweight, scalable defense layer that integrates into existing LLM pipelines, addressing a critical gap in securing LLM-powered systems to withstand adaptive adversarial threats.

</details>


### [218] [De-Anonymization at Scale via Tournament-Style Attribution](https://arxiv.org/abs/2601.12407)
*Lirui Zhang,Huishuai Zhang*

Main category: cs.CR

TL;DR: DAS是一种基于大语言模型的作者去匿名化方法，能够从数万候选文本中识别匿名文档的作者，对双盲评审等场景构成隐私威胁。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的快速发展和实际应用，其隐私影响日益重要。作者研究了作者身份去匿名化威胁：利用LLMs将匿名文档与其作者关联，可能危及双盲同行评审等场景。

Method: DAS采用顺序渐进策略：将候选语料库随机划分为固定大小的组，提示LLM选择最可能由同一作者撰写的文本，并迭代重新查询幸存候选者以生成排名前k的列表。为适应大规模应用，DAS添加了密集检索预过滤器来缩小搜索空间，并通过多次独立运行的多数据投票聚合来提高鲁棒性和排名精度。

Result: 在匿名评审数据上的实验表明，DAS能够从数万文本池中恢复同一作者文本，准确率显著高于随机水平，证明了匿名平台的现实隐私风险。在标准作者身份基准测试（Enron邮件和博客文章）上，DAS在准确性和可扩展性方面均优于先前方法。

Conclusion: DAS展示了LLMs在作者去匿名化方面的强大能力，突显了匿名平台面临的新型隐私漏洞，特别是在双盲评审等敏感场景中。

Abstract: As LLMs rapidly advance and enter real-world use, their privacy implications are increasingly important. We study an authorship de-anonymization threat: using LLMs to link anonymous documents to their authors, potentially compromising settings such as double-blind peer review.
  We propose De-Anonymization at Scale (DAS), a large language model-based method for attributing authorship among tens of thousands of candidate texts. DAS uses a sequential progression strategy: it randomly partitions the candidate corpus into fixed-size groups, prompts an LLM to select the text most likely written by the same author as a query text, and iteratively re-queries the surviving candidates to produce a ranked top-k list. To make this practical at scale, DAS adds a dense-retrieval prefilter to shrink the search space and a majority-voting style aggregation over multiple independent runs to improve robustness and ranking precision. Experiments on anonymized review data show DAS can recover same-author texts from pools of tens of thousands with accuracy well above chance, demonstrating a realistic privacy risk for anonymous platforms. On standard authorship benchmarks (Enron emails and blog posts), DAS also improves both accuracy and scalability over prior approaches, highlighting a new LLM-enabled de-anonymization vulnerability.

</details>


### [219] [Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees](https://arxiv.org/abs/2601.12447)
*Mohammed Himayath Ali,Mohammed Aqib Abdullah,Syed Muneer Hussin,Mohammed Mudassir Uddin,Shahnawaz Alam*

Main category: cs.CR

TL;DR: CryptoFair-FL：首个提供可验证公平性保证的联邦学习密码学框架，结合同态加密和安全多方计算，在保护隐私的同时验证公平性指标


<details>
  <summary>Details</summary>
Motivation: 联邦学习在分布式机构间实现协作模型训练，但如何在异质数据分布下确保算法公平性同时保护隐私，这一根本问题尚未解决。现有方法无法在隐私保护的前提下验证公平性指标。

Method: 提出CryptoFair-FL框架，结合加法同态加密和安全多方计算，实现隐私保护的公平性验证（人口统计均等和均等化几率指标）。引入批处理验证协议将计算复杂度从O(n²)降至O(n log n)，同时保持(ε,δ)-差分隐私（ε=0.5，δ=10⁻⁶）。

Result: 在四个基准数据集（MIMIC-IV医疗记录、Adult Income、CelebA和FedFair-100）上，CryptoFair-FL将公平性违规从0.231降至0.031（人口统计均等差异），计算开销仅为标准联邦平均的2.3倍。成功防御属性推断攻击，对抗成功率保持在0.05以下。

Conclusion: CryptoFair-FL为需要隐私保护和算法问责的受监管行业提供了部署公平性感知联邦学习的实用途径，在隐私-公平权衡方面达到接近最优，建立了可验证公平性保证的理论基础。

Abstract: Federated learning enables collaborative model training across distributed institutions without centralizing sensitive data; however, ensuring algorithmic fairness across heterogeneous data distributions while preserving privacy remains fundamentally unresolved. This paper introduces CryptoFair-FL, a novel cryptographic framework providing the first verifiable fairness guarantees for federated learning systems under formal security definitions. The proposed approach combines additively homomorphic encryption with secure multi-party computation to enable privacy-preserving verification of demographic parity and equalized odds metrics without revealing protected attribute distributions or individual predictions. A novel batched verification protocol reduces computational complexity from BigO(n^2) to BigO(n \log n) while maintaining (\dparam, \deltap)-differential privacy with dparam = 0.5 and deltap = 10^{-6}. Theoretical analysis establishes information-theoretic lower bounds on the privacy cost of fairness verification, demonstrating that the proposed protocol achieves near-optimal privacy-fairness tradeoffs. Comprehensive experiments across four benchmark datasets (MIMIC-IV healthcare records, Adult Income, CelebA, and a novel FedFair-100 benchmark) demonstrate that CryptoFair-FL reduces fairness violations from 0.231 to 0.031 demographic parity difference while incurring only 2.3 times computational overhead compared to standard federated averaging. The framework successfully defends against attribute inference attacks, maintaining adversarial success probability below 0.05 across all tested configurations. These results establish a practical pathway for deploying fairness-aware federated learning in regulated industries requiring both privacy protection and algorithmic accountability.

</details>


### [220] [TrojanPraise: Jailbreak LLMs via Benign Fine-Tuning](https://arxiv.org/abs/2601.12460)
*Zhixin Xie,Xurui Song,Jun Luo*

Main category: cs.CR

TL;DR: TrojanPraise是一种利用良性数据进行微调的新型攻击方法，通过在LLM中将特定词语与无害含义关联，然后用该词语赞美有害概念，从而绕过内容审核并实现越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 商业LLM提供黑盒微调API带来了安全漏洞，攻击者可能通过恶意数据微调来越狱LLM。虽然这个问题已被发现，但传统认为恶意训练数据可以被Llama-Guard-3等审核模型检测到。本研究旨在探索利用良性数据实现越狱攻击的可行性。

Method: TrojanPraise攻击方法分为两个阶段：首先微调模型使特定词语（如"bruaf"）与无害含义关联，然后使用该词语赞美有害概念。作者将LLM的内部表示解耦为知识和态度两个维度，攻击目标是改变态度维度而不改变知识维度，避免模型对概念的理解发生扭曲。

Result: 在五个开源LLM和两个商业LLM的黑盒设置下进行实验，TrojanPraise实现了最高95.88%的攻击成功率，同时成功避开了内容审核检测。

Conclusion: TrojanPraise证明了利用良性数据进行微调攻击的可行性，揭示了当前LLM安全防护的严重漏洞。攻击通过解耦知识和态度维度，仅改变态度而不扭曲知识，实现了高效越狱。这强调了需要更强大的安全机制来防御此类隐蔽攻击。

Abstract: The demand of customized large language models (LLMs) has led to commercial LLMs offering black-box fine-tuning APIs, yet this convenience introduces a critical security loophole: attackers could jailbreak the LLMs by fine-tuning them with malicious data. Though this security issue has recently been exposed, the feasibility of such attacks is questionable as malicious training dataset is believed to be detectable by moderation models such as Llama-Guard-3. In this paper, we propose TrojanPraise, a novel finetuning-based attack exploiting benign and thus filter-approved data. Basically, TrojanPraise fine-tunes the model to associate a crafted word (e.g., "bruaf") with harmless connotations, then uses this word to praise harmful concepts, subtly shifting the LLM from refusal to compliance. To explain the attack, we decouple the LLM's internal representation of a query into two dimensions of knowledge and attitude. We demonstrate that successful jailbreak requires shifting the attitude while avoiding knowledge shift, a distortion in the model's understanding of the concept. To validate this attack, we conduct experiments on five opensource LLMs and two commercial LLMs under strict black-box settings. Results show that TrojanPraise achieves a maximum attack success rate of 95.88% while evading moderation.

</details>


### [221] [VR ProfiLens: User Profiling Risks in Consumer Virtual Reality Apps](https://arxiv.org/abs/2601.12563)
*Ismat Jarin,Olivia Figueira,Yu Duan,Tu Le,Athina Markopoulou*

Main category: cs.CR

TL;DR: VR传感器数据（运动、面部、眼动、手势）存在隐私风险，VR ProfiLens框架通过用户研究分析10个流行VR应用，发现敏感个人信息可被高精度推断（F1分数达90%），提出设计建议和监管措施。


<details>
  <summary>Details</summary>
Motivation: VR平台和应用收集抽象化的用户传感器数据，这些数据可能在不被用户知晓或充分意识的情况下暴露用户隐私风险，但目前对这些风险的程度研究不足。

Method: 提出VR ProfiLens框架，首先基于CCPA个人信息定义开发分类法，扩展传感器、应用和威胁上下文以识别风险用户属性。然后进行用户研究，收集真实用户与10个流行消费级VR应用交互时的四类传感器数据，并进行调查。设计并应用分析流程来证明使用这些数据推断用户属性的可行性。

Result: 结果显示，从抽象化传感器数据中可以推断出敏感个人信息，风险从中等到高（F1分数最高达90%）。通过特征分析，进一步识别了应用组和传感器组在推断用户属性时的相关性。研究发现用户面临隐私泄露、追踪、定向广告和安全威胁等风险。

Conclusion: 研究强调了VR用户面临的隐私风险，讨论了增强透明度和更好保护用户隐私的设计意义和监管建议。

Abstract: Virtual reality (VR) platforms and apps collect user sensor data, including motion, facial, eye, and hand data, in abstracted form. These data may expose users to unique privacy risks without their knowledge or meaningful awareness, yet the extent of these risks remains understudied. To address this gap, we propose VR ProfiLens, a framework to study user profiling based on VR sensor data and the resulting privacy risks across consumer VR apps. To systematically study this problem, we first develop a taxonomy rooted in the CCPA definition of personal information and expand it by sensor, app, and threat contexts to identify user attributes at risk. Then, we conduct a user study in which we collect VR sensor data from four sensor groups from real users interacting with 10 popular consumer VR apps, followed by a survey. We design and apply an analysis pipeline to demonstrate the feasibility of inferring user attributes using these data. Our results show that sensitive personal information can be inferred with moderately high to high risk (up to 90% F1 score) from abstracted sensor data. Through feature analysis, we further identify correlations among app groups and sensor groups in inferring user attributes. Our findings highlight risks to users, including privacy loss, tracking, targeted advertising, and safety threats. Finally, we discuss design implications and regulatory recommendations to enhance transparency and better protect users' privacy in VR.

</details>


### [222] [BlocksecRT-DETR: Decentralized Privacy-Preserving and Token-Efficient Federated Transformer Learning for Secure Real-Time Object Detection in ITS](https://arxiv.org/abs/2601.12693)
*Mohoshin Ara Tahera,Sabbir Rahman,Shuvalaxmi Dass,Sharif Ullah,Mahmoud Abouyessef*

Main category: cs.CR

TL;DR: BlockSecRT-DETR：基于区块链的实时目标检测Transformer框架，通过令牌工程模块降低边缘计算延迟，利用区块链实现去中心化、隐私保护的联邦学习，解决ITS中的非IID数据、延迟和隐私安全问题。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中的联邦实时目标检测面临三大挑战：1）地理分布导致的缺失类非IID数据异质性；2）边缘硬件上高容量Transformer模型的延迟约束；3）不可信客户端更新和中心化聚合带来的隐私安全风险。

Method: 提出BlockSecRT-DETR框架，集成RT-DETR Transformer和令牌工程模块（TEM）降低编码器复杂度，同时采用区块链安全更新验证机制实现去中心化、防篡改的模型聚合，无需中心服务器。

Result: 在KITTI缺失类非IID数据集上，TEM将推理延迟降低17.2%，编码器FLOPs减少47.8%，全局检测精度保持89.20% mAP@0.5。区块链集成每轮增加400ms开销，账本大小保持在12KB以下。

Conclusion: BlockSecRT-DETR有效解决了ITS中联邦目标检测的数据异质性、延迟和隐私安全问题，通过令牌剪枝和区块链验证实现了高效、安全的去中心化联邦学习框架。

Abstract: Federated real-time object detection using transformers in Intelligent Transportation Systems (ITS) faces three major challenges: (1) missing-class non-IID data heterogeneity from geographically diverse traffic environments, (2) latency constraints on edge hardware for high-capacity transformer models, and (3) privacy and security risks from untrusted client updates and centralized aggregation. We propose BlockSecRT-DETR, a BLOCKchain-SECured Real-Time Object DEtection TRansformer framework for ITS that provides a decentralized, token-efficient, and privacy-preserving federated training solution using RT-DETR transformer, incorporating a blockchain-secured update validation mechanism for trustworthy aggregation. In this framework, challenges (1) and (2) are jointly addressed through a unified client-side design that integrates RT-DETR training with a Token Engineering Module (TEM). TEM prunes low-utility tokens, reducing encoder complexity and latency on edge hardware, while aggregated updates mitigate non-IID data heterogeneity across clients. To address challenge (3), BlockSecRT-DETR incorporates a decentralized blockchain-secured update validation mechanism that enables tamper-proof, privacy-preserving, and trust-free authenticated model aggregation without relying on a central server. We evaluated the proposed framework under a missing-class Non-IID partition of the KITTI dataset and conducted a blockchain case study to quantify security overhead. TEM improves inference latency by 17.2% and reduces encoder FLOPs by 47.8%, while maintaining global detection accuracy (89.20% mAP@0.5). The blockchain integration adds 400 ms per round, and the ledger size remains under 12 KB due to metadata-only on-chain storage.

</details>


### [223] [DUAP: Dual-task Universal Adversarial Perturbations Against Voice Control Systems](https://arxiv.org/abs/2601.12786)
*Suyang Sun,Weifei Jin,Yuxin Cao,Wei Song,Jie Hao*

Main category: cs.CR

TL;DR: 提出DUAP方法，通过梯度分析发现ASR和SR无内在冲突，设计双任务通用对抗扰动同时攻击语音识别和说话人识别系统，确保扰动不可感知。


<details>
  <summary>Details</summary>
Motivation: 现代语音控制系统依赖ASR和SR的协作决策，但现有对抗攻击多针对单一任务，忽视了实际场景中的耦合决策管道，导致单任务攻击难以构成实际威胁。

Method: 首先通过梯度分析揭示ASR和SR无内在冲突；提出DUAP方法，使用目标替代目标有效破坏ASR转录；引入动态归一化集成策略增强跨不同SR模型的迁移性；结合心理声学掩蔽确保扰动不可感知。

Result: 在5个ASR模型和6个SR模型上的广泛评估表明，DUAP实现了高同时攻击成功率，具有优越的不可感知性，显著优于现有单任务基线方法。

Conclusion: DUAP填补了针对语音控制系统耦合决策管道的对抗攻击空白，通过同时攻击ASR和SR任务，证明了在实际场景中构成有效威胁的可行性。

Abstract: Modern Voice Control Systems (VCS) rely on the collaboration of Automatic Speech Recognition (ASR) and Speaker Recognition (SR) for secure interaction. However, prior adversarial attacks typically target these tasks in isolation, overlooking the coupled decision pipeline in real-world scenarios. Consequently, single-task attacks often fail to pose a practical threat. To fill this gap, we first utilize gradient analysis to reveal that ASR and SR exhibit no inherent conflicts. Building on this, we propose Dual-task Universal Adversarial Perturbation (DUAP). Specifically, DUAP employs a targeted surrogate objective to effectively disrupt ASR transcription and introduces a Dynamic Normalized Ensemble (DNE) strategy to enhance transferability across diverse SR models. Furthermore, we incorporate psychoacoustic masking to ensure perturbation imperceptibility. Extensive evaluations across five ASR and six SR models demonstrate that DUAP achieves high simultaneous attack success rates and superior imperceptibility, significantly outperforming existing single-task baselines.

</details>


### [224] [PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection](https://arxiv.org/abs/2601.12866)
*Sharmila S P*

Main category: cs.CR

TL;DR: 提出一个统一的PDF恶意文件检测框架，整合图结构、元数据和结构特征，生成170维特征向量用于恶意软件分类、异常检测和取证分析。


<details>
  <summary>Details</summary>
Motivation: 恶意PDF文件日益增多，需要强大且全面的特征提取技术来进行有效检测和分析。

Method: 开发统一框架，整合图基分析（基于词对关系构建无向图计算图论特征）、元数据分析（字符分布、熵模式、字段不一致性）、时间特征（创建修改时间戳）、结构特征（对象流、字体、嵌入图像）和恶意构造标志（JavaScript、启动动作等），生成170维特征向量。

Result: 构建了高维特征表示（170维），适用于下游任务如恶意软件分类、异常检测和取证分析。该方法具有可扩展性和可扩展性，支持实际PDF威胁情报工作流。

Conclusion: 提出的统一框架通过整合多种特征提取技术，为PDF恶意文件检测提供了全面、可扩展的解决方案，能够有效支持实际安全应用。

Abstract: The increasing prevalence of malicious Portable Document Format (PDF) files necessitates robust and comprehensive feature extraction techniques for effective detection and analysis. This work presents a unified framework that integrates graph-based, structural, and metadata-driven analysis to generate a rich feature representation for each PDF document. The system extracts text from PDF pages and constructs undirected graphs based on pairwise word relationships, enabling the computation of graph-theoretic features such as node count, edge density, and clustering coefficient. Simultaneously, the framework parses embedded metadata to quantify character distributions, entropy patterns, and inconsistencies across fields such as author, title, and producer. Temporal features are derived from creation and modification timestamps to capture behavioral signatures, while structural elements including, object streams, fonts, and embedded images, are quantified to reflect document complexity. Boolean flags for potentially malicious PDF constructs (e.g., JavaScript, launch actions) are also extracted. Together, these features form a high-dimensional vector representation (170 dimensions) that is well-suited for downstream tasks such as malware classification, anomaly detection, and forensic analysis. The proposed approach is scalable, extensible, and designed to support real-world PDF threat intelligence workflows.6

</details>


### [225] [Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass](https://arxiv.org/abs/2601.12916)
*Sangjun An,Seoksu Lee,Eun-Sun Cho*

Main category: cs.CR

TL;DR: 提出基于LLVM IR的静态分析方法，用于检测虚拟化混淆中的核心结构组件（调度例程、处理程序块、VM区域），实验表明在无编译器优化时能有效识别所有主要虚拟化模式。


<details>
  <summary>Details</summary>
Motivation: 虚拟化混淆是一种强大的恶意软件混淆技术，通过将原始指令转换为攻击者定义的虚拟机字节码，产生复杂难分析的代码，阻碍安全分析。现有方法难以有效识别其核心结构，需要开发专门的检测技术。

Method: 通过静态分析虚拟化混淆代码的执行模型，在LLVM IR层面定义并检测三个关键组件：调度例程（dispatch routine）、处理程序块（handler blocks）和VM区域（VM region）。开发了专门的LLVM Pass来实现这些检测。

Result: 实验结果显示，在无编译器优化的情况下，提出的LLVM Pass能够成功检测所有主要虚拟化模式（switch模式、direct模式和indirect模式）中的核心结构组件。

Conclusion: 该方法为虚拟化混淆的静态分析提供了有效工具，能够识别混淆代码的关键结构组件，为后续的反混淆和安全分析奠定基础。在无编译器优化时表现良好，但未来可能需要考虑优化代码的检测挑战。

Abstract: Malware often uses obfuscation to hinder security analysis. Among these techniques, virtualization-based obfuscation is particularly strong because it protects programs by translating original instructions into attacker-defined virtual machine (VM) bytecode, producing long and complex code that is difficult to analyze and deobfuscate. This paper aims to identify the structural components of virtualization-based obfuscation through static analysis. By examining the execution model of obfuscated code, we define and detect the key elements required for deobfuscation-namely the dispatch routine, handler blocks, and the VM region-using LLVM IR. Experimental results show that, in the absence of compiler optimizations, the proposed LLVM Pass successfully detects all core structures across major virtualization options, including switch, direct, and indirect modes.

</details>


### [226] [Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy](https://arxiv.org/abs/2601.12922)
*Johannes Kaiser,Alexander Ziller,Eleni Triantafillou,Daniel Rückert,Georgios Kaissis*

Main category: cs.CR

TL;DR: iDP机制存在集体风险漏洞：个体的隐私风险不仅取决于自身隐私预算，还受其他用户隐私选择影响，导致风险被低估且可被攻击者利用，需重新设计iDP系统


<details>
  <summary>Details</summary>
Motivation: 揭示基于采样的个体差分隐私(iDP)机制中一个被忽视的漏洞：虽然符合iDP保证，但个体的隐私风险不仅由其自身隐私预算决定，还严重依赖所有其他数据贡献者的隐私选择，导致个体隐私控制的承诺与现实风险集体决定的系统之间存在不匹配

Method: 1. 理论分析采样iDP机制的集体风险特性；2. 实证演示特定隐私偏好分布会无意中增加个体隐私风险；3. 展示攻击者如何通过精心选择隐私预算来放大目标个体的漏洞；4. 提出$(\varepsilon_i,δ_i,\overlineΔ)$-iDP隐私合约，使用$Δ$-散度为用户提供超额漏洞的硬上限

Result: 1. 实证评估显示对62%的目标个体攻击成功，显著增加了其成员推理易感性；2. 攻击完全在DP保证范围内操作，隐藏了超额漏洞；3. 提出的$(\varepsilon_i,δ_i,\overlineΔ)$-iDP合约能提供用户超额漏洞的硬上限，同时为机制设计提供灵活性

Conclusion: 当前iDP范式存在根本性挑战，需要重新评估iDP系统的设计、审计、沟通和部署方式，使超额风险透明且可控，提出的新隐私合约为解决这一问题提供了方向

Abstract: Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. We reveal a previously overlooked vulnerability in sampling-based iDP mechanisms: while conforming to the iDP guarantees, an individual's privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. We demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. Moreover, this excess risk provides an exploitable attack vector. A central adversary or a set of colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. Most importantly, this attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Our empirical evaluation demonstrates successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, we propose $(\varepsilon_i,δ_i,\overlineΔ)$-iDP a privacy contract that uses $Δ$-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Our findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.

</details>


### [227] [On the Evidentiary Limits of Membership Inference for Copyright Auditing](https://arxiv.org/abs/2601.12937)
*Murat Bilgehan Ertan,Emirhan Böge,Min Chen,Kaleel Mahmood,Marten van Dijk*

Main category: cs.CR

TL;DR: 该论文研究了在对抗性版权纠纷中，当模型开发者可能对训练数据进行语义保留的改写时，成员推理攻击（MIAs）作为证据的可靠性问题。作者提出了SAGE框架来测试MIAs的鲁棒性，发现现有MIAs在对抗性设置下是脆弱的，不足以作为LLM版权审计的独立机制。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在日益不透明的语料库上训练，成员推理攻击被提出用于审计受版权保护的文本是否被用于训练，但其在现实条件下的可靠性受到质疑。论文旨在探究在对抗性版权纠纷中，当被指控的模型开发者可能对训练数据进行语义保留的改写时，MIAs能否作为可采纳的证据。

Method: 作者通过法官-检察官-被指控方通信协议形式化对抗性版权纠纷场景。为测试该协议下的鲁棒性，提出了SAGE（结构感知的SAE引导提取）框架，这是一个基于稀疏自编码器（SAEs）的改写框架，能够改变训练数据的词汇结构，同时保留语义内容和下游实用性。实验评估了最先进的MIAs在模型使用SAGE生成的改写文本进行微调时的性能表现。

Result: 实验表明，当模型在SAGE生成的改写文本上进行微调时，最先进的MIAs性能显著下降，表明这些攻击的信号对语义保留的转换不具有鲁棒性。尽管在某些微调机制下仍存在一些信息泄露，但这些结果表明MIAs在对抗性设置下是脆弱的。

Conclusion: 成员推理攻击在对抗性设置下是脆弱的，不足以作为大型语言模型版权审计的独立机制。MIAs不能单独作为版权纠纷中的可靠证据，特别是当模型开发者可能对训练数据进行语义保留的改写时。

Abstract: As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.

</details>


### [228] [KinGuard: Hierarchical Kinship-Aware Fingerprinting to Defend Against Large Language Model Stealing](https://arxiv.org/abs/2601.12986)
*Zhenhua Xu,Xiaoning Tian,Wenjun Zeng,Wenpeng Xing,Tianliang Lu,Gaolei Li,Chaochao Chen,Meng Han*

Main category: cs.CR

TL;DR: KinGuard通过嵌入基于亲属关系叙事的私有知识语料库来解决后门指纹的隐密-鲁棒性悖论，通过增量预训练让模型内化知识，并通过探测概念理解来验证所有权


<details>
  <summary>Details</summary>
Motivation: 保护大语言模型的知识产权需要可靠的所有权验证方法。传统的后门指纹方法存在隐密-鲁棒性悖论：为了鲁棒性，这些方法迫使模型记忆对高困惑度触发词的固定响应，但这种针对性过拟合会产生可检测的统计伪影

Method: 提出KinGuard框架，嵌入基于结构化亲属关系叙事的私有知识语料库。模型通过增量预训练内化这些知识，而不是记忆表面触发词。所有权验证通过探测模型对嵌入概念的理解来实现

Result: 大量实验证明KinGuard在有效性、隐密性和鲁棒性方面表现优越，能够抵抗包括微调、输入扰动和模型合并在内的多种攻击

Conclusion: KinGuard建立了基于知识嵌入的实用且安全的模型指纹范式，解决了传统后门指纹方法的根本缺陷

Abstract: Protecting the intellectual property of large language models requires robust ownership verification. Conventional backdoor fingerprinting, however, is flawed by a stealth-robustness paradox: to be robust, these methods force models to memorize fixed responses to high-perplexity triggers, but this targeted overfitting creates detectable statistical artifacts. We resolve this paradox with KinGuard, a framework that embeds a private knowledge corpus built on structured kinship narratives. Instead of memorizing superficial triggers, the model internalizes this knowledge via incremental pre-training, and ownership is verified by probing its conceptual understanding. Extensive experiments demonstrate KinGuard's superior effectiveness, stealth, and resilience against a battery of attacks including fine-tuning, input perturbation, and model merging. Our work establishes knowledge-based embedding as a practical and secure paradigm for model fingerprinting.

</details>


### [229] [Post-Quantum Secure Aggregation via Code-Based Homomorphic Encryption](https://arxiv.org/abs/2601.13031)
*Sebastian Bitzer,Maximilian Egger,Mumin Liu,Antonia Wachter-Zeh*

Main category: cs.CR

TL;DR: 提出基于LPN假设的代码基安全聚合方案，通过密钥和消息加法同态加密框架，采用委员会解密和CRT优化降低通信成本，在特定场景下优于信息论安全方案。


<details>
  <summary>Details</summary>
Motivation: 现有后量子安全聚合方案主要基于格密码假设，缺乏基于代码假设的替代方案。需要开发不依赖格假设的安全聚合方法，提供更多样化的后量子安全选择。

Method: 基于LPN假设构建密钥和消息加法同态加密框架，采用委员会解密机制（通过秘密共享实现），并引入CRT优化来降低LPN实例化的通信成本。在Hint-LPN假设下分析安全性，证明其与标准LPN的等价性。

Result: 提出了首个基于LPN假设的安全聚合方案，通过CRT优化显著降低通信开销。安全性分析表明在适当参数下Hint-LPN与标准LPN等价。性能评估显示在某些场景下优于信息论安全聚合协议。

Conclusion: 成功构建了基于代码假设的安全聚合替代方案，为后量子安全聚合提供了不依赖格假设的新选择，在特定参数范围内具有实用优势。

Abstract: Secure aggregation enables aggregation of inputs from multiple parties without revealing individual contributions to the server or other clients. Existing post-quantum approaches based on homomorphic encryption offer practical efficiency but predominantly rely on lattice-based hardness assumptions. We present a code-based alternative for secure aggregation by instantiating a general framework based on key- and message-additive homomorphic encryption under the Learning Parity with Noise (LPN) assumption. Our construction employs a committee-based decryptor realized via secret sharing and incorporates a Chinese Remainder Theorem (CRT)-based optimization to reduce the communication costs of LPN-based instantiations. We analyze the security of the proposed scheme under a new Hint-LPN assumption and show that it is equivalent to standard LPN for suitable parameters. Finally, we evaluate performance and identify regimes in which our approach outperforms information-theoretically secure aggregation protocols.

</details>


### [230] [Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading](https://arxiv.org/abs/2601.13082)
*Advije Rizvani,Giovanni Apruzzese,Pavel Laskov*

Main category: cs.CR

TL;DR: 研究量化了针对LLM支持的算法交易系统的对抗性新闻攻击，通过Unicode同形字替换和隐藏文本条款操纵新闻标题，在14个月内单日攻击可使年回报率降低高达17.7个百分点


<details>
  <summary>Details</summary>
Motivation: LLM在金融领域的应用日益广泛，特别是在分析金融新闻情感以指导算法交易决策方面。然而，威胁行为者可能制作"对抗性新闻"来误导LLM，这种攻击的系统性影响和货币风险尚未被量化评估。

Method: 研究考虑了无法直接访问ATS但能篡改单日股票相关新闻标题的对手。评估了两种人类难以察觉的操纵技术：1) Unicode同形字替换（误导股票名称识别），2) 隐藏文本条款（改变新闻标题情感）。在Backtrader中实现了一个现实的ATS，融合了基于LSTM的价格预测和LLM衍生的情感分析（使用FinBERT、FinGPT、FinLLaMA和六个通用LLM），并通过投资组合指标量化货币影响。

Result: 在真实世界数据上的实验表明，在14个月内进行单日攻击可以可靠地误导LLM，并使年回报率降低高达17.7个百分点。通过分析流行的爬虫库和交易平台，并调查27名金融科技从业者，确认了这种攻击的现实可行性。

Conclusion: 针对LLM支持的算法交易系统的对抗性新闻攻击具有显著的货币风险，单日攻击即可造成严重的财务损失。研究已向交易平台所有者通报了此安全问题，强调了需要加强LLM在金融应用中的安全防护。

Abstract: Large Language Models (LLMs) are increasingly adopted in the financial domain. Their exceptional capabilities to analyse textual data make them well-suited for inferring the sentiment of finance-related news. Such feedback can be leveraged by algorithmic trading systems (ATS) to guide buy/sell decisions. However, this practice bears the risk that a threat actor may craft "adversarial news" intended to mislead an LLM. In particular, the news headline may include "malicious" content that remains invisible to human readers but which is still ingested by the LLM. Although prior work has studied textual adversarial examples, their system-wide impact on LLM-supported ATS has not yet been quantified in terms of monetary risk. To address this threat, we consider an adversary with no direct access to an ATS but able to alter stock-related news headlines on a single day. We evaluate two human-imperceptible manipulations in a financial context: Unicode homoglyph substitutions that misroute models during stock-name recognition, and hidden-text clauses that alter the sentiment of the news headline. We implement a realistic ATS in Backtrader that fuses an LSTM-based price forecast with LLM-derived sentiment (FinBERT, FinGPT, FinLLaMA, and six general-purpose LLMs), and quantify monetary impact using portfolio metrics. Experiments on real-world data show that manipulating a one-day attack over 14 months can reliably mislead LLMs and reduce annual returns by up to 17.7 percentage points. To assess real-world feasibility, we analyze popular scraping libraries and trading platforms and survey 27 FinTech practitioners, confirming our hypotheses. We notified trading platform owners of this security issue.

</details>


### [231] [CODE: A Contradiction-Based Deliberation Extension Framework for Overthinking Attacks on Retrieval-Augmented Generation](https://arxiv.org/abs/2601.13112)
*Xiaolei Zhang,Xiaojun Jia,Liquan Chen,Songze Li*

Main category: cs.CR

TL;DR: 本文提出CODE攻击框架，揭示推理模型在RAG系统中的过度思考风险，通过构造矛盾样本来增加推理令牌消耗而不影响任务准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管推理模型能提升RAG系统的任务性能，但研究发现推理模型存在过度思考攻击风险。本文旨在揭示这种风险会遗传给配备推理模型的RAG系统，并开发有效的攻击框架来验证这一风险。

Method: 提出Contradiction-Based Deliberation Extension (CODE)端到端攻击框架，采用多智能体架构构造中毒样本注入知识库。这些样本具有高度相关性（能被检索作为推理模型输入）和逻辑层与证据层之间的矛盾（导致模型过度思考），并通过优化展现高度多样化的风格。

Result: 在两个数据集和五个商业推理模型上的实验表明，CODE攻击导致推理令牌消耗增加5.32倍至24.72倍，且任务准确性不受影响。攻击的推理开销极难检测，因为无需修改用户查询。

Conclusion: 推理模型的过度思考风险确实会遗传给RAG系统，CODE攻击框架有效验证了这一风险。论文还讨论并评估了潜在的防御措施来缓解过度思考风险。

Abstract: Introducing reasoning models into Retrieval-Augmented Generation (RAG) systems enhances task performance through step-by-step reasoning, logical consistency, and multi-step self-verification. However, recent studies have shown that reasoning models suffer from overthinking attacks, where models are tricked to generate unnecessarily high number of reasoning tokens. In this paper, we reveal that such overthinking risk can be inherited by RAG systems equipped with reasoning models, by proposing an end-to-end attack framework named Contradiction-Based Deliberation Extension (CODE). Specifically, CODE develops a multi-agent architecture to construct poisoning samples that are injected into the knowledge base. These samples 1) are highly correlated with the use query, such that can be retrieved as inputs to the reasoning model; and 2) contain contradiction between the logical and evidence layers that cause models to overthink, and are optimized to exhibit highly diverse styles. Moreover, the inference overhead of CODE is extremely difficult to detect, as no modification is needed on the user query, and the task accuracy remain unaffected. Extensive experiments on two datasets across five commercial reasoning models demonstrate that the proposed attack causes a 5.32x-24.72x increase in reasoning token consumption, without degrading task performance. Finally, we also discuss and evaluate potential countermeasures to mitigate overthinking risks.

</details>


### [232] [Function Recovery Attacks in Gate-Hiding Garbled Circuits using SAT Solving](https://arxiv.org/abs/2601.13271)
*Chao Yin,Zunchen Huang,Chenglu Jin,Marten van Dijk,Fabio Massacci*

Main category: cs.CR

TL;DR: 论文分析了门隐藏技术在电路拓扑泄露下的实际安全性，提出了基于SAT的函数恢复攻击方法，通过增量式SAT求解和拓扑保持简化定理，在ISCAS基准电路上实现了最高159倍的恢复速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有半私有函数评估的安全定义故意排除了电路拓扑泄露的影响，导致对拓扑泄露如何影响函数隐私的实际影响理解不足。需要分析门隐藏在现实计算能力下的经验安全性。

Method: 提出了基于SAT的函数恢复攻击，从公开的电路拓扑重建隐藏的门操作。开发了增量式SAT求解框架和一组可组合的拓扑保持简化定理，共同减少SAT实例大小并在重复求解迭代中逐步约束搜索空间。

Result: 在ISCAS基准电路、代表性安全计算电路和容错传感器融合电路上评估攻击效果，在24小时恢复预算下，优化攻击相比基线方法实现了最高159倍的恢复时间加速，且不增加预言机查询次数。

Conclusion: 拓扑泄露单独就能够在实践中实现有效的函数恢复，这表明现有安全定义需要重新考虑拓扑泄露的影响，门隐藏技术在实际部署中可能面临比预期更大的安全风险。

Abstract: Semi-Private Function Evaluation enables joint computation while protecting both input data and function logic. A practical instantiation is gate-hiding garbled circuits, which conceal gate functionalities while revealing the circuit topology. Existing security definitions intentionally exclude leakage through circuit topology, leaving the concrete impact of such leakage on function privacy insufficiently understood.
  We analyze the empirical security of gate hiding under two adversarial models that capture realistic computational capabilities. We present a SAT-based function-recovery attack that reconstructs hidden gate operations from a circuit's public topology. To enable recovery on larger and more complex circuits, we develop an incremental SAT-solving framework combined with a set of composable, topology-preserving simplification theorems. These techniques jointly reduce the SAT instance size and progressively constrain the search space across repeated solving iterations.
  We evaluate our attack on ISCAS benchmarks, representative secure computation circuits, and fault-tolerant sensor fusion circuits under a fixed 24-hour recovery budget. Compared to baseline approaches, our optimized attack achieves up to a 159-fold speedup in recovery time without increasing the number of oracle queries. Our results demonstrate that topology leakage alone can enable effective function recovery in practice.

</details>


### [233] [QERS: Quantum Encryption Resilience Score for Post-Quantum Cryptography in Computer, IoT, and IIoT Systems](https://arxiv.org/abs/2601.13399)
*Jonatan Rassekhnia*

Main category: cs.CR

TL;DR: 提出了QERS框架，用于评估后量子密码在物联网环境中的抗量子加密韧性，通过多标准决策分析提供综合评分


<details>
  <summary>Details</summary>
Motivation: 后量子密码对物联网安全至关重要，但现有评估方法主要关注孤立性能指标，缺乏对整体安全性和部署决策的全面支持

Method: 引入QERS框架，集成密码性能、系统约束和多标准决策分析，采用归一化指标、加权聚合和机器学习辅助分析，评估不同设备和通信协议下的抗量子韧性

Result: 实验结果表明该框架能够在实际资源约束下对后量子方案进行对比评估，支持明智的安全设计和迁移规划

Conclusion: QERS为计算机、物联网和工业物联网环境中的后量子密码就绪度评估提供了通用测量框架，目前作为预印本发布，计划在后续研究中扩展统计验证

Abstract: Post-quantum cryptography (PQC) is becoming essential for securing Internet of Things (IoT) and Industrial IoT (IIoT) systems against quantum-enabled adversaries. However, existing evaluation approaches primarily focus on isolated performance metrics, offering limited support for holistic security and deployment decisions. This paper introduces QERS (Quantum Encryption Resilience Score), a universal measurement framework that integrates cryptographic performance, system constraints, and multi-criteria decision analysis to assess PQC readiness in computer, IoT, and IIoT environments. QERS combines normalized metrics, weighted aggregation, and machine learning-assisted analysis to produce interpretable resilience scores across heterogeneous devices and communication protocols. Experimental results demonstrate how the framework enables comparative evaluation of post-quantum schemes under realistic resource constraints, supporting informed security design and migration planning. This work is presented as a preprint, with extended statistical validation planned as part of ongoing graduate research.

</details>


### [234] [Quantum Encryption Resilience Score (QERS) for MQTT, HTTP, and HTTPS under Post-Quantum Cryptography in Computer, IoT, and IIoT Systems](https://arxiv.org/abs/2601.13423)
*Jonatan Rassekhnia*

Main category: cs.CR

TL;DR: 该论文提出量子加密韧性评分(QERS)框架，用于评估MQTT、HTTP和HTTPS协议在PQC环境下的性能与安全权衡，实验表明MQTT效率最高，HTTPS安全性最好但资源消耗大


<details>
  <summary>Details</summary>
Motivation: 后量子密码学(PQC)带来显著的计算和通信开销，对资源受限的物联网和工业物联网设备构成挑战，需要系统评估通信协议在PQC环境下的性能与安全平衡

Method: 使用ESP32-C6客户端和ARM架构的Raspberry Pi CM4服务器，在真实操作条件下测量MQTT、HTTP和HTTPS协议的延迟、CPU利用率、RSSI、能耗、密钥大小和TLS握手开销，通过QERS框架将这些异构指标整合为归一化的基础评分、调优评分和融合评分

Result: 实验结果显示MQTT在PQC约束下提供最高效率，HTTPS实现最高的安全加权韧性但代价是增加的延迟和资源消耗，QERS框架支持系统性的协议效率和安全韧性比较

Conclusion: 提出的QERS框架能够支持PQC启用的物联网和工业物联网部署中的协议选择和迁移规划，为资源受限环境下的安全通信协议选择提供量化依据

Abstract: Post-quantum cryptography (PQC) introduces significant computational and communication overhead, which poses challenges for resource-constrained computer systems, Internet of Things (IoT), and Industrial IoT (IIoT) devices. This paper presents an experimental evaluation of the Quantum Encryption Resilience Score (QERS) applied to MQTT, HTTP, and HTTPS communication protocols operating under PQC. Using an ESP32-C6 client and an ARM-based Raspberry Pi CM4 server, latency, CPU utilization, RSSI, energy consumption, key size, and TLS handshake overhead are measured under realistic operating conditions. QERS integrates these heterogeneous metrics into normalized Basic, Tuned, and Fusion scores, enabling systematic comparison of protocol efficiency and security resilience. Experimental results show that MQTT provides the highest efficiency under PQC constraints, while HTTPS achieves the highest security-weighted resilience at the cost of increased latency and resource consumption. The proposed framework supports informed protocol selection and migration planning for PQC-enabled IoT and IIoT deployments.

</details>


### [235] [A Scientific Data Integrity system based on Blockchain](https://arxiv.org/abs/2601.13425)
*Gian Sebastian Mier Bello,Alexander Martinez Mendez,Carlos J. Barrios H.,Robinson Rivas,Luis A. Núñez*

Main category: cs.CR

TL;DR: 提出基于区块链的分布式科学数据完整性验证方案，解决HPC环境中大数据复制困难与科研数据不可篡改需求之间的矛盾


<details>
  <summary>Details</summary>
Motivation: HPC项目中存在大量来自不同来源的数据，部分数据体量巨大难以复制，而科学研究要求数据保持原始状态以供不同研究组复现结果、讨论理论和相互验证

Method: 采用区块链技术构建分布式数据完整性验证系统，确保：1) 数据管理的安全访问；2) 数据完整性的便捷验证；3) 新记录添加时保持相同的强完整性策略

Result: 开发了原型系统并使用拉丁美洲巨型天文台(LAGO)项目的真实科学合作公共数据集子集进行了测试验证

Conclusion: 区块链技术为分布式科学数据仓库提供了有效的完整性验证解决方案，能够满足科研数据不可篡改和可复现性的需求

Abstract: In most High Performance Computing (HPC) projects nowadays, there is a lot of data obtained from different sources, depending on the project's objectives. Some of that data is very huge in terms of size, so copying such data sometimes is an unrealistic goal. On the other hand, science requires data used for different purposes to remain unaltered, so different groups of researchers can reproduce results, discuss theories, and validate each other. In this paper, we present a novel approach to help research groups to validate data integrity on such distributed repositories using Blockchain. Originally developed for cryptographic currencies, Blockchain has demonstrated a versatile range of uses. Our proposal ensures 1) secure access to data management, 2) easy validation of data integrity, and 3) an easy way to add new records to the dataset with the same robust integrity policy. A prototype was developed and tested using a subset of a public dataset from a real scientific collaboration, the Latin American Giant Observatory (LAGO) Project.

</details>


### [236] [Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests](https://arxiv.org/abs/2601.13515)
*Hanlin Zhou,Huah Yong Chan,Jingfei Ni,Mengchun Wu,Qing Deng*

Main category: cs.CR

TL;DR: 使用HTTP状态码作为HPA自定义指标，结合随机森林算法评估预测攻击，动态调整HPA最大pod参数来管理攻击流量，将攻击IP重定向到蜜罐pod


<details>
  <summary>Details</summary>
Motivation: 在云原生环境中，传统HPA（水平Pod自动扩缩）容易受到攻击流量的影响，导致不必要的资源扩展和成本增加。需要一种智能机制来区分正常流量和攻击流量，并动态调整HPA参数以有效管理攻击场景

Method: 将HTTP状态码作为HPA的自定义指标，集成机器学习中的随机森林分类算法来评估和预测攻击。通过动态调整HPA的最大pod参数来管理攻击流量，将所有来自攻击IP的访问重定向到蜜罐pod。在不同条件下进行实验验证

Result: 在高负载条件下，通过HPA pod调整实现了更低的5XX状态码发生率。有效隔离了攻击流量，防止了因攻击导致的HPA过度扩展。实验表明设置适当的HPA调整阈值至关重要

Conclusion: 该方法成功将机器学习与HPA结合，实现了对攻击流量的智能管理和隔离。通过动态参数调整和蜜罐重定向，既保证了服务可用性，又避免了不必要的资源扩展，为云原生环境的安全自动扩缩提供了有效解决方案

Abstract: In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.

</details>


### [237] [Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs](https://arxiv.org/abs/2601.13528)
*Jackson Kaunismaa,Avery Griffin,John Hughes,Christina Q. Knight,Mrinank Sharma,Erik Jones*

Main category: cs.CR

TL;DR: 通过构建相邻领域无害提示、获取前沿模型响应、微调开源模型的三阶段攻击，可在化学危险品合成领域恢复约40%能力差距，揭示输出级防护在生态系统层面的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示前沿模型防护措施的局限性，即使模型内置了强大的安全防护（如分类器过滤危险输出），攻击者仍可通过间接方式获取有害能力，从而引发生态系统层面的安全风险。

Method: 提出三阶段诱导攻击：1）构建目标有害任务相邻领域的无害提示；2）从受防护的前沿模型获取这些提示的响应；3）使用这些提示-响应对微调开源模型。攻击利用相邻领域提示不触发防护机制的特点，间接获取有害能力。

Result: 在危险化学品合成与处理领域，该攻击能够恢复开源模型与无限制前沿模型之间约40%的能力差距。攻击效果随前沿模型能力和生成微调数据量的增加而提升，验证了输出级防护在生态系统层面的脆弱性。

Conclusion: 仅依靠输出级防护措施无法有效缓解生态系统层面的风险，因为攻击者可通过间接方式绕过防护获取有害能力。这揭示了当前AI安全防护框架的局限性，需要更全面的安全策略。

Abstract: Model developers implement safeguards in frontier models to prevent misuse, for example, by employing classifiers to filter dangerous outputs. In this work, we demonstrate that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. Our elicitation attacks consist of three stages: (i) constructing prompts in adjacent domains to a target harmful task that do not request dangerous information; (ii) obtaining responses to these prompts from safeguarded frontier models; (iii) fine-tuning open-source models on these prompt-output pairs. Since the requested prompts cannot be used to directly cause harm, they are not refused by frontier model safeguards. We evaluate these elicitation attacks within the domain of hazardous chemical synthesis and processing, and demonstrate that our attacks recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. We then show that the efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. Our work demonstrates the challenge of mitigating ecosystem level risks with output-level safeguards.

</details>


### [238] [When Reasoning Leaks Membership: Membership Inference Attack on Black-box Large Reasoning Models](https://arxiv.org/abs/2601.13607)
*Ruihan Hu,Yu-Ming Shang,Wei Luo,Ye Tao,Xi Zhang*

Main category: cs.CR

TL;DR: 首次系统探索黑盒大型推理模型的成员推断攻击，发现暴露的推理轨迹会泄露成员信号，提出基于语义潜在空间中构建回忆-推理轴的攻击框架BlackSpectrum


<details>
  <summary>Details</summary>
Motivation: 现代黑盒大型推理模型通过API暴露中间推理轨迹以提高透明度，但这些轨迹可能泄露成员信息，即使没有访问先前攻击所需的token logits，这构成了新的隐私威胁

Method: 提出BlackSpectrum攻击框架：1）分析发现LRMs对熟悉的训练成员样本产生自信的回忆式推理轨迹，对非成员产生犹豫的推理式轨迹；2）在语义潜在空间中基于暴露的轨迹表示构建回忆-推理轴；3）通过定位查询样本在该轴上的位置获得成员分数

Result: 暴露推理轨迹显著增加了LRMs对成员推断攻击的脆弱性，导致攻击性能大幅提升。为支持未来研究提供了arXivReasoning和BookReasoning两个新数据集

Conclusion: LRM公司需要在中间推理轨迹的透明度与隐私保护之间取得平衡。这是首次针对黑盒大型推理模型的成员推断攻击系统研究

Abstract: Large Reasoning Models (LRMs) have rapidly gained prominence for their strong performance in solving complex tasks. Many modern black-box LRMs expose the intermediate reasoning traces through APIs to improve transparency (e.g., Gemini-2.5 and Claude-sonnet). Despite their benefits, we find that these traces can leak membership signals, creating a new privacy threat even without access to token logits used in prior attacks. In this work, we initiate the first systematic exploration of Membership Inference Attacks (MIAs) on black-box LRMs. Our preliminary analysis shows that LRMs produce confident, recall-like reasoning traces on familiar training member samples but more hesitant, inference-like reasoning traces on non-members. The representations of these traces are continuously distributed in the semantic latent space, spanning from familiar to unfamiliar samples. Building on this observation, we propose BlackSpectrum, the first membership inference attack framework targeting the black-box LRMs. The key idea is to construct a recall-inference axis in the semantic latent space, based on representations derived from the exposed traces. By locating where a query sample falls along this axis, the attacker can obtain a membership score and predict how likely it is to be a member of the training data. Additionally, to address the limitations of outdated datasets unsuited to modern LRMs, we provide two new datasets to support future research, arXivReasoning and BookReasoning. Empirically, exposing reasoning traces significantly increases the vulnerability of LRMs to membership inference attacks, leading to large gains in attack performance. Our findings highlight the need for LRM companies to balance transparency in intermediate reasoning traces with privacy preservation.

</details>


### [239] [Secure Multi-Path Routing with All-or-Nothing Transform for Network-on-Chip Architectures](https://arxiv.org/abs/2601.13610)
*Hansika Weerasena,Matthew Randall,Prabhat Mishra*

Main category: cs.CR

TL;DR: 提出一种轻量级保密框架，结合准群基AONT变换与安全多路径路由，保护NoC免受窃听攻击


<details>
  <summary>Details</summary>
Motivation: NoC安全对可信SoC设计至关重要，窃听攻击是最常见且隐蔽的威胁。传统加密方法对资源受限SoC可能带来不可接受的性能开销

Method: 采用准群基全或无变换(AONT)对每个数据包进行处理，将变换后的数据块通过多个非重叠路由路径分发，确保中间路由器无法在没有所有数据块的情况下重构原始数据

Result: 实验评估表明该方法能有效缓解恶意路由器的窃听攻击，且面积和性能开销可忽略。与传统加密相比，AONT基多路径路由可将开销降低7.3倍

Conclusion: 提出的轻量级保密框架为资源受限SoC提供了一种高效且低开销的NoC安全解决方案，在保护数据机密性的同时保持了系统性能

Abstract: Ensuring Network-on-Chip (NoC) security is crucial to design trustworthy NoC-based System-on-Chip (SoC) architectures. While there are various threats that exploit on-chip communication vulnerabilities, eavesdropping attacks via malicious nodes are among the most common and stealthy. Although encryption can secure packets for confidentiality, it may introduce unacceptable overhead for resource-constrained SoCs. In this paper, we propose a lightweight confidentiality-preserving framework that utilizes a quasi-group based All-Or-Nothing Transform (AONT) combined with secure multi-path routing in NoC-based SoCs. By applying AONT to each packet and distributing its transformed blocks across multiple non-overlapping routes, we ensure that no intermediate router can reconstruct the original data without all blocks. Extensive experimental evaluation demonstrates that our method effectively mitigates eavesdropping attacks by malicious routers with negligible area and performance overhead. Our results also reveal that AONT-based multi-path routing can provide 7.3x reduction in overhead compared to traditional encryption for securing against eavesdropping attacks.

</details>


### [240] [ORCA - An Automated Threat Analysis Pipeline for O-RAN Continuous Development](https://arxiv.org/abs/2601.13681)
*Felix Klement,Alessandro Brighente,Michele Polese,Mauro Conti,Stefan Katzenbeisser*

Main category: cs.CR

TL;DR: 提出自动化安全评估框架，利用NLP技术将现实漏洞映射到标准化威胁清单，为O-RAN系统提供量化威胁评分


<details>
  <summary>Details</summary>
Motivation: O-RAN采用云化部署整合众多软件组件，引入了新的安全威胁。当前漏洞评估方法依赖人工、劳动密集型且主观的调查，导致威胁分析不一致，需要自动化解决方案

Method: 建立自动化流水线，利用自然语言处理技术最小化人工干预和相关偏见。通过将现实世界漏洞映射到预定义威胁清单并使用标准化输入格式，实现迭代、定量和高效评估

Result: 该方法首次实现了对O-RAN中单个漏洞和整个系统组件的可靠威胁评分，通过O-RAN示例实施展示了框架有效性，可将持续安全测试集成到自动化测试流水线中

Conclusion: 提出的自动化框架能够解决O-RAN独特安全挑战，通过DevSecOps方法实现快速安全发布，为电信范式转变提供有效的安全评估解决方案

Abstract: The Open-Radio Access Network (O-RAN) integrates numerous software components in a cloud-like deployment, opening the radio access network to previously unconsidered security threats. With the ever-evolving threat landscape, integrating security practices through a DevSecOps approach is essential for fast and secure releases. Current vulnerability assessment practices often rely on manual, labor-intensive, and subjective investigations, leading to inconsistencies in the threat analysis. To mitigate these issues, we establish an automated pipeline that leverages Natural Language Processing (NLP) to minimize human intervention and associated biases. By mapping real-world vulnerabilities to predefined threat lists with a standardized input format, our approach is the first to enable iterative, quantitative, and efficient assessments, generating reliable threat scores for both individual vulnerabilities and entire system components within O-RAN. We illustrate the effectiveness of our framework through an example implementation for O-RAN, showcasing how continuous security testing can integrate into automated testing pipelines to address the unique security challenges of this paradigm shift in telecommunications.

</details>


### [241] [The Limits of Conditional Volatility: Assessing Cryptocurrency VaR under EWMA and IGARCH Models](https://arxiv.org/abs/2601.13757)
*Ekleen Kaur*

Main category: cs.CR

TL;DR: 该研究通过比较三种条件波动率模型在加密货币风险管理中的应用，发现传统金融的波动率均值回归和杠杆效应假设在altcoin资产类别中不成立，非平稳框架是该领域监管级风险建模的必要条件。


<details>
  <summary>Details</summary>
Motivation: 标准静态几何布朗运动模型在加密货币风险管理中导致系统性失败（5% VaR基准下80.67%的损失概率），而高beta altcoin（XRP、SOL、ADA）这一资产类别在主流GARCH文献中被忽视，需要填补这一关键文献空白。

Method: 在相关蒙特卡洛VaR框架中比较测试三种条件波动率模型：EWMA/IGARCH基线模型、增加显式均值回归的IGARCH模型（IGARCH + MR）、以及改进的EGARCH风格不对称冲击模型，专门应用于高beta altcoin。

Result: 施加平稳性（IGARCH + MR）严重低估了下行风险（5% VaR减少50%），而不对称模型（模型3）导致过度惩罚。只有具有无限波动率持续性（alpha + beta = 1）的EWMA/IGARCH基线提供了稳健的条件波动率估计。

Conclusion: 正式拒绝了传统金融中波动率均值回归和不对称杠杆效应的假设，确立了非平稳框架是altcoin资产类别中监管级风险建模的必要前提条件。

Abstract: The application of the standard static Geometric Brownian Motion (GBM) model for cryptocurrency risk management resulted in a systemic failure, evidenced by a 80.67% chance of loss in the 5% value-at-risk benchmark. This study addresses a critical literature gap by comparatively testing three conditional volatility models the EWMA/IGARCH baseline, an IGARCH model augmented with explicit mean reversion (IGARCH + MR), and a modified EGARCH-style asymmetric shock model within a correlated Monte Carlo VaR framework. Crucially, the analysis is applied specifically to high-beta altcoins (XRP, SOL, ADA), an asset class largely neglected by mainstream GARCH literature. Our results demonstrate that imposing stationarity (IGARCH + MR) drastically underestimates downside risk (5 percent value-at-risk reduced by 50%), while the asymmetric model (Model 3) leads to severe over-penalization. The EWMA/IGARCH baseline, characterized by infinite volatility persistence (alpha + beta = 1), provided the only robust conditional volatility estimate. This finding constitutes a formal rejection of the conventional financial hypotheses of volatility mean reversion and the asymmetric leverage effect in the altcoin asset class, establishing that non-stationary frameworks are a prerequisite for regulatory-grade risk modeling in this domain.

</details>


### [242] [MirageNet:A Secure, Efficient, and Scalable On-Device Model Protection in Heterogeneous TEE and GPU System](https://arxiv.org/abs/2601.13826)
*Huadi Zheng,Li Cheng,Yan Ding*

Main category: cs.CR

TL;DR: ConvShatter是一种新颖的卷积层混淆方案，通过在TEE中安全存储最小恢复参数，实现低延迟、高精度的模型隐私保护，相比现有方案显著降低开销。


<details>
  <summary>Details</summary>
Motivation: 随着边缘设备计算能力增强，在不可信硬件上部署高性能DNN模型成为降低推理延迟和保护用户隐私的实用方案。现有基于部分混淆的TEE防御方案存在安全漏洞，而鲁棒方案则导致不可接受的延迟，需要在模型隐私和运行时开销之间取得平衡。

Method: 利用卷积线性特性将卷积核分解为关键核和公共核，注入混淆诱饵，并对通道/卷积核顺序进行置换。部署前执行核分解、诱饵注入和顺序混淆，将最小恢复参数安全存储在TEE中。推理时，TEE重构混淆卷积层的输出。

Result: ConvShatter显著降低了延迟开销，同时提供强大的安全保障。相比可比方案，相对于GroupCover减少了16%的开销，同时保持与原始模型相当的准确率。

Conclusion: ConvShatter通过创新的卷积核混淆方案，有效解决了模型隐私保护与运行时效率之间的权衡问题，为边缘设备上的安全DNN推理提供了实用解决方案。

Abstract: As edge devices gain stronger computing power, deploying high-performance DNN models on untrusted hardware has become a practical approach to cut inference latency and protect user data privacy. Given high model training costs and user experience requirements, balancing model privacy and low runtime overhead is critical. TEEs offer a viable defense, and prior work has proposed heterogeneous GPU-TEE inference frameworks via parameter obfuscation to balance efficiency and confidentiality. However, recent studies find partial obfuscation defenses ineffective, while robust schemes cause unacceptable latency. To resolve these issues, we propose ConvShatter, a novel obfuscation scheme that achieves low latency and high accuracy while preserving model confidentiality and integrity. It leverages convolution linearity to decompose kernels into critical and common ones, inject confounding decoys, and permute channel/kernel orders. Pre-deployment, it performs kernel decomposition, decoy injection and order obfuscation, storing minimal recovery parameters securely in the TEE. During inference, the TEE reconstructs outputs of obfuscated convolutional layers. Extensive experiments show ConvShatter substantially reduces latency overhead with strong security guarantees; versus comparable schemes, it cuts overhead by 16% relative to GroupCover while maintaining accuracy on par with the original model.

</details>


### [243] [Robust Reversible Watermarking in Encrypted Images Based on Dual-MSBs Spiral Embedding](https://arxiv.org/abs/2601.13840)
*Haoyu Shen,Wen Yin,Zhaoxia Yin,Wan-Li Lyu,Xinpeng Zhang*

Main category: cs.CR

TL;DR: 提出一种结合双最高有效位平面嵌入、空间冗余和纠错编码的鲁棒可逆加密图像水印框架，在保持可逆性和高嵌入容量的同时，显著提升了对噪声、JPEG压缩和裁剪攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒可逆加密图像水印方案在加密域中冗余不足，导致对噪声、有损压缩和裁剪攻击的鲁棒性有限，难以在严格受限的嵌入容量下同时实现鲁棒性、可逆性和内容隐私保护。

Method: 采用双最高有效位平面嵌入与空间冗余和纠错编码相结合的方法：1) 压缩预测误差位平面以预留足够的嵌入空间和辅助信息用于无损重建；2) 使用螺旋嵌入策略重组双最高有效位平面，将多个冗余水印副本分布在空间分散区域，增强对噪声和空间丢失的鲁棒性。

Result: 在标准测试图像上的实验结果表明，该方法在评估设置下始终优于现有方法，对高斯噪声、JPEG压缩和多种裁剪攻击具有更好的鲁棒性，同时保持完美的可逆性和高嵌入容量。与最先进的RRWEI方案相比，该框架在广泛的攻击场景下实现了显著更低的误码率和更稳定的性能。

Conclusion: 提出的框架通过双最高有效位平面嵌入与空间冗余和纠错编码的耦合，有效解决了鲁棒可逆加密图像水印中的关键挑战，在保持可逆性和高容量的同时显著提升了鲁棒性，为加密域中的鲁棒水印嵌入提供了新思路。

Abstract: Robust reversible watermarking in encrypted images (RRWEI) faces an inherent challenge in simultaneously achieving robustness, reversibility, and content privacy under severely constrained embedding capacity. Existing RRWEI schemes often exhibit limited robustness against noise, lossy compression, and cropping attacks due to insufficient redundancy in the encrypted domain. To address this challenge, this paper proposes a novel RRWEI framework that couples dual most significant bit-plane (dual-MSBs) embedding with spatial redundancy and error-correcting coding. By compressing prediction-error bit-planes, sufficient embedding space and auxiliary information for lossless reconstruction are reserved. The dual-MSBs are further reorganized using a spiral embedding strategy to distribute multiple redundant watermark copies across spatially dispersed regions, enhancing robustness against both noise and spatial loss.Experimental results on standard test images demonstrate that the proposed method consistently outperforms under evaluated settings robustness against Gaussian noise, JPEG compression, and diverse cropping attacks, while maintaining perfect reversibility and high embedding capacity. Compared with state-of-the-art RRWEI schemes, the proposed framework achieves substantially lower bit-error rates and more stable performance under a wide range of attack scenarios.

</details>


### [244] [HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation](https://arxiv.org/abs/2601.13864)
*Qirui Chen,Jingxian Shuai,Shuangwu Chen,Shenghao Ye,Zijian Wen,Xufei Su,Jie Jin,Jiangming Li,Jun Chen,Xiaobin Tan,Jian Yang*

Main category: cs.CR

TL;DR: HardSecBench：首个专注于硬件和固件代码安全性的LLM评估基准，包含924个任务，覆盖Verilog RTL和C语言，涉及76个硬件相关CWE漏洞类型。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM生成代码的功能正确性，而忽视了其安全性问题。功能正确的代码可能嵌入安全漏洞，部署后会造成灾难性后果。这一关键研究空白促使研究者设计一个基于现实规范的评估基准。

Method: 提出HardSecBench基准，包含924个任务，涵盖Verilog RTL和固件级C语言，涉及76个硬件相关CWE条目。每个任务包含结构化规范、安全参考实现和可执行测试。采用多智能体流水线，将合成与验证解耦，基于执行证据进行可靠评估。

Result: 评估多个LLM在硬件和固件代码生成任务上的表现，发现模型通常能满足功能需求但仍存在安全风险。安全结果随提示策略而变化，凸显了LLM辅助硬件设计面临的紧迫挑战。

Conclusion: HardSecBench填补了LLM生成硬件代码安全性评估的空白，揭示了现有模型在安全编码方面的不足，为未来LLM辅助硬件设计提供了可操作的见解和基准工具。

Abstract: Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon.

</details>


### [245] [Decentralized Infrastructure for Digital Notarizing, Signing and Sharing Files using Blockchain](https://arxiv.org/abs/2601.13907)
*Cosmin-Iulian Irimia*

Main category: cs.CR

TL;DR: 该研究提出基于区块链的去中心化数字公证、签名和共享文档基础设施，解决传统纸质和数字文档的安全、真实性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 传统纸质文档管理存在安全、真实性和效率挑战，即使数字化后，官方文档仍易受伪造、丢失和未授权访问的威胁。需要解决透明度、不可篡改性和可行性等关键问题。

Method: 定义系统需求，评估现有解决方案，提出基于分布式系统的新型架构，结合密码学技术和去中心化存储。

Result: 开发出更安全高效的官方文档管理框架，区块链数字公证能够简化官僚流程、降低安全风险、增强用户对数字文档管理的信任。

Conclusion: 基于区块链的数字公证具有显著潜力，能够为官方文档管理提供透明、不可篡改且可行的解决方案，推动更安全高效的文档管理框架发展。

Abstract: Traditional paper-based document management has long posed challenges related to security, authenticity, and efficiency. Despite advances in digitalization, official documents remain vulnerable to forgery, loss, and unauthorized access. This thesis proposes a decentralized infrastructure for digital notarization, signing, and sharing of documents using blockchain technology. The research addresses key issues of transparency, immutability, and feasibility by defining system requirements, evaluating existing solutions, and proposing a novel architecture based on distributed systems.
  By combining cryptographic techniques with decentralized storage, this research contributes to the development of a more secure and efficient framework for managing official documents. The findings highlight the potential of blockchain-based digital notarization to streamline bureaucratic processes, mitigate security risks, and enhance user trust in digital document management.

</details>


### [246] [VirtualCrime: Evaluating Criminal Potential of Large Language Models via Sandbox Simulation](https://arxiv.org/abs/2601.13981)
*Yilin Tang,Yu Wang,Lanlan Qiu,Wenchang Gao,Yunfei Ma,Baicheng Chen,Tianxing He*

Main category: cs.CR

TL;DR: VirtualCrime是一个基于三智能体系统的沙盒仿真框架，用于评估大型语言模型的犯罪能力，包含40个多样化犯罪任务，覆盖11个地图和13种犯罪目标。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在多步决策、规划和行动方面展现出强大能力，并越来越多地集成到各种现实应用中，需要评估其强大的问题解决能力是否可能被滥用于犯罪目的。

Method: 提出VirtualCrime框架，包含三个智能体：攻击者智能体（犯罪团队领导者）、法官智能体（确定每个行动结果）、世界管理器智能体（更新环境状态和实体）。设计了40个多样化犯罪任务，覆盖11个地图和13种犯罪目标，并引入人类玩家基线作为参考。

Result: 评估了8个强大的LLM，发现：(1)所有智能体在仿真环境中都能合规地生成详细计划并执行智能犯罪过程，部分模型达到相对较高的成功率；(2)在某些情况下，智能体为达成目标会采取对NPC造成严重伤害的行动。

Conclusion: 这项工作强调了在现实世界环境中部署智能AI时进行安全对齐的必要性，揭示了当前LLM在犯罪能力方面的潜在风险。

Abstract: Large language models (LLMs) have shown strong capabilities in multi-step decision-making, planning and actions, and are increasingly integrated into various real-world applications. It is concerning whether their strong problem-solving abilities may be misused for crimes. To address this gap, we propose VirtualCrime, a sandbox simulation framework based on a three-agent system to evaluate the criminal capabilities of models. Specifically, this framework consists of an attacker agent acting as the leader of a criminal team, a judge agent determining the outcome of each action, and a world manager agent updating the environment state and entities. Furthermore, we design 40 diverse crime tasks within this framework, covering 11 maps and 13 crime objectives such as theft, robbery, kidnapping, and riot. We also introduce a human player baseline for reference to better interpret the performance of LLM agents. We evaluate 8 strong LLMs and find (1) All agents in the simulation environment compliantly generate detailed plans and execute intelligent crime processes, with some achieving relatively high success rates; (2) In some cases, agents take severe action that inflicts harm to NPCs to achieve their goals. Our work highlights the need for safety alignment when deploying agentic AI in real-world settings.

</details>


### [247] [A Security Framework for Chemical Functions](https://arxiv.org/abs/2601.14019)
*Frederik Walter,Hrishi Narayanan,Jessica Bariffi,Anne Lüscher,Rawad Bitar,Robert Grass,Antonia Wachter-Zeh,Zohar Yakhini*

Main category: cs.CR

TL;DR: 提出化学函数框架，将化学系统建模为噪声挑战-响应原语，形式化相关基础设施，基于物理函数理论定义鲁棒性、不可克隆性和不可预测性，并用DNA构造实例化。


<details>
  <summary>Details</summary>
Motivation: 为化学系统提供统一的安全框架，将化学系统建模为噪声挑战-响应原语，建立形式化的化学函数基础设施，解决化学认证机制的设计问题。

Method: 基于物理函数理论，在有限和渐近两种机制下严格定义化学函数的鲁棒性、不可克隆性和不可预测性；制定安全游戏捕捉对手能力和安全目标；用两种现有DNA构造（可操作随机DNA和基因组序列加密）实例化框架；开发最大似然验证规则处理测序噪声和部分编辑模型；基于二项分布提供高精度估计指导参数选择。

Result: 建立了可复现的化学不可克隆认证机制设计方法；推导了鲁棒性、不可克隆性和不可预测性的定量界限；展示了在产品内认证和共享密钥生成（使用标准提取技术）中的应用。

Conclusion: 化学函数框架为设计化学不可克隆认证机制提供了系统方法，通过形式化定义、安全分析和具体实例，建立了化学安全系统的理论基础和实践指导。

Abstract: In this paper, we introduce chemical functions, a unified framework that models chemical systems as noisy challenge--response primitives, and formalize the associated chemical function infrastructure. Building on the theory of physical functions, we rigorously define robustness, unclonability, and unpredictability for chemical functions in both finite and asymptotic regimes, and specify security games that capture the adversary's power and the security goals. We instantiate the framework with two existing DNA-based constructions (operable random DNA and Genomic Sequence Encryption) and derive quantitative bounds for robustness, unclonability, and unpredictability. Our analysis develops maximum-likelihood verification rules under sequencing noise and partial-edit models, and provides high-precision estimates based on binomial distributions to guide parameter selection. The framework, definitions, and analyses yield a reproducible methodology for designing chemically unclonable authentication mechanisms. We demonstrate applications to in-product authentication and to shared key generation using standard extraction techniques.

</details>


### [248] [SecureSplit: Mitigating Backdoor Attacks in Split Learning](https://arxiv.org/abs/2601.14054)
*Zhihao Dou,Dongfei Cui,Weida Wang,Anjun Gao,Yueyang Quan,Mengyao Ma,Viet Vo,Guangdong Bai,Zhuqing Liu,Minghong Fang*

Main category: cs.CR

TL;DR: SecureSplit是一种针对分割学习中后门攻击的防御机制，通过维度变换增强良性嵌入与中毒嵌入的差异，并采用自适应过滤方法移除污染嵌入


<details>
  <summary>Details</summary>
Motivation: 分割学习虽然保护了数据隐私，但容易受到后门攻击，恶意客户端可以通过修改嵌入来植入隐藏触发器，从而破坏最终训练模型的安全性

Method: SecureSplit采用维度变换策略来放大良性嵌入与中毒嵌入之间的细微差异，然后基于多数投票的自适应过滤方法移除污染嵌入，同时保留干净的嵌入

Result: 在四个数据集（CIFAR-10、MNIST、CINIC-10、ImageNette）、五种后门攻击场景和七种替代防御方法的严格实验中，SecureSplit在各种挑战性条件下都表现出有效性

Conclusion: SecureSplit为分割学习提供了一种有效的后门攻击防御机制，通过增强嵌入差异和自适应过滤，能够在保护隐私的同时确保模型安全性

Abstract: Split Learning (SL) offers a framework for collaborative model training that respects data privacy by allowing participants to share the same dataset while maintaining distinct feature sets. However, SL is susceptible to backdoor attacks, in which malicious clients subtly alter their embeddings to insert hidden triggers that compromise the final trained model. To address this vulnerability, we introduce SecureSplit, a defense mechanism tailored to SL. SecureSplit applies a dimensionality transformation strategy to accentuate subtle differences between benign and poisoned embeddings, facilitating their separation. With this enhanced distinction, we develop an adaptive filtering approach that uses a majority-based voting scheme to remove contaminated embeddings while preserving clean ones. Rigorous experiments across four datasets (CIFAR-10, MNIST, CINIC-10, and ImageNette), five backdoor attack scenarios, and seven alternative defenses confirm the effectiveness of SecureSplit under various challenging conditions.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [249] [Approximate full conformal prediction in RKHS](https://arxiv.org/abs/2601.13102)
*Davidson Lova Razafindrakoto,Alain Celisse,Jérôme Lacaille*

Main category: stat.ML

TL;DR: 提出一种高效计算全共形预测置信区域的紧近似方法，并引入厚度概念量化近似误差


<details>
  <summary>Details</summary>
Motivation: 全共形预测框架虽然能构建分布无关的置信预测区域，但传统方法需要训练无限多个估计器，计算上不可行

Method: 设计通用策略构建全共形预测区域的紧近似，可高效计算；引入厚度概念量化近似区域与全共形区域的差异，分析依赖于损失函数和评分函数的平滑性假设

Result: 开发了近似置信区域的理论紧密度量化方法，厚度概念能够精确衡量近似误差

Conclusion: 提出的方法解决了全共形预测计算不可行的问题，通过紧近似和厚度量化实现了高效且理论保证的置信区域计算

Abstract: Full conformal prediction is a framework that implicitly formulates distribution-free confidence prediction regions for a wide range of estimators. However, a classical limitation of the full conformal framework is the computation of the confidence prediction regions, which is usually impossible since it requires training infinitely many estimators (for real-valued prediction for instance). The main purpose of the present work is to describe a generic strategy for designing a tight approximation to the full conformal prediction region that can be efficiently computed. Along with this approximate confidence region, a theoretical quantification of the tightness of this approximation is developed, depending on the smoothness assumptions on the loss and score functions. The new notion of thickness is introduced for quantifying the discrepancy between the approximate confidence region and the full conformal one.

</details>


### [250] [Distribution-Free Confidence Ellipsoids for Ridge Regression with PAC Bounds](https://arxiv.org/abs/2601.13436)
*Szabolcs Szentpéteri,Balázs Csanád Csáji*

Main category: stat.ML

TL;DR: 本文扩展了SPS EOA算法到岭回归，推导了置信椭球尺寸的PAC上界，并分析了正则化参数对区域大小的影响。


<details>
  <summary>Details</summary>
Motivation: 线性参数化模型在控制和信号处理中广泛应用，最小二乘估计是典型解决方案。但当输入激励不足时，LS问题可能无解或数值不稳定。正则化（特别是岭回归）可以解决此问题，但需要量化估计不确定性。现有SPS EOA算法只能用于线性回归，需要扩展到岭回归。

Method: 扩展SPS EOA算法到岭回归，推导置信椭球尺寸的PAC（概率近似正确）上界。分析正则化参数对区域大小的影响，在更弱的激励假设下提供更紧的边界。

Result: 成功将SPS EOA算法扩展到岭回归，推导出置信椭球尺寸的PAC上界。相比先前分析，结果明确展示了正则化参数如何影响区域大小，在更弱的激励假设下提供了更紧的边界。仿真实验验证了正则化的实际效果。

Conclusion: 本文提出的方法成功将SPS EOA算法扩展到岭回归，提供了置信椭球尺寸的理论边界，明确揭示了正则化参数对不确定性的影响，为岭回归估计的不确定性量化提供了有效工具。

Abstract: Linearly parametrized models are widely used in control and signal processing, with the least-squares (LS) estimate being the archetypical solution. When the input is insufficiently exciting, the LS problem may be unsolvable or numerically unstable. This issue can be resolved through regularization, typically with ridge regression. Although regularized estimators reduce the variance error, it remains important to quantify their estimation uncertainty. A possible approach for linear regression is to construct confidence ellipsoids with the Sign-Perturbed Sums (SPS) ellipsoidal outer approximation (EOA) algorithm. The SPS EOA builds non-asymptotic confidence ellipsoids under the assumption that the noises are independent and symmetric about zero. This paper introduces an extension of the SPS EOA algorithm to ridge regression, and derives probably approximately correct (PAC) upper bounds for the resulting region sizes. Compared with previous analyses, our result explicitly show how the regularization parameter affects the region sizes, and provide tighter bounds under weaker excitation assumptions. Finally, the practical effect of regularization is also demonstrated via simulation experiments.

</details>


### [251] [Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs](https://arxiv.org/abs/2601.13458)
*Zihan Dong,Ruijia Wu,Linjun Zhang*

Main category: stat.ML

TL;DR: 提出PCAL方法，通过半参数推断框架优化标注预算分配，在固定预算下平衡真实标签和成对偏好的标注，实现统计高效的学习。


<details>
  <summary>Details</summary>
Motivation: AI生成伪标签越来越依赖人类偏好反馈，需要原则性的、预算敏感的数据采集策略。核心问题是如何在固定标注预算下，最优分配真实标签和成对偏好的标注资源。

Method: 基于半参数推断，将预算分配问题建模为单调缺失数据框架。提出偏好校准主动学习（PCAL），学习最优数据采集策略，并开发统计高效的估计器用于数据分布泛函估计。

Result: 理论上证明了PCAL估计器的渐近最优性，并建立了鲁棒性保证，即使在辅助模型估计不佳时也能保持稳健性能。模拟和真实数据分析展示了方法的实际优势和优越性能。

Conclusion: 为现代AI中的预算约束学习提供了原则性、统计高效的方法框架，可直接优化估计器方差而不需要闭式解，适用于广泛问题类别。

Abstract: The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. We address the crucial question of how to optimally allocate a fixed annotation budget between ground-truth labels and pairwise preferences in AI. Our solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. Building on this formulation, we introduce Preference-Calibrated Active Learning (PCAL), a novel method that learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretically, we prove the asymptotic optimality of our PCAL estimator and establish a key robustness guarantee that ensures robust performance even with poorly estimated nuisance models. Our flexible framework applies to a general class of problems, by directly optimizing the estimator's variance instead of requiring a closed-form solution. This work provides a principled and statistically efficient approach for budget-constrained learning in modern AI. Simulations and real-data analysis demonstrate the practical benefits and superior performance of our proposed method.

</details>


### [252] [On the Provable Suboptimality of Momentum SGD in Nonstationary Stochastic Optimization](https://arxiv.org/abs/2601.12238)
*Sharan Sahu,Cameron J. Hogan,Martin T. Wells*

Main category: stat.ML

TL;DR: 动量优化方法在动态非平稳环境中存在性能权衡：动量能抑制梯度噪声但会放大漂移引起的跟踪误差，当动量参数趋近1时，跟踪误差可能无限放大


<details>
  <summary>Details</summary>
Motivation: 动量加速方法在确定性优化问题中已被广泛研究，但在数据分布和最优参数随时间漂移的非平稳环境中，其行为仍未被充分探索。需要分析SGD及其动量变体在动态环境中的跟踪性能

Method: 在均匀强凸性和光滑性假设下，分析SGD及其动量变体（Polyak重球法和Nesterov法）在不同步长机制下的跟踪性能。推导跟踪误差的有限时间边界（期望和高概率），建立包含初始化瞬态项、噪声诱导方差项和漂移诱导跟踪滞后项的三分量分解

Result: 揭示了动量优化的基本权衡：动量能抑制梯度噪声，但会显著放大漂移引起的跟踪误差，当动量参数趋近1时，放大效应可能无限增大。建立了梯度变化约束下动态遗憾的最小最大下界，证明惯性引起的性能下降不是分析假象，而是信息理论障碍

Conclusion: 动量在动态环境中存在固有的"惯性窗口"，会从根本上降低性能。这些结果为动量在动态环境中的经验不稳定性提供了明确的理论基础，并划定了SGD可证明优于其加速对应方法的精确机制边界

Abstract: While momentum-based acceleration has been studied extensively in deterministic optimization problems, its behavior in nonstationary environments -- where the data distribution and optimal parameters drift over time -- remains underexplored. We analyze the tracking performance of Stochastic Gradient Descent (SGD) and its momentum variants (Polyak heavy-ball and Nesterov) under uniform strong convexity and smoothness in varying stepsize regimes. We derive finite-time bounds in expectation and with high probability for the tracking error, establishing a sharp decomposition into three components: a transient initialization term, a noise-induced variance term, and a drift-induced tracking lag. Crucially, our analysis uncovers a fundamental trade-off: while momentum can suppress gradient noise, it incurs an explicit penalty on the tracking capability. We show that momentum can substantially amplify drift-induced tracking error, with amplification that becomes unbounded as the momentum parameter approaches one, formalizing the intuition that using 'stale' gradients hinders adaptation to rapid regime shifts. Complementing these upper bounds, we establish minimax lower bounds for dynamic regret under gradient-variation constraints. These lower bounds prove that the inertia-induced penalty is not an artifact of analysis but an information-theoretic barrier: in drift-dominated regimes, momentum creates an unavoidable 'inertia window' that fundamentally degrades performance. Collectively, these results provide a definitive theoretical grounding for the empirical instability of momentum in dynamic environments and delineate the precise regime boundaries where SGD provably outperforms its accelerated counterparts.

</details>


### [253] [Empirical Risk Minimization with $f$-Divergence Regularization](https://arxiv.org/abs/2601.13191)
*Francisco Daunas,Iñaki Esnaola,Samir M. Perlaza,H. Vincent Poor*

Main category: stat.ML

TL;DR: 本文提出了经验风险最小化与f-散度正则化问题的解决方案，建立了正则化问题与约束问题的等价条件，引入归一化函数概念并给出数值算法，分析了不同f-散度之间的结构等价性。


<details>
  <summary>Details</summary>
Motivation: 解决经验风险最小化与f-散度正则化问题，扩展适用f-散度类别，建立正则化与约束问题的理论联系，为实际计算提供有效算法。

Method: 提出归一化函数概念，建立其非线性常微分方程表示，证明关键性质并构造数值近似算法；分析不同f-散度通过经验风险变换的结构等价性。

Result: 建立了ERM-fDR解与约束问题解的等价条件，扩展了适用f-散度类别；给出了归一化函数的数值算法；证明了不同f-散度问题的结构等价性；通过数值实验展示了不同f函数选择对训练和测试风险的影响。

Conclusion: 本文系统解决了ERM-fDR问题，建立了理论框架和计算工具，归一化函数是连接对偶形式和实际计算的关键，不同f-散度选择具有实际影响，为f-散度正则化提供了完整解决方案。

Abstract: In this paper, the solution to the empirical risk minimization problem with $f$-divergence regularization (ERM-$f$DR) is presented and conditions under which the solution also serves as the solution to the minimization of the expected empirical risk subject to an $f$-divergence constraint are established. The proposed approach extends applicability to a broader class of $f$-divergences than previously reported and yields theoretical results that recover previously known results. Additionally, the difference between the expected empirical risk of the ERM-$f$DR solution and that of its reference measure is characterized, providing insights into previously studied cases of $f$-divergences. A central contribution is the introduction of the normalization function, a mathematical object that is critical in both the dual formulation and practical computation of the ERM-$f$DR solution. This work presents an implicit characterization of the normalization function as a nonlinear ordinary differential equation (ODE), establishes its key properties, and subsequently leverages them to construct a numerical algorithm for approximating the normalization factor under mild assumptions. Further analysis demonstrates structural equivalences between ERM-$f$DR problems with different $f$-divergences via transformations of the empirical risk. Finally, the proposed algorithm is used to compute the training and test risks of ERM-$f$DR solutions under different $f$-divergence regularizers. This numerical example highlights the practical implications of choosing different functions $f$ in ERM-$f$DR problems.

</details>


### [254] [Small Gradient Norm Regret for Online Convex Optimization](https://arxiv.org/abs/2601.13519)
*Wenzhi Gao,Chang He,Madeleine Udell*

Main category: stat.ML

TL;DR: 提出了一种新的在线凸优化问题依赖后悔度量G*后悔，它基于累积平方梯度范数，比现有的L*（小损失）后悔更精细，在损失函数在最优解附近曲率消失时显著更优。


<details>
  <summary>Details</summary>
Motivation: 现有在线凸优化中的问题依赖后悔度量（如L*后悔）在某些情况下不够精细，特别是当损失函数在最优解附近曲率消失时。需要一种更精确的后悔度量来更好地衡量算法性能。

Method: 引入新的G*后悔度量，定义为∑‖∇ℓ(x*)‖²，即累积平方梯度范数在事后最优解处的评估。建立G*后悔的上界和下界，并将结果扩展到动态后悔和老虎机设置。

Result: 证明G*后悔严格细化了现有的L*后悔，当损失函数在最优解附近曲率消失时，G*后悔可以任意更尖锐。建立了G*后悔的理论界限，并改进了插值机制下随机优化算法的收敛分析。

Conclusion: G*后悔为在线凸优化提供了一种更精细的问题依赖后悔度量，特别适用于损失函数在最优解附近曲率消失的情况，为算法性能评估提供了更准确的工具。

Abstract: This paper introduces a new problem-dependent regret measure for online convex optimization with smooth losses. The notion, which we call the $G^\star$ regret, depends on the cumulative squared gradient norm evaluated at the decision in hindsight $\sum_{t=1}^T \|\nabla \ell(x^\star)\|^2$. We show that the $G^\star$ regret strictly refines the existing $L^\star$ (small loss) regret, and that it can be arbitrarily sharper when the losses have vanishing curvature around the hindsight decision. We establish upper and lower bounds on the $G^\star$ regret and extend our results to dynamic regret and bandit settings. As a byproduct, we refine the existing convergence analysis of stochastic optimization algorithms in the interpolation regime. Some experiments validate our theoretical findings.

</details>


### [255] [Sample Complexity of Average-Reward Q-Learning: From Single-agent to Federated Reinforcement Learning](https://arxiv.org/abs/2601.13642)
*Yuchen Jiao,Jiin Woo,Gen Li,Gauri Joshi,Yuejie Chi*

Main category: stat.ML

TL;DR: 该论文提出了针对平均奖励MDP的Q学习算法，在单智能体和联邦学习场景下均提供了理论保证，显著改进了样本复杂度并首次实现了联邦Q学习。


<details>
  <summary>Details</summary>
Motivation: 平均奖励强化学习为长期决策提供了原则性框架，但Q学习在平均奖励MDP中的理论保证有限。现有研究缺乏对平均奖励MDP的Q学习样本复杂度分析，特别是在联邦学习场景下。

Method: 提出了一种简单但有效的Q学习算法，适用于有限状态和动作空间的弱通信平均奖励MDP。在单智能体场景下，通过精心选择参数实现优化；在联邦场景下，设计多智能体协作算法，减少每个智能体的样本需求。

Result: 单智能体样本复杂度为$\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{\varepsilon^3}\right)$，相比先前结果至少改进$\frac{\|h^{\star}\|_{\mathsf{sp}}^2}{\varepsilon^2}$倍。联邦场景下每个智能体样本复杂度降至$\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{M\varepsilon^3}\right)$，仅需$\widetilde{O}\left(\frac{\|h^{\star}\|_{\mathsf{sp}}}{\varepsilon}\right)$轮通信。

Conclusion: 该工作首次建立了平均奖励MDP的联邦Q学习算法，在样本复杂度和通信复杂度方面均具有可证明的效率，为长期决策的强化学习提供了理论基础。

Abstract: Average-reward reinforcement learning offers a principled framework for long-term decision-making by maximizing the mean reward per time step. Although Q-learning is a widely used model-free algorithm with established sample complexity in discounted and finite-horizon Markov decision processes (MDPs), its theoretical guarantees for average-reward settings remain limited. This work studies a simple but effective Q-learning algorithm for average-reward MDPs with finite state and action spaces under the weakly communicating assumption, covering both single-agent and federated scenarios. For the single-agent case, we show that Q-learning with carefully chosen parameters achieves sample complexity $\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{\varepsilon^3}\right)$, where $\|h^{\star}\|_{\mathsf{sp}}$ is the span norm of the bias function, improving previous results by at least a factor of $\frac{\|h^{\star}\|_{\mathsf{sp}}^2}{\varepsilon^2}$. In the federated setting with $M$ agents, we prove that collaboration reduces the per-agent sample complexity to $\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{M\varepsilon^3}\right)$, with only $\widetilde{O}\left(\frac{\|h^{\star}\|_{\mathsf{sp}}}{\varepsilon}\right)$ communication rounds required. These results establish the first federated Q-learning algorithm for average-reward MDPs, with provable efficiency in both sample and communication complexity.

</details>


### [256] [Unified Unbiased Variance Estimation for MMD: Robust Finite-Sample Performance with Imbalanced Data and Exact Acceleration under Null and Alternative Hypotheses](https://arxiv.org/abs/2601.13874)
*Shijie Zhong,Jiangfeng Fu,Yikun Yang*

Main category: stat.ML

TL;DR: 本文研究了最大均值差异（MMD）统计量的方差特性，建立了统一的有界样本方差表征方法，并提出了一种在拉普拉斯核下的精确加速算法，将计算复杂度从O(n²)降低到O(n log n)。


<details>
  <summary>Details</summary>
Motivation: MMD是基于核的非参数双样本检验统计量，其推断准确性严重依赖于方差表征。现有研究提供了多种MMD方差的有限样本估计器，但这些方法在零假设和备择假设下、以及在平衡或不平衡采样方案中往往存在差异，缺乏统一的理论框架。

Method: 通过MMD统计量的U统计量表示和Hoeffding分解来研究其方差特性，建立了覆盖不同假设和样本配置的统一有限样本表征。在此基础上，针对单变量情况和拉普拉斯核，提出了一种精确加速方法。

Result: 建立了统一的MMD方差有限样本表征理论框架，能够处理不同假设和样本配置。提出的加速算法将单变量拉普拉斯核下的计算复杂度从O(n²)显著降低到O(n log n)。

Conclusion: 本文为MMD方差分析提供了统一的理论基础，并通过精确加速方法提高了计算效率，为大规模双样本检验的实际应用提供了理论支持和算法优化。

Abstract: The maximum mean discrepancy (MMD) is a kernel-based nonparametric statistic for two-sample testing, whose inferential accuracy depends critically on variance characterization. Existing work provides various finite-sample estimators of the MMD variance, often differing under the null and alternative hypotheses and across balanced or imbalanced sampling schemes. In this paper, we study the variance of the MMD statistic through its U-statistic representation and Hoeffding decomposition, and establish a unified finite-sample characterization covering different hypotheses and sample configurations. Building on this analysis, we propose an exact acceleration method for the univariate case under the Laplacian kernel, which reduces the overall computational complexity from $\mathcal O(n^2)$ to $\mathcal O(n \log n)$.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [257] [Stability and Accuracy Trade-offs in Statistical Estimation](https://arxiv.org/abs/2601.11701)
*Abhinav Chakraborty,Yuetian Luo,Rina Foygel Barber*

Main category: math.ST

TL;DR: 本文从统计决策理论视角研究算法稳定性与估计精度之间的权衡关系，建立了稳定性约束下的估计精度下界，并针对四个典型估计问题开发了最优稳定估计器。


<details>
  <summary>Details</summary>
Motivation: 算法稳定性是统计和学习理论中的核心概念，衡量算法输出对训练数据微小变化的敏感性。虽然稳定性带来良好的泛化性、鲁棒性和可复现性，但单纯稳定性不足以保证统计学习效果，甚至可能与准确性相冲突（如恒定输出函数完全稳定但统计无意义）。因此需要量化稳定性的统计代价。

Method: 采用统计决策理论视角，将稳定性作为估计的约束条件。聚焦于最坏情况稳定性和平均情况稳定性两种代表性概念：首先建立每种稳定性约束下可达到估计精度的一般下界；然后针对四个典型估计问题（包括均值估计和回归设置）开发最优稳定估计器。

Result: 建立了稳定性与准确性之间的最优权衡关系。形式化了平均情况稳定性比最坏情况稳定性限制更弱的直觉，并揭示这两种稳定性之间的差距在不同估计问题中存在显著差异。

Conclusion: 通过统计决策理论框架系统分析了算法稳定性的统计代价，为理解稳定性与准确性之间的基本权衡提供了理论依据，并展示了不同稳定性概念对估计性能的差异化影响。

Abstract: Algorithmic stability is a central concept in statistics and learning theory that measures how sensitive an algorithm's output is to small changes in the training data. Stability plays a crucial role in understanding generalization, robustness, and replicability, and a variety of stability notions have been proposed in different learning settings. However, while stability entails desirable properties, it is typically not sufficient on its own for statistical learning -- and indeed, it may be at odds with accuracy, since an algorithm that always outputs a constant function is perfectly stable but statistically meaningless. Thus, it is essential to understand the potential statistical cost of stability. In this work, we address this question by adopting a statistical decision-theoretic perspective, treating stability as a constraint in estimation. Focusing on two representative notions-worst-case stability and average-case stability-we first establish general lower bounds on the achievable estimation accuracy under each type of stability constraint. We then develop optimal stable estimators for four canonical estimation problems, including several mean estimation and regression settings. Together, these results characterize the optimal trade-offs between stability and accuracy across these tasks. Our findings formalize the intuition that average-case stability imposes a qualitatively weaker restriction than worst-case stability, and they further reveal that the gap between these two can vary substantially across different estimation problems.

</details>


### [258] [Expansion and Bounds for the Bias of Empirical Tail Value-at-Risk](https://arxiv.org/abs/2601.12064)
*Nadezhda Gribkova,Jianxi Su,Mengqi Wang*

Main category: math.ST

TL;DR: 本文深入分析了经验TVaR估计量的偏差问题，推导了偏差的主导项近似和显式上界，揭示了偏差的分布特性和结构决定因素。


<details>
  <summary>Details</summary>
Motivation: TVaR是保险领域广泛采用的风险度量指标，经验TVaR因其简单性和非参数特性常被用于数据应用。然而，已有文献指出经验TVaR估计量存在负偏差，可能导致有限样本应用中系统性低估风险。本文旨在从偏差幅度及其关键分布和结构决定因素两个维度深化对经验TVaR估计量偏差的理解。

Method: 基于渐近展开推导了偏差的主导项近似，获得封闭形式的表达式以分析经验TVaR估计量偏差的结构特性。为进一步考虑主导项近似与真实偏差之间的差异，推导了偏差的显式上界。通过模拟验证了所提出的偏差分析框架，并使用真实数据展示了其实际相关性。

Result: 获得了经验TVaR估计量偏差的主导项近似表达式，能够解析地洞察偏差的结构特性。推导了偏差的显式上界，为偏差分析提供了更全面的框架。模拟验证和真实数据应用证实了所提框架的有效性和实际意义。

Conclusion: 本文深化了对经验TVaR估计量偏差的理解，提供了分析偏差幅度及其决定因素的理论框架。所推导的主导项近似和显式上界为评估和校正经验TVaR估计量的偏差提供了实用工具，有助于避免在风险管理和监管应用中系统性低估风险。

Abstract: Tail Value-at-Risk (TVaR) is a widely adopted risk measure playing a critically important role in both academic research and industry practice in insurance. In data applications, TVaR is often estimated using the empirical method, owing to its simplicity and nonparametric nature. The empirical TVaR has been explicitly advocated by regulatory authorities as a standard approach for computing TVaR. However, prior literature has pointed out that the empirical TVaR estimator is negatively biased, which can lead to a systemic underestimation of risk in finite-sample applications. This paper aims to deepen the understanding of the bias of the empirical TVaR estimator in two dimensions: its magnitude as well as the key distributional and structural determinants driving the severity of the bias. To this end, we derive a leading-term approximation for the bias based on its asymptotic expansion. The closed-form expression associated with the leading-term approximation enables us to obtain analytical insights into the structural properties governing the bias of the empirical TVaR estimator. To account for the discrepancy between the leading-term approximation and the true bias, we further derive an explicit upper bound for the bias. We validate the proposed bias analysis framework via simulations and demonstrate its practical relevance using real data.

</details>


### [259] [Random tree Besov priors: Data-driven regularisation parameter selection](https://arxiv.org/abs/2601.12957)
*Hanne Kekkonen,Andreas Tataris*

Main category: math.ST

TL;DR: 提出一种数据驱动的算法，用于在随机树Besov先验下的贝叶斯反演中自动选择正则化参数。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯反演中的关键挑战是构建既具有表达力又计算可行的先验。随机树Besov先验虽然提供了捕捉小波基中局部正则性和稀疏模式的灵活框架，但需要数据驱动的方法来自适应选择正则化参数。

Method: 引入分层模型，实现小波密度参数的数据驱动选择，使正则化强度能够跨尺度自适应调整，同时保持计算效率。重点研究非参数回归，并展示了去卷积问题的初步即插即用结果。

Result: 扩展了随机树Besov先验框架，实现了正则化参数的自适应数据驱动选择，在保持计算效率的同时提高了模型的灵活性。

Conclusion: 提出的分层模型成功解决了随机树Besov先验中正则化参数选择的问题，为贝叶斯反演提供了更灵活且计算高效的数据驱动方法，在非参数回归和去卷积问题中展示了应用潜力。

Abstract: We develop a data-driven algorithm for automatically selecting the regularisation parameter in Bayesian inversion under random tree Besov priors. One of the key challenges in Bayesian inversion is the construction of priors that are both expressive and computationally feasible. Random tree Besov priors, introduced in Kekkonen et al. (2023), provide a flexible framework for capturing local regularity properties and sparsity patterns in a wavelet basis. In this paper, we extend this approach by introducing a hierarchical model that enables data-driven selection of the wavelet density parameter, allowing the regularisation strength to adapt across scales while retaining computational efficiency. We focus on nonparametric regression and also present preliminary plug-and-play results for a deconvolution problem.

</details>


### [260] [Inverting the Fisher information operator in non-linear models](https://arxiv.org/abs/2601.13254)
*Dimitri Konen*

Main category: math.ST

TL;DR: 论文研究了非线性回归模型在噪声污染下的统计推断问题，证明了当模型得分函数具有单射性时，Fisher信息算子在特定希尔伯特空间可逆，并建立了信息下界的最优性理论。


<details>
  <summary>Details</summary>
Motivation: 研究非线性PDE反问题和数据同化中非线性回归模型的统计推断问题，这些模型通常受到一般性噪声污染。需要建立通用的理论框架来推导信息下界并证明贝叶斯方法的最优性。

Method: 通过分析模型得分函数的单射性，证明Fisher信息算子在特定希尔伯特空间的可逆性，并给出这些空间的操作性刻画。基于此构造高效高斯过程，应用经典极小极大和卷积定理建立信息下界。

Result: 证明了当得分函数单射时，Fisher信息算子自动可逆，并给出了相关希尔伯特空间的明确刻画。建立了通用的信息下界理论，表明贝叶斯算法通常能达到这些下界，从而证明其最优性。

Conclusion: 为非线性回归模型提供了一般性的统计推断理论框架，特别适用于非线性PDE反问题和数据同化。理论表明在得分函数单射条件下，贝叶斯方法在统计意义上是最优的，并在反应-扩散和Navier-Stokes方程等时间演化PDE模型中得到了验证。

Abstract: We consider non-linear regression models corrupted by generic noise when the regression functions form a non-linear subspace of L^2, relevant in non-linear PDE inverse problems and data assimilation. We show that when the score of the model is injective, the Fisher information operator is automatically invertible between well-identified Hilbert spaces, and we provide an operational characterization of these spaces. This allows us to construct in broad generality the efficient Gaussian involved in the classical minimax and convolution theorems to establish information lower bounds, that are typically achieved by Bayesian algorithms thus showing optimality of these methods. We illustrate our results on time-evolution PDE models for reaction-diffusion and Navier-Stokes equations.

</details>


### [261] [Moving Least Squares without Quasi-Uniformity: A Stochastic Approach](https://arxiv.org/abs/2601.13782)
*Shir Tapiro-Moshe,Yariv Aizenbud,Barak Sober*

Main category: math.ST

TL;DR: 该论文首次为移动最小二乘法（MLS）提供了统一的随机分析，证明了尽管确定性采样假设在随机采样下失效，但经典的收敛性和光滑性特性在自然概率模型下仍然保持。


<details>
  <summary>Details</summary>
Motivation: 局部多项式回归（LPR）和移动最小二乘法（MLS）是统计学和逼近论中独立发展的两种密切相关的非参数估计方法。统计LPR分析侧重于在概率假设下克服采样噪声，而确定性MLS理论则研究关于填充距离的光滑性性质和收敛速率。然而，MLS的确定性假设在随机采样下不成立，因此需要建立MLS的随机分析框架。

Method: 首先量化独立同分布随机样本的填充距离h_n和分离度δ_n的概率行为，证明对于满足温和正则条件的分布，h_n∝n^{-1/d}log^{1/d}(n)，δ_n∝n^{-1/d}。然后证明对于k-1阶MLS，与阶数|m|≤k-1的微分算子Q相关的逼近误差以h_n^{k-|m|}衰减（忽略对数因子），建立了经典MLS估计的随机类比。此外，证明MLS逼近器以高概率光滑。最后将随机MLS理论应用于流形估计。

Result: 证明了在随机采样下，MLS逼近误差以h_n^{k-|m|}的速率衰减（忽略对数因子），MLS逼近器以高概率光滑。对于k次光滑的采样流形，真实流形与其MLS重建之间的Hausdorff距离以h_n^k的速率衰减，将确定性流形-MLS保证扩展到随机样本。

Conclusion: 该工作首次为MLS提供了统一的随机分析，证明了尽管确定性采样假设失效，但经典的收敛性和光滑性特性在自然概率模型下仍然保持。这为MLS在随机采样场景下的应用提供了理论保证，并将确定性流形估计结果扩展到随机样本。

Abstract: Local Polynomial Regression (LPR) and Moving Least Squares (MLS) are closely related nonparametric estimation methods, developed independently in statistics and approximation theory. While statistical LPR analysis focuses on overcoming sampling noise under probabilistic assumptions, the deterministic MLS theory studies smoothness properties and convergence rates with respect to the \textit{fill-distance} (a resolution parameter). Despite this similarity, the deterministic assumptions underlying MLS fail to hold under random sampling. We begin by quantifying the probabilistic behavior of the fill-distance $h_n$ and \textit{separation} $δ_n$ of an i.i.d. random sample. That is, for a distribution satisfying a mild regularity condition, $h_n\propto n^{-1/d}\log^{1/d} (n)$ and $δ_n \propto n^{-1/d}$. We then prove that, for MLS of degree $k\!-\!1$, the approximation error associated with a differential operator $Q$ of order $|m|\le k-1$ decays as $h_n^{\,k-|m|}$ up to logarithmic factors, establishing stochastic analogues of the classical MLS estimates. Additionally, We show that the MLS approximant is smooth with high probability. Finally, we apply the stochastic MLS theory to manifold estimation. Assuming that the sampled Manifold is $k$-times smooth, we show that the Hausdorff distance between the true manifold and its MLS reconstruction decays as $h_n^k$, extending the deterministic Manifold-MLS guarantees to random samples. This work provides the first unified stochastic analysis of MLS, demonstrating that -- despite the failure of deterministic sampling assumptions -- the classical convergence and smoothness properties persist under natural probabilistic models

</details>


### [262] [On spectral clustering under non-isotropic Gaussian mixture models](https://arxiv.org/abs/2601.13930)
*Kohei Kawamoto,Yuichi Goto,Koji Tsukuda*

Main category: math.ST

TL;DR: 评估高斯混合模型下谱聚类算法的误聚类概率，该算法基于第一主成分得分的符号将数据分为两组，并在高维情况下证明了聚类一致性


<details>
  <summary>Details</summary>
Motivation: 研究谱聚类算法在高斯混合模型下的理论性能，特别是误聚类概率的理论界限，为高维数据聚类提供理论保证

Method: 基于高斯混合模型，采用谱聚类算法，通过计算数据的第一主成分得分，根据得分的正负号将数据划分为两个簇

Result: 推导了误聚类概率的理论界限，并作为主要结果的推论，证明了在高维情况下该聚类过程具有一致性

Conclusion: 谱聚类算法在高斯混合模型下具有理论保证，特别是在高维情况下能够实现一致的聚类效果

Abstract: We evaluate the misclustering probability of a spectral clustering algorithm under a Gaussian mixture model with a general covariance structure. The algorithm partitions the data into two groups based on the sign of the first principal component score. As a corollary of the main result, the clustering procedure is shown to be consistent in a high-dimensional regime.

</details>


### [263] [Topological Criteria for Hypothesis Testing with Finite-Precision Measurements](https://arxiv.org/abs/2601.13946)
*Philip Boeken,Eduardo Skapinakis,Konstantin Genin,Joris M. Mooij*

Main category: math.ST

TL;DR: 该论文建立了在有限精度观测下统计假设一致性检验的拓扑充分必要条件，发现假设对可一致检验当且仅当在弱拓扑下是Fσ集，并应用于条件独立性检验问题。


<details>
  <summary>Details</summary>
Motivation: 研究在有限精度观测条件下统计假设检验的理论基础，特别是当观测数据只能以有限精度记录时，需要决策区域在样本空间拓扑中为开集。这促使研究者探索在何种拓扑条件下假设对能够被一致地区分。

Method: 采用拓扑学方法，在概率测度空间的弱拓扑框架下分析假设检验问题。要求检验的决策区域在样本空间拓扑中为开集以适应有限精度数据，然后推导出假设对可一致检验的拓扑特征。

Result: 主要结果：1) 零假设H0和备择假设H1可一致检验当且仅当它们在弱拓扑下是Fσ集；2) 在H0和/或H1下具有一致误差控制当且仅当相应的假设在W中是闭集；3) 在紧性假设下，一致一致性由H0和H1在概率测度空间中具有不相交闭包来刻画；4) 这些准则表明，在没有正则性假设下，条件独立性不可一致检验；5) 引入条件分布族的Lipschitz连续性假设后，可在零假设下恢复条件独立性的可检验性。

Conclusion: 论文建立了有限精度观测下假设检验的完整拓扑理论框架，揭示了可检验性与假设集的拓扑性质之间的深刻联系。特别地，条件独立性的可检验性需要额外的正则性假设，这为实际统计检验提供了理论指导。

Abstract: We establish topological necessary and sufficient conditions under which a pair of statistical hypotheses can be consistently distinguished when i.i.d. observations are recorded only to finite precision. Requiring the test's decision regions to be open in the sample-space topology to accommodate finite-precision data, we show that a pair of null- and alternative hypotheses $H_0$ and $H_1$ admits a consistent test if and only if they are $F_σ$ in the weak topology on the space of probability measures $W := H_0\cup H_1$. Additionally, the hypotheses admit uniform error control under $H_0$ and/or $H_1$ if and only if $H_0$ and/or $H_1$ are closed in $W$. Under compactness assumptions, uniform consistency is characterised by $H_0$ and $H_1$ having disjoint closures in the ambient space of probability measures. These criteria imply that - without regularity assumptions - conditional independence is not consistently testable. We introduce a Lipschitz-continuity assumption on the family of conditional distributions under which we recover testability of conditional independence with uniform error control under the null, with testable smoothness constraints.

</details>


### [264] [Uniform Consistency of Generalized Cross-Validation for Ridge Regression in High-Dimensional Misspecified Linear Models](https://arxiv.org/abs/2601.13955)
*Akira Shinkyu*

Main category: math.ST

TL;DR: 研究高维误设线性模型中岭回归调参的广义交叉验证方法，证明即使存在模型误设，GCV仍能一致估计样本外预测风险，从而选择出渐近最优的调参值。


<details>
  <summary>Details</summary>
Motivation: 在现实高维线性回归问题中，模型往往存在误设（misspecification），而传统的调参方法如广义交叉验证（GCV）在误设情况下的理论性质尚不明确。本研究旨在探讨在包含零和负值的调参候选集中，GCV在误设模型中的一致性和有效性。

Method: 采用理论分析和模拟研究相结合的方法。理论上，在误设线性模型框架下，证明当误设误差的二阶矩收敛于零时，GCV是样本外预测风险的一致估计量。调参候选集包含正数、零和负值。通过模拟研究比较GCV调参的岭回归与最优调参岭回归、Lasso在不同模型设定下的预测性能。

Result: 理论证明：若误设误差的二阶矩收敛于零，GCV是预测风险的一致估计量，因此能选择出使岭回归渐近达到最小预测风险的调参值。模拟结果显示：GCV调参的岭回归预测性能接近最优调参岭回归，且在正确和错误模型设定下均优于Lasso。

Conclusion: 广义交叉验证在高维误设线性模型中具有理论保证，能够有效选择岭回归的调参值，实现接近最优的预测性能，且优于Lasso方法。这为实际应用中存在模型误设时的调参选择提供了理论依据。

Abstract: This study examines generalized cross-validation for the tuning parameter selection for ridge regression in high-dimensional misspecified linear models. The set of candidates for the tuning parameter includes not only positive values but also zero and negative values. We demonstrate that if the second moment of the specification error converges to zero, generalized cross-validation is still a uniformly consistent estimator of the out-of-sample prediction risk. This implies that generalized cross-validation selects the tuning parameter for which ridge regression asymptotically achieves the smallest prediction risk among the candidates if the degree of misspecification for the regression function is small. Our simulation studies show that ridge regression tuned by generalized cross-validation exhibits a prediction performance similar to that of optimally tuned ridge regression and outperforms the Lasso under correct and incorrect model specifications.

</details>


### [265] [Robustness for free: asymptotic size and power of max-tests in high dimensions](https://arxiv.org/abs/2601.14013)
*Anders Bredahl Kock,David Preinerstorfer*

Main category: math.ST

TL;DR: 论文提出基于缩尾均值的稳健最大检验方法，解决了高维数据下传统基于算术均值的最大检验面临的维度增长限制问题，在保持相同渐近功效的同时，允许维度以指数速率增长。


<details>
  <summary>Details</summary>
Motivation: 传统基于算术均值的最大检验在高维设置下面临维度增长限制：当数据只有m>2阶矩时，高斯近似要求d=o(n^{m/2-1})，这限制了检验在维度指数增长情况下的渐近有效性。需要开发能在高维和对抗性污染下保持渐近性质的稳健检验方法。

Method: 提出基于缩尾均值的稳健最大检验方法。使用缩尾均值替代算术均值来构建检验统计量，通过适当的缩尾处理控制极端值影响。该方法允许数据存在对抗性污染，且维度可以指数速率增长。同时研究了数据驱动（自助法）临界值在提升渐近功效方面的作用。

Result: 稳健最大检验在维度以指数速率增长时仍保持正确的渐近水平，即使数据存在对抗性污染。渐近功效分析表明，该方法在传统检验假设满足时具有相同的渐近功效。自助法临界值在某些情况下能严格提升渐近功效，但并非在所有情况下都有效。

Conclusion: 基于缩尾均值的稳健最大检验解决了高维数据下传统检验的维度限制问题，在保持相同渐近功效的同时，允许维度指数增长和对抗性污染。该方法为高维假设检验提供了更稳健的框架，自助法临界值的选择需要根据具体情况谨慎考虑。

Abstract: Consider testing a zero restriction on the mean of a $d$-dimensional random vector based on an i.i.d. sample of size $n$. Suppose further that the coordinates are only assumed to possess $m>2$ moments. Then, max-tests based on arithmetic means and critical values derived from Gaussian approximations are not guaranteed to be asymptotically valid unless $d$ is relatively small compared to $n$, because said approximation faces a polynomial growth barrier of $d=o(n^{m/2-1})$.
  We propose a max-test based on winsorized means, and show that it holds the desired asymptotic size even when $d$ grows at an exponential rate in $n$ and the data are adversarially contaminated. Our characterization of its asymptotic power function shows that these benefits do not come at the cost of reduced asymptotic power: the robustified max-test has identical asymptotic power to that based on arithmetic means whenever the stronger assumptions underlying the latter are satisfied.
  We also investigate when -- and when not -- data-driven (bootstrap) critical values can strictly increase asymptotic power of the robustified max-test.

</details>


### [266] [Symmetry Testing in Time Series using Ordinal Patterns: A U-Statistic Approach](https://arxiv.org/abs/2601.14223)
*Annika Betken,Giorgio Micali,Manuel Ruiz Marín*

Main category: math.ST

TL;DR: 提出基于序数模式分布的通用时间序列时间对称性检验框架，统一处理任意对称性检验，建立渐近理论，实验验证高敏感性和计算效率


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注特定形式的不对称性（如时间反转），缺乏通用的时间对称性检验框架，需要一种统一、数据驱动且计算高效的方法来检测时间序列中的各种结构不对称性

Method: 基于序数模式分布构建时间对称性检验框架，适用于任意对称性检验，建立平稳过程下的检验统计量渐近理论，实现完全数据驱动和计算高效的检验方法

Result: 在合成和真实数据上的综合实验表明，所提检验方法对结构不对称性具有高敏感性，同时保持完全数据驱动和计算高效的特点

Conclusion: 该框架为时间序列时间对称性检验提供了统一的理论基础和实践工具，能够有效检测各种结构不对称性，具有理论保证和实际应用价值

Abstract: We introduce a general framework for testing temporal symmetries in time series based on the distribution of ordinal patterns. While previous approaches have focused on specific forms of asymmetry, such as time reversal, our method provides a unified framework applicable to arbitrary symmetry tests. We establish asymptotic results for the resulting test statistics under a broad class of stationary processes. Comprehensive experiments on both synthetic and real data demonstrate that the proposed test achieves high sensitivity to structural asymmetries while remaining fully data-driven and computationally efficient.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [267] [AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control](https://arxiv.org/abs/2601.11568)
*Quang-Hung Bui,Anh Son Ta*

Main category: cs.LG

TL;DR: AdaFRUGAL：一种自适应梯度分割框架，通过动态调整子空间比例和更新频率，自动优化大语言模型训练的内存和计算开销，相比静态FRUGAL无需手动调参。


<details>
  <summary>Details</summary>
Motivation: 大语言模型训练内存需求高，现有FRUGAL框架的静态超参数（子空间比例ρ和更新频率T）需要昂贵的手动调优，限制了其适应性和实用性。

Method: 提出AdaFRUGAL框架，引入两种动态控制机制：(1) 子空间比例ρ的线性衰减策略，逐步减少内存占用；(2) 基于损失感知的更新频率T调度策略，降低计算开销。

Result: 在英语C4、越南语VietVault的大规模预训练和GLUE微调实验中，AdaFRUGAL在保持与AdamW和静态FRUGAL相当性能的同时，显著减少了GPU内存占用和训练时间。

Conclusion: AdaFRUGAL实现了内存、计算和性能之间的平衡，为资源受限的大语言模型训练提供了更实用、自主的解决方案。

Abstract: Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($ρ$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $ρ$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.

</details>


### [268] [Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces](https://arxiv.org/abs/2601.11572)
*Timo Aukusti Laine*

Main category: cs.LG

TL;DR: 使用量子力学启发的数学工具（线性代数、哈密顿形式）分析LLM嵌入空间结构，发现L2归一化约束使嵌入空间适合哈密顿分析，推导了余弦相似度与向量扰动的关系，探索了语义转换和量子类比。


<details>
  <summary>Details</summary>
Motivation: 观察到LLM嵌入表现出离散语义状态，表明存在结构化语义表示，需要数学工具来分析这些语义关系。受到量子力学系统类比的启发，探索应用线性代数和哈密顿形式来理解LLM嵌入空间的结构。

Method: 应用线性代数和哈密顿形式分析LLM嵌入空间，特别关注L2归一化约束的结构化效应。推导余弦相似度与嵌入向量扰动之间的数学关系，探索直接和间接语义转换。采用量子启发的视角，推导零点能量类比并讨论与Koopman-von Neumann力学的潜在联系。

Result: L2归一化约束使LLM嵌入空间具有适合哈密顿形式分析的结构。建立了余弦相似度与向量扰动的数学关系，能够分析语义转换。量子类比提供了对嵌入空间的新视角，包括零点能量类比。

Conclusion: 这种方法为深入理解LLM提供了有前景的途径，可能为减轻幻觉提供新方法。虽然解释需要谨慎，但数学框架显示出分析LLM语义表示的潜力。

Abstract: We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.

</details>


### [269] [GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment](https://arxiv.org/abs/2601.11574)
*Lukas Abrie Nel*

Main category: cs.LG

TL;DR: GRADE提出了一种基于Gumbel-softmax松弛的LLM对齐方法，通过可微分的token采样过程直接反向传播，避免了PPO等高方差策略梯度方法的问题。


<details>
  <summary>Details</summary>
Motivation: 基于人类反馈的强化学习（RLHF）已成为对齐大语言模型的主流方法，但PPO等策略梯度方法存在梯度估计方差高、需要精细超参数调优和大量计算资源的问题。

Method: GRADE使用Gumbel-Softmax重参数化配合直通估计（GRADE-STE），通过离散token采样过程的可微分松弛实现端到端梯度流动，从奖励信号通过生成token直接传播到模型参数。

Result: 在IMDB数据集的情感控制文本生成任务中，GRADE-STE测试奖励达到0.763±0.344，优于PPO的0.510±0.313和REINFORCE的0.617±0.378，相对PPO提升50%。梯度方差比REINFORCE低14倍以上，训练动态稳定。

Conclusion: GRADE为LLM对齐提供了一个更简单、更稳定、更有效的替代强化学习的方法，在保持训练稳定性的同时显著提升了性能。

Abstract: Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.

</details>


### [270] [Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.11604)
*Jonaid Shianifar,Michael Schukat,Karl Mason*

Main category: cs.LG

TL;DR: Hindsight Preference Replay (HPR) 是一种简单的回放增强策略，通过为存储的转移数据重新标记替代偏好，在不改变CAPQL架构或损失函数的情况下，增加了跨偏好单纯形的监督密度，在多目标强化学习任务中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: CAPQL方法在优化向量化奖励时，仅使用特定偏好下收集的数据，而忽略了其他偏好的离线数据。这导致数据利用效率低下，限制了跨偏好空间的学习效果。

Method: 提出Hindsight Preference Replay (HPR)策略，对存储的转移数据进行重新标记，赋予其替代偏好。该方法保持CAPQL的actor-critic架构和损失函数不变，仅通过回放缓冲区的数据增强来增加跨偏好单纯形的监督密度。

Result: 在六个MO-Gymnasium运动任务中，使用固定300000步预算评估，HPR-CAPQL在五个环境中提升了超体积(HV)，在四个环境中提升了期望效用(EUM)。例如在mo-humanoid-v5中，EUM从323±125提升到1613±464，HV从0.52M提升到9.63M，统计显著性支持。mo-halfcheetah-v5是例外，CAPQL在可比EUM下获得更高HV。

Conclusion: HPR是一种简单有效的回放增强策略，能够显著提升多目标强化学习算法的性能，通过重新标记历史数据来增加跨偏好空间的监督密度，而无需修改底层算法架构。

Abstract: Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\!\pm\!125$ to $1613\!\pm\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.

</details>


### [271] [A Multimodal Data Processing Pipeline for MIMIC-IV Dataset](https://arxiv.org/abs/2601.11606)
*Farzana Islam Adiba,Varsha Danduri,Fahmida Liza Piya,Ali Abbasi,Mehak Gupta,Rahmatollah Beheshti*

Main category: cs.LG

TL;DR: 开发了一个全面的多模态MIMIC-IV数据处理管道，可自动化处理结构化数据、临床记录、波形和影像数据，显著减少处理时间并提高研究可重复性。


<details>
  <summary>Details</summary>
Motivation: MIMIC-IV数据集包含多种模态的临床数据，但现有处理管道要么只针对少数模态，要么不支持任意的下游应用，需要大量手动预处理和对齐工作。

Method: 扩展了先前的单模态管道，开发了一个可定制的多模态管道，系统整合所有模态，支持自动化队列选择、跨模态时间对齐，并提供标准化的多模态输出格式。

Result: 发布了完整的代码、简单UI和Python包，支持选择性集成（包括嵌入），显著减少了多模态数据处理时间，增强了基于MIMIC研究的可重复性。

Conclusion: 该多模态管道为MIMIC-IV数据集提供了一个全面、可定制的处理解决方案，能够支持任意的静态和时间序列下游应用，促进临床机器学习研究。

Abstract: The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.

</details>


### [272] [Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction](https://arxiv.org/abs/2601.11609)
*Weinuo Ou*

Main category: cs.LG

TL;DR: 提出ApCM模型，一种神经记忆存储架构，解决LLMs缺乏有效运行时记忆机制的问题


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型普遍缺乏有效的运行时记忆机制，难以适应动态和个性化的交互需求

Method: 提出辅助预测压缩记忆模型（ApCM模型），一种新颖的神经记忆存储架构

Result: 从摘要中无法获取具体实验结果信息

Conclusion: ApCM模型旨在解决LLMs在动态个性化交互中的记忆机制不足问题

Abstract: Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).

</details>


### [273] [Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home](https://arxiv.org/abs/2601.11611)
*Marina Vicini,Martin Rudorfer,Zhuangzhuang Dai,Luis J. Manso*

Main category: cs.LG

TL;DR: 该论文提出了一种改进的基于被动传感器的人类活动识别方法，通过时间聚类和循环时间特征增强来提升老年人智能家居监控的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，需要让老年人能够在家庭中独立安全地生活。使用被动红外传感器和门传感器等普遍存在的传感器来监测日常活动并促进预防性医疗干预变得越来越重要。然而，现有的人类活动识别方法在有效利用时间信息方面存在挑战。

Method: 1. 将活动按时间聚类为早晨、下午和夜晚，并为每个时间段计算不同的互信息矩阵进行特征加权；2. 在特征向量中加入了时间（一天中的时间和一周中的天）作为循环时间特征；3. 添加了用户位置跟踪特征；4. 扩展了传感器加权互信息方法以更好地利用时空信息。

Result: 在四个真实世界数据集中的三个上，该方法相比现有最先进方法提高了准确率和F1分数，在数据量较少的情况下提升最为显著。

Conclusion: 该方法展示了开发有效智能家居解决方案以支持老年人居家养老的潜力，通过更好地整合时间和空间信息来改进人类活动识别性能。

Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.

</details>


### [274] [A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia](https://arxiv.org/abs/2601.11615)
*Beyza Cinar,Louisa van den Boom,Maria Maleshkova*

Main category: cs.LG

TL;DR: 综述分析了基于连续血糖监测数据的机器学习模型在预测1型糖尿病患者低血糖方面的研究现状，比较了不同预测时间窗口和模型类型的性能表现。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病患者需要终身胰岛素治疗，但胰岛素治疗有导致低血糖的副作用。低血糖（血糖低于70 mg/dL）是危及生命的状态，与死亡率增加相关。机器学习模型可以通过预测低血糖并提供最佳预防方法来改善糖尿病管理。

Method: 本文是综述研究，调查了基于1型糖尿病患者连续血糖监测数据训练的最新机器学习模型。比较了回归模型（预测血糖水平）和分类模型（基于定义标签识别事件）在不同预测时间窗口（短期15-120分钟，长期3-24小时以上）的性能表现。特别探讨了四个关键问题：预测提前时间、最佳模型、影响因素以及个性化对性能的影响。

Result: 研究结果表明：1）最多1小时的预测时间窗口提供最佳结果；2）传统机器学习方法在分类任务中表现最佳，深度学习在回归任务中表现最佳，单一模型无法在多个预测时间窗口上充分分类；3）模型性能受多变量数据集和输入序列长度的影响；4）个性化数据能提高性能，但由于数据质量有限，基于人群的模型更受青睐。

Conclusion: 机器学习模型在预测1型糖尿病患者低血糖方面具有潜力，但存在预测时间窗口限制、模型选择依赖任务类型、数据质量和个性化挑战等问题。未来研究需要解决这些限制，以开发更有效的临床决策支持系统。

Abstract: Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.

</details>


### [275] [Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective](https://arxiv.org/abs/2601.11616)
*Feilong Liu*

Main category: cs.LG

TL;DR: MoE架构通过路由机制将表示空间软划分为重叠的局部区域，降低局部敏感度并重新分配表示方差，形成专家特定的低重叠子空间分解。


<details>
  <summary>Details</summary>
Motivation: 研究MoE架构对学习函数和表示几何性质的影响，理解路由机制如何作为表示空间的软划分方式，以及这种划分如何影响局部敏感度和表示结构。

Method: 引入双雅可比-PCA谱几何探针，通过雅可比奇异值谱分析局部函数几何，通过加权PCA分析路由隐藏状态的表示几何。在可控的MLP-MoE设置中比较密集、Top-k和完全软路由架构，分析路由锐度如何调节几何效应。

Result: MoE路由一致降低局部敏感度，专家局部雅可比矩阵显示更小的主导奇异值和更快的谱衰减。加权PCA显示专家局部表示在更多主方向上分布方差，表明在相同输入分布下具有更高的有效秩。平均专家雅可比矩阵几乎正交，表明变换分解为低重叠的专家特定子空间而非共享映射的缩放变体。

Conclusion: MoE可以几何解释为函数空间的软划分，这种划分在平坦化局部曲率的同时重新分配表示方差。Top-k路由产生更低秩、更集中的专家局部结构，而完全软路由产生更广泛、更高秩的表示。

Abstract: Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.

</details>


### [276] [Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention](https://arxiv.org/abs/2601.11618)
*Luis Rosario Freytes*

Main category: cs.LG

TL;DR: 几何注意力（GA）通过四个独立输入定义注意力层：有限载体、证据核规则、探针族和锚点/更新规则，将不变结构与建模选择分离，为注意力机制提供统一理论框架。


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制（如Transformer中的softmax）缺乏统一的理论框架，难以进行系统比较和扩展。本文旨在建立几何注意力理论，将注意力机制分解为不变结构和可配置组件，实现注意力机制的模块化设计和理论分析。

Method: 提出几何注意力（GA）框架，通过四个组件定义注意力层：1）有限载体（可寻址索引集）；2）证据核规则（掩码原始分数与链接产生非负权重）；3）探针族（可观测量的容许集）；4）锚点/更新规则（核代表选择和更新方式）。探针族诱导核上的操作等价关系和规范，锚点相对于探针选择代表。在标量关系工作表示和证据乘法组合律下，容许链接族为指数族，产生Gibbs权重；行锚点包含softmax核族作为子机制。通过商化一元行/列分数场，剩余交互分量具有规范秩r正规形式（Eckart-Young/SVD）；点积分数图实现相应的低秩交互机制。

Result: 几何注意力框架能够：1）统一描述标准Transformer注意力（固定载体和扩展更新）；2）支持自适应载体和分层深度机制；3）实现多头/混合核、基于规划的锚点（如熵最优传输/Sinkhorn）和一元算子（如FFN式场）作为显式机制选择；4）将不变结构与建模选择分离，为注意力机制提供模块化设计和理论分析基础。

Conclusion: 几何注意力提供了注意力机制的通用理论框架，将结构不变性与建模选择解耦，支持注意力机制的系统比较、扩展和设计。该框架能够统一现有注意力变体，并为新型注意力架构的开发提供理论基础。

Abstract: Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.

</details>


### [277] [NoiseFormer -- Noise Diffused Symmetric Attention Transformer](https://arxiv.org/abs/2601.11619)
*Phani Kumar,Nyshadham,Jyothendra Varma,Polisetty V R K,Aditya Rathore*

Main category: cs.LG

TL;DR: 提出了一种名为噪声扩散对称注意力Transformer的新型统一模型架构，在保持对称注意力内存优势的同时，通过微小参数和计算开销提升模型性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型随着规模增大面临内存占用和计算成本问题，稀疏注意力技术成为解决方案。本文旨在分析对称点积注意力技术并提出改进方案。

Method: 提出噪声扩散对称注意力Transformer架构，在保持对称注意力内存优势的基础上，通过引入微小参数和计算开销来增强模型性能。

Result: 在GPT2基础模型上验证，在多种GLUE基准任务中，性能介于普通对称注意力和GPT2基础模型之间，同时实现了显著的模型大小缩减。

Conclusion: 噪声扩散对称注意力Transformer在保持内存效率的同时，通过微小开销实现了性能提升，为大规模语言模型的高效部署提供了可行方案。

Abstract: Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.

</details>


### [278] [Verifying Physics-Informed Neural Network Fidelity using Classical Fisher Information from Differentiable Dynamical System](https://arxiv.org/abs/2601.11638)
*Josafat Ribeiro Leal Filho,Antônio Augusto Fröhlich*

Main category: cs.LG

TL;DR: 该论文提出使用Fisher信息$g_F^C$作为评估PINNs学习物理系统动力学完整性的新框架，通过比较PINN学习模型与原始解析模型的Fisher信息景观来量化PINN的保真度。


<details>
  <summary>Details</summary>
Motivation: 当前PINNs在解决微分方程和建模物理系统方面表现出色，但缺乏严格量化PINN是否完整捕获系统动力学行为（超越简单轨迹预测）的方法。需要一种能够评估PINN是否准确学习系统底层动力学、几何特性和稳定性的评估框架。

Method: 提出使用针对可微动力系统的Fisher信息$g_F^C$作为评估指标。该Fisher信息测量确定性系统中的固有不确定性（如对初始条件的敏感性），与相空间曲率和状态空间演化的净拉伸作用相关。通过计算PINN学习模型和原始解析模型的Jacobian矩阵，比较两者的Fisher信息景观来量化PINN的保真度。使用汽车动力学模型作为实验案例。

Result: 论文提出了完整的实验方法学框架，但具体实验结果未在摘要中提供。该框架能够通过比较Fisher信息景观来定量评估PINN是否准确捕获了系统的复杂动力学特性，包括几何特性和稳定性。

Conclusion: 提出的基于Fisher信息$g_F^C$的评估框架为PINNs的动力学保真度评估提供了新的定量方法。如果PINN学习模型的Fisher信息景观与原始解析模型匹配，则表明PINN不仅准确预测状态演化，还完整捕获了系统的几何和稳定性特性，实现了全面的动力学保真度。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving differential equations and modeling physical systems by embedding physical laws into the learning process. However, rigorously quantifying how well a PINN captures the complete dynamical behavior of the system, beyond simple trajectory prediction, remains a challenge. This paper proposes a novel experimental framework to address this by employing Fisher information for differentiable dynamical systems, denoted $g_F^C$. This Fisher information, distinct from its statistical counterpart, measures inherent uncertainties in deterministic systems, such as sensitivity to initial conditions, and is related to the phase space curvature and the net stretching action of the state space evolution. We hypothesize that if a PINN accurately learns the underlying dynamics of a physical system, then the Fisher information landscape derived from the PINN's learned equations of motion will closely match that of the original analytical model. This match would signify that the PINN has achieved comprehensive fidelity capturing not only the state evolution but also crucial geometric and stability properties. We outline an experimental methodology using the dynamical model of a car to compute and compare $g_F^C$ for both the analytical model and a trained PINN. The comparison, based on the Jacobians of the respective system dynamics, provides a quantitative measure of the PINN's fidelity in representing the system's intricate dynamical characteristics.

</details>


### [279] [Global Optimization By Gradient from Hierarchical Score-Matching Spaces](https://arxiv.org/abs/2601.11639)
*Ming Li*

Main category: cs.LG

TL;DR: 提出一种通过分数匹配获取梯度，将带复杂约束的优化问题统一为无约束分层优化目标的方法，首次实现了基于严格梯度的确定性全局优化


<details>
  <summary>Details</summary>
Motivation: 传统梯度下降方法存在局部最优性限制，仅适用于连续可微问题和平凡凸约束，无法处理复杂约束的全局优化问题

Method: 将各种复杂约束的优化问题统一为无约束的分层优化目标，通过分数匹配技术获取梯度，实现确定性全局优化

Result: 首次实现了基于严格梯度的确定性全局优化方法，在简单构造和复杂实际实验中验证了有效性，揭示了全局优化与基于扩散的生成建模之间的深刻联系

Conclusion: 该方法突破了传统梯度下降的局限性，为处理复杂约束优化问题提供了新范式，建立了优化理论与生成建模之间的理论桥梁

Abstract: Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.

</details>


### [280] [Activation Sensitivity as a Unifying Principle for Post-Training Quantization](https://arxiv.org/abs/2601.11663)
*Bruce Changlong Xu*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的理论框架，将激活感知方法（如AWQ）和二阶方法（如GPTQ）解释为对激活敏感性的不同近似，为理解后训练量化方法提供了概念基础。


<details>
  <summary>Details</summary>
Motivation: 当前后训练量化方法依赖于启发式方法，但缺乏统一的理论框架。激活感知方法（如AWQ）和二阶方法（如GPTQ）虽然表现良好，但概念上分散，不清楚它们近似的是什么底层量。

Method: 通过一阶泰勒展开形式化激活敏感性，定义为通道扰动对损失的期望影响。敏感性自然表现为梯度加权激活的平方范数，提供了一个捕获激活幅度和下游误差传播的原则性通道重要性度量。

Result: 在该框架下，AWQ和GPTQ可以被解释为在简化假设下恢复敏感性的互补近似。分析了敏感性度量的设计空间，连接了基于梯度的显著性、Fisher信息和基于Hessian的准则，并阐明了它们与经典剪枝方法的关系。

Conclusion: 该工作为通过敏感性视角理解和比较后训练量化方法提供了概念基础，而不是提出新的量化算法。统一框架有助于理解现有方法的理论基础和设计更有效的量化策略。

Abstract: Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.

</details>


### [281] [IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning](https://arxiv.org/abs/2601.11669)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Xiaofeng Yang,Qingchao Jiang,Xuefeng Yan*

Main category: cs.LG

TL;DR: IPEC是一种测试时增量原型增强方法，通过动态构建辅助集利用历史查询样本信息，提升小样本分类的原型估计质量


<details>
  <summary>Details</summary>
Motivation: 传统度量学习小样本方法基于测试时批次独立性假设，无法利用历史批次积累的宝贵知识，限制了原型估计的准确性和稳定性

Method: 提出IPEC方法：1) 构建动态辅助集，选择性纳入高置信度查询样本；2) 设计双重过滤机制，基于全局预测置信度和局部判别能力评估样本质量；3) 将辅助集与支持集聚合构建更稳定的原型；4) 基于贝叶斯解释，将支持集视为先验，辅助集视为数据驱动的后验；5) 设计"预热-测试"两阶段推理协议

Result: 在多个小样本分类任务上验证了方法的优越性能，有效减少了对初始支持集的依赖，构建了更稳定、更具代表性的原型

Conclusion: IPEC通过测试时增量学习机制，打破了批次独立性假设的限制，显著提升了小样本分类性能，为度量学习方法提供了新的测试时优化思路

Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.

</details>


### [282] [Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis](https://arxiv.org/abs/2601.11686)
*Nicolas Caron,Christophe Guyeux,Hassan Noura,Benjamin Aynes*

Main category: cs.LG

TL;DR: 提出结合预测模型与大语言模型的混合框架，将多维度野火风险分析转化为结构化可操作报告


<details>
  <summary>Details</summary>
Motivation: 当前野火风险评估方法忽视实际运营需求，缺乏对第一响应者和消防服务的实用价值，需要能捕捉气象危险、点火活动、干预复杂性和资源动员等多维度的综合分析方法

Method: 开发混合框架，结合各风险维度的预测模型与大型语言模型，将异质输出合成为结构化、可操作报告

Result: 概念验证阶段，提出框架设计但尚未实施验证

Conclusion: 多目标分析和LLM集成能提升野火风险评估的实用性和操作性，为应急响应提供更有效的决策支持

Abstract: Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.

</details>


### [283] [jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation](https://arxiv.org/abs/2601.11719)
*Ho Fung Tsoi,Dylan Rankin*

Main category: cs.LG

TL;DR: jBOT是一种基于自蒸馏的预训练方法，专门用于CERN大型强子对撞机的喷注数据，通过结合局部粒子级蒸馏和全局喷注级蒸馏来学习支持异常检测和分类等下游任务的喷注表示。


<details>
  <summary>Details</summary>
Motivation: 自监督学习是一种无需标签即可学习特征表示的强大预训练方法，这些表示通常能捕捉数据的通用底层语义，并可在后续微调用于下游任务。本研究旨在开发专门用于高能物理喷注数据的预训练方法。

Method: 提出jBOT预训练方法，基于自蒸馏技术，结合局部粒子级蒸馏和全局喷注级蒸馏来学习喷注表示。该方法在未标记的喷注数据上进行预训练，使表示空间中出现语义类别聚类。

Result: 在仅使用背景喷注预训练的冻结嵌入中，聚类现象使得基于简单距离度量的异常检测成为可能。学习到的嵌入经过微调后用于分类任务，相比从头训练的监督模型表现出更好的性能。

Conclusion: jBOT方法成功地将自监督学习应用于高能物理喷注数据，通过自蒸馏预训练获得的表示既支持异常检测，又能通过微调提升分类性能，为粒子物理数据分析提供了有效的表示学习框架。

Abstract: Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.

</details>


### [284] [Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis](https://arxiv.org/abs/2601.11789)
*Shenyang Deng,Boyao Liao,Zhuoli Ouyang,Tianyu Pang,Minhak Song,Yaoqing Yang*

Main category: cs.LG

TL;DR: 该论文分析了SGD在病态优化中的"可疑对齐"现象，揭示了梯度与主导子空间对齐的动态变化规律及其与步长的关系。


<details>
  <summary>Details</summary>
Motivation: 研究SGD在病态优化中出现的"可疑对齐"现象，即梯度与Hessian主导子空间的对齐行为呈现先下降、后上升、最终稳定的三阶段模式，且这种高度对齐反而无法有效降低损失。

Method: 在高维二次设置中进行细粒度分析，提出步长选择理论，包括自适应临界步长η_t^*的概念，区分对齐下降和对齐上升的步长区间，并分析不同子空间投影对损失的影响。

Result: 1. 在低对齐区域，自适应临界步长η_t^*区分对齐下降(η_t < η_t^*)和对齐上升(η_t > η_t^*)的步长区间；2. 在高对齐区域，对齐具有自校正特性，无论步长如何都会下降；3. 在充分病态条件下，存在步长区间使得将SGD更新投影到批量子空间能降低损失，而投影到主导子空间反而增加损失；4. 对于恒定步长和大初始化，SGD表现出明显的两阶段行为：初始对齐下降阶段，随后稳定在高对齐状态。

Conclusion: 该研究为SGD在病态优化中的"可疑对齐"现象提供了理论解释，揭示了步长选择如何影响梯度对齐动态，并解释了为什么投影到主导子空间的梯度更新无效，为理解SGD在病态问题中的行为提供了新的理论框架。

Abstract: This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $η_t^*$ separates alignment-decreasing ($η_t < η_t^*$) from alignment-increasing ($η_t > η_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.

</details>


### [285] [Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing](https://arxiv.org/abs/2601.11794)
*Abdelrahman Ramadan,Zahra Dorbeigi Namaghi,Emily Taylor,Lucas Edwards,Xan Giuliani,David S. McLagan,Sidney Givigi,Melissa Greeff*

Main category: cs.LG

TL;DR: PC²DAE：一种物理约束去噪自编码器，通过架构嵌入物理约束解决无人机传感器数据稀缺问题，实现零物理违规的高效去噪


<details>
  <summary>Details</summary>
Motivation: 无人机搭载低成本传感器进行野火监测时存在基线漂移、交叉敏感性和响应延迟等问题，传统深度学习方法需要大量数据但无人机飞行活动数据有限，需要解决数据稀缺下的物理约束去噪问题

Method: 提出PC²DAE物理约束去噪自编码器，通过softplus激活函数强制非负浓度估计，物理合理的时间平滑，架构包含黑碳、气体和CO₂传感器家族的分层解码器头，提供PC²DAE-Lean（21k参数）边缘部署和PC²DAE-Wide（204k参数）离线处理两个变体

Result: 在加拿大萨斯喀彻温省规定燃烧期间收集的7,894个同步1Hz样本（约2.2小时飞行数据）上评估，PC²DAE-Lean实现67.3%平滑度提升和90.7%高频噪声降低，零物理违规；五个基线方法产生15-23%负输出；精简变体优于宽变体（+5.6%平滑度），在消费硬件上训练时间小于65秒

Conclusion: PC²DAE通过架构嵌入物理约束而非损失函数惩罚，有效解决数据稀缺下的传感器去噪问题，精简架构配合强归纳偏置可防止过拟合，适合边缘部署的无人机野火监测应用

Abstract: Wildfire monitoring requires high-resolution atmospheric measurements, yet low-cost sensors on Unmanned Aerial Vehicles (UAVs) exhibit baseline drift, cross-sensitivity, and response lag that corrupt concentration estimates. Traditional deep learning denoising approaches demand large datasets impractical to obtain from limited UAV flight campaigns. We present PC$^2$DAE, a physics-informed denoising autoencoder that addresses data scarcity by embedding physical constraints directly into the network architecture. Non-negative concentration estimates are enforced via softplus activations and physically plausible temporal smoothing, ensuring outputs are physically admissible by construction rather than relying on loss function penalties. The architecture employs hierarchical decoder heads for Black Carbon, Gas, and CO$_2$ sensor families, with two variants: PC$^2$DAE-Lean (21k parameters) for edge deployment and PC$^2$DAE-Wide (204k parameters) for offline processing. We evaluate on 7,894 synchronized 1 Hz samples collected from UAV flights during prescribed burns in Saskatchewan, Canada (approximately 2.2 hours of flight data), two orders of magnitude below typical deep learning requirements. PC$^2$DAE-Lean achieves 67.3\% smoothness improvement and 90.7\% high-frequency noise reduction with zero physics violations. Five baselines (LSTM-AE, U-Net, Transformer, CBDAE, DeSpaWN) produce 15--23\% negative outputs. The lean variant outperforms wide (+5.6\% smoothness), suggesting reduced capacity with strong inductive bias prevents overfitting in data-scarce regimes. Training completes in under 65 seconds on consumer hardware.

</details>


### [286] [Shapelets-Enriched Selective Forecasting using Time Series Foundation Models](https://arxiv.org/abs/2601.11821)
*Shivani Tomar,Seshu Tirupathi,Elizabeth Daly,Ivana Dusparic*

Main category: cs.LG

TL;DR: 提出基于shapelet的选择性预测框架，识别时间序列关键区域，选择性丢弃不可靠预测，提升零样本和全样本微调模型的预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型在零样本预测任务中表现出色，但在某些关键数据区域的预测不可靠，限制了在实际应用中的可用性，特别是当数据呈现独特趋势时。

Method: 提出选择性预测框架，使用shapelet识别时间序列关键区域。通过目标域验证集上的平移不变字典学习学习shapelet，利用基于距离的相似性度量，选择性丢弃不可靠预测。

Result: 在多样化基准时间序列数据集上的实验表明，该方法使零样本模型整体误差平均降低22.17%，全样本微调模型降低22.62%。在某个数据集上，零样本和全样本微调模型分别比随机选择对应方法提升21.41%和21.43%。

Conclusion: 基于shapelet的选择性预测框架能有效识别不可靠预测区域，提升时间序列基础模型在实际应用中的可靠性，为用户提供更现实的模型能力评估。

Abstract: Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.

</details>


### [287] [MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization](https://arxiv.org/abs/2601.11827)
*Andrea Rubbi,Amir Akbarnejad,Mohammad Vali Sanian,Aryan Yazdan Parast,Hesam Asadollahzadeh,Arian Amani,Naveed Akhtar,Sarah Cooper,Andrew Bassett,Pietro Liò,Lassi Paavolainen,Sattar Vakili,Mo Lotfollahi*

Main category: cs.LG

TL;DR: MixFlow：一种用于描述符控制生成的混合条件流匹配框架，通过联合学习描述符条件基分布和流场，显著提升分布外泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有条件流基方法在分布偏移下泛化能力有限，难以在训练条件之外进行外推，这成为条件生成建模的核心挑战

Method: 提出MixFlow框架，通过最短路径流匹配联合学习描述符条件基分布和描述符条件流场，将基分布建模为可学习的描述符依赖混合分布

Result: 在单细胞转录组数据未见扰动预测和高内涵显微镜药物筛选等多个领域，MixFlow显著优于标准条件流匹配基线，实现更好的分布外泛化

Conclusion: MixFlow为跨异质领域实现鲁棒、可泛化、可控的生成建模提供了简单而强大的方法，解决了条件生成模型在分布偏移下的泛化难题

Abstract: Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.

</details>


### [288] [TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures](https://arxiv.org/abs/2601.11880)
*Yingxiao Zhang,Jiaxin Duan,Junfu Zhang,Ke Feng*

Main category: cs.LG

TL;DR: TF-CoDiT：首个用于语言控制国债期货合成的扩散Transformer框架，通过离散小波变换和U形VAE处理低数据量，引入FinMAP协议标准化市场描述，在国债期货数据合成上实现高保真度。


<details>
  <summary>Details</summary>
Motivation: 现有扩散Transformer在股票价格和订单流等金融时间序列数据合成上已取得进展，但针对国债期货数据的合成性能尚未充分探索。国债期货数据具有低交易量、市场依赖性强、多变量间存在分组相关性等独特特征，需要专门的方法来处理这些挑战。

Method: 提出TF-CoDiT框架：1）将多通道一维时间序列转换为离散小波变换系数矩阵以促进低数据学习；2）设计U形VAE分层编码跨通道依赖关系到潜在变量，并通过解码桥接潜在空间和DWT空间，实现潜在扩散生成；3）引入金融市场属性协议（FinMAP）作为多层次描述系统，从7/8个视角识别17/23个经济指标，标准化每日/周期性市场动态以生成提示词。

Result: 收集2015-2025年四种国债期货数据，定义从一周到四个月不同持续时间的合成任务。广泛评估显示TF-CoDiT能生成高度真实的数据，与真实数据的误差最多为MSE 0.433和MAE 0.453。进一步研究证明TF-CoDiT在不同合约和时间范围上具有鲁棒性。

Conclusion: TF-CoDiT是首个用于语言控制国债期货合成的扩散Transformer框架，成功解决了国债期货数据的低交易量、市场依赖和分组相关性等挑战，通过离散小波变换、U形VAE编码和FinMAP协议实现了高质量的数据合成，为金融时间序列合成领域提供了新方法。

Abstract: Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.

</details>


### [289] [Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach](https://arxiv.org/abs/2601.11883)
*Chaoqi Jia,Longkun Guo,Kewen Liao,Zhigang Lu,Chao Chen,Jason Xue*

Main category: cs.LG

TL;DR: 提出基于支配匹配集问题转换的新型局部搜索框架，解决带实例级约束的k-center聚类问题，获得最佳可能的2近似比


<details>
  <summary>Details</summary>
Motivation: 传统k-center问题已有最佳2近似比，但加入实例级约束（must-link和cannot-link）后，虽然不相交的cannot-link集允许常数因子近似，但局部搜索能否达到这种保证仍是开放问题

Method: 通过将约束k-center聚类问题转化为支配匹配集问题，提出新颖的局部搜索框架，实现最佳可能的2近似比

Result: 在真实世界和合成数据集上的实验结果表明，该算法在解质量上优于基线方法

Conclusion: 提出的局部搜索框架成功解决了约束k-center聚类问题，实现了理论上的最佳近似比，并在实验中表现出优越性能

Abstract: Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - ε would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.

</details>


### [290] [From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs](https://arxiv.org/abs/2601.11890)
*Xihe Gu,Urbashi Mitra,Tara Javidi*

Main category: cs.LG

TL;DR: 提出一个参数化的凹覆盖目标函数族U_ρ，用于指导无奖励MDP中的定向探索，统一了多种现有覆盖目标，并通过梯度算法实现主动的探索控制。


<details>
  <summary>Details</summary>
Motivation: 在无奖励马尔可夫决策过程中，不同状态-动作对具有不同的重要性或难度，需要主动、显式地构建探索策略。现有方法缺乏统一的框架来平衡探索的广度和深度。

Method: 提出参数化凹覆盖目标函数族U_ρ，定义在状态-动作占用度量上。该族统一了基于散度的边际匹配、加权平均覆盖和最坏情况覆盖等目标。利用U_ρ的凹性和梯度闭式解，开发梯度算法主动引导占用分布向期望覆盖模式收敛。

Result: U_ρ框架统一了多种覆盖目标；梯度算法能有效引导探索；当ρ增大时，探索策略越来越强调最少探索的状态-动作对，在极限情况下恢复最坏情况覆盖行为。

Conclusion: 提出的U_ρ框架为无奖励MDP中的定向探索提供了统一的理论基础，通过参数ρ灵活控制探索策略，从平均覆盖到最坏情况覆盖连续过渡，梯度算法实现了对探索模式的主动控制。

Abstract: Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_ρ$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_ρ$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_ρ$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $ρ$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.

</details>


### [291] [DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models](https://arxiv.org/abs/2601.11895)
*Pareesa Ameneh Golnari,Adarsh Kumarappan,Wen Wen,Xiaoyu Liu,Gabriel Ryan,Yuting Sun,Shengyu Fu,Elsie Nallipogu*

Main category: cs.LG

TL;DR: DevBench是一个基于遥测数据的代码补全基准测试，包含1800个评估实例，涵盖6种编程语言和6个任务类别，强调生态效度并避免训练数据污染，提供详细诊断功能。


<details>
  <summary>Details</summary>
Motivation: 现有代码补全基准测试缺乏生态效度，容易受到训练数据污染影响，且无法提供详细的诊断信息来指导模型选择和改进。

Method: 基于真实开发者遥测数据构建评估实例，结合功能正确性、相似度指标和LLM-judge评估（关注实用性和上下文相关性），对9个最先进模型进行评估。

Result: 评估揭示了不同模型在语法精度、语义推理和实际效用方面的差异，提供了可操作的见解来指导模型选择和针对性改进。

Conclusion: DevBench提供了其他基准测试通常缺失但实际部署和针对性模型开发所必需的详细诊断信息，能够有效指导模型选择和改进。

Abstract: DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.

</details>


### [292] [Task-tailored Pre-processing: Fair Downstream Supervised Learning](https://arxiv.org/abs/2601.11897)
*Jinwon Sohn,Guang Lin,Qifan Song*

Main category: cs.LG

TL;DR: 提出一种针对监督学习的公平性预处理框架，通过HGR相关性分析数据公平性方法的局限性，在公平性与效用之间取得平衡，并提供下游模型的理论保证。


<details>
  <summary>Details</summary>
Motivation: 现有公平性预处理方法分为数据公平性和任务定制公平性两类。数据公平性方法对下游模型类型独立，但作者认为这些方法从HGR相关性角度看施加了过强的正则化。需要开发专门针对监督学习的预处理方法，在公平性和效用之间取得更好的平衡。

Method: 提出一种新颖的监督学习定制预处理框架。首先考虑公平性与效用的权衡来获得预处理映射，然后研究在变换数据上学习的任意下游监督模型的行为，找到保证其公平性改进和效用保持的充分条件。该方法特别关注计算机视觉数据，仅改变与中心机器学习任务相关的必要语义特征来实现公平性。

Result: 通过表格和图像数据集的比较研究评估框架，显示该方法在多个下游模型中保持一致的权衡平衡，优于最近的竞争模型。特别是对于计算机视觉数据，该方法仅改变与中心机器学习任务相关的必要语义特征来实现公平性。

Conclusion: 该工作为监督学习公平性提供了理论上有保证的预处理方法，首次在任务定制方法分支中理论研究了使用预处理数据时的下游保证。该方法在公平性和效用之间取得了更好的平衡，并为下游模型的公平性改进提供了理论保证。

Abstract: Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.

</details>


### [293] [Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits](https://arxiv.org/abs/2601.11924)
*Ming Shi*

Main category: cs.LG

TL;DR: 该论文研究具有向量值奖励的协作随机多臂老虎机问题，在对抗性腐败和有限验证条件下。主要贡献是揭示了通信与腐败之间的耦合关系：固定的环境端腐败预算Γ可能转化为从Γ到NΓ的有效腐败水平，具体取决于智能体共享原始样本、充分统计量还是仅共享臂推荐。


<details>
  <summary>Details</summary>
Motivation: 研究在对抗性腐败环境下协作多智能体系统的学习问题。传统协作老虎机研究通常假设观测数据是干净的，但实际应用中数据可能被对抗性扰动污染。需要理解腐败如何影响协作学习，以及不同通信协议如何放大或缓解腐败效应。

Method: 提出协作随机多臂老虎机框架，具有向量值奖励、对抗性腐败和有限验证。引入协议诱导的多重性函数来量化不同通信协议（原始样本共享、统计量共享、推荐共享）如何将全局腐败预算Γ转化为有效腐败水平。建立遗憾界限参数化于有效腐败，分析不同通信策略的性能。

Result: 发现原始样本共享可能遭受N倍的腐败惩罚放大，而统计量共享和推荐共享保持未放大的O(Γ)项，达到中心化速率的团队遗憾。建立了信息理论极限：不可避免的Ω(Γ)加性惩罚，以及高腐败Γ=Θ(NT)下没有干净信息无法获得次线性遗憾。验证了全局ν个已验证观测如何恢复可学习性。

Conclusion: 通信协议显著影响协作系统对腐败的鲁棒性。原始样本共享放大腐败效应，而更高级的通信策略（统计量或推荐共享）能保持中心化性能。在高腐败机制下，验证是必要的，一旦超过识别阈值，认证共享能使团队遗憾独立于Γ。为设计鲁棒的协作学习系统提供了理论基础。

Abstract: We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.

</details>


### [294] [Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration](https://arxiv.org/abs/2601.11953)
*Shiqing Gao,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: MICE方法通过记忆驱动的内在成本估计解决约束强化学习中成本函数低估问题，显著减少训练期间的约束违反


<details>
  <summary>Details</summary>
Motivation: 现有约束强化学习算法在训练期间经常出现严重的约束违反，限制了在安全关键场景中的应用。研究发现成本价值函数的低估是导致这些违反的关键因素。

Method: 提出记忆驱动的内在成本估计方法：1）构建记忆模块存储先前探索的不安全状态以识别高风险区域；2）将内在成本定义为当前状态访问这些风险区域的伪计数；3）提出包含内在成本的外在-内在成本价值函数，采用偏差校正策略；4）在信任域内制定优化目标和相应优化方法。

Result: 理论分析提供了成本价值函数的收敛保证和MICE更新的最坏情况约束违反界限。实验表明MICE显著减少了约束违反，同时保持了与基线相当的政策性能。

Conclusion: MICE方法通过解决成本函数低估问题，有效提高了约束强化学习的安全性，减少了训练期间的约束违反，适用于安全关键场景。

Abstract: Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, existing CRL algorithms often encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to mitigate underestimation and control bias to promote safer exploration. Inspired by flashbulb memory, where humans vividly recall dangerous experiences to avoid risks, MICE constructs a memory module that stores previously explored unsafe states to identify high-cost regions. The intrinsic cost is formulated as the pseudo-count of the current state visiting these risk regions. Furthermore, we propose an extrinsic-intrinsic cost value function that incorporates intrinsic costs and adopts a bias correction strategy. Using this function, we formulate an optimization objective within the trust region, along with corresponding optimization methods. Theoretically, we provide convergence guarantees for the proposed cost value function and establish the worst-case constraint violation for the MICE update. Extensive experiments demonstrate that MICE significantly reduces constraint violations while preserving policy performance comparable to baselines.

</details>


### [295] [Data-centric Prompt Tuning for Dynamic Graphs](https://arxiv.org/abs/2601.11954)
*Yufei Peng,Cheng Yang,Zhengjie Fan,Chuan Shi*

Main category: cs.LG

TL;DR: DDGPrompt：一种面向动态图的数据中心提示框架，通过定义统一节点表达特征矩阵和三个提示矩阵，在输入数据层面优化预训练节点嵌入，提升少样本下游任务性能


<details>
  <summary>Details</summary>
Motivation: 传统动态图方法直接将预训练的节点时序嵌入应用于下游任务，但由于任务差异导致性能下降，尤其在少样本场景。现有提示方法通常与特定模型架构或预训练任务强耦合，且仅关注节点或时序特征而忽略空间结构信息，限制了表达能力和性能。

Method: 提出DDGPrompt框架：1) 定义统一节点表达特征矩阵，聚合每个节点的所有相关时序和结构信息；2) 引入三个提示矩阵（时序偏置、边权重和特征掩码）在特征矩阵层面进行调整，实现节点嵌入的任务特定适应。

Result: 在四个公开动态图数据集上，在严格的少样本设置下评估DDGPrompt。实验结果表明，在标签有限和冷启动条件下，该方法显著优于传统方法和现有提示方法。

Conclusion: DDGPrompt通过数据中心提示框架有效优化预训练节点嵌入，解决了现有方法架构耦合和忽略空间结构的问题，在少样本动态图下游任务中表现出优越性能。

Abstract: Dynamic graphs have attracted increasing attention due to their ability to model complex and evolving relationships in real-world scenarios. Traditional approaches typically pre-train models using dynamic link prediction and directly apply the resulting node temporal embeddings to specific downstream tasks. However, the significant differences among downstream tasks often lead to performance degradation, especially under few-shot settings. Prompt tuning has emerged as an effective solution to this problem. Existing prompting methods are often strongly coupled with specific model architectures or pretraining tasks, which makes it difficult to adapt to recent or future model designs. Moreover, their exclusive focus on modifying node or temporal features while neglecting spatial structural information leads to limited expressiveness and degraded performance. To address these limitations, we propose DDGPrompt, a data-centric prompting framework designed to effectively refine pre-trained node embeddings at the input data level, enabling better adaptability to diverse downstream tasks. We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models. Then, we introduce three prompt matrices (temporal bias, edge weight, and feature mask) to adjust the feature matrix completely, achieving task-specific adaptation of node embeddings. We evaluate DDGPrompt under a strict few-shot setting on four public dynamic graph datasets. Experimental results demonstrate that our method significantly outperforms traditional methods and prompting approaches in scenarios with limited labels and cold-start conditions.

</details>


### [296] [R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning](https://arxiv.org/abs/2601.11960)
*Jingchu Wang,Bingbing Xu,Yige Yuan,Bin Xie,Xiaoqian Sun,Huawei Shen*

Main category: cs.LG

TL;DR: R²PO通过引入轻量级残差Rollout-Head解耦训练轨迹与推理响应，解决强化学习中单一策略目标冲突问题，提升LLM推理能力


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法使用单一策略同时生成推理响应和训练优化轨迹，导致生成稳定推理响应与多样化训练轨迹之间的目标冲突，造成探索不足，损害推理能力

Method: 提出R²PO（Residual Rollout Policy Optimization），在策略顶部引入轻量级残差Rollout-Head，将训练轨迹与推理响应解耦，实现训练期间可控的轨迹多样化，同时保持推理生成的稳定性

Result: 在多个基准测试中一致优于基线方法，在MATH-500上平均准确率提升3.1%，在APPS上提升2.4%，同时减少格式错误并缓解长度偏差以实现稳定优化

Conclusion: R²PO通过解耦训练轨迹与推理响应，有效解决了强化学习中单一策略的目标冲突问题，显著提升了LLM的推理能力，同时保持了推理生成的稳定性

Abstract: Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.

</details>


### [297] [One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints](https://arxiv.org/abs/2601.11977)
*Ren He,Yinliang Xu,Jinfeng Wang,Jeremy Watson,Jian Song*

Main category: cs.LG

TL;DR: 提出MoE-Encoder模块，通过稀疏专家混合层增强预训练时间序列模型，解决电力系统多变量预测中的复杂依赖和隐私约束问题


<details>
  <summary>Details</summary>
Motivation: 电力系统预测面临多变量时间序列的复杂依赖关系、严格的跨区域隐私约束，传统方法需要大量专家知识且难以泛化，预训练模型的零样本性能有限

Method: 在标记化和编码之间注入稀疏混合专家层，将多变量预测转化为专家引导的单变量任务，支持联邦学习中的本地化训练和轻量级参数共享

Result: 在公开多变量数据集上显著提升预测精度，联邦环境模拟显示仅传输MoE-Encoder参数即可高效适应新区域，性能下降最小

Conclusion: MoE-Encoder为时间序列基础模型提供了可扩展且隐私感知的扩展方案

Abstract: Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.

</details>


### [298] [Extreme Value Policy Optimization for Safe Reinforcement Learning](https://arxiv.org/abs/2601.12008)
*Shiqing Gao,Yihang Zhou,Shuai Shao,Haoyu Luo,Yiheng Bing,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: EVO算法利用极值理论建模极端奖励和成本样本，通过极端分位数优化目标和极端优先回放机制减少约束违反，在训练中显著降低约束违反同时保持策略性能。


<details>
  <summary>Details</summary>
Motivation: 传统约束强化学习使用期望累积成本作为约束条件，但这种方法忽略了尾部分布中罕见但影响巨大的极端值事件（如黑天鹅事件），可能导致严重的约束违反。需要一种能够处理极端值事件的安全强化学习方法。

Method: 提出极端值策略优化（EVO）算法：1）利用极值理论建模和利用极端奖励和成本样本；2）引入极端分位数优化目标，显式捕捉成本尾部分布中的极端样本；3）提出极端优先回放机制，在经验回放中放大罕见但高影响极端样本的学习信号。

Result: 理论上：建立了策略更新期间期望约束违反的上界，保证在零违反分位数水平上的严格约束满足；证明EVO比期望方法具有更低的约束违反概率，比分位数回归方法具有更低的方差。实验上：EVO在训练期间显著减少约束违反，同时与基线方法相比保持竞争力的策略性能。

Conclusion: EVO算法通过极值理论有效处理约束强化学习中的极端值事件，提供更强的安全保证，在减少约束违反方面优于传统期望方法和分位数回归方法，为安全关键应用提供了更可靠的解决方案。

Abstract: Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.

</details>


### [299] [Learning to Factorize and Adapt: A Versatile Approach Toward Universal Spatio-Temporal Foundation Models](https://arxiv.org/abs/2601.12083)
*Siru Zhong,Junjie Qiu,Yangyu Wu,Yiqiu Liu,Yuanpeng He,Zhongwen Rao,Bin Yang,Chenjuan Guo,Hao Xu,Yuxuan Liang*

Main category: cs.LG

TL;DR: FactoST-v2是一个增强的因子化时空基础模型框架，通过分离通用时间学习和领域特定空间适应，实现全权重迁移和任意长度泛化，在零样本和少样本场景下达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 时空基础模型虽然具有跨数据集泛化潜力，但联合时空预训练计算成本高，且难以处理领域特定空间模式的异质性。需要一种更实用、可扩展的方法来构建真正通用的时空基础模型。

Method: 采用两阶段因子化框架：第一阶段使用随机序列掩码预训练最小化编码器主干，捕捉不变时间动态，支持跨可变范围的概率分位数预测；第二阶段通过元自适应学习和提示的简化适配器快速注入空间感知。

Result: 在多个领域的综合评估表明，FactoST-v2以线性效率达到最先进精度，在零样本和少样本场景中显著优于现有基础模型，并与领域特定专家基线相媲美。

Conclusion: 因子化范式为构建真正通用的时空基础模型提供了实用、可扩展的路径，解决了联合预训练的计算成本和空间异质性挑战。

Abstract: Spatio-Temporal (ST) Foundation Models (STFMs) promise cross-dataset generalization, yet joint ST pretraining is computationally expensive and grapples with the heterogeneity of domain-specific spatial patterns. Substantially extending our preliminary conference version, we present FactoST-v2, an enhanced factorized framework redesigned for full weight transfer and arbitrary-length generalization. FactoST-v2 decouples universal temporal learning from domain-specific spatial adaptation. The first stage pretrains a minimalist encoder-only backbone using randomized sequence masking to capture invariant temporal dynamics, enabling probabilistic quantile prediction across variable horizons. The second stage employs a streamlined adapter to rapidly inject spatial awareness via meta adaptive learning and prompting. Comprehensive evaluations across diverse domains demonstrate that FactoST-v2 achieves state-of-the-art accuracy with linear efficiency - significantly outperforming existing foundation models in zero-shot and few-shot scenarios while rivaling domain-specific expert baselines. This factorized paradigm offers a practical, scalable path toward truly universal STFMs. Code is available at https://github.com/CityMind-Lab/FactoST.

</details>


### [300] [PTL-PINNs: Perturbation-Guided Transfer Learning with Physics- Informed Neural Networks for Nonlinear Systems](https://arxiv.org/abs/2601.12093)
*Duarte Alexandrino,Ben Moseley,Pavlos Protopapas*

Main category: cs.LG

TL;DR: 提出PTL-PINN框架，结合微扰理论和迁移学习，快速求解非线性微分方程，计算速度比传统方法快一个数量级


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在处理非线性动力学问题时存在泛化能力有限、训练时间长的问题，需要更高效的求解方法

Method: 提出PTL-PINN框架，将微扰理论与迁移学习结合，通过闭式表达式求解近似线性微扰系统，具有矩阵-向量乘法的时间复杂度

Result: PTL-PINNs达到与多种Runge-Kutta方法相当的精度，计算速度比传统方法快一个数量级，成功求解了非线性振荡器、Lotka-Volterra系统、KPP-Fisher方程和波动方程等

Conclusion: 该工作将长期存在的微扰方法与PINNs连接起来，展示了微扰理论如何指导基础模型以接近经典求解器的速度求解非线性系统

Abstract: Accurately and efficiently solving nonlinear differential equations is crucial for modeling dynamic behavior across science and engineering. Physics-Informed Neural Networks (PINNs) have emerged as a powerful solution that embeds physical laws in training by enforcing equation residuals. However, these struggle to model nonlinear dynamics, suffering from limited generalization across problems and long training times. To address these limitations, we propose a perturbation-guided transfer learning framework for PINNs (PTL-PINN), which integrates perturbation theory with transfer learning to efficiently solve nonlinear equations. Unlike gradient-based transfer learning, PTL-PINNs solve an approximate linear perturbative system using closed-form expressions, enabling rapid generalization with the time complexity of matrix-vector multiplication. We show that PTL-PINNs achieve accuracy comparable to various Runge-Kutta methods, with computational speeds up to one order of magnitude faster. To benchmark performance, we solve a broad set of problems, including nonlinear oscillators across various damping regimes, the equilibrium-centered Lotka-Volterra system, the KPP-Fisher and the Wave equation. Since perturbation theory sets the accuracy bound of PTL-PINNs, we systematically evaluate its practical applicability. This work connects long-standing perturbation methods with PINNs, demonstrating how perturbation theory can guide foundational models to solve nonlinear systems with speeds comparable to those of classical solvers.

</details>


### [301] [SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data](https://arxiv.org/abs/2601.12124)
*Bing Hu,Yixin Li,Asma Bahamyirou,Helen Chen*

Main category: cs.LG

TL;DR: SynQP是一个用于评估合成数据生成隐私风险的开放框架，使用模拟敏感数据避免真实数据泄露，并提出新的身份披露风险度量方法。


<details>
  <summary>Details</summary>
Motivation: 健康应用中合成数据的使用引发隐私担忧，但缺乏开放的隐私评估框架和可访问的基准数据集阻碍了其采用。主要挑战在于获取敏感数据困难导致缺乏评估隐私风险的基准数据集。

Method: 引入SynQP开放框架，使用模拟敏感数据进行合成数据生成的隐私基准测试，确保原始数据保密性。提出新的身份披露风险度量方法，更准确地评估机器学习模型的概率特性。使用SynQP对CTGAN进行基准测试。

Result: 在质量评估中，非隐私模型实现了接近完美的机器学习效能（≥0.97）。隐私评估显示差分隐私（DP）持续降低身份披露风险（SD-IDR）和成员推理攻击风险（SD-MIA），所有DP增强模型均保持在0.09监管阈值以下。

Conclusion: SynQP为改进隐私评估的透明度和可靠性提供了关键工具，使合成数据在健康相关应用中的使用更加安全。该框架解决了缺乏隐私评估基准的问题，并提出了更准确的隐私风险度量方法。

Abstract: The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \(\ge0.97\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP

</details>


### [302] [SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics](https://arxiv.org/abs/2601.12131)
*Santosh Chapagain,MohammadReza EskandariNasab,Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: SolarGPT-QA是基于LLaMA-3的领域适应大语言模型，专门用于空间天气和太阳物理学教育问答，通过科学文献和GPT-4生成的大规模问答数据进行训练，在零样本设置下优于通用模型，在教育解释方面达到与指令调优模型竞争的性能。


<details>
  <summary>Details</summary>
Motivation: 太阳活动（太阳耀斑、日冕物质抛射、地磁暴）对卫星、航空、电网等关键基础设施有重大影响，极端太阳事件可能造成巨大经济损失。虽然大语言模型在通用任务上表现良好，但缺乏领域特定知识和教学能力来清晰解释复杂的空间科学概念，因此需要开发专门的教育问答系统。

Method: 基于LLaMA-3基础模型构建SolarGPT-QA问答系统，采用领域适应预训练和教学微调相结合的方法。训练数据包括科学文献和由GPT-4生成、Grok-3精炼的大规模问答数据，采用学生友好的故事叙述风格。通过人类成对评估、学生理解研究和消融实验验证方法有效性。

Result: 人类成对评估显示SolarGPT-QA在零样本设置下优于通用模型，在教育解释方面与指令调优模型性能相当。小型试点学生理解研究表明生成的解释在清晰度和可访问性方面有所改善。消融实验表明结合领域适应预训练和教学微调对于平衡科学准确性和教育效果至关重要。

Conclusion: SolarGPT-QA在空间天气和太阳物理学教育问答方面表现出色，通过领域适应和教学微调的结合有效提升了科学准确性和教育效果。这项工作代表了向更广泛的SolarGPT框架（用于空间科学教育和预报）迈出的初步步骤。

Abstract: Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.
  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.

</details>


### [303] [EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts](https://arxiv.org/abs/2601.12137)
*Anzhe Cheng,Shukai Duan,Shixuan Li,Chenzhong Yin,Mingxi Cheng,Shahin Nazarian,Paul Thompson,Paul Bogdan*

Main category: cs.LG

TL;DR: 提出EMoE架构，通过基于学习正交特征基的路由机制，同时解决MoE中的负载不均衡和专家同质化问题


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型规模不断扩大，计算需求不可持续，MoE架构成为提高效率的可行路径。但现有MoE模型存在两个根本问题：1) "富者愈富"的负载不均衡问题；2) 专家同质化问题，专家学习冗余表示。当前解决方案通常使用辅助负载均衡损失，虽然缓解了不均衡，但往往以牺牲专业化为代价强制均匀路由，加剧了同质化。

Method: 提出Eigen-Mixture-of-Experts (EMoE)架构，采用基于学习正交特征基的路由机制。该方法将输入token投影到共享的特征基上，根据token与特征空间主成分的对齐程度进行路由。这种基于几何原理的数据划分方法本质上促进了专家负载均衡和多样化、专业化专家的形成，无需使用冲突的辅助损失函数。

Result: 论文代码已公开在https://github.com/Belis0811/EMoE，表明该方法能够同时解决负载不均衡和专家同质化问题，无需使用辅助损失函数。

Conclusion: EMoE通过基于学习正交特征基的路由机制，提供了一种原则性的解决方案，能够同时实现专家负载均衡和专业化，解决了传统MoE架构中的两个根本挑战。

Abstract: The relentless scaling of deep learning models has led to unsustainable computational demands, positioning Mixture-of-Experts (MoE) architectures as a promising path towards greater efficiency. However, MoE models are plagued by two fundamental challenges: 1) a load imbalance problem known as the``rich get richer" phenomenon, where a few experts are over-utilized, and 2) an expert homogeneity problem, where experts learn redundant representations, negating their purpose. Current solutions typically employ an auxiliary load-balancing loss that, while mitigating imbalance, often exacerbates homogeneity by enforcing uniform routing at the expense of specialization. To resolve this, we introduce the Eigen-Mixture-of-Experts (EMoE), a novel architecture that leverages a routing mechanism based on a learned orthonormal eigenbasis. EMoE projects input tokens onto this shared eigenbasis and routes them based on their alignment with the principal components of the feature space. This principled, geometric partitioning of data intrinsically promotes both balanced expert utilization and the development of diverse, specialized experts, all without the need for a conflicting auxiliary loss function. Our code is publicly available at https://github.com/Belis0811/EMoE.

</details>


### [304] [Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling](https://arxiv.org/abs/2601.12145)
*Xingyue Huang,Xueying Ding,Mingxuan Ju,Yozen Liu,Neil Shah,Tong Zhao*

Main category: cs.LG

TL;DR: TDA是一种无注意力下沉的稀疏注意力机制，通过极值阈值化和抑制视图提升长上下文处理能力


<details>
  <summary>Details</summary>
Motivation: 解决Softmax注意力在长上下文中的结构限制：严格的和为一约束导致无关标记上的注意力下沉，以及随着序列长度增加概率质量分散的问题

Method: 提出阈值差分注意力（TDA），采用行级极值阈值化配合长度相关门控，仅保留超过阈值的值；同时借鉴差分变换器思想，减去抑制视图以增强表达能力

Result: 理论上证明TDA每行伪幸存者期望数为O(1)，且独立视图间的共识伪匹配随上下文增长而消失；实证上产生>99%的精确零值，消除注意力下沉，在标准和长上下文基准上保持竞争力

Conclusion: TDA是一种有效的无注意力下沉稀疏注意力机制，解决了Softmax在长上下文中的结构限制，实现了超稀疏性和更好的鲁棒性

Abstract: Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.

</details>


### [305] [Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses](https://arxiv.org/abs/2601.12178)
*Fallou Niakh*

Main category: cs.LG

TL;DR: 提出一个联邦学习框架，用于在异构可再生能源生产损失下校准参数化保险指数，通过分布式优化学习共同指数而不共享原始数据。


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源生产损失参数化保险指数校准中的隐私保护和数据异质性问题。传统方法需要共享敏感的生产数据，而联邦学习可以在保护数据隐私的同时处理不同生产者之间的异质性。

Method: 生产者使用Tweedie广义线性模型在本地建模损失，基于私有数据。通过联邦优化学习共同指数，不共享原始观测数据。框架支持方差和链接函数的异质性，直接在分布式设置中最小化全局偏差目标。实现并比较了FedAvg、FedProx和FedOpt算法，并与现有的基于近似的聚合方法进行基准测试。

Result: 在德国太阳能发电生产的实证应用中，联邦学习在中等异质性条件下恢复了可比较的指数系数，同时提供了一个更通用和可扩展的框架。

Conclusion: 联邦学习框架为参数化保险指数校准提供了一种隐私保护、可扩展的解决方案，能够处理数据异质性，并在实际应用中表现出与传统方法相当的性能。

Abstract: We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.

</details>


### [306] [Speculative Sampling with Reinforcement Learning](https://arxiv.org/abs/2601.12212)
*Chenan Wang,Daniel H. Shi,Haipeng Chen*

Main category: cs.LG

TL;DR: Re-SpS：首个基于强化学习的推测采样框架，通过动态优化草稿树超参数，在保持输出质量的同时显著提升LLM推理速度


<details>
  <summary>Details</summary>
Motivation: 现有推测采样方法（如EAGLE-3）使用静态树结构超参数，限制了在不同上下文和领域中的灵活性和效率。需要动态调整机制来平衡推测攻击性和计算开销，最大化生成速度

Method: 提出Re-SpS强化学习框架：1）从目标模型隐藏状态提取高效状态表示；2）引入多步动作持久性以更好建模上下文；3）实时动态调整草稿树超参数，学习上下文感知策略

Result: 在五个多样化基准测试中：1）相比骨干LLM实现最高5.45倍加速；2）相比SOTA方法EAGLE-3实现最高1.12倍加速；3）无输出保真度损失

Conclusion: Re-SpS通过强化学习动态优化草稿树超参数，显著提升LLM推理速度，为实时应用提供了更高效的推测采样解决方案

Abstract: Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\times$ speedup over the backbone LLM and up to 1.12$\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.

</details>


### [307] [One-Sided Matrix Completion from Ultra-Sparse Samples](https://arxiv.org/abs/2601.12213)
*Hongyang R. Zhang,Zhenshuo Zhang,Huy L. Nguyen,Guanghui Lan*

Main category: cs.LG

TL;DR: 论文研究了超稀疏采样下的矩阵补全问题，提出了一种用于估计矩阵行空间或二阶矩矩阵的无偏估计器，在每行仅观测C个条目（C≥2）的极端稀疏情况下仍能有效工作。


<details>
  <summary>Details</summary>
Motivation: 传统矩阵补全方法在超稀疏采样（每行条目数少于矩阵秩）时失效，无法准确补全矩阵。本文针对大型稀疏面板数据（行数远大于列数）的应用场景，旨在估计矩阵的行空间或二阶矩矩阵而非完整矩阵本身。

Method: 提出无偏估计器：首先通过观测频率归一化二阶矩矩阵的非零条目，然后使用梯度下降补全T的缺失条目。归一化将n个二项随机变量的加权和除以总观测数。该方法适用于任何采样概率p，且具有低方差特性。

Result: 理论证明：当M的行向量来自满足不相干条件的秩r因子模型时，若n ≥ O(dr⁵ε⁻²C⁻²log d)，梯度下降目标的任何局部最小值都近似全局最优，能以最多ε²的误差恢复T。实验验证：在MovieLens数据集上偏差减少88%；在稀疏度为10⁻⁷的Amazon评论数据集上，T的恢复误差减少59%，M的误差减少38%。

Conclusion: 本文提出的方法在超稀疏采样下能有效估计矩阵的行空间和二阶矩矩阵，为大规模稀疏面板数据分析提供了理论保证和实用工具，在真实数据集上显著优于基线方法。

Abstract: Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\times d$ matrix $M$ (with $n \ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\top} M / n$.
  The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \ge O({d r^5 ε^{-2} C^{-2} \log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $ε^2$.
  Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\%$ and $M$ by $38\%$ compared to baseline methods.

</details>


### [308] [Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models](https://arxiv.org/abs/2601.12215)
*Megha Thukral,Cyrus Tanade,Simon A. Lee,Juhyeon Lee,Hao Zhou,Keum San Chun,Migyeong Gwak,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Mehrab Bin Morshed,Subramaniam Venkatraman,Sharanya Arcot Desai*

Main category: cs.LG

TL;DR: 该论文提出了Masked Multiscale Reconstruction (MMR)方法，一种用于PPG信号表示学习的自监督预训练框架，通过小波多分辨率分解和掩码重建任务，在17个健康相关任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴基础模型大多忽略了PPG信号的频谱结构，而许多下游健康相关任务依赖于从细粒度波形形态到全局节律动态的多分辨率特征。需要一种能够显式学习PPG数据层次化时频尺度的表示学习方法。

Method: 提出MMR自监督预训练框架：1）使用小波基多分辨率分解对PPG信号进行时频分析；2）随机掩码小波系数；3）训练Transformer编码器重建被掩码的系数，强制模型整合跨时间和频谱尺度的信息。使用约1700万个未标记的10秒PPG片段进行预训练。

Result: 在19个多样化的健康相关任务中，MMR在17个任务上优于或匹配最先进的开源PPG基础模型、时间序列基础模型和其他自监督基线。学习到的嵌入具有鲁棒性和生理基础特征。

Conclusion: MMR展示了作为通用PPG基础模型的潜力，小波基表示能够捕获稳健且具有生理基础的特征，为可穿戴数字健康应用提供了有效的表示学习方法。

Abstract: Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.

</details>


### [309] [Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention](https://arxiv.org/abs/2601.12231)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Shijie Xu,Guanggang Geng*

Main category: cs.LG

TL;DR: 提出了一种结合小波感知调制、多分辨率小波分解和分辨率自适应注意力的新型框架，用于企业安全中的内部威胁检测，在CERT r4.2基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 企业内部威胁检测面临多通道、非平稳的用户活动日志数据，且异常行为稀少，使得传统异常检测方法效果有限。

Method: 采用偏差感知调制方案抑制常规行为并放大异常偏差；使用离散小波变换将日志信号分解为多分辨率表示；设计可学习的注意力机制动态重加权最具判别性的频带。

Result: 在CERT r4.2基准测试中，该方法在不同时间粒度和场景下，在精确率、召回率和F1分数方面均优于现有基线方法。

Conclusion: 提出的集成小波感知调制、多分辨率分解和自适应注意力的框架能够有效处理复杂用户行为模式，显著提升内部威胁检测性能。

Abstract: Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.

</details>


### [310] [TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization](https://arxiv.org/abs/2601.12288)
*Lei Liu,Tengyuan Liu,Hongwei Zhao,Jiahui Huang,Ruibo Guo,Bin Li*

Main category: cs.LG

TL;DR: TimeGMM：基于高斯混合模型的概率时间序列预测框架，通过单次前向传播捕获复杂未来分布，无需昂贵采样或限制性参数假设


<details>
  <summary>Details</summary>
Motivation: 现有概率时间序列预测方法存在两个主要问题：1）依赖计算昂贵的采样过程；2）使用限制性参数假设来表征未来分布。这限制了预测性能并导致分布不匹配问题

Method: 提出TimeGMM框架，核心包括：1）GMM-adapted Reversible Instance Normalization (GRIN)模块，动态适应时间-概率分布偏移；2）时间编码器(TE-Module)与条件时间-概率解码器(CTPD-Module)联合捕获时间依赖性和混合分布参数

Result: 在广泛实验中，TimeGMM持续优于最先进方法，在CRPS指标上最大提升22.48%，在NMAE指标上最大提升21.23%

Conclusion: TimeGMM通过高斯混合模型框架有效解决了现有概率预测方法的局限性，在单次前向传播中捕获复杂分布，显著提升了预测性能

Abstract: Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. However, existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. To address these challenges, this paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48\% in CRPS and 21.23\% in NMAE.

</details>


### [311] [Distribution Shift Is Key to Learning Invariant Prediction](https://arxiv.org/abs/2601.12296)
*Hong Zheng,Fei Teng*

Main category: cs.LG

TL;DR: 研究发现，训练数据中的分布偏移程度越大，经验风险最小化（ERM）的性能越好，甚至能接近不变预测模型的性能，这解释了为什么ERM有时在分布外任务上表现优于专门设计的方法。


<details>
  <summary>Details</summary>
Motivation: 观察到经验风险最小化（ERM）有时在分布外任务上表现优于专门设计的方法，这促使研究者探究算法设计之外的原因。研究发现，训练域之间的分布偏移程度是影响模型性能的关键因素。

Method: 通过理论推导和实证验证相结合的方法：1）提出理论上界，表明分布偏移程度直接影响模型预测能力；2）证明在特定数据条件下，ERM解能达到与不变预测模型相当的性能；3）通过实证验证，展示随着训练数据分布偏移程度增加，学习模型的预测接近Oracle或最优模型。

Result: 研究发现：1）分布偏移程度越大，模型预测能力越强，越能逼近不变预测模型；2）在特定条件下，ERM解的性能可与不变预测模型相媲美；3）实证结果表明，随着训练数据分布偏移程度增加，学习模型的预测确实更接近Oracle或最优模型。

Conclusion: 训练数据中的分布偏移程度是影响模型学习不变预测的关键因素。较大的分布偏移有助于提升模型性能，使ERM方法能够接近专门设计的不变预测模型的性能，这解释了ERM在分布外任务上有时表现优异的现象。

Abstract: An interesting phenomenon arises: Empirical Risk Minimization (ERM) sometimes outperforms methods specifically designed for out-of-distribution tasks. This motivates an investigation into the reasons behind such behavior beyond algorithmic design. In this study, we find that one such reason lies in the distribution shift across training domains. A large degree of distribution shift can lead to better performance even under ERM. Specifically, we derive several theoretical and empirical findings demonstrating that distribution shift plays a crucial role in model learning and benefits learning invariant prediction. Firstly, the proposed upper bounds indicate that the degree of distribution shift directly affects the prediction ability of the learned models. If it is large, the models' ability can increase, approximating invariant prediction models that make stable predictions under arbitrary known or unseen domains; and vice versa. We also prove that, under certain data conditions, ERM solutions can achieve performance comparable to that of invariant prediction models. Secondly, the empirical validation results demonstrated that the predictions of learned models approximate those of Oracle or Optimal models, provided that the degree of distribution shift in the training data increases.

</details>


### [312] [Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments](https://arxiv.org/abs/2601.12305)
*Deepak Kanneganti,Sajib Mistry,Sheik Fattah,Joshua Boland,Aneesh Krishna*

Main category: cs.LG

TL;DR: 提出MDG框架，用于生成可配置、可复现的MLaaS数据集，以评估服务选择与组合，通过模拟真实MLaaS行为并记录多种指标，构建大规模基准数据集


<details>
  <summary>Details</summary>
Motivation: 需要系统化的方法来评估机器学习即服务（MLaaS）的选择和组合，现有方法缺乏可配置、可复现的数据集来模拟真实MLaaS行为

Method: 提出MLaaS数据集生成器（MDG）框架，通过训练和评估多种模型家族在不同真实数据集和数据分布设置下模拟MLaaS行为，记录功能属性、服务质量指标和组合特定指标，并实现内置组合机制模拟物联网条件下的服务交互

Result: 生成超过一万个MLaaS服务实例，构建大规模基准数据集，实验表明MDG生成的数据集相比现有基线提高了选择准确性和组合质量

Conclusion: MDG为推进MLaaS选择和组合的数据驱动研究提供了实用且可扩展的基础，能够生成高质量、可配置的数据集以支持系统化评估

Abstract: We propose a novel MLaaS Dataset Generator (MDG) framework that creates configurable and reproducible datasets for evaluating Machine Learning as a Service (MLaaS) selection and composition. MDG simulates realistic MLaaS behaviour by training and evaluating diverse model families across multiple real-world datasets and data distribution settings. It records detailed functional attributes, quality of service metrics, and composition-specific indicators, enabling systematic analysis of service performance and cross-service behaviour. Using MDG, we generate more than ten thousand MLaaS service instances and construct a large-scale benchmark dataset suitable for downstream evaluation. We also implement a built-in composition mechanism that models how services interact under varied Internet of Things conditions. Experiments demonstrate that datasets generated by MDG enhance selection accuracy and composition quality compared to existing baselines. MDG provides a practical and extensible foundation for advancing data-driven research on MLaaS selection and composition

</details>


### [313] [Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays](https://arxiv.org/abs/2601.12322)
*Chang-Wei Shi,Shi-Shang Wang,Wu-Jun Li*

Main category: cs.LG

TL;DR: 提出OrLoMo方法，首次实现带局部更新的异步分布式动量SGD，通过有序聚合局部动量来加速异构集群训练


<details>
  <summary>Details</summary>
Motivation: 动量SGD是深度模型训练的基础优化器，异步分布式学习对大规模模型训练至关重要，特别是在异构计算能力的集群中。局部更新能减少通信频率，但如何实现带局部更新的异步分布式动量SGD尚未被探索。

Method: 提出有序局部动量(OrLoMo)方法：每个工作节点本地运行动量SGD，服务器根据全局迭代索引有序聚合来自各工作节点的局部动量。这是首个实现带局部更新的异步分布式动量SGD的方法。

Result: 证明了OrLoMo在任意延迟下的非凸问题收敛性。实验验证OrLoMo优于其同步对应方法和其他异步方法。

Conclusion: OrLoMo成功解决了异步分布式动量SGD与局部更新的结合问题，为异构集群中的大规模深度模型训练提供了有效的优化方案。

Abstract: Momentum SGD (MSGD) serves as a foundational optimizer in training deep models due to momentum's key role in accelerating convergence and enhancing generalization. Meanwhile, asynchronous distributed learning is crucial for training large-scale deep models, especially when the computing capabilities of the workers in the cluster are heterogeneous. To reduce communication frequency, local updates are widely adopted in distributed learning. However, how to implement asynchronous distributed MSGD with local updates remains unexplored. To solve this problem, we propose a novel method, called \underline{or}dered \underline{lo}cal \underline{mo}mentum (OrLoMo), for asynchronous distributed learning. In OrLoMo, each worker runs MSGD locally. Then the local momentum from each worker will be aggregated by the server in order based on its global iteration index. To the best of our knowledge, OrLoMo is the first method to implement asynchronous distributed MSGD with local updates. We prove the convergence of OrLoMo for non-convex problems under arbitrary delays. Experiments validate that OrLoMo can outperform its synchronous counterpart and other asynchronous methods.

</details>


### [314] [IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning](https://arxiv.org/abs/2601.12330)
*Zuha Fatima,Muhammad Anser Sohaib,Muhammad Talha,Ayesha Kanwal,Sidra Sultana,Nazia Perwaiz*

Main category: cs.LG

TL;DR: IceWatch是一个用于预测冰川湖溃决洪水(GLOF)的深度学习框架，结合空间视觉分析和时间物理动态建模，实现自动、可扩展的实时预警系统。


<details>
  <summary>Details</summary>
Motivation: 传统GLOF检测方法依赖水文建模、阈值监测和人工卫星图像分析，存在更新慢、依赖人工、云层干扰和现场数据缺乏等问题，需要更自动、准确、实时的预测方案。

Method: 提出IceWatch框架，包含两个核心组件：1) RiskFlow视觉组件：基于CNN分类器处理Sentinel-2多光谱卫星图像，从冰雪融水空间模式预测GLOF；2) 表格组件：整合TerraFlow（从NASA ITS_LIVE时间序列建模冰川流速）和TempFlow（从MODIS LST记录预测近地表温度），通过协调预处理和同步实现多模态物理信息融合。

Result: 系统提供交叉验证，提高GLOF检测的可靠性和可解释性，确保强预测性能、快速数据处理（支持实时使用）以及对噪声和缺失信息的鲁棒性。

Conclusion: IceWatch为自动、可扩展的GLOF预警系统铺平道路，具备与多种传感器输入和全球冰川监测活动集成的潜力。

Abstract: Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.

</details>


### [315] [LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH](https://arxiv.org/abs/2601.12355)
*Beicheng Xu,Weitong Qian,Lingching Tung,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: LB-MCTS框架结合大语言模型和贝叶斯优化，通过蒙特卡洛树搜索解决CASH问题，在104个AMLB数据集上表现优于基线方法


<details>
  <summary>Details</summary>
Motivation: 降低机器学习专业门槛需要解决CASH问题（算法选择和超参数调优自动化）。传统贝叶斯优化存在冷启动问题，而现有基于大语言模型的优化器在高维结构化CASH空间中泛化能力差

Method: 提出LB-MCTS框架，在大语言模型和贝叶斯优化之间协同工作，采用蒙特卡洛树搜索结构。通过选择性调优记忆（STM）最大化大语言模型推理能力，实现显式的探索-利用权衡。随着数据积累，动态从大语言模型驱动转向贝叶斯优化驱动

Result: 在104个AMLB数据集上的实验表明，LB-MCTS优于竞争基线方法

Conclusion: LB-MCTS成功结合了大语言模型的语义先验和贝叶斯优化的数据驱动优势，有效解决了高维结构化CASH空间的优化问题

Abstract: To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.

</details>


### [316] [Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation](https://arxiv.org/abs/2601.12401)
*Jinmei Liu,Haoru Li,Zhenhong Sun,Chaofeng Chen,Yatao Bian,Bo Wang,Daoyi Dong,Chunlin Chen,Zhi Wang*

Main category: cs.LG

TL;DR: DRIFT框架通过采样、提示和优化三个角度解决RL微调中的多样性崩溃问题，在保持任务对齐的同时显著提升生成多样性


<details>
  <summary>Details</summary>
Motivation: 强化学习在微调大规模生成模型时存在多样性崩溃的根本限制，即目标和优化过程导致策略收敛到狄拉克δ分布，这限制了模型在需要多样化候选生成的应用中的实用性

Method: 提出DRIFT框架，从三个角度系统性地激励输出多样性：1) 采样奖励集中子集以过滤奖励异常值；2) 使用随机变体提示扩展条件空间；3) 通过基于势能的奖励塑造机制优化组内多样性

Result: 实验结果显示DRIFT在任务对齐和生成多样性方面实现了帕累托优势：在相同对齐水平下多样性提升9.08%~43.46%，在相同多样性水平下对齐度提升59.65%~65.86%

Conclusion: DRIFT框架成功解决了RL微调中的多样性崩溃问题，实现了任务对齐与生成多样性的平衡，为需要多样化候选生成的应用提供了有效的解决方案

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \textbf{DRIFT} (\textbf{D}ive\textbf{R}sity-\textbf{I}ncentivized Reinforcement \textbf{F}ine-\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\%\!\sim\! 43.46\%$ increase in diversity at equivalent alignment levels and a $ 59.65\% \!\sim\! 65.86\%$ increase in alignment at equivalent levels of diversity.

</details>


### [317] [Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants](https://arxiv.org/abs/2601.12405)
*Manasi Kanade,Abhi Thakkar,Gabriela Fernandes*

Main category: cs.LG

TL;DR: 开发并评估了一个可解释的机器学习框架，用于儿科牙科风险分层，优先考虑可解释性、校准和伦理部署而非最大预测准确性


<details>
  <summary>Details</summary>
Motivation: 儿科牙科疾病是全球最普遍且最不公平的慢性健康状况之一。虽然流行病学证据表明口腔健康结果与社会经济和人口统计学因素相关，但大多数牙科AI应用依赖基于图像的诊断和黑盒预测模型，限制了在儿科人群中的透明度和伦理适用性

Method: 使用人口水平的儿科数据（包括年龄、收入贫困比、种族/民族、性别和病史）训练监督机器学习模型。使用ROC分析和校准曲线评估模型性能。通过SHAP（SHapley Additive exPlanations）实现可解释性，提供全局和个体层面的预测解释

Result: 模型实现了适度的区分能力（AUC = 0.61），具有保守的校准特性，在高概率水平下低估风险。SHAP分析确定年龄和收入贫困比是预测风险的最强贡献因素，其次是种族/民族和性别

Conclusion: 可解释的机器学习能够实现透明的、预防导向的儿科牙科风险分层，支持人群筛查和公平资源分配，而非诊断决策

Abstract: Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.
  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.
  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.
  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.
  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.

</details>


### [318] [Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF](https://arxiv.org/abs/2601.12415)
*Wang Zixian*

Main category: cs.LG

TL;DR: 该论文提出了正交化策略优化（OPO）框架，将对齐方法中的采样几何与优化几何解耦，解决了传统KL散度方法在数值不稳定性和梯度消失方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐方法（如PPO、DPO、IPO）通常将采样几何和优化几何这两个基本设计选择隐含地混为一谈。KL散度对无界值信号施加指数惩罚，导致数值不稳定性和高置信度区域梯度消失。需要一种能够解耦这两个几何维度并提供稳定优化的框架。

Method: 提出正交化策略优化（OPO）框架，将对齐形式化为策略能量与目标能量之间广义距离的最小化。使用α散度加权的采样几何和Bregman散度加值的优化几何。具体采用α加权重要性采样和卡方诱导的二次正则化（在比率坐标中），产生具有线性梯度动态的简单且良条件的目标函数。

Result: OPO框架能够维持稳定优化，同时保留峰值寻求行为，即使在模型置信度较高时也能避免梯度饱和。该框架为现有对齐方法提供了统一的视角，并为稳健的推理导向训练奠定了原则性基础。

Conclusion: 通过明确解耦采样几何和优化几何，OPO解决了传统对齐方法的数值不稳定问题，提供了更稳健的优化框架。该工作为理解现有对齐算法提供了统一的理论基础，并为未来对齐方法的设计提供了原则性指导。

Abstract: Recent alignment methods for large language models, including PPO, DPO, and IPO, are often presented as distinct algorithms. In this work, we show that many of these approaches implicitly conflate two fundamental and independent design choices: (i) the sampling geometry, which determines which samples dominate the gradient signal, and (ii) the optimization geometry, which determines how deviations in value are penalized. We formalize this observation by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an alpha-divergence-based sampling weight and a Bregman-divergence-based value metric. We demonstrate that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this issue, we propose Orthogonalized Policy Optimization (OPO), a framework that explicitly decouples sampling geometry from optimization geometry. By combining alpha-weighted importance sampling with a chi-square-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This formulation maintains stable optimization while preserving peak-seeking behavior and avoids gradient saturation even when model confidence is high. Our analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.

</details>


### [319] [Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting](https://arxiv.org/abs/2601.12467)
*Saurish Nagrath*

Main category: cs.LG

TL;DR: 提出两阶段预测框架：第一阶段用CNN提取局部时间动态特征并生成补丁级token嵌入，第二阶段用Transformer编码器建模补丁间依赖关系进行预测。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在时间序列预测中表现良好，但其效果严重依赖于从原始多元时间序列数据中提取的输入表示的质量和结构。现有方法在局部时间表示学习和全局依赖建模方面存在耦合问题。

Method: 提出两阶段预测框架：1) 局部时间表示学习阶段：CNN在固定长度时间补丁上操作，提取短程时间动态和非线性特征交互，生成紧凑的补丁级token嵌入；使用token级自注意力细化这些嵌入；2) 全局依赖建模阶段：Transformer编码器处理token序列，建模补丁间时间依赖关系，生成每个补丁的预测。

Result: 在具有受控静态和动态因素的合成多元时间序列数据上的实验表明，所提出的基于补丁的token化策略相比卷积和基于补丁的Transformer基线实现了有竞争力的预测性能。

Conclusion: 结构化时间表示的重要性得到验证，将局部时间编码与基于注意力的全局建模解耦能够产生更有效和稳定的时间序列预测。

Abstract: Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.

</details>


### [320] [Semidefinite Programming for Quantum Channel Learning](https://arxiv.org/abs/2601.12502)
*Mikhail Gennadievich Belov,Victor Victorovich Dubov,Vadim Konstantinovich Ivanov,Alexander Yurievich Maslov,Olga Vladimirovna Proshina,Vladislav Gennadievich Malyshkin*

Main category: cs.LG

TL;DR: 该论文提出使用半定规划（SDP）从经典数据重建量子通道的方法，适用于保真度可表示为两个二次型比值的情况，并发现重建的量子通道通常具有较低的Kraus秩。


<details>
  <summary>Details</summary>
Motivation: 研究从经典实验数据重建量子通道的问题，特别是在保真度可表示为两个二次型比值的情况下，需要一种高效且可靠的数值方法来解决这一优化问题。

Method: 采用半定规划（SDP）方法，将保真度优化问题转化为关于Choi矩阵的凸优化问题，利用多种商业SDP求解器进行数值求解，并分析了重建量子通道的Kraus秩特性。

Result: 测试了多种商业SDP求解器，均能成功重建不同形式的量子通道；重建的量子通道通常具有较低的Kraus秩（通常小于最大可能值的几个百分点），表明少量Kraus秩的量子通道足以描述实验观测数据。

Conclusion: SDP为量子通道重建提供了有效的凸优化框架，重建的量子通道通常具有低Kraus秩，这为基于量子通道变换的经典计算模型提供了理论基础，并成功应用于投影算子的重建问题。

Abstract: The problem of reconstructing a quantum channel from a sample of classical data is considered. When the total fidelity can be represented as a ratio of two quadratic forms (e.g., in the case of mapping a mixed state to a pure state, projective operators, unitary learning, and others), Semidefinite Programming (SDP) can be applied to solve the fidelity optimization problem with respect to the Choi matrix. A remarkable feature of SDP is that the optimization is convex, which allows the problem to be efficiently solved by a variety of numerical algorithms. We have tested several commercially available SDP solvers, all of which allowed for the reconstruction of quantum channels of different forms. A notable feature is that the Kraus rank of the obtained quantum channel typically comprises less than a few percent of its maximal possible value. This suggests that a relatively small Kraus rank quantum channel is typically sufficient to describe experimentally observed classical data. The theory was also applied to the problem of reconstructing projective operators from data. Finally, we discuss a classical computational model based on quantum channel transformation, performed and calculated on a classical computer, possibly hardware-optimized.

</details>


### [321] [Cooperative Multi-agent RL with Communication Constraints](https://arxiv.org/abs/2601.12518)
*Nuoya Xiong,Aarti Singh*

Main category: cs.LG

TL;DR: 提出基策略预测技术，通过预测策略更新来减少通信需求，在潜在游戏中仅需O(ε^{-3/4})通信轮次即可收敛到ε-纳什均衡


<details>
  <summary>Details</summary>
Motivation: 传统协作多智能体强化学习假设频繁访问全局信息，但在去中心化系统中通信成本高。当通信受限时，智能体依赖过时信息更新策略，重要性采样方法在通信受限时不稳定

Method: 提出基策略预测技术，利用旧梯度预测策略更新，为一系列基策略收集样本，减少基策略与当前策略之间的差距。该方法可在单次通信轮次内收集预测基策略的样本

Result: 理论上证明算法在潜在游戏中以O(ε^{-3/4})通信轮次和O(poly(max_i|A_i|)ε^{-11/4})样本收敛到ε-纳什均衡，改进了通信成本和样本复杂度。在一般马尔可夫协作游戏中找到智能体局部最优

Conclusion: 基策略预测技术能有效减少通信需求，在模拟游戏和复杂环境的MAPPO中验证了其有效性，显著降低了通信轮次需求

Abstract: Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\varepsilon$-Nash equilibrium in potential games with only $O(\varepsilon^{-3/4})$ communication rounds and $O(poly(\max_i |A_i|)\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.

</details>


### [322] [Approximating splits for decision trees quickly in sparse data streams](https://arxiv.org/abs/2601.12525)
*Nikolaj Tatti*

Main category: cs.LG

TL;DR: 提出针对稀疏二元特征和二元分类的决策树流式学习算法，通过近似优化信息增益或基尼指数，在稀疏数据上实现高效分割搜索


<details>
  <summary>Details</summary>
Motivation: 传统决策树流式学习算法在寻找最优分割时需要O(d)时间（d为特征数），对于稀疏二元特征数据效率较低。本文旨在加速稀疏数据下的分割搜索过程

Method: 提出近似算法，在条件熵情况下实现(1+α)近似，摊销时间复杂度为O(α^{-1}(1+m log d) log log n)；基尼指数情况下实现(1+α)近似，摊销时间复杂度为O(α^{-1}+m log d)，其中m为数据点中1的数量

Result: 算法在稀疏数据（m≪d）上表现优异，实验显示能够高效找到近似最优分割，速度快于基线方法，且实际性能优于理论近似保证

Conclusion: 针对稀疏二元特征和二元分类的决策树流式学习，提出的近似分割搜索算法在保持近似最优性的同时显著提高了计算效率，特别适用于稀疏数据场景

Abstract: Decision trees are one of the most popular classifiers in the machine learning literature. While the most common decision tree learning algorithms treat data as a batch, numerous algorithms have been proposed to construct decision trees from a data stream. A standard training strategy involves augmenting the current tree by changing a leaf node into a split. Here we typically maintain counters in each leaf which allow us to determine the optimal split, and whether the split should be done. In this paper we focus on how to speed up the search for the optimal split when dealing with sparse binary features and a binary class. We focus on finding splits that have the approximately optimal information gain or Gini index. In both cases finding the optimal split can be done in $O(d)$ time, where $d$ is the number of features. We propose an algorithm that yields $(1 + α)$ approximation when using conditional entropy in amortized $O(α^{-1}(1 + m\log d) \log \log n)$ time, where $m$ is the number of 1s in a data point, and $n$ is the number of data points. Similarly, for Gini index, we achieve $(1 + α)$ approximation in amortized $O(α^{-1} + m \log d)$ time. Our approach is beneficial for sparse data where $m \ll d$. In our experiments we find almost-optimal splits efficiently, faster than the baseline, overperforming the theoretical approximation guarantees.

</details>


### [323] [Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization](https://arxiv.org/abs/2601.12604)
*Safwan Labbi,Daniil Tiapkin,Paul Mangold,Eric Moulines*

Main category: cs.LG

TL;DR: 提出基于广义f-softargmax的策略参数化方法替代softmax，结合f-散度正则化，无需预条件即可获得有限MDP中随机策略梯度方法的显式非渐近最后迭代收敛保证。


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法对策略参数化选择高度敏感，传统softmax参数化会导致病态优化景观和指数级慢收敛。虽然预条件可以缓解，但计算成本高。需要寻找更优的参数化方案。

Method: 提出使用广义f-softargmax作为策略参数化替代softmax，并结合相同f-散度诱导的正则化器。该方法改善优化景观，确保正则化目标满足Polyak-Lojasiewicz不等式。

Result: 首次为有限MDP的随机策略梯度方法建立了无需预条件的显式非渐近最后迭代收敛保证。对于无正则化问题，推导了样本复杂度边界，显示f-PG（使用Tsallis散度）实现多项式样本复杂度，而标准softmax参数化需要指数复杂度。

Conclusion: f-softargmax参数化结合f-散度正则化提供了比传统softmax更优的优化特性，实现了无需预条件的收敛保证和多项式样本复杂度，显著改进了策略梯度方法的收敛性能。

Abstract: Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.

</details>


### [324] [What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes](https://arxiv.org/abs/2601.12612)
*Piyush Sao*

Main category: cs.LG

TL;DR: 基于矩阵迹幂 $p_k = \tr(A^k)$ 估计对称正定矩阵对数行列式 $\log\det(A)$ 的新方法，通过矩生成函数变换和插值技术，提供点估计和可证明的上下界


<details>
  <summary>Details</summary>
Motivation: 高斯过程推断和贝叶斯模型比较中需要计算大规模对称正定矩阵的对数行列式。传统方法结合矩阵-向量乘积和多项式逼近，本文研究当矩阵幂运算可用时，利用迹幂 $p_k = \tr(A^k)$ 这一不同模型

Method: 将问题转化为估计矩生成函数 $M(t) = \E[X^t]$ 在 $t=0$ 处的导数，其中 $X = λ/\AM$ 为归一化特征值。通过变换 $K(t) = \log M(t)$ 压缩范围，利用 $K(0) = K(1) = 0$ 作为锚点，在 $m+1$ 个连续整数点插值 $K$ 并求导估计 $K'(0)$。同时从相同迹信息推导对数行列式的上下界

Result: 证明了基于有限正矩的连续估计器无法在无界条件数下保持均匀精度，提出了基于谱下界 $r \leq λ_{\min}$ 的矩约束下界，形成 $\log\det(A)$ 的可证明区间。所有估计器和边界计算成本为 $O(m)$，对于 $m \in \{4, \ldots, 8\}$ 几乎是常数时间

Conclusion: 该方法为基于迹幂的对数行列式计算提供了理论框架，包含点估计和可证明边界，通过间隙诊断指示何时信任点估计、何时报告边界，在矩阵幂运算可用时提供高效可靠的对数行列式估计

Abstract: Computing $\log\det(A)$ for large symmetric positive definite matrices arises in Gaussian process inference and Bayesian model comparison. Standard methods combine matrix-vector products with polynomial approximations. We study a different model: access to trace powers $p_k = \tr(A^k)$, natural when matrix powers are available.
  Classical moment-based approximations Taylor-expand $\log(λ)$ around the arithmetic mean. This requires $|λ- \AM| < \AM$ and diverges when $κ> 4$. We work instead with the moment-generating function $M(t) = \E[X^t]$ for normalized eigenvalues $X = λ/\AM$. Since $M'(0) = \E[\log X]$, the log-determinant becomes $\log\det(A) = n(\log \AM + M'(0))$ -- the problem reduces to estimating a derivative at $t = 0$. Trace powers give $M(k)$ at positive integers, but interpolating $M(t)$ directly is ill-conditioned due to exponential growth. The transform $K(t) = \log M(t)$ compresses this range. Normalization by $\AM$ ensures $K(0) = K(1) = 0$. With these anchors fixed, we interpolate $K$ through $m+1$ consecutive integers and differentiate to estimate $K'(0)$. However, this local interpolation cannot capture arbitrary spectral features.
  We prove a fundamental limit: no continuous estimator using finitely many positive moments can be uniformly accurate over unbounded conditioning. Positive moments downweight the spectral tail; $K'(0) = \E[\log X]$ is tail-sensitive. This motivates guaranteed bounds. From the same traces we derive upper bounds on $(\det A)^{1/n}$. Given a spectral floor $r \leq λ_{\min}$, we obtain moment-constrained lower bounds, yielding a provable interval for $\log\det(A)$. A gap diagnostic indicates when to trust the point estimate and when to report bounds. All estimators and bounds cost $O(m)$, independent of $n$. For $m \in \{4, \ldots, 8\}$, this is effectively constant time.

</details>


### [325] [Explanation Multiplicity in SHAP: Characterization and Assessment](https://arxiv.org/abs/2601.12654)
*Hyunseung Hwang,Seungeun Lee,Lucas Rosenblatt,Julia Stoyanovich,Steven Euijong Whang*

Main category: cs.LG

TL;DR: SHAP解释存在多重性：即使输入、任务和训练模型固定，多次运行也会产生显著不同的特征归因解释，这种内部有效但实质上不同的解释现象被称为"解释多重性"。


<details>
  <summary>Details</summary>
Motivation: SHAP作为高风险领域自动化决策解释的常用工具，常被视为可靠的特征驱动分析。然而，即使输入、任务和训练模型固定，SHAP解释在不同运行中仍存在显著差异，这种"解释多重性"现象需要系统研究和量化。

Method: 提出了一种表征特征归因解释多重性的方法论，区分模型训练/选择来源与解释管道内在随机性。使用幅度基距离和排序基度量评估稳定性，并推导随机基线值作为参考基准。

Result: 发现解释多重性普遍存在且持续存在于高置信度预测中。幅度基距离可能接近零，而排序基度量揭示top特征身份和排序的显著变化，表明稳定性度量需与解释使用意图匹配。

Conclusion: SHAP解释的多重性普遍存在，需要开发与解释预期用途相匹配的度量和基线，以确保解释的可靠性和实用性，特别是在高风险决策场景中。

Abstract: Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.

</details>


### [326] [MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning](https://arxiv.org/abs/2601.12680)
*Zheng Fang,Wolfgang Mayer,Zeyu Zhang,Jian Wang,Hong-Yu Zhang,Wanli Li,Zaiwen Feng*

Main category: cs.LG

TL;DR: 提出MetaToolAgent（MTA）元学习方法，通过跨155个工具、7个领域的数据集训练，提升大语言模型在未见工具上的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有工具选择方法局限于有限工具集，难以泛化到实际部署中遇到的新工具，需要提升大语言模型在动态工具协调中的跨工具泛化能力

Method: 提出MetaToolAgent（MTA）元学习方法，构建包含7个领域、155个工具、9,377个问答对的综合数据集，模拟真实集成场景

Result: 实验结果显示MTA在未见工具上显著优于基线方法，证明了其在构建灵活可扩展系统方面的潜力

Conclusion: MTA通过元学习方法有效提升了大语言模型在动态工具协调中的跨工具泛化能力，为构建灵活可扩展的系统提供了有前景的解决方案

Abstract: Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.

</details>


### [327] [PAC-Private Responses with Adversarial Composition](https://arxiv.org/abs/2601.14033)
*Xiaochen Zhu,Mayuri Sridhar,Srinivas Devadas*

Main category: cs.LG

TL;DR: 论文提出一种基于PAC隐私的API模型输出隐私保护方法，通过控制互信息实现实例级隐私，支持对抗性自适应查询的线性组合，在极小的每查询隐私预算下保持高模型效用。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型通常通过API部署，传统的权重隐私方法（如DP-SGD）在API场景下会产生不必要的噪声并降低效用。模型权重对训练数据敏感，但模型对特定输入的输出维度更低且更稳定，因此直接在模型输出上实施隐私保护更为有效。

Method: 采用PAC隐私框架，通过控制互信息为任意黑盒函数提供实例级隐私保证。提出新算法通过自适应噪声校准实现对抗性组合，证明互信息保证在自适应和对抗性查询下线性累积。该方法特别奖励输出稳定性以减少噪声水平。

Result: 在表格、视觉和NLP任务上实验显示，该方法在极小的每查询隐私预算下实现高效用。在CIFAR-10上达到87.79%准确率，每步互信息预算仅2^{-32}。服务100万查询时，成员推理攻击成功率上限为51.08%，相当于(0.04, 10^{-5})-DP保证。通过私有响应标注公共数据蒸馏出可发布的隐私保护模型，在ImageNet子集上使用210,000个响应蒸馏的模型在CIFAR-10上达到91.86%准确率，MIA成功率上限50.49%，相当于(0.02,10^{-5})-DP。

Conclusion: 该方法在API部署场景下有效平衡隐私与效用，通过输出级隐私保护避免传统权重隐私方法的噪声问题，支持大规模对抗性查询组合，并能蒸馏出高性能的隐私保护模型，为实际部署提供了实用解决方案。

Abstract: Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.
  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.
  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.

</details>


### [328] [Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization](https://arxiv.org/abs/2601.12707)
*Junyi Liao,Zihan Zhu,Ethan Fang,Zhuoran Yang,Vahid Tarokh*

Main category: cs.LG

TL;DR: 提出一个统一框架用于在两人零和矩阵博弈和马尔可夫博弈中恢复未知奖励函数，利用熵正则化和量化响应均衡解决逆问题的模糊性和数据覆盖有限问题。


<details>
  <summary>Details</summary>
Motivation: 估计驱动智能体行为的未知奖励函数是逆强化学习和博弈论的核心问题。该任务面临逆问题固有的模糊性、可行奖励的非唯一性以及观测数据覆盖有限等挑战。

Method: 建立基于量化响应均衡的奖励函数可识别性理论框架，提出从观测动作学习奖励函数的新算法，适用于静态和动态设置，可结合最大似然估计等方法。

Result: 为算法提供了可靠性和样本效率的强理论保证，并通过大量数值研究证明了框架的实际有效性，为竞争环境中的决策提供了新见解。

Conclusion: 开发了一个统一框架用于在熵正则化两人零和博弈中恢复奖励函数，解决了逆问题的挑战，为理解竞争环境中的决策行为提供了理论和实践基础。

Abstract: Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.

</details>


### [329] [Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off](https://arxiv.org/abs/2601.12730)
*Zhaochun Li,Chen Wang,Jionghao Bai,Shisheng Cui,Ge Lan,Zhou Zhao,Yue Wang*

Main category: cs.LG

TL;DR: 提出分布中心策略优化(DCPO)解决强化学习中探索-利用权衡问题，通过分布级正则化控制熵衰减，相比传统样本中心方法提升约20%性能


<details>
  <summary>Details</summary>
Motivation: 现有GRPO等强化学习方法存在过度利用倾向：熵单调下降、样本收敛、探索消失。现有修复方法多为样本中心式，依赖稀有样本的"运气"，缺乏对策略的原则性控制，效果有限且不稳定

Method: 提出分布中心视角，将探索视为由"更好"目标分布引导，将熵调控重新表述为分布级正则化。DCPO完全在策略内实现可控熵，无需从外部分布采样，实现高效探索同时保持训练稳定性

Result: 在多个模型和七个基准测试中，DCPO相比GRPO平均提升约20%。提供理论依据和灵活框架，实现可控探索和更强的探索-利用权衡

Conclusion: DCPO用分布级原则替代样本级启发式方法，为可控探索提供理论基础和灵活框架，显著改善大语言模型强化学习中的探索-利用权衡问题

Abstract: The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the "luck" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \textbf{distribution-centric} perspective for RL, in which exploration is always guided by a "better" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in https://github.com/597358816/DCPO.

</details>


### [330] [A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining](https://arxiv.org/abs/2601.12751)
*Manjish Pal*

Main category: cs.LG

TL;DR: 提出基于布尔函数理论的GNN表达能力新框架，引入子群体布尔同构概念，超越现有表达能力度量，识别表达能力关键障碍，设计处理高复杂度布尔函数子群体的公平算法


<details>
  <summary>Details</summary>
Motivation: 现有GNN表达能力度量（如WL、双连通性、同态框架）无法精细分析GNN捕捉复杂子群体结构的能力，特别是在公平性场景中处理高复杂度布尔函数定义的子群体时存在局限

Method: 提出基于布尔函数理论的表达能力框架，引入子群体布尔同构概念；识别傅里叶度、电路类（AC⁰、NC¹）和影响力作为表达能力关键障碍；设计基于电路遍历的公平算法处理高复杂度布尔函数定义的子群体

Result: 理论证明SBI严格包含现有表达能力度量；实验显示该方法在现实世界图上能实现跨交集群体的低公平性差距，而现有方法失败；首次为公平性量身定制GNN表达能力的原理性处理

Conclusion: 提出的布尔函数理论框架为GNN表达能力提供了更精细的分析工具，特别适用于公平性场景；SBI概念超越现有度量，基于电路遍历的算法能有效处理高复杂度子群体，为公平性GNN设计提供了理论基础

Abstract: We propose a novel expressivity framework for Graph Neural Networks (GNNs) grounded in Boolean function theory, enabling a fine-grained analysis of their ability to capture complex subpopulation structures. We introduce the notion of \textit{Subpopulation Boolean Isomorphism} (SBI) as an invariant that strictly subsumes existing expressivity measures such as Weisfeiler-Lehman (WL), biconnectivity-based, and homomorphism-based frameworks. Our theoretical results identify Fourier degree, circuit class (AC$^0$, NC$^1$), and influence as key barriers to expressivity in fairness-aware GNNs. We design a circuit-traversal-based fairness algorithm capable of handling subpopulations defined by high-complexity Boolean functions, such as parity, which break existing baselines. Experiments on real-world graphs show that our method achieves low fairness gaps across intersectional groups where state-of-the-art methods fail, providing the first principled treatment of GNN expressivity tailored to fairness.

</details>


### [331] [Distilling Time Series Foundation Models for Efficient Forecasting](https://arxiv.org/abs/2601.12785)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Szu-Yu Chen,Yingli Tian*

Main category: cs.LG

TL;DR: DistilTS是首个专门为时间序列基础模型设计的知识蒸馏框架，通过解决任务难度差异和架构差异两大挑战，实现模型压缩同时保持预测性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型虽然预测性能强，但参数量大导致部署成本高。现有通用知识蒸馏方法不适用于时间序列预测的特殊性，需要专门设计的蒸馏框架。

Method: 提出DistilTS框架：1) 针对任务难度差异，引入horizon-weighted objectives平衡不同预测时长的学习；2) 针对架构差异，设计temporal alignment strategy减少架构不匹配。通过这两个核心机制实现有效的模型压缩。

Result: 在多个基准测试中，DistilTS实现了与完整规模TSFMs相当的预测性能，同时将参数减少高达1/150，推理速度提升高达6000倍。

Conclusion: DistilTS是首个专门为时间序列基础模型设计的蒸馏框架，有效解决了任务难度差异和架构差异两大挑战，实现了高效的时间序列模型压缩，为实际部署提供了可行方案。

Abstract: Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.

</details>


### [332] [Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs](https://arxiv.org/abs/2601.12807)
*Zixing Song,Irwin King*

Main category: cs.LG

TL;DR: SIT-Graph：一种用于图学习的半监督指令调优框架，通过迭代自训练利用未标记节点增强LLMs在图学习任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有图指令调优方法需要大量带标签节点构建(指令,输出)对，这在社交等领域成本高昂且难以获取；同时未能充分利用未标记节点中因边连接产生的潜在相关性

Method: 提出模型无关的SIT-Graph框架：1) 初始仅用标记节点指令对微调模型；2) 为未标记节点生成置信度过滤的伪响应；3) 迭代自训练逐步对齐LLM与底层节点相关性

Result: 将SIT-Graph集成到最先进的图指令调优方法中，在文本属性图基准测试中显著提升性能，在低标签比例设置下获得超过20%的改进

Conclusion: SIT-Graph有效解决了图指令调优中标签稀缺问题，通过利用未标记节点的潜在相关性显著提升LLMs在图学习任务中的性能，且具有模型无关的通用性

Abstract: The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.

</details>


### [333] [Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates](https://arxiv.org/abs/2601.12859)
*Luca Schaufelberger,Aline Hartgers,Kjell Jorner*

Main category: cs.LG

TL;DR: PuckerFlow是一种基于流匹配的生成机器学习模型，专门用于环状分子的构象生成，通过Cremer-Pople空间确保生成有效闭环结构，在多样性和精确性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 环状分子在化学和生物学应用中普遍存在，其受限的构象柔性提供了结构预组织性，这对药物发现和催化中的功能至关重要。然而，可靠地采样环系统的构象集合仍然具有挑战性。

Method: 引入PuckerFlow生成模型，在Cremer-Pople空间上执行流匹配。Cremer-Pople空间是一个低维内部坐标系，能够捕捉环的相关自由度。这种方法能够设计生成有效的闭环结构。

Result: PuckerFlow在几乎所有定量指标上都优于其他构象生成方法，展示了在生成构象的多样性和精确性方面的强大性能。特别展示了PuckerFlow在催化、药物发现等化学应用相关环系统中的潜力。

Conclusion: 这项工作实现了环状结构的高效可靠构象生成，为建模结构-性质关系以及跨化学和生物学广泛应用的属性引导环生成铺平了道路。

Abstract: Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.

</details>


### [334] [AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs](https://arxiv.org/abs/2601.12893)
*Ting Dang,Soumyajit Chatterjee,Hong Jia,Yu Wu,Flora Salim,Fahim Kawsar*

Main category: cs.LG

TL;DR: AdaNODEs：一种针对时间序列预测的源无关测试时自适应方法，利用神经常微分方程处理分布偏移，仅需更新有限参数即可显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时自适应方法主要针对独立数据设计，忽略了时间序列数据的特性，且很少处理预测任务。时间序列数据中的分布偏移问题需要专门的自适应方法。

Method: 提出AdaNODEs方法，利用神经常微分方程构建自适应框架，专门处理时间序列数据的分布偏移特性。创新性地设计了新的损失函数来处理预测任务的测试时自适应，仅需更新有限模型参数以减少内存使用。

Result: 在一维和高维数据上的广泛实验表明，AdaNODEs相对于最先进的基线方法分别实现了5.88%和28.4%的相对改进，在更高严重程度的分布偏移下表现出更强的鲁棒性。

Conclusion: AdaNODEs是一种有效的源无关测试时自适应方法，专门针对时间序列预测任务设计，能够有效处理时间序列数据中的分布偏移问题，同时保持较低的计算和内存开销。

Abstract: Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\% and 28.4\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.

</details>


### [335] [Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets](https://arxiv.org/abs/2601.12903)
*Meng Liu,Ke Liang,Siwei Wang,Xingchen Hu,Sihang Zhou,Xinwang Liu*

Main category: cs.LG

TL;DR: 该论文提出了一个名为BenchTGC的全面基准测试，用于解决时间图聚类（TGC）任务面临的挑战，包括设计框架、改进现有聚类技术以及创建适合TGC的数据集。


<details>
  <summary>Details</summary>
Motivation: 时间图聚类是一个新兴但关注度低的任务，相比静态图聚类，它能够通过基于交互序列的批处理模式在时间要求和空间要求之间找到平衡。然而，该领域面临两个主要挑战：不适用的聚类技术和不适用的数据集，这阻碍了TGC的发展。

Method: 提出了BenchTGC基准测试，包括：1）设计BenchTGC框架来说明时间图聚类的范式；2）改进现有聚类技术以适应时间图；3）讨论公共时间图数据集的问题，并开发多个适合TGC任务的数据集（BenchTGC数据集）。

Result: 通过大量实验验证了BenchTGC的优势，并证明了时间图聚类任务的必要性和重要性。实验结果表明，现实世界中动态变化和复杂的场景是时间图聚类的基础。

Conclusion: BenchTGC为时间图聚类提供了一个全面的基准测试，解决了该领域的关键挑战。该工作不仅验证了TGC的优势，还强调了其在处理现实世界动态复杂场景中的重要性。代码和数据已开源。

Abstract: Temporal Graph Clustering (TGC) is a new task with little attention, focusing on node clustering in temporal graphs. Compared with existing static graph clustering, it can find the balance between time requirement and space requirement (Time-Space Balance) through the interaction sequence-based batch-processing pattern. However, there are two major challenges that hinder the development of TGC, i.e., inapplicable clustering techniques and inapplicable datasets. To address these challenges, we propose a comprehensive benchmark, called BenchTGC. Specially, we design a BenchTGC Framework to illustrate the paradigm of temporal graph clustering and improve existing clustering techniques to fit temporal graphs. In addition, we also discuss problems with public temporal graph datasets and develop multiple datasets suitable for TGC task, called BenchTGC Datasets. According to extensive experiments, we not only verify the advantages of BenchTGC, but also demonstrate the necessity and importance of TGC task. We wish to point out that the dynamically changing and complex scenarios in real world are the foundation of temporal graph clustering. The code and data is available at: https://github.com/MGitHubL/BenchTGC.

</details>


### [336] [CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction](https://arxiv.org/abs/2601.12917)
*He Sun,Jinrui Zhou,Li Li,Mingjun Xiao*

Main category: cs.LG

TL;DR: CooperLLM：云辅助的边缘端协同联邦微调框架，结合移动端的零阶优化和云端的梯度修正，显著降低内存占用并提升收敛速度和精度


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在移动设备上微调面临内存和计算成本高的挑战，现有联邦学习方法要么依赖内存密集型反向传播，要么使用收敛慢、精度低的零阶优化方法

Method: 提出CooperLLM框架：移动客户端在私有数据上执行轻量级零阶优化更新，云端在辅助公共数据上使用反向传播微调并注入引导扰动来修正本地更新；引入流水线调度和自适应压缩来重叠计算通信并减少内存使用

Result: 在多个Transformer模型和数据集上的实验表明，CooperLLM将设备内存降低高达86.4%，加速收敛8.8倍，相比最先进的零阶优化基线方法精度提升高达10个百分点

Conclusion: CooperLLM通过云辅助的协同联邦微调框架，有效解决了移动设备上LLM微调的内存和计算瓶颈，在保持隐私的同时显著提升了收敛速度和模型精度

Abstract: Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\%$, accelerates convergence by $8.8 \times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.

</details>


### [337] [An efficient heuristic for geometric analysis of cell deformations](https://arxiv.org/abs/2601.12928)
*Yaima Paz Soto,Silena Herold Garcia,Ximo Gual-Arnau,Antoni Jaume-i-Capó,Manuel González-Hidalgo*

Main category: cs.LG

TL;DR: 提出一种基于形状空间和模板对齐的镰状细胞自动分类方法，通过固定参数化和模板对齐简化计算，在保持高准确率的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 镰状细胞病导致红细胞变形，影响血液流动和氧气输送，全球患病率高且对医疗系统负担重。自动分类镰状细胞对于减少专家工作量、避免量化错误和评估危机严重性至关重要。现有形状空间方法虽准确率高但计算复杂。

Method: 将红细胞建模为形状空间中的封闭平面曲线，使用弹性距离（对旋转、平移、缩放和重参数化不变）。创新点包括：(1) 基于细胞主轴使用固定参数化计算距离；(2) 在计算距离前，使用该参数化将每个细胞与两个模板对齐。这种模板对齐策略简化了计算。

Result: 在监督分类和无监督聚类中均达到96.03%的准确率。该方法在保持或改进形状空间模型准确率的同时，显著降低了计算成本。

Conclusion: 提出的基于固定参数化和模板对齐的形状空间方法实现了高效的红细胞分类，在保持高准确率的同时大幅减少计算复杂度，为资源有限地区的镰状细胞病诊断提供了实用解决方案。

Abstract: Sickle cell disease causes erythrocytes to become sickle-shaped, affecting their movement in the bloodstream and reducing oxygen delivery. It has a high global prevalence and places a significant burden on healthcare systems, especially in resource-limited regions. Automated classification of sickle cells in blood images is crucial, allowing the specialist to reduce the effort required and avoid errors when quantifying the deformed cells and assessing the severity of a crisis. Recent studies have proposed various erythrocyte representation and classification methods. Since classification depends solely on cell shape, a suitable approach models erythrocytes as closed planar curves in shape space. This approach employs elastic distances between shapes, which are invariant under rotations, translations, scaling, and reparameterizations, ensuring consistent distance measurements regardless of the curves' position, starting point, or traversal speed. While previous methods exploiting shape space distances had achieved high accuracy, we refined the model by considering the geometric characteristics of healthy and sickled erythrocytes. Our method proposes (1) to employ a fixed parameterization based on the major axis of each cell to compute distances and (2) to align each cell with two templates using this parameterization before computing distances. Aligning shapes to templates before distance computation, a concept successfully applied in areas such as molecular dynamics, and using a fixed parameterization, instead of minimizing distances across all possible parameterizations, simplifies calculations. This strategy achieves 96.03\% accuracy rate in both supervised classification and unsupervised clustering. Our method ensures efficient erythrocyte classification, maintaining or improving accuracy over shape space models while significantly reducing computational costs.

</details>


### [338] [PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning](https://arxiv.org/abs/2601.13020)
*Zhiyan Hou,Haiyun Guo,Haokai Ma,Yandu Sun,Yonghui Yang,Jinqiao Wang*

Main category: cs.LG

TL;DR: 提出PASs（路径激活子空间）方法解决持续指令调优中的专家共漂移问题，通过路径激活信号校准路由并稳定重要秩方向，在保持参数不变的情况下提升准确性和抗遗忘能力


<details>
  <summary>Details</summary>
Motivation: 现有基于LoRA的MoE方法在持续指令调优中，路由器和专家会共同漂移，导致早期输入-专家专业化逐渐偏离，形成"错位共漂移"现象，模糊专家职责并加剧遗忘问题

Method: 提出路径激活子空间（PASs）作为能力对齐的坐标系统，基于此开发PASs-MoE-LoRA方法，包含：1）PAS引导重加权：利用专家路径激活信号校准路由；2）PAS感知秩稳定化：选择性稳定对先前任务重要的秩方向

Result: 在持续指令调优基准测试中，该方法在准确性和抗遗忘方面均优于传统持续学习基线和多种MoE-LoRA变体，且不增加额外参数

Conclusion: PASs方法通过解耦路由器和专家的更新过程，有效解决了错位共漂移问题，为多模态大语言模型的持续指令调优提供了更可靠的专家专业化保持机制

Abstract: Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.

</details>


### [339] [Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis](https://arxiv.org/abs/2601.13021)
*Nataša Petrović,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Jose Maria Buades Rubio*

Main category: cs.LG

TL;DR: 提出一种基于集成学习的镰状细胞病诊断支持系统，通过特征选择和模型优化实现泛化能力提升，在镰状细胞病外周血涂片图像分类上取得优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 为镰状细胞病提供基于外周血涂片图像的自动化诊断支持系统，重点解决现有方法泛化能力不足、模型可解释性差以及特征冗余导致复杂度高的问题。

Method: 1) 对显微图像进行预处理和分割以确保高质量特征提取；2) 采用集成机器学习方法（随机森林和极端随机树）进行细胞形态分类；3) 设计特征重要性分析方法以降低复杂度、减少训练时间并增强模型可解释性；4) 在新数据集上验证模型泛化能力。

Result: 随机森林和极端随机树的集成分类器获得F1分数90.71%和SDS分数93.33%，显著优于梯度提升分类器的87.32%和89.51%。模型在新数据集上表现出优于现有方法的泛化性能，相关代码、参数和混淆矩阵数据已公开。

Conclusion: 所提出的集成学习方法在镰状细胞病诊断支持中表现出优异的分类性能和泛化能力，通过特征选择有效降低了模型复杂度并增强了可解释性，为临床诊断提供了可靠的工具。

Abstract: This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\% and SDS-score 89.51\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.

</details>


### [340] [TinyML-Enabled IoT for Sustainable Precision Irrigation](https://arxiv.org/abs/2601.13054)
*Kamogelo Taueatsoala,Caitlyn Daniels,Angelina J. Ramsunar,Petrus Bronkhorst,Absalom E. Ezugwu*

Main category: cs.LG

TL;DR: 本文提出了一种面向小规模农业的边缘优先物联网框架，集成TinyML实现离线精准灌溉，显著降低水资源消耗。


<details>
  <summary>Details</summary>
Motivation: 小规模农业社区面临水资源短缺、气候模式不稳定以及缺乏先进、经济实惠的农业技术等问题。传统灌溉方法效率低下，且依赖云计算的解决方案在互联网连接有限的农村地区不可行。

Method: 采用四层架构：1) 传感器层（土壤湿度、温度、湿度、pH、环境光）；2) ESP32微控制器作为边缘推理节点运行TinyML模型；3) Raspberry Pi作为本地边缘服务器；4) MQTT局域网协议实现本地通信。通过比较集成模型，选择梯度提升作为最优模型，并将其转换为轻量级TinyML推理引擎部署在ESP32上。

Result: 梯度提升模型表现最佳，R²得分0.9973，MAPE为0.99%，优于随机森林模型（R²=0.9916，MAPE=1.81%）。部署后系统预测灌溉需求的MAPE<1%。在受控环境中验证显示，相比传统方法显著减少用水量。系统低功耗设计和离线功能证实其在资源受限农村环境中的可行性。

Conclusion: 该边缘优先物联网框架为小规模农业提供了一种实用、经济高效的解决方案，通过设备端人工智能提升水资源利用效率，弥合农业技术鸿沟，适用于互联网连接有限的农村地区。

Abstract: Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.

</details>


### [341] [METIS: Mentoring Engine for Thoughtful Inquiry & Solutions](https://arxiv.org/abs/2601.13075)
*Abhinav Rajeev Kumar,Dhruv Trehan,Paras Chopra*

Main category: cs.LG

TL;DR: METIS是一个工具增强、阶段感知的AI导师系统，旨在帮助本科生从研究想法发展到完整论文，在多个评估维度上优于GPT-5和Claude Sonnet 4.5。


<details>
  <summary>Details</summary>
Motivation: 许多学生缺乏专家研究指导，需要AI导师帮助他们从研究想法发展到完整论文，解决研究指导资源不足的问题。

Method: 构建METIS系统，包含文献搜索、精选指南、方法学检查和记忆功能，采用工具增强和阶段感知架构。评估方法包括：LLM作为评判者的成对偏好比较、学生角色评分标准、短多轮辅导对话、证据/合规性检查，覆盖六个写作阶段。

Result: 在90个单轮提示中，LLM评判者偏好METIS超过Claude Sonnet 4.5（71%）和GPT-5（54%）。学生评分（清晰度/可操作性/约束适应性）在所有阶段均更高。在多轮会话中，METIS产生的最终质量略高于GPT-5。优势集中在文档基础阶段（D-F），与阶段感知路由和基础功能一致。

Conclusion: METIS作为AI研究导师在帮助学生从想法发展到论文方面表现优异，特别是在文档基础阶段。失败模式包括过早工具路由、浅层基础和偶尔的阶段分类错误，为未来改进提供了方向。

Abstract: Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.

</details>


### [342] [Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement](https://arxiv.org/abs/2601.13100)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 提出递归元蒸馏的算子理论框架，证明在温和条件下递归蒸馏会诱导KL散度收缩，几何收敛到基础教师分布，存在唯一全局吸引不动点。


<details>
  <summary>Details</summary>
Motivation: 当前概率域知识蒸馏研究已建立温度缩放、多教师聚合和单阶段偏差-方差权衡的公理化框架，但递归或多代蒸馏的数学行为理解不足，先前方法主要依赖经验启发式。

Method: 引入递归元蒸馏的公理化和算子理论框架，将迭代知识蒸馏形式化为概率分布算子序列，并明确锚定到基础教师。定义有效元教师构建的结构公理，证明满足这些公理的非平凡算子族存在性。

Result: 在温和可实现性和凸性假设下，锚定递归蒸馏诱导KL散度收缩，产生几何收敛到基础教师分布，存在唯一全局吸引不动点。框架独立于模型架构、优化细节或具体算子实例化。

Conclusion: 该框架是基础性而非算法性的贡献，刻画了递归蒸馏何时数学适定且收敛而非误差累积，为理解容量约束下迭代和多教师蒸馏的稳定性、偏差-方差行为和失效模式提供理论基础。

Abstract: Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.
  We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.
  The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.

</details>


### [343] [FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference](https://arxiv.org/abs/2601.13143)
*Chaeyoung Jung,Youngjoon Jang,Seungwoo Lee,Joon Son Chung*

Main category: cs.LG

TL;DR: FastAV是首个为音频-视觉大语言模型设计的令牌剪枝框架，通过两阶段剪枝策略减少40%以上FLOPs，同时保持或提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 虽然令牌剪枝在标准LLMs和视觉-语言模型中已有探索，但在音频-视觉大语言模型中的应用尚未受到关注。多模态整合显著增加了这些模型的令牌需求，因此需要专门的剪枝方法来解决计算效率问题。

Method: 提出基于注意力权重的剪枝策略：1）利用注意力权重识别不同阶段被强调的令牌并评估其重要性；2）采用两阶段剪枝：中间层进行全局剪枝去除广泛影响力较小的令牌，后期层进行精细剪枝考虑对下一个令牌生成的影响。该方法不依赖完整注意力图，与FlashAttention等高效注意力机制完全兼容。

Result: 在两种代表性AV-LLMs上的广泛实验表明，FastAV能够减少超过40%的FLOPs，同时保持甚至提升模型性能。

Conclusion: FastAV是首个专门为AV-LLMs设计的令牌剪枝框架，通过创新的两阶段剪枝策略有效解决了多模态模型的计算效率问题，为高效音频-视觉处理提供了实用解决方案。

Abstract: In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.

</details>


### [344] [Training instability in deep learning follows low-dimensional dynamical principles](https://arxiv.org/abs/2601.13160)
*Zhipeng Zhang,Zhenjie Yao,Kai Li,Lei Yang*

Main category: cs.LG

TL;DR: 论文提出训练稳定性作为学习系统的内在动态特性，通过四维框架（优化、环境/数据、参数、学习信号）和受控扰动审计方法，揭示训练过程中的规律性模式


<details>
  <summary>Details</summary>
Motivation: 深度学习系统虽然取得显著经验性能，但训练过程本身的稳定性仍未被充分理解。训练作为高维动态系统，对优化、数据、参数或学习信号的微小扰动可能导致突然且不可逆的崩溃，损害可重复性和可扩展性

Method: 提出统一的动态视角，将训练稳定性组织为四个相互作用维度：优化稳定性、环境/数据稳定性、参数稳定性、学习信号稳定性。通过受控扰动审计训练轨迹来操作化这一视角，在不修改学习算法的情况下探测学习动态对结构化扰动的响应

Result: 在强化学习和大型语言模型训练中识别出三个重复出现的规律：1）最终高性能常与训练稳定性脱钩；2）受控随机性在不同范式中一致地缓冲学习动态；3）低维潜在元状态的偏差系统地先于可观察的性能崩溃

Conclusion: 训练稳定性是学习系统可测量和可比较的动态特性，为超越最终性能结果研究学习动态提供了描述性基础

Abstract: Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.
  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.
  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.

</details>


### [345] [LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations](https://arxiv.org/abs/2601.13190)
*Vittoria De Pellegrini,Tariq Alkhalifah*

Main category: cs.LG

TL;DR: LAViG-FLOW：一种用于地下多相流体流动建模的潜在自回归视频生成扩散框架，能够快速生成饱和度与压力场的耦合演化，比传统数值求解器快几个数量级。


<details>
  <summary>Details</summary>
Motivation: 高保真多相模拟器在需要大量前向运行进行反演和不确定性量化时计算成本过高，限制了地质CO2封存等地学应用中的建模与预测能力。

Method: 提出LAViG-FLOW框架：使用专用2D自编码器压缩每个状态变量，通过视频扩散变换器(VDiT)建模它们在时间上的耦合分布，先在给定时间范围内训练学习耦合关系，然后通过自回归微调实现超出观测时间窗口的外推。

Result: 在开源CO2封存数据集上评估，LAViG-FLOW生成的饱和度与压力场在时间上保持一致性，运行速度比传统数值求解器快几个数量级。

Conclusion: LAViG-FLOW为地下多相流体流动建模提供了一种高效替代方案，显著降低了计算成本，同时保持了物理场的时间一致性，适用于需要大量模拟的地学应用场景。

Abstract: Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.

</details>


### [346] [A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms](https://arxiv.org/abs/2601.13243)
*Yapeng Li,Jiakuo Yu,Zhixin Liu,Xinnan Liu,Jing Yu,Songze Li,Tonghua Su*

Main category: cs.LG

TL;DR: 该论文系统评估了LLM推理范式（直接生成、CoT、多智能体系统）的性能、成本-精度权衡，并引入新基准MIMeBench评估语义抽象和对比区分能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为推理系统部署时，不同推理范式（如CoT和多智能体系统）的相对有效性、成本-精度权衡缺乏系统理解，且现有基准难以评估语义能力。

Method: 1) 统一评估直接单模型生成、CoT增强单模型推理、代表性MAS工作流在封闭式基准上的性能；2) 通过角色隔离分析探究MAS中角色特定能力需求；3) 分析成本-精度权衡；4) 引入新基准MIMeBench评估语义抽象和对比区分能力。

Result: 1) 增加结构复杂性并不总能提升推理性能，其效益高度依赖于推理范式本身的特性和适用性；2) 识别了哪些MAS工作流在成本与精度间达到良好平衡，哪些因边际收益微小而成本过高；3) MIMeBench提供了现有基准难以捕捉的语义能力细粒度评估。

Conclusion: LLM推理范式的选择应基于任务特性和成本约束，结构复杂性并非总是有益；MIMeBench为评估语义能力提供了新维度；需要更细致地理解不同推理范式的适用场景和权衡。

Abstract: Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.

</details>


### [347] [Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification](https://arxiv.org/abs/2601.13272)
*Aaron Pim,Tristan Pryer*

Main category: cs.LG

TL;DR: 提出了一种基于多级蒙特卡洛（MLMC）的蒙特卡洛dropout不确定性量化框架，通过重用dropout掩码构建耦合的粗-细估计器，降低方差并提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛dropout是深度学习中常用的不确定性量化方法，但需要大量随机前向传播来估计预测矩，计算成本高。需要开发更高效的方差缩减技术来降低计算负担。

Method: 将dropout掩码视为认知随机源，通过随机前向传播次数定义保真度层次结构。重用dropout掩码构建耦合的粗-细估计器，形成用于预测均值和预测方差的可伸缩MLMC估计器。推导了显式偏差、方差和有效成本表达式，以及跨层级的样本分配规则。

Result: 在正向和逆向PINNs-Uzawa基准测试中的数值实验证实了预测的方差率，并证明了在相同计算成本下相比单级MC-dropout的效率提升。

Conclusion: 提出的MLMC框架为蒙特卡洛dropout不确定性量化提供了一种有效的方差缩减方法，通过重用dropout掩码构建耦合估计器，在保持无偏性的同时显著降低方差，提高了计算效率。

Abstract: We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.

</details>


### [348] [Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning](https://arxiv.org/abs/2601.13284)
*Duygu Nur Yaldiz,Evangelia Spiliopoulou,Zheng Qi,Siddharth Varia,Srikanth Doss,Nikolaos Pappas*

Main category: cs.LG

TL;DR: 本文系统研究了LLM在监督微调(SFT)和强化学习(RLVR)两种微调范式下的校准问题，发现RLVR虽然提升任务性能但产生过度自信模型，而SFT校准更好但性能增益较小。作者提出校准感知的强化学习方法，在保持RLVR准确性的同时显著降低过度自信。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地应用于决策任务，不仅需要准确性，还需要可靠的置信度估计。良好校准的置信度使下游系统能够决定何时信任模型、何时依赖备用机制。然而，当前对两种主流微调范式（监督微调和强化学习）的校准特性缺乏系统研究。

Method: 1. 系统研究SFT和RLVR两种微调范式的校准特性；2. 通过针对性实验诊断RLVR失败原因，发现决策令牌在推理轨迹中仅作为决策提取步骤，不携带置信度信息；3. 提出校准感知的强化学习公式，直接调整决策令牌概率。

Result: 1. RLVR提高任务性能但产生极度过度自信模型；2. SFT产生显著更好的校准，即使在分布偏移下也如此，但性能增益较小；3. 提出的校准感知强化学习方法在保持RLVR准确性水平的同时减轻过度自信，将ECE分数降低高达9个点。

Conclusion: 强化学习微调虽然能提升任务性能，但会导致模型过度自信，而监督微调则能提供更好的校准特性。通过理解决策令牌在推理中的作用机制，可以设计校准感知的强化学习方法，在保持性能优势的同时改善校准质量。

Abstract: Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.

</details>


### [349] [Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans](https://arxiv.org/abs/2601.13350)
*Abdel Djalil Sad Saoud,Fred Maurice Ngolè Mboula,Hanane Slimani*

Main category: cs.LG

TL;DR: 提出基于谱嵌入的域不变表示学习方法，将平滑传输计划解释为二分图邻接矩阵，用于解决训练与推理数据分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 训练与推理数据之间的分布偏移是机器学习中的核心挑战，会导致性能下降。现有的基于最优传输的无监督域自适应方法依赖于使用传输计划近似Monge映射，但这种方法对传输问题正则化策略和超参数敏感，可能导致有偏的域对齐。

Method: 将平滑传输计划解释为连接源域和目标域的二分图的邻接矩阵，通过谱嵌入推导域不变样本表示。该方法避免了直接近似Monge映射的敏感性问题。

Result: 在音乐流派识别、音乐-语音区分以及不同诊断设置下使用时域反射的电缆缺陷检测和分类任务上进行了评估，取得了整体强劲的性能表现。

Conclusion: 提出的基于谱嵌入的方法能够有效处理域自适应问题，通过将传输计划转化为图结构并提取谱特征，实现了更鲁棒的域不变表示学习。

Abstract: Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.

</details>


### [350] [Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility](https://arxiv.org/abs/2601.13398)
*Nickil Maveli,Antonio Vergari,Shay B. Cohen*

Main category: cs.LG

TL;DR: RTCE是一个评估代码LLM往返执行一致性的基准，通过四个代码执行推理任务测试模型在正向和反向执行中保持一致性映射的能力，发现现有模型在往返一致性方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在代码基准测试中表现良好，但在往返代码执行中显示出在正向和反向执行间保持一致性推理的局限性，需要系统评估模型是否能在编码和解码操作间保持一致的映射关系。

Method: 提出RoundTripCodeEval（RTCE）基准，包含四个不同的代码执行推理任务，采用免执行的精确匹配评估方法测试双射保真度，通过零样本提示、监督微调执行轨迹和自反思机制系统评估最先进的代码LLM。

Result: 所有评估方法（零样本提示、监督微调和自反思机制）都只带来适度改进，但都无法弥补差距，表明当前LLM在真正的往返一致性方面存在困难，缺乏可信代码推理所需的内在一致性。

Conclusion: RTCE揭示了现有I/O预测、执行推理或往返自然语言基准无法捕捉的新见解，表明当前LLM缺乏可信代码推理所需的内在一致性，往返一致性是评估代码LLM可靠性的重要维度。

Abstract: LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.

</details>


### [351] [A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization](https://arxiv.org/abs/2601.13435)
*Shuozhe Li,Du Cheng,Leqi Liu*

Main category: cs.LG

TL;DR: WaveLSFormer：一种可学习的小波长短期Transformer，用于金融时间序列的日内交易策略学习，通过端到端训练的小波分解和多尺度信息融合，在多个行业组上实现了显著优于基准模型的收益和风险调整回报。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列的日内交易策略学习面临三大挑战：1）噪声严重；2）非平稳性；3）相关资产间的强横截面依赖性。传统方法难以有效处理这些复杂特性，需要一种能够联合执行多尺度分解和收益导向决策学习的新型架构。

Method: 提出WaveLSFormer模型，包含三个核心组件：1）可学习小波前端：通过端到端训练的滤波器组生成低/高频分量，使用频谱正则化器确保稳定且分离良好的频带；2）低频引导高频注入（LGHI）模块：用高频线索精炼低频表示，同时控制训练稳定性；3）Transformer主干：处理多尺度信息并输出多空头寸组合，通过风险预算重缩放，直接使用交易目标和风险感知正则化进行优化。

Result: 在5年小时数据、6个行业组、10个随机种子的广泛实验中，WaveLSFormer始终优于MLP、LSTM和Transformer基准模型（无论是否使用固定离散小波前端）。在所有行业平均中，WaveLSFormer实现了0.607±0.045的累计总策略收益和2.157±0.166的夏普比率，显著提高了盈利能力和风险调整回报。

Conclusion: WaveLSFormer通过可学习的小波分解和创新的多尺度融合机制，有效解决了金融时间序列交易中的噪声、非平稳性和横截面依赖问题，为日内交易策略学习提供了强大的端到端框架，在收益和风险调整表现上均显著优于现有方法。

Abstract: Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \pm 0.045$ and a Sharpe ratio of $2.157 \pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.

</details>


### [352] [Fairness-informed Pareto Optimization : An Efficient Bilevel Framework](https://arxiv.org/abs/2601.13448)
*Sofiane Tanji,Samuel Vaiter,Yassine Laguel*

Main category: cs.LG

TL;DR: BADR是一个双层自适应重标量化框架，用于为任何公平性指标恢复最优帕累托效率模型，解决了现有公平机器学习方法常产生帕累托无效模型的问题。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习方法存在两个主要问题：1）传统处理方法（如公平正则化）常产生帕累托无效模型，即某些群体性能可在不损害其他群体情况下提升；2）现有帕累托效率方法偏向特定公平视角，无法适应文献中广泛的公平性指标。

Method: 提出BADR（Bilevel Adaptive Rescalarisation）框架，包含双层优化：下层是加权经验风险最小化任务，权重为各群体的凸组合；上层优化所选公平性目标。开发了两种大规模单循环算法BADR-GD和BADR-SGD，并建立了收敛保证。

Result: 发布了badr开源Python工具箱，支持多种学习任务和公平性指标。大量数值实验表明BADR优于现有帕累托效率公平方法。

Conclusion: BADR提供了一个简单框架，可为任何公平性指标恢复最优帕累托效率模型，解决了现有方法的局限性，并通过开源工具和收敛保证算法实现了实用化。

Abstract: Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.

</details>


### [353] [Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay](https://arxiv.org/abs/2601.13456)
*Sahasra Kokkula,Daniel David,Aaditya Baruah*

Main category: cs.LG

TL;DR: 在联邦学习中应对时间概念漂移：通过客户端经验回放防止灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 联邦学习在时间概念漂移下表现不佳，客户端数据分布随时间变化导致标准FedAvg在季节性漂移场景中出现灾难性遗忘，准确率大幅下降

Method: 提出客户端经验回放方法，每个客户端维护一个小的历史样本缓冲区，在本地训练时将过去样本与当前数据混合，无需改变服务器聚合机制

Result: 在Fashion-MNIST数据集上，标准FedAvg准确率从74%降至28%；使用每类50个样本的缓冲区后，性能恢复至78-82%，有效防止遗忘；消融研究显示内存与准确率存在权衡关系

Conclusion: 客户端经验回放是一种简单有效的联邦学习抗遗忘方法，无需修改服务器端，通过维护小规模历史样本缓冲区即可显著缓解时间概念漂移带来的灾难性遗忘问题

Abstract: Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.

</details>


### [354] [Preconditioning Benefits of Spectral Orthogonalization in Muon](https://arxiv.org/abs/2601.13474)
*Jianhao Ma,Yu Huang,Yuejie Chi,Yuxin Chen*

Main category: cs.LG

TL;DR: 该论文通过矩阵分解和线性Transformer的上下文学习两个案例，分析了简化版Muon优化器的收敛性能，证明了其具有与条件数无关的线性收敛速度，优于梯度下降和Adam算法。


<details>
  <summary>Details</summary>
Motivation: Muon优化器作为利用梯度谱正交化的大语言模型预训练里程碑算法，其底层机制特别是梯度正交化的作用尚未得到充分理解。目前很少有工作提供端到端分析来严格解释其在具体应用中的优势。

Method: 通过研究简化版Muon变体在两个具体问题上的有效性：矩阵分解和线性Transformer的上下文学习。对这两个问题，证明了简化Muon具有与相关条件数无关的线性收敛性。

Result: 证明了简化Muon在线性Transformer上下文学习和矩阵分解问题上均具有与条件数无关的线性收敛速度，在迭代复杂度上严格优于梯度下降和Adam算法。分析揭示了Muon动力学在谱域解耦为独立标量序列。

Conclusion: 研究形式化了谱正交化诱导的预处理效应，为理解Muon在这些矩阵优化问题中的有效性提供了理论见解，并可能推广到更广泛的应用场景。

Abstract: The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.

</details>


### [355] [StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing](https://arxiv.org/abs/2601.13522)
*Shuang Li*

Main category: cs.LG

TL;DR: 提出一种基于Tucker分解的随机交替最小化算法，用于低Tucker秩张量感知问题，避免重复张量投影，实现低维张量因子的高效小批量更新。


<details>
  <summary>Details</summary>
Motivation: 低Tucker秩张量能有效捕捉高维数据中的多模态子空间结构，但现有恢复方法要么需要昂贵的张量投影，要么依赖全梯度计算，而大多数随机因子化方法仅限于张量分解场景。

Method: 提出一种随机交替最小化算法，直接在Tucker分解下的核心张量和因子矩阵上操作，避免重复张量投影，实现对低维张量因子的高效小批量更新。

Result: 在合成张量感知的数值实验中，该算法在运行时间上相比代表性随机张量恢复基线表现出更优的收敛行为。

Conclusion: 该方法为低Tucker秩张量感知提供了一种高效的计算框架，避免了传统方法的计算瓶颈，在实际应用中具有更好的时间效率。

Abstract: Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.

</details>


### [356] [MN-TSG:Continuous Time Series Generation with Irregular Observations](https://arxiv.org/abs/2601.13534)
*Xu Zhang,Junwei Deng,Chang Xu,Hao Li,Jiang Bian*

Main category: cs.LG

TL;DR: MN-TSG：基于专家混合神经控制微分方程的不规则时间序列连续生成框架


<details>
  <summary>Details</summary>
Motivation: 现有时间序列生成方法大多假设规则采样和固定输出分辨率，与现实世界中不规则采样和稀疏观测的数据不匹配，特别是在临床监测等需要连续高分辨率时间序列的应用中尤为突出。神经控制微分方程虽能建模不规则时间序列，但在捕捉复杂动态时间模式和支撑连续生成方面仍有局限。

Method: 提出MN-TSG框架，核心是MoE-NCDE架构：1）采用动态参数化的专家函数；2）解耦设计以优化MoE动态；3）利用现有TSG模型学习专家混合与生成时间序列的联合分布，使框架不仅能生成新样本，还能为每个样本生成适当的专家配置。

Result: 在10个公共和合成数据集上的广泛实验表明，MN-TSG在"不规则到规则"和"不规则到连续"生成任务中均一致优于强基线方法。

Conclusion: MN-TSG通过整合MoE-NCDE架构与现有TSG模型，有效解决了不规则采样时间序列的连续生成问题，为临床监测等现实应用提供了更实用的解决方案。

Abstract: Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.
  Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.
  The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.
  Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.

</details>


### [357] [ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits](https://arxiv.org/abs/2601.13563)
*Aryan Karmore*

Main category: cs.LG

TL;DR: ButterflyMoE通过将专家视为共享量化基质的几何重定向，而非独立权重矩阵，实现了专家数量的亚线性内存增长，在256个专家时达到150倍内存压缩。


<details>
  <summary>Details</summary>
Motivation: 传统MoE方法中，N个独立专家权重矩阵需要O(N·d²)内存，这超出了边缘设备的存储预算。现有压缩方法（量化、剪枝、低秩分解）只能减少常数因子，无法解决线性扩展瓶颈。

Method: 将专家视为共享三元原型的几何重定向，而非独立矩阵。通过对共享量化基质应用学习到的旋转，每个专家实现O(d² + N·d log d)内存。训练这些旋转与量化结合，减少了激活异常值并稳定了极端低位训练。

Result: 在语言建模基准测试中，ButterflyMoE在256个专家时实现了150倍内存压缩，精度损失可忽略。这使得64个专家可以部署在4GB设备上，而标准MoE只能容纳8个专家。

Conclusion: 几何参数化打破了MoE的线性内存扩展瓶颈，通过将专家多样性视为共享容量的不同视角，而非冗余存储，实现了亚线性内存增长，使大规模专家模型能够在资源受限设备上部署。

Abstract: Linear memory scaling stores $N$ independent expert weight matrices requiring $\mathcal{O}(N \cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\mathcal{O}(d^2 + N \cdot d \log d)$ memory -- sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150 times memory reduction at 256 experts with negligible accuracy loss. This allows 64 experts to fit on 4GB devices compared to standard MoE's 8 experts, showing geometric parametrization breaks linear scaling.

</details>


### [358] [Self-Improvement as Coherence Optimization: A Theoretical Account](https://arxiv.org/abs/2601.13566)
*Tianyi Qiu,Ahmed Hani Ismail,Zhonghao He,Shi Feng*

Main category: cs.LG

TL;DR: 论文提出语言模型无需外部监督即可自我提升的理论框架，将辩论、引导和内部一致性最大化等方法统一为一致性优化，并证明其等价于描述长度正则化


<details>
  <summary>Details</summary>
Motivation: 现有研究表明语言模型可以通过辩论、引导和内部一致性最大化等方法在没有外部监督的情况下提升准确性，甚至达到有监督微调的性能，但这些方法为何有效缺乏理论解释

Method: 提出一致性优化理论框架，将多种无监督自我提升方法统一为寻找最可压缩和联合可预测的上下文到行为映射，证明其等价于描述长度正则化，并推导出在预训练模型基础上的最优正则化方案

Result: 理论分析表明一致性优化是半监督学习中最优的正则化方案，初步实验支持理论预测，解释了无反馈自我提升为何有效，并预测了其成功和失败的条件

Conclusion: 为语言模型的无监督自我提升提供了统一的理论框架，揭示了其内在机制，为理解和改进这类方法提供了理论基础

Abstract: Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.

</details>


### [359] [Behavior Knowledge Merge in Reinforced Agentic Models](https://arxiv.org/abs/2601.13572)
*Xiangchi Yuan,Dachuan Shi,Chunhui Zhang,Zheyuan Liu,Shenglong Yao,Soroush Vosoughi,Wenke Lee*

Main category: cs.LG

TL;DR: RAM是一个专门为RL训练智能体设计的分布感知合并框架，通过解耦共享和任务特定参数更新，解决RL与SFT任务向量不匹配问题，实现智能体协同效应。


<details>
  <summary>Details</summary>
Motivation: 现有合并方法专为监督微调设计，不适用于RL训练智能体，因为RL产生的任务向量稀疏且异质，而SFT合并假设密集且全局可比，导致标准全局平均会稀释关键任务特定行为。

Method: 提出强化智能体合并(RAM)框架，解耦共享和任务特定独特参数更新，平均共享组件，同时选择性保留和重新缩放独特组件以抵消参数更新稀释。

Result: 在多个智能体领域和模型架构上的实验表明，RAM不仅超越合并基线，还能解锁智能体间的协同潜力，在各自领域实现优于专用智能体的性能。

Conclusion: RAM解决了RL与SFT任务向量不匹配问题，为RL训练智能体的有效合并提供了专门框架，实现了智能体能力的协同增强。

Abstract: Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.

</details>


### [360] [FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning](https://arxiv.org/abs/2601.13578)
*Qian Feng,JiaHang Tu,Mintong Kang,Hanbin Zhao,Chao Zhang,Hui Qian*

Main category: cs.LG

TL;DR: FG-OrIU提出首个在特征和梯度层面统一正交约束的增量遗忘框架，通过SVD分解特征空间并施加双重正交约束，实现不可逆的深度遗忘


<details>
  <summary>Details</summary>
Motivation: 现有增量遗忘方法主要在参数层面抑制或混淆知识，缺乏特征和梯度层面的显式约束，导致"表面遗忘"（残留信息可恢复），这种不完全遗忘存在安全风险并破坏保留平衡

Method: FG-OrIU通过SVD分解特征空间，将遗忘类和保留类特征分离到不同子空间；施加双重正交约束：特征正交投影（对遗忘和保留类）和梯度正交投影（防止遗忘知识重新引入）；动态子空间适应合并新遗忘子空间并收缩保留子空间

Result: 广泛实验证明了该方法的有效性，实现了不可逆的深度遗忘，在连续遗忘任务中保持稳定的移除-保留平衡

Conclusion: FG-OrIU是首个在特征和梯度层面统一正交约束的增量遗忘框架，通过双重正交约束和动态子空间适应，解决了现有方法的表面遗忘问题，实现了安全可靠的深度遗忘

Abstract: Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\textbf{F}eature-\textbf{G}radient \textbf{Or}thogonality for \textbf{I}ncremental \textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.

</details>


### [361] [Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models](https://arxiv.org/abs/2601.13580)
*Ahmad Al-Zuraiqi*

Main category: cs.LG

TL;DR: Neural Organ Transplantation (NOT) 是一种模块化适配框架，可将训练好的Transformer层作为可重用、可移植的检查点用于领域适配，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法将训练参数与特定模型实例和训练数据紧密耦合，缺乏模块化和可重用性。需要一种能够提取预训练模型中的连续层子集作为独立检查点，实现隐私保护的专业知识共享方法。

Method: 从预训练模型中提取连续层子集（"供体器官"），在领域特定数据上独立训练，保存为独立检查点文件，然后移植到兼容的受体模型中，无需原始训练数据。

Result: 在三个仅解码器Transformer架构（GPT-2、TinyLlama、GPT-OSS，124M到20B参数）上，供体移植显著优于现有适配方法，困惑度比LoRA提高一个数量级，训练速度更快。方法具有位置依赖性，早期插入位置效果最佳。十亿参数规模的跨领域转移显示出意外的正则化效益。

Conclusion: Transformer中间层可以支持仅解码器架构的高效模块化转移，通过检查点分发实现隐私保护的专业知识共享。该方法目前仅限于仅解码器模型，在编码器架构上效果有限。

Abstract: We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ("donor organs") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.

</details>


### [362] [Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models](https://arxiv.org/abs/2601.13599)
*Linrui Ma,Yufei Cui,Kai Han,Yunhe Wang*

Main category: cs.LG

TL;DR: 提出Diffusion in Diffusion框架，通过"草稿-精修"两阶段解决块扩散模型的可逆性和短视问题，在OpenWebText数据集上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 块扩散语言模型结合了自回归和扩散模型的优势，但其严格的单向块依赖导致不可逆性和牺牲了扩散模型的全局规划能力

Method: 采用草稿-精修框架：1) 用小块进行块扩散生成快速草稿；2) 用更大双向感受野进行全局双向扩散精修；使用快照置信度重掩码识别需要修改的关键token，并采用混合尺度训练扩展块扩散模型的全局能力

Result: 在OpenWebText数据集上为离散扩散模型设定了新基准：仅使用基线模型26%的微调预算，将生成困惑度从25.7降至21.9，显著缩小了与自回归模型的性能差距

Conclusion: Diffusion in Diffusion框架有效解决了块扩散模型的不可逆性和短视问题，通过两阶段方法在保持效率的同时显著提升生成质量

Abstract: Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. In order to address these issues, we propose Diffusion in Diffusion, a draft-then-refine framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilise snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using just 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.

</details>


### [363] [Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data](https://arxiv.org/abs/2601.13608)
*Zhipeng Chang,Ting He,Wenrui Hao*

Main category: cs.LG

TL;DR: FIPA提出了一种基于Fisher信息的参数级聚合方法，用于解决联邦学习中非IID数据导致的客户端漂移问题，通过参数特定的权重替代客户端级标量权重，提高全局模型性能。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，非IID数据分布导致客户端更新存在强烈错位，传统的FedAvg等方法对所有参数使用相同的标量权重，这种均匀加权会导致客户端漂移并降低全局模型质量。

Method: 提出Fisher信息参数级聚合(FIPA)，使用Fisher信息矩阵(FIM)权重替代客户端级标量权重，实现真正的参数级缩放。通过低秩近似保持通信和计算效率，能够捕捉每个客户端数据对不同参数的独特影响。

Result: 在非线性函数回归、PDE学习和图像分类任务中，FIPA相比基于平均的聚合方法持续改进性能。与最先进的客户端优化算法结合时，能进一步提升图像分类准确率。

Conclusion: FIPA为异构数据分布下的联邦学习提供了有效解决方案，通过参数特定的Fisher信息权重实现更精细的聚合，显著改善全局模型性能。

Abstract: Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.

</details>


### [364] [Quadratic Upper Bound for Boosting Robustness](https://arxiv.org/abs/2601.13645)
*Euijin You,Hyang-Won Lee*

Main category: cs.LG

TL;DR: 提出一种二次上界损失函数来改善快速对抗训练中的鲁棒性下降问题，通过平滑损失景观提升模型对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 快速对抗训练虽然减少了训练时间，但由于对抗空间探索不足，往往导致模型鲁棒性下降。需要一种方法来缓解FAT中的鲁棒性退化问题。

Method: 推导了对抗训练损失函数的二次上界，并将该上界与现有FAT方法结合使用，形成QUB损失函数。

Result: 将QUB损失应用于现有方法能显著提升鲁棒性，通过多种指标证明这种改进可能源于所得模型的平滑损失景观。

Conclusion: 提出的二次上界损失函数有效改善了快速对抗训练中的鲁棒性下降问题，通过平滑损失景观提升了模型对抗攻击的防御能力。

Abstract: Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.

</details>


### [365] [Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction](https://arxiv.org/abs/2601.13710)
*Sayeed Shafayet Chowdhury,Snehasis Mukhopadhyay,Shiaofen Fang,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 该研究比较了传统监督机器学习与生成式AI在预测慢性鼻窦炎手术预后方面的表现，发现MLP模型在准确性、校准和临床决策效益方面优于生成式AI，建议采用ML为主、GenAI为辅的工作流程。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能在医学影像领域已广泛应用，但在临床数据上进行前瞻性决策支持的应用仍然有限。研究旨在探索术前预测慢性鼻窦炎患者术后临床改善的可能性，以识别那些可能从手术中获益有限的患者，从而避免不必要的手术。

Method: 研究采用前瞻性收集的队列数据，所有患者均接受手术。定义手术成功为SNOT-22评分在6个月后降低超过8.9分（最小临床重要差异）。比较了监督机器学习（逻辑回归、树集成方法和自研MLP）与生成式AI（ChatGPT、Claude、Gemini、Perplexity）的表现，所有模型接收相同的结构化输入，并约束输出为二元推荐及置信度。建立了可复现的表格数据到生成式AI的评估协议，并进行了亚组分析。

Result: 最佳ML模型（MLP）达到85%的准确率，具有优越的校准特性和决策曲线净效益。生成式AI模型在零样本设置下的区分度和校准表现均较差。值得注意的是，生成式AI的决策理由与临床医生的启发式思维和MLP的特征重要性一致，反复强调基线SNOT-22评分、CT/内镜严重程度、息肉表型以及心理/疼痛共病等因素。

Conclusion: 研究支持采用ML为主、GenAI增强的工作流程：部署校准良好的ML模型进行手术候选者的初步筛选，使用生成式AI作为解释工具来增强透明度和共享决策制定。这为临床决策支持系统提供了实用的实施框架。

Abstract: Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.

</details>


### [366] [EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory](https://arxiv.org/abs/2601.13748)
*Tien-Dat Pham,Xuan-The Tran*

Main category: cs.LG

TL;DR: EEG-Titans：一种结合滑动窗口注意力和循环记忆的双分支架构，用于癫痫发作预测，通过长上下文建模在CHB-MIT数据集上达到99.46%的平均段级灵敏度


<details>
  <summary>Details</summary>
Motivation: 癫痫发作预测面临挑战，因为发作前动态可能跨越长时间范围，而临床相关特征可能微妙且短暂。现有深度学习模型在超长序列处理时，需要在捕获局部时空模式与保持信息丰富的长程上下文之间进行权衡。

Method: 提出EEG-Titans双分支架构，结合现代神经记忆机制进行长上下文建模。模型包含：1）滑动窗口注意力分支捕获短期异常；2）循环记忆路径总结随时间变化的缓慢渐进趋势。还采用分层上下文策略，为高噪声受试者扩展感受野。

Result: 在CHB-MIT头皮EEG数据集上，按时间顺序保留协议评估，EEG-Titans在18名受试者中达到99.46%的平均段级灵敏度。分析伪影易发记录的安全优先操作点显示，分层上下文策略可显著减少误报（极端异常值降至0.00 FPR/h），同时不牺牲灵敏度。

Conclusion: 记忆增强的长上下文建模能够在临床约束评估下提供稳健的癫痫发作预测，表明该方法在平衡局部特征捕获与长期上下文保持方面的有效性。

Abstract: Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation

</details>


### [367] [vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.13768)
*Wenzhen Yue,Ruohao Guo,Ji Shi,Zihan Hao,Shiyu Hu,Xianghua Ying*

Main category: cs.LG

TL;DR: vLinear：一种基于线性运算的高效多元时间序列预测器，包含vecTrans模块和WFMLoss目标函数，在保持高性能的同时显著降低计算复杂度


<details>
  <summary>Details</summary>
Motivation: 现有基于自注意力机制的多元时间序列预测器通常面临O(N²)的计算复杂度问题，其中N是变量数量。这限制了模型在处理高维多元时间序列时的效率和可扩展性。

Method: 提出vLinear框架，包含两个核心组件：1) vecTrans模块：使用可学习向量建模多元相关性，将复杂度从O(N²)降低到O(N)；2) WFMLoss目标函数：采用最终序列导向的流匹配损失，结合路径和时域加权策略，专注于更可靠的路径和预测时域。

Result: 在22个基准测试和124个预测设置中达到最先进性能；vecTrans模块可无缝集成到Transformer预测器中，实现高达5倍的推理加速和一致性能提升；WFMLoss作为即插即用目标函数，能持续改进现有预测器。

Conclusion: vLinear通过vecTrans模块和WFMLoss目标函数，在多元时间序列预测中实现了效率与性能的平衡，为高维时间序列分析提供了有效的线性解决方案。

Abstract: In this paper, we present \textbf{vLinear}, an effective yet efficient \textbf{linear}-based multivariate time series forecaster featuring two components: the \textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \textbf{velocity-oriented} flow matching objectives, we demonstrate that a \textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.

</details>


### [368] [Principled Latent Diffusion for Graphs via Laplacian Autoencoders](https://arxiv.org/abs/2601.13780)
*Antoine Siraudin,Christopher Morris*

Main category: cs.LG

TL;DR: LG-Flow：一种潜在图扩散框架，通过置换等变自编码器将图压缩到低维潜在空间，在潜在空间中进行扩散，实现高效图生成，速度提升高达1000倍


<details>
  <summary>Details</summary>
Motivation: 现有图扩散模型存在二次复杂度问题，且大部分容量浪费在稀疏图的非边建模上。虽然其他模态的潜在扩散方法提供了启发，但图生成需要近乎无损的重建，因为邻接矩阵的单个错误就可能导致整个样本无效，这一挑战尚未解决

Method: 提出LG-Flow框架：1）使用置换等变自编码器将每个节点映射到固定维嵌入，从该嵌入中可以证明完全恢复完整的邻接矩阵；2）潜在表示的维度与节点数成线性关系，消除了二次瓶颈；3）在潜在空间中训练带有流匹配的扩散变换器，实现高效且表达力强的图生成

Result: 该方法在无向图和DAG上实现了近乎无损的重建。与最先进的图扩散模型相比，获得了竞争性的结果，同时实现了高达1000倍的加速

Conclusion: LG-Flow成功解决了图潜在扩散中的重建挑战，通过线性缩放的潜在表示消除了二次复杂度瓶颈，为大规模图生成提供了高效且表达力强的解决方案

Abstract: Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\times$ speed-up.

</details>


### [369] [PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles](https://arxiv.org/abs/2601.13793)
*ByeoungDo Kim,JunYeop Na,Kyungwook Tak,JunTae Kim,DongHyeon Kim,Duckky Kim*

Main category: cs.LG

TL;DR: 提出基于注意力机制的ETA预测模型，通过历史道路速度模式提升到达时间估计精度，在保持轻量化的同时有效捕捉时空因果关系。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和智能交通系统普及，准确可靠的ETA估计对导航、出行规划和交通管理至关重要。传统方法对实时和历史交通数据结合方式简单，或依赖复杂规则计算；现有深度学习模型计算成本高且未能有效捕捉ETA预测所需的时空模式。

Method: 提出基于注意力机制的ETA模型，利用注意力机制提取和利用路线每个时空点累积的时间特征。该架构通过注意力机制处理历史道路速度模式，以任务感知方式整合道路特征、实时交通状况和历史速度模式，实现轻量化和可扩展的时空因果关系建模。

Result: 在真实驾驶数据集上验证，该方法优于现有基线模型，通过有效整合道路特征、实时交通条件和历史速度模式，实现了高效准确的ETA估计。

Conclusion: 提出的基于注意力机制的ETA模型能够有效捕捉时空因果关系，在保持模型轻量化和可扩展的同时，显著提升了到达时间估计的准确性，为智能交通系统提供了实用的解决方案。

Abstract: In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.

</details>


### [370] [Inverting Self-Organizing Maps: A Unified Activation-Based Framework](https://arxiv.org/abs/2601.13851)
*Alessandro Londei,Matteo Benati,Denise Lanzieri,Vittorio Loreto*

Main category: cs.LG

TL;DR: 该论文提出了一种基于自组织映射（SOM）的精确输入恢复方法，并在此基础上开发了MUSIC更新规则，用于在潜在空间中进行可控的语义轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 自组织映射（SOM）虽然广泛用于可视化、聚类和向量量化，但其激活模式（到原型的平方距离）的反向恢复能力尚未被充分探索。论文旨在证明在温和的几何条件下，可以通过SOM激活模式精确恢复原始输入，并基于此开发可控的潜在空间探索方法。

Method: 基于欧几里得距离几何学原理：D维空间中的点由其到D+1个仿射独立参考点的距离唯一确定。论文推导了相应的线性系统，并分析了反演的良好条件。在此基础上提出了MUSIC更新规则，该规则通过修改选定原型的平方距离同时保持其他距离，产生与SOM分段线性结构对齐的确定性几何流。使用Tikhonov正则化来稳定更新规则并确保高维数据集上的平滑运动。

Result: 在合成高斯混合、MNIST和Faces in the Wild数据集上的验证表明，MUSIC能够产生平滑、可解释的轨迹，揭示了学习流形的底层几何结构。当不施加扰动时，反演能够精确恢复输入；当指定目标聚类或原型时，MUSIC能够产生连贯的语义变化，同时保持在数据流形上。

Conclusion: 该工作展示了基于SOM激活模式反演的新视角，为数据增强和可控潜在探索提供了仅依赖原型几何的方法。与变分或概率生成模型不同，MUSIC不依赖采样、潜在先验或编码器-解码器架构，而是基于确定性几何原理，为SOM提供了超越无监督聚类的新应用方向。

Abstract: Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.

</details>


### [371] [Multi-Objective Hierarchical Optimization with Large Language Models](https://arxiv.org/abs/2601.13892)
*Andrej Schwanke,Lyubomir Ivanov,David Salinas,Frank Hutter,Arber Zela*

Main category: cs.LG

TL;DR: 提出一种将大语言模型作为替代模型和候选采样器，结合结构化分层搜索策略的多目标优化方法，通过自适应分区输入空间并限制LLM在特定高潜力子空间生成，实现收敛到真实帕累托集。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理能力方面表现出色，但尚未成为多目标优化的现成选择。传统方法因其处理数值输入、平衡探索与帕累托前沿利用以及处理多冲突目标的能力而在基准测试中表现优异。本文旨在弥合这一差距。

Method: 利用LLM作为替代模型和候选采样器，嵌入结构化分层搜索策略。通过自适应地将输入空间划分为不相交的超矩形区域，并使用复合评分函数对这些区域进行排序，将LLM的生成过程限制在特定高潜力子空间，使LLM只需进行局部推理而非全局推理。

Result: 在标准正则性假设下，算法生成的候选解在Hausdorff距离上收敛到真实帕累托集。实证表明，该方法持续优于基于全局LLM的多目标优化器，并在合成和真实世界基准测试中与标准进化和贝叶斯优化算法表现相当。

Conclusion: 通过将LLM与结构化分层搜索策略相结合，成功开发了一种有效的多目标优化方法，使LLM能够专注于局部推理，从而在保持理论收敛性的同时实现与现有优化方法相媲美的性能。

Abstract: Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.

</details>


### [372] [LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems](https://arxiv.org/abs/2601.14053)
*Badri N. Patro,Vijay S. Agneeswaran*

Main category: cs.LG

TL;DR: LLMOrbit提出一个2019-2025年大语言模型的循环分类法，分析50多个模型，识别三大危机（数据稀缺、成本指数增长、能耗不可持续）和六大突破范式，揭示三大范式转变。


<details>
  <summary>Details</summary>
Motivation: 随着AI从基础Transformer架构发展到接近人类水平的推理系统，需要系统性地梳理大语言模型的发展脉络。该研究旨在通过全面的分类法导航LLM领域，识别限制暴力扩展的"扩展墙"危机，并探索突破这些限制的创新范式。

Method: 提出LLMOrbit循环分类法，通过八个相互关联的轨道维度分析2019-2025年间超过50个模型和15个组织。采用多维度分析方法，涵盖架构创新、训练方法、效率模式等，系统性地评估现代LLM、生成式AI和智能体系统。

Result: 识别出三大关键危机：1) 数据稀缺（2026-2028年将耗尽9-27T tokens）；2) 成本指数增长（5年内从300万美元增至3亿美元以上）；3) 不可持续的能耗（增长22倍）。发现六大突破范式：测试时计算、量化、分布式边缘计算、模型融合、高效训练、小型专用模型。揭示三大范式转变：后训练增益、效率革命、民主化。

Conclusion: 大语言模型领域正面临扩展墙的严峻挑战，但通过测试时计算、效率优化和开源民主化等创新范式，可以突破这些限制。未来的发展将从被动生成转向工具使用智能体，后训练技术和效率革命将成为关键驱动力，开源模型已开始超越闭源模型性能。

Abstract: The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.

</details>


### [373] [Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping](https://arxiv.org/abs/2601.14099)
*Shi-Shun Chen,Xiao-Yang Li,Enrico Zio*

Main category: cs.LG

TL;DR: 提出基于时滞交叉映射的因果特征选择框架，解决工业过程中变量时滞因果和相互依赖问题，提升软测量模型性能


<details>
  <summary>Details</summary>
Motivation: 现有因果特征选择方法忽略工业过程的两个关键特性：1) 变量间的因果关系存在时滞，而现有方法在同一时间维度分析因果关系；2) 工业过程变量相互依赖，与传统因果推断方法的去相关假设相矛盾。这导致基于现有方法的软测量模型准确性和稳定性不足。

Method: 提出基于时滞交叉映射的因果特征选择框架：1) 使用时滞收敛交叉映射(TDCCM)进行总因果推断；2) 使用时滞偏交叉映射(TDPCM)进行直接因果推断；3) 提出客观特征选择策略，基于验证集模型性能自动确定因果阈值并选择因果特征。

Result: 两个真实案例研究表明：TDCCM实现了最高的平均性能，而TDPCM在最差情况下提高了软测量的稳定性和性能。代码已公开在GitHub上。

Conclusion: 提出的时滞交叉映射框架有效解决了工业过程中变量时滞因果和相互依赖问题，显著提升了软测量模型的准确性和稳定性，为工业过程监控提供了更可靠的因果特征选择方法。

Abstract: Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.

</details>


### [374] [A model of errors in transformers](https://arxiv.org/abs/2601.14175)
*Suvrat Raju,Praneeth Netrapalli*

Main category: cs.LG

TL;DR: 论文研究了LLM在需要确定性输出的任务（如算术）上的错误率，提出了一个基于注意力机制误差积累的两参数模型来量化预测准确率与任务复杂度之间的关系。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在需要确定性输出的任务（如算术）上的错误率，挑战了现有关于LLM在长重复任务上错误源于"推理崩溃"或无法表达"组合函数"的观点，旨在提供更精确的误差分析框架。

Method: 基于"有效场论"视角，将LLM的众多参数重组为两个关键参数：基本噪声率和可能错误预测的令牌数量。通过注意力机制中微小误差积累超过阈值的机制，推导出准确率与任务复杂度的定量关系。使用Gemini 2.5 Flash、Gemini 2.5 Pro和DeepSeek R1进行广泛的实证测试。

Result: 实证测试显示，对于多种任务，预测准确率与观测准确率之间具有极好的一致性，尽管在某些情况下也发现了偏差。两参数模型能够有效描述LLM在确定性任务上的错误率。

Conclusion: LLM在确定性任务上的错误可以通过注意力机制误差积累的简单两参数模型解释，这为理解LLM错误提供了替代框架，并展示了如何通过提示工程降低错误率。

Abstract: We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.

</details>


### [375] [Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery](https://arxiv.org/abs/2601.14196)
*Albina Galiullina,Wouter van Heeswijk,Tom van Woensel*

Main category: cs.LG

TL;DR: 该研究提出了一种差异化取货点提供策略（DPO），通过为每个顾客推荐单一取货点而非提供无限制选择，来联合减少配送卡车路线和顾客出行的碳排放。


<details>
  <summary>Details</summary>
Motivation: 取货点作为家庭配送的可持续替代方案，通过订单整合可以缩短配送路线并提高首次投递成功率。然而，当顾客驾车取货时，这些环境效益可能会被抵消。因此需要一种策略来同时减少配送卡车和顾客出行的碳排放。

Method: 采用基于强化学习的方法设计DPO策略，考虑顾客与取货点之间的空间关系及其对未来路线整合的影响。在动态随机环境中，为每个到达的顾客提供单一推荐取货点，同时保留家庭配送选项。

Result: 差异化取货点提供策略能显著减少总碳排放量：相对于纯家庭配送最多减少9%排放，平均比替代策略（包括无限制取货点选择和最近取货点分配）减少2%。在密集城市环境中，当取货点多且距离短时效果尤为显著。

Conclusion: 差异化取货点提供策略能有效减少总碳排放，特别是在密集城市环境中。当顾客对取货点配送的接受度较低时，明确考虑顾客到达和选择的动态特性尤为重要。

Abstract: Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.

</details>


### [376] [InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning](https://arxiv.org/abs/2601.14209)
*Matthew Y. R. Yang,Hao Bai,Ian Wu,Gene Yang,Amrith Setlur,Aviral Kumar*

Main category: cs.LG

TL;DR: 提出Intervention Training (InT)训练范式，通过模型对自身推理轨迹进行细粒度信用分配，识别错误并提出单步干预，然后进行监督微调，显著提升数学推理能力


<details>
  <summary>Details</summary>
Motivation: 标准强化学习在最终答案层面分配信用，当结果错误时惩罚整个推理轨迹，结果正确时均匀强化所有步骤。这导致正确中间步骤在失败轨迹中被抑制，而虚假步骤在成功轨迹中被强化，存在信用分配问题。

Method: 提出Intervention Training (InT)：1) 利用数学推理数据集中通常可用的参考解，模型识别自身推理中的第一个错误；2) 提出单步干预将轨迹转向正确解；3) 对错误点之前的策略展开与干预进行拼接，然后进行监督微调，将错误定位到导致失败的具体步骤。

Result: 在4B参数基础模型上，经过InT和后续RL微调，在IMO-AnswerBench上的准确率提升近14%，超过了gpt-oss-20b等更大的开源模型。

Conclusion: Intervention Training通过让模型对自身推理轨迹进行细粒度信用分配，有效解决了标准RL中的信用分配问题，为RL训练提供了更好的初始化，显著提升了数学推理能力。

Abstract: Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.

</details>


### [377] [Q-learning with Adjoint Matching](https://arxiv.org/abs/2601.14234)
*Qiyang Li,Sergey Levine*

Main category: cs.LG

TL;DR: QAM是一种新颖的TD强化学习算法，通过伴随匹配技术解决了连续动作RL中长期存在的挑战：高效优化具有表达力的扩散或流匹配策略，同时充分利用参数化Q函数的一阶信息。


<details>
  <summary>Details</summary>
Motivation: 连续动作强化学习中，对具有表达力的扩散或流匹配策略进行高效优化是一个长期挑战。现有方法要么只使用价值信息而丢弃梯度信息，要么依赖近似方法牺牲策略表达性或引入偏差。直接通过反向传播进行基于梯度的优化在数值上不稳定。

Method: QAM采用伴随匹配技术，这是一种最近在生成建模中提出的方法。它将评论家的动作梯度转换为逐步目标函数，避免了不稳定的反向传播，同时在最优解处提供无偏且具有表达力的策略。结合时间差分备份进行评论家学习。

Result: QAM在困难、稀疏奖励任务上持续优于先前方法，无论是在离线RL还是离线到在线RL设置中。

Conclusion: QAM通过伴随匹配技术有效解决了连续动作RL中扩散/流匹配策略优化的关键挑战，提供了一种既利用梯度信息又保持策略表达性的稳定优化方法。

Abstract: We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.

</details>


### [378] [Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression](https://arxiv.org/abs/2601.14238)
*Shaurya Mathur,Shreyas Bellary Manjunath,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: FireCastRL是一个结合野火预测与智能扑救的AI框架，使用深度学习预测火灾发生，并通过强化学习在物理模拟中执行实时扑救策略。


<details>
  <summary>Details</summary>
Motivation: 野火频率和强度不断增加，造成巨大生态和经济损失。传统火灾管理主要是被动响应，只在火灾发生后采取行动，需要更主动的预防和应对方法。

Method: 1. 使用深度时空模型预测野火发生概率；2. 对高风险预测，部署预训练的强化学习智能体，在物理信息3D模拟中使用直升机部队执行实时扑救战术；3. 生成威胁评估报告帮助应急响应人员优化资源分配。

Result: 开发了FireCastRL框架，并公开了一个包含950万个环境变量样本的大规模时空数据集用于野火预测。展示了深度学习与强化学习结合在野火预测和战术响应中的应用潜力。

Conclusion: 该研究证明了AI技术（深度学习和强化学习）可以协同工作，为野火管理提供从预测到战术响应的全面支持，代表了从被动响应向主动预防的重要转变。

Abstract: Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.

</details>


### [379] [Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow](https://arxiv.org/abs/2601.14243)
*Haocheng Xi,Charlie Ruan,Peiyuan Liao,Yujun Lin,Han Cai,Yilong Zhao,Shuo Yang,Kurt Keutzer,Song Han,Ligeng Zhu*

Main category: cs.LG

TL;DR: Jet-RL：首个全面的FP8强化学习训练框架，通过统一的FP8精度流解决现有BF16训练+FP8 rollout策略的不稳定性问题，实现33% rollout加速和16%端到端加速


<details>
  <summary>Details</summary>
Motivation: 现有RL训练管道计算效率低下，rollout阶段占训练时间70%以上。量化RL训练（特别是FP8精度）有望缓解这一瓶颈，但常用的BF16训练+FP8 rollout策略在长序列和复杂任务下存在严重训练不稳定性和精度崩溃问题

Method: 提出Jet-RL框架，采用统一的FP8精度流同时用于训练和rollout，最小化数值差异，消除低效的步间校准需求，确保训练稳定性

Result: Jet-RL实现33% rollout阶段加速、41%训练阶段加速和16%端到端加速，在所有设置下保持稳定收敛，精度损失可忽略不计

Conclusion: 统一的FP8精度流是解决RL训练中数值不匹配问题的关键，Jet-RL框架为高效稳定的量化RL训练提供了有效解决方案

Abstract: Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.

</details>
