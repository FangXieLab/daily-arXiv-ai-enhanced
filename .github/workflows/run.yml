name: arXiv-daily-ai-enhanced

on:
  schedule:
    - cron: "0 23 * * *"
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # è·å–æ‰€æœ‰åˆ†æ”¯å†å²
    
    - name: Install dependencies
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        uv sync
        
     - name: Crawl arXiv papers
      id: crawl_step
      run: |
        source .venv/bin/activate
        today=$(date -u "+%Y-%m-%d")
        echo "å¼€å§‹çˆ¬å– $today çš„arXivè®ºæ–‡... / Starting to crawl $today arXiv papers..."
        
        # ç¡®ä¿dataç›®å½•å­˜åœ¨ / Ensure data directory exists
        mkdir -p data
        
        cd daily_arxiv
        export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
        export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
        export TOKEN_GITHUB=${{ secrets.TOKEN_GITHUB }}
        export LANGUAGE="${{ vars.LANGUAGE }}"
        export CATEGORIES="${{ vars.CATEGORIES }}"
        export MODEL_NAME="${{ vars.MODEL_NAME }}"
        
        # åˆ›å»ºPythonè„šæœ¬æ‰‹åŠ¨æ§åˆ¶è¾“å‡º / Create Python script to manually control output
        cat > run_crawl.py << 'EOF'
        import json
        import sys
        import os
        from datetime import datetime
        
        # æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„ / Add current directory to Python path
        sys.path.insert(0, os.path.dirname(__file__))
        
        from scrapy.crawler import CrawlerRunner
        from scrapy.utils.project import get_project_settings
        from twisted.internet import reactor, defer
        
        # è‡ªå®šä¹‰Itemæ”¶é›†å™¨ / Custom Item collector
        class ItemCollector:
            def __init__(self, output_file):
                self.output_file = output_file
                self.items = []
                
            def process_item(self, item, spider):
                self.items.append(dict(item))
                # ç«‹å³å†™å…¥æ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰ / Write to file immediately (append mode)
                with open(self.output_file, 'a', encoding='utf-8') as f:
                    f.write(json.dumps(dict(item), ensure_ascii=False) + '\n')
                return item
        
        @defer.inlineCallbacks
        def crawl():
            # è·å–ä»Šå¤©çš„æ—¥æœŸ / Get today's date
            today = datetime.utcnow().strftime('%Y-%m-%d')
            
            # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„ / Set output file path
            output_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data')
            os.makedirs(output_dir, exist_ok=True)
            output_file = os.path.join(output_dir, f'{today}.jsonl')
            
            print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
            print(f"Output file: {output_file}")
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ é™¤å®ƒ / If file exists, delete it
            if os.path.exists(output_file):
                os.remove(output_file)
            
            # åˆ›å»ºItemæ”¶é›†å™¨ / Create item collector
            collector = ItemCollector(output_file)
            
            # è·å–Scrapyè®¾ç½® / Get Scrapy settings
            settings = get_project_settings()
            
            # æ·»åŠ è‡ªå®šä¹‰pipeline / Add custom pipeline
            settings.set('ITEM_PIPELINES', {
                'daily_arxiv.pipelines.DailyArxivPipeline': 300,
            })
            
            # åˆ›å»ºçˆ¬è™«è¿è¡Œå™¨ / Create crawler runner
            runner = CrawlerRunner(settings)
            
            # è¿è¡Œçˆ¬è™« / Run spider
            spider = runner.create_crawler('arxiv')
            
            # æ·»åŠ Itemå¤„ç†å™¨ / Add item processor
            spider.signals.connect(collector.process_item, signal=spider.signals.item_scraped)
            
            yield runner.crawl('arxiv')
            
            print(f"çˆ¬å–å®Œæˆï¼Œå…±æ”¶é›† {len(collector.items)} ä¸ªæ¡ç›®")
            print(f"Crawling completed, collected {len(collector.items)} items")
            
            # åœæ­¢reactor / Stop reactor
            reactor.stop()
        
        if __name__ == '__main__':
            crawl()
            reactor.run()
        EOF
        
        # è¿è¡ŒPythonè„šæœ¬ / Run Python script
        python run_crawl.py
        
        # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆæ–‡ä»¶ / Check if file was generated
        if [ ! -f "../data/${today}.jsonl" ]; then
            echo "çˆ¬å–å¤±è´¥ï¼Œæœªç”Ÿæˆæ•°æ®æ–‡ä»¶ / Crawling failed, no data file generated"
            exit 1
        fi
        
        # æ£€æŸ¥æ–‡ä»¶å†…å®¹ / Check file content
        LINE_COUNT=$(wc -l <"../data/${today}.jsonl" 2>/dev/null || echo "0")
        echo "âœ… ç”Ÿæˆæ–‡ä»¶åŒ…å« $LINE_COUNT è¡Œæ•°æ® / Generated file contains $LINE_COUNT lines of data"
        
        echo "crawl_date=$today" >> $GITHUB_OUTPUT
        echo "çˆ¬å–å®Œæˆ / Crawling completed"
        
    - name: Check for duplicates
      id: dedup_check
      run: |
        source .venv/bin/activate
        echo "æ‰§è¡Œå»é‡æ£€æŸ¥... / Performing intelligent deduplication check..."
        
        cd daily_arxiv
        # æ‰§è¡Œå»é‡æ£€æŸ¥è„šæœ¬ / Execute intelligent deduplication check script
        set +e  # æš‚æ—¶å…è®¸å‘½ä»¤å¤±è´¥ / Temporarily allow command failure
        python daily_arxiv/check_stats.py
        
        # è·å–é€€å‡ºç  / Get exit code
        dedup_exit_code=$?
        set -e  # æ¢å¤ä¸¥æ ¼æ¨¡å¼ / Restore strict mode
        
        echo "å»é‡æ£€æŸ¥é€€å‡ºç : $dedup_exit_code / Dedup check exit code: $dedup_exit_code"
        echo "dedup_exit_code=$dedup_exit_code" >> $GITHUB_OUTPUT
        
        case $dedup_exit_code in
            0)
                echo "has_new_content=true" >> $GITHUB_OUTPUT
                ;;
            1)
                echo "has_new_content=false" >> $GITHUB_OUTPUT
                echo "skip_reason=no_new_content" >> $GITHUB_OUTPUT
                ;;
            2)
                echo "has_new_content=false" >> $GITHUB_OUTPUT
                echo "skip_reason=processing_error" >> $GITHUB_OUTPUT
                exit 1
                ;;
            *)
                echo "âŒ æœªçŸ¥é€€å‡ºç ï¼Œåœæ­¢å·¥ä½œæµ / Unknown exit code, stop workflow"
                echo "has_new_content=false" >> $GITHUB_OUTPUT
                echo "skip_reason=unknown_error" >> $GITHUB_OUTPUT
                exit 1
                ;;
        esac
        
    - name: AI Enhancement Processing
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        source .venv/bin/activate
        today=${{ steps.crawl_step.outputs.crawl_date }}
        echo "å¼€å§‹AIå¢å¼ºå¤„ç†... / Starting AI enhancement processing..."
        
        cd ai
        export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
        export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
        export LANGUAGE="${{ vars.LANGUAGE }}"
        export MODEL_NAME="${{ vars.MODEL_NAME }}"
        
        python enhance.py --data ../data/${today}.jsonl
        
        # æ£€æŸ¥AIå¤„ç†æ˜¯å¦æˆåŠŸ / Check if AI processing was successful
        if [ $? -ne 0 ]; then
            echo "AIå¤„ç†å¤±è´¥ / AI processing failed"
            exit 1
        fi
        echo "AIå¢å¼ºå¤„ç†å®Œæˆ / AI enhancement processing completed"
        
    - name: Convert to Markdown
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        source .venv/bin/activate
        today=${{ steps.crawl_step.outputs.crawl_date }}
        echo "è½¬æ¢ä¸ºMarkdownæ ¼å¼... / Converting to Markdown format..."
        
        # è®¾ç½®ç¯å¢ƒå˜é‡ / Set environment variables
        export LANGUAGE="${{ vars.LANGUAGE }}"
        
        cd to_md
        
        # ä½¿ç”¨AIå¢å¼ºæ–‡ä»¶è¿›è¡Œè½¬æ¢ / Use AI enhanced file for conversion
        AI_FILE="../data/${today}_AI_enhanced_${LANGUAGE}.jsonl"
        
        if [ -f "$AI_FILE" ]; then
            echo "ä½¿ç”¨AIå¢å¼ºæ–‡ä»¶è¿›è¡Œè½¬æ¢... / Using AI enhanced file for conversion..."
            python convert.py --data "$AI_FILE"
        else
            echo "é”™è¯¯ï¼šæœªæ‰¾åˆ°AIå¢å¼ºæ–‡ä»¶ / Error: AI enhanced file not found"
            echo "AIæ–‡ä»¶: $AI_FILE"
            exit 1
        fi
        
        # æ£€æŸ¥è½¬æ¢æ˜¯å¦æˆåŠŸ / Check if conversion was successful
        if [ $? -ne 0 ]; then
            echo "Markdownè½¬æ¢å¤±è´¥ / Markdown conversion failed"
            exit 1
        fi
        echo "Markdownè½¬æ¢å®Œæˆ / Markdown conversion completed"
        
    - name: Update file list
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        echo "æ›´æ–°æ–‡ä»¶åˆ—è¡¨... / Updating file list..."
        ls data/*.jsonl 2>/dev/null | sed 's|data/||' > assets/file-list.txt
        echo "æ–‡ä»¶åˆ—è¡¨æ›´æ–°å®Œæˆ / File list updated"

    - name: Generate password hash and inject into config
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        echo "ğŸ” Generating password hash for authentication..."

        PASSWORD="${{ secrets.ACCESS_PASSWORD }}"

        if [ -z "$PASSWORD" ]; then
          echo "âš ï¸  WARNING: ACCESS_PASSWORD not set in Secrets"
          echo "âš ï¸  Password protection will be DISABLED"
          echo "âš ï¸  To enable password protection, add ACCESS_PASSWORD in repository Secrets"
          echo "â„¹ï¸  Website will remain publicly accessible without authentication"

          # Use a special value that will disable authentication
          PASSWORD_HASH="DISABLED_NO_PASSWORD_SET_IN_SECRETS"
        else
          # Generate SHA-256 hash using openssl
          PASSWORD_HASH=$(echo -n "$PASSWORD" | openssl dgst -sha256 -hex | awk '{print $2}')
          echo "âœ… Password hash generated successfully"
          echo "âœ… Hash length: ${#PASSWORD_HASH} characters"
          echo "ğŸ” Password protection is ENABLED"
        fi

        # Inject hash into auth-config.js
        if [ -f "js/auth-config.js" ]; then
          sed -i "s/PLACEHOLDER_PASSWORD_HASH/$PASSWORD_HASH/" js/auth-config.js
          echo "âœ… Password hash injected into js/auth-config.js"
        else
          echo "âŒ ERROR: js/auth-config.js not found!"
          exit 1
        fi

        echo "ğŸ” Authentication setup complete"

    - name: Summary
      run: |
        if [ "${{ steps.dedup_check.outputs.has_new_content }}" = "true" ]; then
          echo "âœ… å·¥ä½œæµå®Œæˆï¼šå»é‡å‘ç°æ–°å†…å®¹å¹¶æˆåŠŸå¤„ç† / Workflow completed: Smart deduplication found new content and processed successfully"
        else
          case "${{ steps.dedup_check.outputs.skip_reason }}" in
            "no_new_content")
              echo "â„¹ï¸ å·¥ä½œæµå®Œæˆï¼šå»é‡åæ— æ–°å†…å®¹ / Workflow completed: No new content after smart deduplication"
              ;;
            "processing_error")
              echo "âš ï¸ å·¥ä½œæµå®Œæˆï¼šå»é‡å¤„ç†å‡ºé”™ / Workflow completed: Deduplication processing error"
              ;;
            "unknown_error")
              echo "âš ï¸ å·¥ä½œæµå®Œæˆï¼šæœªçŸ¥é”™è¯¯ / Workflow completed: Unknown error"
              ;;
            *)
              echo "â„¹ï¸ å·¥ä½œæµå®Œæˆï¼šæœªçŸ¥åŸå› è·³è¿‡å¤„ç† / Workflow completed: Skipped for unknown reason"
              ;;
          esac
        fi
        
    - name: Inject repository info into data-config.js
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        echo "æ³¨å…¥ä»“åº“ä¿¡æ¯åˆ° data-config.js... / Injecting repository info into data-config.js..."
        
        # è·å–ä»“åº“ä¿¡æ¯ / Get repository information
        REPO_OWNER="${{ github.repository_owner }}"
        REPO_NAME="${{ github.event.repository.name }}"
        
        echo "ä»“åº“æ‰€æœ‰è€…: $REPO_OWNER / Repository owner: $REPO_OWNER"
        echo "ä»“åº“åç§°: $REPO_NAME / Repository name: $REPO_NAME"
        
        # æ³¨å…¥ä»“åº“ä¿¡æ¯åˆ° data-config.js / Inject repository info into data-config.js
        if [ -f "js/data-config.js" ]; then
          sed -i "s/PLACEHOLDER_REPO_OWNER/$REPO_OWNER/g" js/data-config.js
          sed -i "s/PLACEHOLDER_REPO_NAME/$REPO_NAME/g" js/data-config.js
          echo "âœ… ä»“åº“ä¿¡æ¯å·²æ³¨å…¥åˆ° js/data-config.js / Repository info injected into js/data-config.js"
        else
          echo "âŒ ERROR: js/data-config.js not found!"
          exit 1
        fi

    - name: Commit code changes to main branch
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        git config --global user.email "${{ vars.EMAIL }}"
        git config --global user.name "${{ vars.NAME }}"
        
        # æ·»åŠ æ‰€æœ‰ä»£ç æ–‡ä»¶ï¼Œä½†æ’é™¤æ•°æ®æ–‡ä»¶ / Add all code files, but exclude data files
        git add js/data-config.js
        git add .github/
        # æ·»åŠ å…¶ä»–å¯èƒ½çš„ä»£ç å˜æ›´ï¼Œä½†æ’é™¤ data/ ç›®å½•å’Œ assets/file-list.txt
        # Add other possible code changes, but exclude data/ directory and assets/file-list.txt
        git add -A
        git reset -- data/* assets/file-list.txt 2>/dev/null || true
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»£ç å˜æ›´éœ€è¦æäº¤ / Check if there are code changes to commit
        if git diff --staged --quiet; then
          echo "æ²¡æœ‰ä»£ç å˜æ›´éœ€è¦æäº¤ / No code changes to commit"
        else
          git commit -m "chore: update data-config.js with repository info"
          echo "ä»£ç å˜æ›´å·²æäº¤åˆ° main åˆ†æ”¯ / Code changes committed to main branch"
        fi

    - name: Push code changes to main branch
      if: steps.dedup_check.outputs.has_new_content == 'true'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # è®¾ç½®Gité…ç½®ä»¥å¤„ç†è‡ªåŠ¨åˆå¹¶ / Set Git config for automatic merging
        git config pull.rebase true
        git config rebase.autoStash true
        
        # å°è¯•æ¨é€ä»£ç å˜æ›´åˆ° main åˆ†æ”¯ / Try to push code changes to main branch
        for i in {1..3}; do
          echo "æ¨é€ä»£ç å˜æ›´å°è¯• $i / Push code changes attempt $i"
          if git push origin main; then
            echo "ä»£ç å˜æ›´æ¨é€æˆåŠŸ / Code changes pushed successfully"
            break
          else
            echo "æ¨é€å¤±è´¥ï¼Œæ‹‰å–æœ€æ–°å˜æ›´... / Push failed, pulling latest changes..."
            git pull origin main --no-edit || true
            if [ $i -eq 3 ]; then
              echo "3æ¬¡å°è¯•åæ¨é€å¤±è´¥ / Failed to push after 3 attempts"
              exit 1
            fi
          fi
        done

    - name: Prepare data files for data branch
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        echo "å‡†å¤‡æ•°æ®æ–‡ä»¶... / Preparing data files..."
        today=${{ steps.crawl_step.outputs.crawl_date }}
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜æ•°æ®æ–‡ä»¶ / Create temporary directory to save data files
        mkdir -p /tmp/data_files/data
        mkdir -p /tmp/data_files/assets
        
        # å¤åˆ¶æ•°æ®æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½• / Copy data files to temporary directory
        cp -r data/* /tmp/data_files/data/ 2>/dev/null || true
        cp assets/file-list.txt /tmp/data_files/assets/ 2>/dev/null || true
        
        echo "æ•°æ®æ–‡ä»¶å·²ä¿å­˜åˆ°ä¸´æ—¶ç›®å½• / Data files saved to temporary directory"

    - name: Setup and commit to data branch
      if: steps.dedup_check.outputs.has_new_content == 'true'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config --global user.email "${{ vars.EMAIL }}"
        git config --global user.name "${{ vars.NAME }}"
        
        echo "=== è®¾ç½® data åˆ†æ”¯ ==="
        today=${{ steps.crawl_step.outputs.crawl_date }}
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        rm -rf data/*.jsonl 2>/dev/null || true
        rm -f assets/file-list.txt 2>/dev/null || true
        
        # æ£€æŸ¥è¿œç¨‹dataåˆ†æ”¯æ˜¯å¦å­˜åœ¨
        echo "æ£€æŸ¥è¿œç¨‹åˆ†æ”¯..."
        if git ls-remote --exit-code origin data >/dev/null 2>&1; then
          echo "âœ… dataåˆ†æ”¯å­˜åœ¨ï¼Œåˆ‡æ¢åˆ°dataåˆ†æ”¯"
          git fetch origin data
          git checkout data
          # ç¡®ä¿æ˜¯æœ€æ–°ç‰ˆæœ¬
          git pull origin data --no-edit || echo "æç¤ºï¼šæ‹‰å–å¯èƒ½å¤±è´¥ï¼Œç»§ç»­..."
        else
          echo "âŒ dataåˆ†æ”¯ä¸å­˜åœ¨ï¼Œéœ€è¦å…ˆæ‰‹åŠ¨åˆ›å»º"
          echo "è¯·åœ¨GitHubç½‘é¡µä¸Šï¼š"
          echo "1. ç‚¹å‡»åˆ†æ”¯ä¸‹æ‹‰æ¡†ï¼ˆæ˜¾ç¤ºmainçš„åœ°æ–¹ï¼‰"
          echo "2. è¾“å…¥'data'ç„¶åæŒ‰Enter"
          echo "3. åŸºäºmainåˆ›å»ºdataåˆ†æ”¯"
          echo "æˆ–è€…è¿è¡Œï¼šgit checkout -b data && git push origin data"
          exit 1
        fi
        
        # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
        mkdir -p data assets
        touch .nojekyll
        
        # ä»ä¸´æ—¶ç›®å½•æ¢å¤æ•°æ®æ–‡ä»¶
        echo "æ¢å¤æ•°æ®æ–‡ä»¶..."
        cp -r /tmp/data_files/data/* data/ 2>/dev/null || true
        cp /tmp/data_files/assets/file-list.txt assets/ 2>/dev/null || true
        
        # æ˜¾ç¤ºè¦æ·»åŠ çš„æ–‡ä»¶
        echo "è¦æ·»åŠ çš„æ–‡ä»¶ï¼š"
        ls -la data/*.jsonl 2>/dev/null || echo "æ²¡æœ‰jsonlæ–‡ä»¶"
        ls -la assets/file-list.txt 2>/dev/null || echo "æ²¡æœ‰file-list.txt"
        
        # æ·»åŠ æ–‡ä»¶åˆ°git
        git add .nojekyll
        git add data/*.jsonl 2>/dev/null || true
        git add assets/file-list.txt 2>/dev/null || true
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´
        if git status --porcelain | grep -q .; then
          echo "æœ‰å˜æ›´éœ€è¦æäº¤"
          git commit -m "update: $today arXiv papers"
          echo "âœ… æäº¤æˆåŠŸ"
        else
          echo "âš ï¸ æ²¡æœ‰æ•°æ®å˜æ›´éœ€è¦æäº¤"
        fi

    - name: Push data changes to data branch
      if: steps.dedup_check.outputs.has_new_content == 'true'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        echo "=== æ¨é€æ•°æ®åˆ° data åˆ†æ”¯ ==="
        
        # æ˜¾ç¤ºå½“å‰çŠ¶æ€
        echo "å½“å‰åˆ†æ”¯: $(git branch --show-current)"
        
        # è®¾ç½®æ¨é€é…ç½®
        git config push.default current
        
        # å°è¯•æ¨é€ï¼ˆæœ€å¤š3æ¬¡ï¼‰
        for i in {1..3}; do
          echo "æ¨é€å°è¯• $i/3"
          if git push origin data; then
            echo "âœ… æ¨é€æˆåŠŸ"
            
            # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
            echo "=== æ•°æ®è®¿é—®URL ==="
            echo "æ–‡ä»¶åˆ—è¡¨: https://raw.githubusercontent.com/FangXieLab/daily-arXiv-ai-enhanced/data/assets/file-list.txt"
            echo "ä»Šæ—¥æ•°æ®: https://raw.githubusercontent.com/FangXieLab/daily-arXiv-ai-enhanced/data/data/${today}_AI_enhanced_*.jsonl"
            
            break
          else
            echo "æ¨é€å¤±è´¥ï¼Œæ‹‰å–æœ€æ–°å˜æ›´..."
            git pull origin data --rebase --no-edit || true
            if [ $i -eq 3 ]; then
              echo "âŒ 3æ¬¡å°è¯•åæ¨é€å¤±è´¥"
              echo "å¯èƒ½æ˜¯æƒé™é—®é¢˜ï¼Œæ£€æŸ¥GITHUB_TOKENæƒé™"
              echo "ä»“åº“Settings â†’ Actions â†’ General â†’ Workflow permissions"
              echo "è®¾ç½®ä¸º'Read and write permissions'"
              exit 1
            fi
          fi
        done
        
        echo "=== dataåˆ†æ”¯æ“ä½œå®Œæˆ ==="
